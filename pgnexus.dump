--
-- PostgreSQL database dump
--

\restrict 7SkCvt6571C87csrsH9l4YiqotyEp3q2fzP3Cgb159WbnSc3LQNJbb4oVHRAt2O

-- Dumped from database version 18.1 (Debian 18.1-1.pgdg13+2)
-- Dumped by pg_dump version 18.1 (Debian 18.1-1.pgdg13+2)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET transaction_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

--
-- Data for Name: poll_jobs; Type: TABLE DATA; Schema: public; Owner: n8n-user
--

COPY public.poll_jobs (jobid, date, status) FROM stdin;
1	2026-01-22 00:11:57.89+00	0
2	2026-01-22 00:20:12.954+00	0
3	2026-01-22 00:48:05.965+00	0
4	2026-01-22 18:12:05.556+00	1
5	2026-01-22 19:14:11.115+00	0
6	2026-01-22 19:32:25.832+00	1
7	2026-01-23 00:14:10.579+00	0
8	2026-01-23 18:37:42.769+00	0
9	2026-01-23 18:39:07.738+00	0
10	2026-01-23 18:40:12.889+00	0
11	2026-01-23 18:41:52.796+00	0
12	2026-01-23 23:23:16.587+00	1
13	2026-01-24 19:15:58.534+00	0
14	2026-01-25 00:00:52.203+00	1
15	2026-01-26 00:00:52.213+00	1
16	2026-01-26 17:39:55.125+00	0
17	2026-01-26 18:26:23.896+00	0
18	2026-01-26 20:20:03.366+00	0
19	2026-01-26 20:26:47.999+00	0
20	2026-01-26 22:19:24.3+00	0
21	2026-01-27 00:00:42.172+00	1
22	2026-01-27 01:39:18.562+00	0
23	2026-01-27 05:24:13.024+00	0
24	2026-01-27 06:45:32.16+00	0
26	2026-01-27 19:14:11.431+00	0
27	2026-01-27 19:25:24.867+00	0
25	2026-01-27 17:52:14.93+00	1
28	2026-01-27 20:03:02.252+00	1
29	2026-01-27 20:08:19.649+00	1
30	2026-01-27 20:08:19.649+00	1
31	2026-01-28 00:00:58.232+00	1
32	2026-01-29 00:00:58.174+00	0
33	2026-01-29 00:38:33.139+00	1
\.


--
-- Data for Name: email_feeds; Type: TABLE DATA; Schema: public; Owner: n8n-user
--

COPY public.email_feeds (jobid, threadid, subject, participants, messages, summary, lastactivity, summary_zh) FROM stdin;
4	19be2a70822b7e71	POC: Parallel processing of indexes in autovacuum	["3danissimo@gmail.com","aekorotkov@gmail.com","matheusssilv97@gmail.com","orlovmg@gmail.com","samimseih@gmail.com","sawada.mshk@gmail.com"]	[{"id":"19be2a70822b7e71","messageId":"<CAA5RZ0vbM_E+C0T475q2j5U1qnUgPBCPQ-3qWYdTxDCRnvE1VQ@mail.gmail.com>","subject":"Re: POC: Parallel processing of indexes in autovacuum","body":"Hi,\\n\\nI took a look at v20-0001,0002 and 0003 and have some comments.\\n\\nv20-0001:\\n\\n1/\\n\\n```\\n+\\n+       /*\\n+        * Cap or increase number of free parallel workers according to the\\n+        * parameter change.\\n+        */\\n+       AutoVacuumShmem->av_freeParallelWorkers = Max(nfree_workers, 0);\\n+\\n+       /*\\n+        * Don't allow number of free workers to become less than zero if the\\n+        * patameter was decreased.\\n+        */\\n+       AutoVacuumShmem->av_freeParallelWorkers =\\n+               Max(AutoVacuumShmem->av_freeParallelWorkers, 0);\\n```\\n\\nThis can probably be simplified to:\\n\\n```\\nAutoVacuumShmem->av_freeParallelWorkers = Max(nfree_workers, 0);\\n```\\n\\nv20-0002:\\n\\n1/\\n\\nI don't think showing \\"reserved\\" in the logging is needed and could be\\nconfusing.\\n\\n```\\nparallel index vacuum/cleanup: 3 workers were planned, 3 workers were\\nreserved and 3 workers were launched in total\\n```\\n\\nAlso, even though the table has `autovacuum_parallel_workers = 2`, I\\nsee 3 workers.\\nThis is because one worker was for cleanup due to a gin index on the\\ntable. I think it's better\\nto show separate lines for index vacuuming and index cleanup, just\\nlike VACUUM VERBOSE.\\n\\n```\\nINFO:  launched 2 parallel vacuum workers for index vacuuming (planned: 2)\\nINFO:  launched 1 parallel vacuum worker for index cleanup (planned: 1)\\n```\\n\\notherwise it will lead the user to think 3 workers were allocated for\\neither vacuuming or cleanup.\\n\\n\\nv20-0003:\\n\\n1/\\n\\ninside vacuum_delay_point, I would re-organize the checks to\\nfirst run the code block for the a/v worker:\\n\\n```\\nif (ConfigReloadPending && AmAutoVacuumWorkerProcess())\\n```\\n\\nthen the a/v/ parallel worker:\\n\\n```\\nif (!AmAutoVacuumWorkerProcess() && IsParallelWorker())\\n```\\n\\nBut I am also wondering if we should have a specific backend_type\\nfor \\"autovacuum parallel worker\\" to differentiate that from the\\nexisting \\"autovacuum worker\\".\\n\\nand also we can have a helper macro like:\\n```\\n#define AmAutoVacuumParallelWorkerProcess() (MyBackendType ==\\nB_AUTOVAC_PARALLEL_WORKER)\\n```\\n\\nWhat do you think?\\n\\n2/\\n\\nAdd\\n```\\n+typedef struct PVSharedCostParams\\n````\\n\\nto src/tools/pgindent/typedefs.list\\n\\n3/\\n\\n+               pg_atomic_init_u32(&shared->cost_params.generation, 0);\\n+               SpinLockInit(&shared->cost_params.spinlock);\\n+               pv_shared_cost_params = &(shared->cost_params);\\n\\nNIT: move SpinLockInit last\\n\\n4/\\n\\nInstead of:\\n\\n```\\n+       params_generation =\\npg_atomic_read_u32(&pv_shared_cost_params->generation);\\n+\\n```\\nand then later on:\\n````\\n+       /*\\n+        * Increase generation of the parameters, i.e. let parallel workers know\\n+        * that they should re-read shared cost params.\\n+        */\\n+       pg_atomic_write_u32(&pv_shared_cost_params->generation,\\n+                                               params_generation + 1);\\n+\\n+       SpinLockRelease(&pv_shared_cost_params->spinlock);\\n```\\n\\nwhy can't we just do:\\n\\npg_atomic_fetch_add_u32(&pv_shared_cost_params->generation, 1);\\n\\nAlso, do the pg_atomic_fetch_add_u32 outside of the spinlock. right?\\n\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be2a70822b7e71","snippet":"Hi, I took a look at v20-0001,0002 and 0003 and have some comments. v20-0001: 1/ ``` + + /* + * Cap or increase number of free parallel workers according to the + * parameter change. + */ +","historyId":"72077","internalDate":"1769034131000","receivedAtUtc":"2026-01-21T22:22:11.000Z","from":"Sami Imseih <samimseih@gmail.com>"},{"id":"19be2ad1a2758689","messageId":"<CAD21AoD7_4gsQ2a82zO3SaRwjdw_3tyiYDHNFPUKQ5DAA5HOtA@mail.gmail.com>","subject":"Re: POC: Parallel processing of indexes in autovacuum","body":"On Sat, Jan 17, 2026 at 6:52 AM Daniil Davydov <3danissimo@gmail.com> wrote:\\n>\\n>\\n>\\n> > I've attached the patch proposing this change (please find\\n> > v19-0001_masahiko.patch).\\n>\\n> Thank you, I'll apply this patch. A few things in the patch that I changed :\\n> 1)\\n> + * The caller must call AutoVacuumReleaseParallelWorkers() to release the...\\n> I think that we also should mention AutoVacuumReleaseAllParallelWorkers.\\n> 2)\\n> + * Similar to AutoVacuumReleaseParallelWorkers(), but this function releases...\\n> If you don't mind, I'll leave the \\"same as above\\" formulation since this is\\n> typical for the postgres code.\\n>\\n\\nAgreed.\\n\\n>\\n> > BTW it seems to me that this GUC should be capped by\\n> > max_parallel_workers instead of max_worker_processes, no?\\n> >\\n>\\n> I explained my point about it here [1] and here [2]. What do you think?\\n\\nI agree that autovacuum_max_parallel_workers should not be capped by\\nother GUC parametres when setting a value. However, these messages\\nseem not explain why this parameter is limited by max_worker_processes\\ninstead of max_parallel_workers. You mentioned:\\n\\n> I will keep the 'max_worker_processes' limit, so autovacuum will not\\n> waste time initializing a parallel context if there is no chance that\\n> the request will succeed.\\n> But it's worth remembering that actually the\\n> 'autovacuum_max_parallel_workers' parameter will always be implicitly\\n> capped by 'max_parallel_workers'.\\n\\nIt doesn't make sense to me that we limit\\nautovacuum_max_parallel_workers by max_worker_processes TBH. When\\nusers want to have more parallel vacuum workers for autovacuum and the\\nVACUUM command, they would have to consider max_worker_processes,\\nmax_parallel_workers, and max_parallel_maintenance_workers separately.\\nGiven that max_parallel_workers is controlling the number of\\nmax_worker_processes that can be used in parallel operations, I\\nbelieve that parallel vacuum workers for autovacuum should also be\\ntaken from that pool.\\n\\n>\\n> > ---\\n> > +        * Note, that this function has no effect if we are non-autovacuum\\n> > +        * parallel worker.\\n> > +        */\\n> >\\n> > I don't think this kind of comment should be noted here since if we\\n> > change the parallel_vacuum_update_shared_delay_params() behavior in\\n> > the future, such comments would get easily out-of-sync.\\n> >\\n>\\n> If behavior will be changed, then all comments for this function will need to\\n> be changed, actually. Don't get me wrong - I just think that this Note is\\n> important for the readers. But if you doubt its usefulness, I don't\\n> mind deleting it.\\n\\nI still could not figure out why it should be mentioned here instead\\nof at the comment of parallel_vacuum_update_shared_delay_params().\\nReaders can notice that calling\\nparallel_vacuum_update_shared_delay_params() for parallel vacuum\\nworker for the VACUUM command has no effect when reading the function.\\nIn my opinion, we should mention here why we call\\nparallel_vacuum_update_shared_delay_params() but should not mention\\nwhat the called function does because it should have been described in\\nthat function.\\n\\nBTW can we expose pv_shared_cost_params so that we can check it in\\nvacuum_delay_point() before trying to call\\nparallel_vacuum_update_shared_delay_params()?\\n\\n>\\n> > > > IIUC autovacuum parallel workers seems to update their\\n> > > > vacuum_cost_{delay|limit} every vacuum_delay_point(), which seems not\\n> > > > good. Can we somehow avoid unnecessary updates?\\n> > >\\n> > > More precisely, parallel worker *reads* leader's parameters every delay_point.\\n> > > Obviously, this does not mean that the parameters will necessarily be updated.\\n> > >\\n> > > But I don't see anything wrong with this logic. We just every time get the most\\n> > > relevant parameters from the leader. Of course we can introduce some\\n> > > signaling mechanism, but it will have the same effect as in the current code.\\n> >\\n> > Although the parameter propagation itself is working correctly, the\\n> > current implementation seems suboptimal performance-wise. Acquiring an\\n> > additional spinlock and updating the local variables for every block\\n> > seems too costly to me. IIUC we would end up incurring these costs\\n> > even when vacuum delays are disabled. I think we need to find a better\\n> > way.\\n> >\\n> > For example, we can have a generation of these parameters. That is,\\n> > the leader increments the generation (stored in PVSharedCostParams)\\n> > whenever updating them after reloading the configuration file, and\\n> > workers maintain its generation of the parameters currently used. If\\n> > the worker's generation < the global generation, it updates its\\n> > parameters along with its generation. I think we can implement the\\n> > generation using pg_atomic_u32, making the check for parameter updates\\n> > lock-free. There might be better ideas, though.\\n> >\\n>\\n> OK, I see your point. Considering that we need to check some shared state (in\\n> order to understand whether we should update our params), an atomic variable\\n> seem to be the best solution.\\n>\\n>\\n> Thank you for the review! Please, see v20 patches. Main changes :\\n> 1) Add new formula for freeParallelWorkers computation\\n> 2) Add 'nreserved' logging for parallel autovacuum\\n> 3) Add atomic variable to speed up checking shared params state change\\n> 4) New test for autovacuum_max_parallel_workers parameter change\\n> 5) Fully get rid of \\"custom\\" injection points in tests\\n>\\n\\nThe 0001 patch looks mostly good to me except for the above comment\\n(max_worker_processes vs. max_parallel_workers) and the following\\npoint:\\n\\n+   nfree_workers =\\n+       autovacuum_max_parallel_workers - prev_max_parallel_workers +\\n+       AutoVacuumShmem->av_freeParallelWorkers;\\n+\\n+   /*\\n+    * Cap or increase number of free parallel workers according to the\\n+    * parameter change.\\n+    */\\n+   AutoVacuumShmem->av_freeParallelWorkers = Max(nfree_workers, 0);\\n+\\n+   /*\\n+    * Don't allow number of free workers to become less than zero if the\\n+    * patameter was decreased.\\n+    */\\n+   AutoVacuumShmem->av_freeParallelWorkers =\\n+       Max(AutoVacuumShmem->av_freeParallelWorkers, 0);\\n\\nWhy does it do Max(x, 0) twice?\\n\\n* 0002 patch:\\n\\n+           if (vacrel->workers_usage.nplanned > 0 &&\\n+               AmAutoVacuumWorkerProcess())\\n+           {\\n+               /* Worker usage stats for parallel autovacuum */\\n+               appendStringInfo(&buf,\\n+                                _(\\"parallel index vacuum/cleanup: %d\\nworkers were planned, %d workers were reserved and %d workers were\\nlaunched in total\\\\n\\"),\\n+                                vacrel->workers_usage.nplanned,\\n+                                vacrel->workers_usage.nreserved,\\n+                                vacrel->workers_usage.nlaunched);\\n+           }\\n+           else if (vacrel->workers_usage.nplanned > 0)\\n+           {\\n+               /* Worker usage stats for manual VACUUM (PARALLEL) */\\n+               appendStringInfo(&buf,\\n+                                _(\\"parallel index vacuum/cleanup: %d\\nworkers were planned and %d workers were launched in total\\\\n\\"),\\n+                                vacrel->workers_usage.nplanned,\\n+                                vacrel->workers_usage.nlaunched);\\n+           }\\n\\nCan we refactoring these codes to:\\n\\nif (vacrel->workers_usage.nplanned > 0)\\n{\\n    if (AmAutoVacuumWorkerProcess())\\n        appendStringInfo(...);\\n    else\\n        appendStringInfo(...);\\n\\n* 0003 patch:\\n\\n+   if (!AmAutoVacuumWorkerProcess() && IsParallelWorker())\\n+   {\\n\\nWe can just check IsParallelWorker() here.\\n\\n---\\n+extern void parallel_vacuum_update_shared_delay_params(void);\\n+extern void parallel_vacuum_propagate_cost_based_params(void);\\n\\nI think it's better to have similar names to these functions for\\nconsistency and readability. How about the following?\\n\\nparallel_vacuum_update_delay_params();\\nparallel_vacuum_propagate_delay_params();\\n\\n---\\n+\\n+   params_generation = pg_atomic_read_u32(&pv_shared_cost_params->generation);\\n+\\n+   SpinLockAcquire(&pv_shared_cost_params->spinlock);\\n+\\n+   pv_shared_cost_params->cost_delay = vacuum_cost_delay;\\n+   pv_shared_cost_params->cost_limit = vacuum_cost_limit;\\n+   pv_shared_cost_params->cost_page_dirty = VacuumCostPageDirty;\\n+   pv_shared_cost_params->cost_page_hit = VacuumCostPageHit;\\n+   pv_shared_cost_params->cost_page_miss = VacuumCostPageMiss;\\n\\nI think we can check if the new cost-based delay parameters are really\\nchanged before changing the shared values. If users don't change\\ncost-based delay parameters, we don't need to increment the generation\\nat all.\\n\\n---\\n+   pg_atomic_write_u32(&pv_shared_cost_params->generation,\\n+                       params_generation + 1);\\n\\nWe can use pg_atomic_add_fetch_u32() instead.\\n\\n---\\n+/*\\n+ * Only autovacuum leader can reload config file. We use this structure in\\n+ * parallel autovacuum for keeping worker's parameters in sync with leader's\\n+ * parameters.\\n+ */\\n+typedef struct PVSharedCostParams\\n\\nI'd suggest writing the overall description first (e.g., what the\\nstruct holds and what the function does etc), and then describing the\\ndetails and notes etc. For instance, readers might be confused when\\nreading the first sentence \\"Only autovacuum leader can reload config\\nfile\\" as the struct definition is not related to the autovacuum\\nimplementation fact that autovacuum workers can reload the config file\\nduring the work. We would need to mention such detail somewhere in the\\ncomments but I think it should not be the first sentence. How about\\nrewriting it to something like:\\n\\n+/*\\n+ * Struct for cost-based vacuum delay related parameters to share among an\\n+ * autovacuum worker and its parallel vacuum workers.\\n+ */\\n\\n---\\n+   slock_t     spinlock;       /* protects all fields below */\\n\\nIt's convention to name 'mutex' as a field name.\\n\\n---\\n+static PVSharedCostParams * pv_shared_cost_params = NULL;\\n+\\n+/* See comments for structure above for the explanation. */\\n+static uint32 shared_params_generation_local = 0;\\n\\nI think it's preferable to move these definitions of static variables\\nright before the function prototypes.\\n\\n---\\n+   /*\\n+    * If 'true' then we are running parallel autovacuum. Otherwise, we are\\n+    * running parallel maintenence VACUUM.\\n+    */\\n+   bool        am_parallel_autovacuum;\\n\\nHow about renaming it to use_shared_delay_params? I think it conveys\\nbetter what the field is used for.\\n\\n* 0004 patch:\\n\\nThe patch introduces 5 injection points, which seems overkill to me\\nfor implementing the tests. IIUC we can implement the test2 with two\\ninjection points: 'autovacuum-start-parallel-vacuum' (set right before\\nlazy_scan_heap() call) and\\n'autovacuum-leader-before-indexes-processing'.\\n\\n1. stop the autovacuum worker at 'autovacuum-start-parallel-vacuum'.\\n2. change delay params and reload the conf.\\n3. let the autovacuum worker process tables (vacuum_delay_point() is\\ncalled during the heap scan).\\n4. stop the autovacuum worker at 'autovacuum-leader-before-indexes-processing'.\\n5. let parallel workers process indexes (vacuum_delay_point() is\\ncalled during index vacuuming).\\n\\nFor test3, I think we can write a DEBUG2 log in\\nadjust_free_parallel_workers() and check it during the test instead of\\nintroducing the test-only function.\\n\\nFor test4 and test5, we check the number of free workers using\\nget_parallel_autovacuum_free_workers(). However, since autovacuum\\ncould retry to vacuum the table again, the test could fail.\\n\\nAnd here are some general comments and suggestions:\\n\\n+use warnings FATAL => 'all';\\n+use PostgreSQL::Test::Cluster;\\n+use PostgreSQL::Test::Utils;\\n+use Test::More;\\n\\nWe need comments to explain what we test with this test file.\\n\\n---\\n+   $node->safe_psql('postgres', qq{\\n+       UPDATE test_autovac SET col_1 = $test_number;\\n+       ANALYZE test_autovac;\\n+   });\\n\\nWhy do we need to execute ANALYZE as well?\\n\\n---\\n+   $node->wait_for_log($expected_log);\\n+   truncate $node->logfile, 0 or die \\"truncate failed: $!\\";\\n+}\\n\\nTruncating all logs every after test would decrease the debuggability\\nmuch. We can pass the offset as the start point to wait for the\\ncontents.\\n\\n---\\n+# Insert specified tuples num into the table\\n+$node->safe_psql('postgres', qq{\\n+   DO \\\\$\\\\$\\n+   DECLARE\\n+       i INTEGER;\\n+   BEGIN\\n+       FOR i IN 1..$initial_rows_num LOOP\\n+           INSERT INTO test_autovac VALUES (i, i + 1, i + 2, i + 3);\\n+       END LOOP;\\n+   END \\\\$\\\\$;\\n+});\\n\\nWe can use generate_series() here. And it's faster to load the data\\nand then create indexes.\\n\\n---\\n+$node->psql('postgres',\\n+   \\"SELECT get_parallel_autovacuum_free_workers();\\",\\n+   stdout => \\\\$psql_out,\\n+);\\n\\nPlease use pgsql_safe() instead.\\n\\nRegards,\\n\\n-- \\nMasahiko Sawada\\nAmazon Web Services: https://aws.amazon.com\\n\\n\\n","threadId":"19be2a70822b7e71","snippet":"On Sat, Jan 17, 2026 at 6:52 AM Daniil Davydov <3danissimo@gmail.com> wrote: > > > > > I've attached the patch proposing this change (please find > > v19-0001_masahiko.","historyId":"72167","internalDate":"1769034504000","receivedAtUtc":"2026-01-21T22:28:24.000Z","from":"Masahiko Sawada <sawada.mshk@gmail.com>"}]	The discussion focuses on reviewing patches v20-0001 through v20-0003 for parallel index processing in autovacuum. Key feedback includes simplifying redundant Max() operations in worker allocation code, improving logging to separate index vacuuming and cleanup worker counts rather than showing confusing totals, and introducing a specific backend type for autovacuum parallel workers. Performance concerns are raised about acquiring spinlocks at every vacuum_delay_point(), with suggestions to use atomic generation counters for lock-free parameter checking. There's ongoing debate about whether autovacuum_max_parallel_workers should be capped by max_worker_processes versus max_parallel_workers. Additional suggestions include refactoring function names for consistency, optimizing parameter change detection before updating shared values, and simplifying test implementations by reducing injection points from five to two while using DEBUG2 logs instead of test-only functions.	2026-01-21 22:28:24+00	\N
6	19be2095ebf4792a	Remaining dependency on setlocale()	["a.kozhemyakin@postgrespro.ru","li.evan.chao@gmail.com","peter@eisentraut.org","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19be2095ebf4792a","messageId":"<eb7e194b3ae2386988dae4b5a7cee128c3f0a628.camel@j-davis.com>","subject":"Re: Remaining dependency on setlocale()","body":"On Tue, 2026-01-20 at 12:27 +0700, Александр Кожемякин wrote:\\n> When executing the following query on branch REL_18_STABLE (first bad\\n> commit 806555e)\\n\\nThank you for the report!\\n\\nThe issue is that the commit in master was dependent on a refactoring\\npatch, which allowed pg_strfold() to work on any pg_locale_t object,\\neven if ctype_is_c. Version 18 doesn't have that commit, so it crashed.\\n\\nIt seems to be fine in master, and it was only backported to 18, so the\\nattached patch is only intended for REL_18_STABLE.\\n\\nRegards,\\n\\tJeff Davis\\n\\n","threadId":"19be2095ebf4792a","snippet":"On Tue, 2026-01-20 at 12:27 +0700, Александр Кожемякин wrote: > When executing the following query on branch REL_18_STABLE (first bad > commit 806555e) Thank you for the report! The issue is that","historyId":"1753","internalDate":"1769023814000","receivedAtUtc":"2026-01-21T19:30:14.000Z","from":"Jeff Davis <pgsql@j-davis.com>"}]	Jeff Davis responded to Александр Кожемякин's bug report about a crash in REL_18_STABLE branch (commit 806555e) when executing a specific query. Davis identified that the issue stems from a dependency problem where the master branch commit relied on a refactoring patch that allows pg_strfold() to work on any pg_locale_t object, even when ctype_is_c is true. However, version 18 lacks this refactoring commit, causing the crash. Davis confirmed the functionality works correctly in master and noted that the problematic commit was only backported to version 18. He provided an attached patch specifically targeting REL_18_STABLE to resolve this dependency issue.	2026-01-21 19:30:14+00	\N
6	19be4ccedbe55f01	Fix accidentally cast away qualifiers	["bertranddrouvot.pg@gmail.com","peter@eisentraut.org"]	[{"id":"19be4ccedbe55f01","messageId":"<5C33CCDF-7A95-4757-B35A-CA62C2D77F31@gmail.com>","subject":"Re: Fix accidentally cast away qualifiers","body":"\\n\\n> On Jan 21, 2026, at 22:56, Bertrand Drouvot <bertranddrouvot.pg@gmail.com> wrote:\\n> \\n> Hi,\\n> \\n> On Wed, Jan 21, 2026 at 02:24:58PM +0000, Bertrand Drouvot wrote:\\n>> Hi,\\n>> \\n>> On Wed, Jan 21, 2026 at 12:31:27PM +0100, Peter Eisentraut wrote:\\n>>> Strange, I don't see that.  What compiler is this, and do you use any\\n>>> special options?\\n>> \\n>> It's gcc 14.1.0 with \\"CFLAGS=-O0 -ggdb3 -fno-omit-frame-pointer -gdwarf-2 -g3\\n>> -Wdiscarded-qualifiers -Wunused-value -Werror=maybe-uninitialized\\n>> -Werror=format -Wreturn-type\\"\\n>> \\n>> But I just tested with a simple test case, some compilers and some options and I've\\n>> always seen the warning (see [1])\\n> \\n> FWIW, and so does the CI: https://github.com/bdrouvot/postgres/runs/61028037498\\n> \\n> Regards,\\n> \\n> -- \\n> Bertrand Drouvot\\n> PostgreSQL Contributors Team\\n> RDS Open Source Databases\\n> Amazon Web Services: https://aws.amazon.com\\n> \\n\\nYeah, I confirm I can see the same warnings:\\n```\\nIn file included from xlogdesc.c:21:\\nIn file included from ../../../src/include/utils/guc.h:17:\\nIn file included from ../../../src/include/utils/array.h:65:\\nIn file included from ../../../src/include/utils/expandeddatum.h:47:\\n../../../src/include/varatt.h:307:9: warning: returning 'const char[]' from a function with result type 'char *' discards qualifiers [-Wincompatible-pointer-types-discards-qualifiers]\\n  307 |         return VARDATA_4B(PTR);\\n      |                ^~~~~~~~~~~~~~~\\n../../../src/include/varatt.h:261:26: note: expanded from macro 'VARDATA_4B'\\n  261 | #define VARDATA_4B(PTR)         (((const varattrib_4b *) (PTR))->va_4byte.va_data)\\n      |                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n../../../src/include/varatt.h:321:9: warning: returning 'const char[]' from a function with result type 'char *' discards qualifiers [-Wincompatible-pointer-types-discards-qualifiers]\\n  321 |         return VARDATA_1B(PTR);\\n      |                ^~~~~~~~~~~~~~~\\n../../../src/include/varatt.h:263:26: note: expanded from macro 'VARDATA_1B'\\n  263 | #define VARDATA_1B(PTR)         (((const varattrib_1b *) (PTR))->va_data)\\n      |                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n../../../src/include/varatt.h:342:9: warning: returning 'const char[]' from a function with result type 'char *' discards qualifiers [-Wincompatible-pointer-types-discards-qualifiers]\\n  342 |         return VARDATA_1B_E(PTR);\\n      |                ^~~~~~~~~~~~~~~~~\\n../../../src/include/varatt.h:264:27: note: expanded from macro 'VARDATA_1B_E'\\n  264 | #define VARDATA_1B_E(PTR)       (((const varattrib_1b_e *) (PTR))->va_data)\\n      |                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n../../../src/include/varatt.h:488:9: warning: returning 'const char *' from a function with result type 'char *' discards qualifiers [-Wincompatible-pointer-types-discards-qualifiers]\\n  488 |         return VARATT_IS_1B(PTR) ? VARDATA_1B(PTR) : VARDATA_4B(PTR);\\n      |                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n../../../src/include/varatt.h:235:2: note: expanded from macro 'VARATT_IS_1B'\\n  235 |         ((((const varattrib_1b *) (PTR))->va_header & 0x01) == 0x01)\\n      |         ^\\n4 warnings generated.\\n```\\n\\nI didn't use any special compiler option, just ran "make".\\n\\nMy configure is:\\n```\\n./configure --enable-debug --enable-cassert --enable-tap-tests --enable-depend\\n```\\n\\nSorry, I didn't notice the warnings in my first review. I guess I left my desktop while building at the time.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be4ccedbe55f01","snippet":"> On Jan 21, 2026, at 22:56, Bertrand Drouvot <bertranddrouvot.pg@gmail.com> wrote: > > Hi, > > On Wed, Jan 21, 2026 at 02:24:58PM +0000, Bertrand Drouvot wrote: >> Hi, >","historyId":"5936","internalDate":"1769070144000","receivedAtUtc":"2026-01-22T08:22:24.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	The discussion centers on compiler warnings related to "accidentally cast away qualifiers" in PostgreSQL code. Bertrand Drouvot reported warnings with gcc 14.1.0 using specific CFLAGS including -Wdiscarded-qualifiers, and provided CI evidence showing the issue. Chao Li confirmed the same warnings, showing specific examples in varatt.h where functions return 'const char[]' from functions with 'char *' result type, discarding qualifiers. The warnings appear in VARDATA_4B, VARDATA_1B, VARDATA_1B_E macros and related code. Multiple developers can reproduce the issue with different compiler setups, confirming it's a legitimate problem that needs fixing. The warnings indicate potential const-correctness issues in the codebase that should be addressed.	2026-01-22 08:22:24+00	\N
6	19be4d0984890d28	proposal: parentid and naturalid for plpgsql nodes	["tgl@sss.pgh.pa.us"]	[{"id":"19be4d0984890d28","messageId":"<CAFj8pRDwT=5UV9cKzCGxpo9ksYghcTm_h+8t_cWebaJDrN0vww@mail.gmail.com>","subject":"proposal: parentid and naturalid for plpgsql nodes","body":"Hi\\n\\nI propose two enhancing of PLpgSQL_stmt structure\\n\\n1. parentid\\n\\nThis is the id (stmtid) of the near outer statement. Why do I need it?\\nInside the plpgsql_check profiler I need to handle exceptions. Exceptions\\nare not supported by the plpgsql debug API, so I need to hold a stack of\\nexecuted statements. When any statements start, I need to check this stack\\nand sometimes (after a handled exception) I need to reduce this stack until\\nI find a statement that has the same parenid as the parentid of the current\\nstatement.\\n\\nCurrently I hold an array with parentid outside, but it is not practical\\nand increases the complexity of plpgsql_check.\\n\\n2. naturalid\\n\\nstmtid is assigned by the plpgsql parser. It is unique, but has a little\\nbit of a messy order, and when something like a statement id is displayed\\nin some reports, then it is confusing for users. I propose extra id (that\\nis unique too), but with order based on searching statements tree\\n\\nexample\\n\\nBEGIN --> stmtid = 3\\n  PERFORM --> stmtid = 1\\n  PERFORM --> stmtid = 2\\n\\nBEGIN --> naturalid = 1\\n  PERFORM --> naturalid = 2\\n  PERFORM --> naturalid = 3\\n\\nMaybe the ordering of stmtid can be changed, and then naturalid can be\\nuseless.\\n\\nProposed change can reduce complexity of plpgsql_check, but I believe it\\ncan help with other exceptions that use pl debug api.\\n\\nComments, notes?\\n\\nRegards\\n\\nPavel\\n","threadId":"19be4d0984890d28","snippet":"Hi I propose two enhancing of PLpgSQL_stmt structure 1. parentid This is the id (stmtid) of the near outer statement. Why do I need it? Inside the plpgsql_check profiler I need to handle exceptions.","historyId":"5937","internalDate":"1769070388000","receivedAtUtc":"2026-01-22T08:26:28.000Z","from":"Pavel Stehule <pavel.stehule@gmail.com>"}]	Pavel Stehule proposes two enhancements to the PLpgSQL_stmt structure to improve plpgsql_check functionality. First, adding a "parentid" field to store the statement ID of the nearest outer statement, which would help handle exceptions by maintaining a proper statement execution stack without external arrays. Currently, exception handling requires complex workarounds since exceptions aren't supported by the plpgsql debug API. Second, introducing a "naturalid" field that provides sequential numbering based on tree traversal order, making statement IDs more intuitive for users compared to the current parser-assigned stmtid which follows a somewhat irregular sequence. The proposed changes aim to reduce plpgsql_check complexity and potentially benefit other tools using the PL debug API.	2026-01-22 08:26:28+00	\N
6	19be4e79751331f7	Use correct collation in pg_trgm	["geidav.pg@gmail.com","hlinnaka@iki.fi"]	[{"id":"19be4e79751331f7","messageId":"<CALdSSPi1o=mYL-wWKfb-AZC+ozUKd-pRkHYqzi_yK9+vtT+V0Q@mail.gmail.com>","subject":"Re: Use correct collation in pg_trgm","body":"On Wed, 21 Jan 2026 at 20:36, David Geier <geidav.pg@gmail.com> wrote:\\n>\\n> Hi hackers,\\n>\\n> In thread [1] we found that pg_trgm always uses DEFAULT_COLLATION_OID\\n> for converting trigrams to lower-case. Here are some examples where\\n> today the collation is ignored:\\n>\\n> CREATE EXSTENSION pg_trgm;\\n> CREATE COLLATION turkish (provider = libc, locale = 'tr_TR.utf8');\\n>\\n> postgres=# SELECT show_trgm('ISTANBUL' COLLATE \\"turkish\\");\\n>                   show_trgm\\n> ---------------------------------------------\\n>  {\\"  i\\",\\" is\\",anb,bul,ist,nbu,sta,tan,\\"ul \\"}\\n>\\n> CREATE TABLE test(col TEXT COLLATE \\"turkish\\");\\n> INSERT INTO test VALUES ('ISTANBUL');\\n>\\n> postgres=# select show_trgm(col) FROM test;\\n>                   show_trgm\\n> ---------------------------------------------\\n>  {\\"  i\\",\\" is\\",anb,bul,ist,nbu,sta,tan,\\"ul \\"}\\n>\\n> postgres=# SELECT similarity('ıstanbul' COLLATE \\"turkish\\", 'ISTANBUL'\\n> COLLATE \\"turkish\\");\\n>  similarity\\n> ------------\\n>         0.5\\n>\\n> If the database is initialized via initdb --locale=\\"tr_TR.utf8\\", the\\n> output changes:\\n>\\n> postgres=# SELECT show_trgm('ISTANBUL');\\n>                        show_trgm\\n> --------------------------------------------------------\\n>  {0xf31e1a,0xfe581d,0x3efd30,anb,bul,nbu,sta,tan,\\"ul \\"}\\n>\\n> and\\n>\\n> postgres=# select show_trgm(col) FROM test;\\n>                        show_trgm\\n> --------------------------------------------------------\\n>  {0xf31e1a,0xfe581d,0x3efd30,anb,bul,nbu,sta,tan,\\"ul \\"}\\n>\\n> postgres=# SELECT similarity('ıstanbul' COLLATE \\"turkish\\", 'ISTANBUL'\\n> COLLATE \\"turkish\\");\\n>  similarity\\n> ------------\\n>           1\\n>\\n> tr_TR.utf8 converts capital I to ı which is a multibyte character, while\\n> my default collation converts I to i.\\n>\\n> The attached patch attempts to fix that. I grepped for all occurrences\\n> of DEFAULT_COLLATION_OID in contrib/pg_trgm and use the function's\\n> collation OID instead DEFAULT_COLLATION_OID.\\n>\\n> The corresponding regression tests pass.\\n>\\n> [1]\\n> https://www.postgresql.org/message-id/e5dd01c6-c469-405d-aea2-feca0b2dc34d%40gmail.com\\n>\\n> --\\n> David Geier\\n\\nHi!\\nLGTM\\n\\n-- \\nBest regards,\\nKirill Reshke\\n\\n\\n","threadId":"19be4e79751331f7","snippet":"On Wed, 21 Jan 2026 at 20:36, David Geier <geidav.pg@gmail.com> wrote: > > Hi hackers, > > In thread [1] we found that pg_trgm always uses DEFAULT_COLLATION_OID > for converting","historyId":"5940","internalDate":"1769071919000","receivedAtUtc":"2026-01-22T08:51:59.000Z","from":"Kirill Reshke <reshkekirill@gmail.com>"}]	David Geier identified an issue where pg_trgm extension ignores explicit collation settings and always uses DEFAULT_COLLATION_OID for trigram conversion to lowercase. This causes incorrect behavior with locale-specific collations like Turkish, where capital 'I' should convert to 'ı' instead of 'i'. The examples demonstrate that similarity calculations between 'ıstanbul' and 'ISTANBUL' return 0.5 with default collation but correctly return 1.0 when the database is initialized with Turkish locale. Geier's proposed patch modifies pg_trgm to use the function's actual collation OID instead of DEFAULT_COLLATION_OID throughout the code. Kirill Reshke reviewed the patch and provided approval with "LGTM" (looks good to me). The regression tests pass successfully with the proposed changes.	2026-01-22 08:51:59+00	\N
6	19be4f0789a66a7c	tablecmds: reject CLUSTER ON for partitioned tables earlier	[]	[{"id":"19be4f0789a66a7c","messageId":"<CAEoWx2k5800OjHO5KhTDv4JFYpDmyfh3MTtuB=7PP-0hLmG8yQ@mail.gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"On Jan 21, 2026, at 11:55, Chao Li <li.evan.chao@gmail.com> wrote:\\n\\nHi Hacker,\\n\\nI noticed this while working other patches related to "ALTER TABLE".\\n\\n"ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for\\npartitioned tables, but currently ATPrepCmd() allows them through and they\\nonly fail later at execution time.\\n\\nThis patch rejects these commands earlier by using the existing\\nATSimplePermissions() infrastructure in ATPrepCmd(), matching the handling\\nof other unsupported ALTER TABLE actions on partitioned tables (such as SET\\nLOGGED / SET UNLOGGED). This makes the behavior more consistent and\\nsimplifies the code path.\\n\\nAs a result, the error reported for partitioned tables changes:\\n\\nBefore the patch:\\n```\\nevantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\nERROR:  cannot mark index clustered in partitioned table\\n```\\n\\nWith the patch:\\n```\\nevantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\nERROR:  ALTER action CLUSTER ON cannot be performed on relation \\"p_test\\"\\nDETAIL:  This operation is not supported for partitioned tables.\\n```\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n<v1-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch>\\n\\n\\n\\nApplying the same change to INHERIT/NO INHeRIT in v2-0002. Other than that,\\nfixing 2 more things for INHERIT/NO INHERIT:\\n\\n* The header comment of ATPrepAddInherit() was a copy-paste mistake, it\\ndescribed something totally unrelated.\\n* NO INHERIT didn't call ATPrepAddInherit() to check early, so it had to go\\ndeeper and run unnecessary checks.\\n\\nBasically, 0001 and 0002 do the same thing on two sub-commands. If\\naccepted, they can be squashed.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n","threadId":"19be4f0789a66a7c","snippet":"On Jan 21, 2026, at 11:55, Chao Li <li.evan.chao@gmail.com> wrote: Hi Hacker, I noticed this while working other patches related to "ALTER TABLE". "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT","historyId":"5941","internalDate":"1769072498000","receivedAtUtc":"2026-01-22T09:01:38.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	Chao Li proposes moving validation for unsupported ALTER TABLE commands on partitioned tables from execution time to preparation time. Currently, "ALTER TABLE ... CLUSTER ON" and "SET WITHOUT CLUSTER" commands are allowed through ATPrepCmd() but fail later during execution. The patch uses the existing ATSimplePermissions() infrastructure to reject these commands earlier, making behavior consistent with other unsupported operations like SET LOGGED/SET UNLOGGED. This changes the error message to a more standardized format indicating the operation is not supported for partitioned tables. A second patch applies the same approach to INHERIT/NO INHERIT commands, fixing a copy-paste error in ATPrepAddInherit() header comment and ensuring NO INHERIT also calls early validation checks to avoid unnecessary processing.	2026-01-22 09:01:38+00	\N
6	19be5000123f9d5e	Optional skipping of unchanged relations during ANALYZE?	["dgrowleyml@gmail.com","ilya.evdokimov@tantorlabs.com","myon@debian.org","rob@xzilla.net","robertmhaas@gmail.com"]	[{"id":"19be5000123f9d5e","messageId":"<CAE2r8H7BwgYX61eiz4XrkWThxNhKKbp9N3Vty9HCrT3JTaVmzA@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"Hi llia,\\n\\nOn Wed, Jan 21, 2026 at 4:19 PM Ilia Evdokimov <\\nilya.evdokimov@tantorlabs.com> wrote:\\n\\n> On 21.01.2026 12:56, VASUKI M wrote:\\n>\\n> On Wed, Jan 21, 2026 at 3:21 PM Christoph Berg <myon@debian.org> wrote:\\n>\\n>> SMART is also a terribly non-descriptive name. How about CHANGED_ONLY?\\n>>\\n>\\n>  Yeah i agree,as of now i am focusing on concept workflow will change name\\n> in next versions of patch.\\n>\\n> Regards,\\n> Vasuki M\\n> C-DAC,Chennai.\\n>\\n> So do I\\n>\\n>\\n> It seems to me that the condition for relations that have never had\\n> statistics collected might be incorrect. If I'm reading this correctly,\\n> shouldn't this be checking 'tabstat->mod_since_analyze > 0' instead of\\n> 'tabstat->mod_since_analyze == 0'? I tested it on simple query:\\n>\\n> CREATE TABLE t (i INT, j INT);\\n> INSERT INTO t SELECT i/10, i/100 FROM generate_series(1, 1000000) i;\\n> ANALYZE (SMART) t;\\n> SELECT COUNT(*) FROM pg_stats WHERE tablename = 't';\\n>  count\\n> -------\\n>      0\\n> (1 row)\\n>\\n\\nThis passes now :)\\n\\n\\nAs discussed in the recent thread, I am sharing a revised v2 patch that\\nintroduces an optional SMART mode for ANALYZE.\\n\\nWhen ANALYZE (SMART) is specified, relations are skipped if:\\n- they have been analyzed before (either manually or via autovacuum),\\n  and\\n- they have not been modified since their last analyze\\n  (n_mod_since_analyze = 0, based on pg_stat statistics).\\n\\nRelations that have never been analyzed before are always analyzed\\nnormally. The default ANALYZE behavior remains unchanged unless SMART\\nis explicitly requested.\\n\\nThe motivation is to reduce unnecessary ANALYZE work in databases with\\na large number of mostly-static tables, while keeping the behavior\\nstrictly opt-in.\\n\\nChanges and clarifications in v2:\\n- Tables that have never been analyzed are never skipped\\n  (checked via last_analyze_time / last_autoanalyze_time)\\n- Skip decisions rely only on pg_stat_user_tables counters\\n- The skip condition is n_mod_since_analyze == 0\\n- Regression tests are added to demonstrate:\\n   -->SMART ANALYZE does not skip never-analyzed tables\\n   -->Only modified tables are re-analyzed\\n\\nThis patch intentionally limits its scope to regular relations and\\nexisting pg_stat statistics only. Partitioned tables, inheritance,\\nforeign tables, extended statistics, and statistics target changes are\\nnot handled yet and can be considered in follow-up work based on\\nfeedback.\\n\\nThe patch applies cleanly on current master and passes:\\nmake distclean\\n ./configure\\nmake -j$(nproc)\\nmake install\\nmake check\\n\\nSee this:\\n\\nanalyze_test=# create table sa6 (id int);\\nCREATE TABLE\\nTime: 3.917 ms\\nanalyze_test=# analyze(smart) sa6;\\nDEBUG:  ANALYZE processing relation \\"sa6\\" (OID 131324)\\nANALYZE\\nTime: 0.585 ms\\nanalyze_test=# SELECT count(*) > 0 AS stats_created\\nFROM pg_stats\\nWHERE tablename = 'sa6';\\n stats_created\\n---------------\\n f\\n(1 row)\\n\\nTime: 0.894 ms\\nanalyze_test=# SELECT relname,\\n       last_analyze,\\n       n_mod_since_analyze\\nFROM pg_stat_user_tables\\nWHERE relname = 'sa6';\\n relname |           last_analyze           | n_mod_since_analyze\\n---------+----------------------------------+---------------------\\n sa6     | 2026-01-22 10:35:23.005045+05:30 |                   0\\n(1 row)\\n\\nThe empty table doesn't have any stats to show as pg_stat is column level\\nstatistics;\\n these are created when rows exists ,it has 0 rows to make samples,most\\ncommon used values,etc,..so no data distribution\\n\\nBut when value is inserted ,\\n\\nanalyze_test=# CREATE TABLE sa4 (i int);\\nCREATE TABLE\\nTime: 10.290 ms\\nanalyze_test=# INSERT INTO sa4 SELECT generate_series(1,10);\\nINSERT 0 10\\nTime: 45.373 ms\\nanalyze_test=# analyze(smart) sa4;\\nDEBUG:  ANALYZE processing relation \\"sa4\\" (OID 131310)\\nANALYZE\\nTime: 47.771 ms\\nanalyze_test=# SELECT count(*) > 0 AS stats_created\\nFROM pg_stats\\nWHERE tablename = 'sa4';\\n stats_created\\n---------------\\n t\\n(1 row)\\n\\nTime: 0.945 ms\\n\\n\\nI would appreciate feedback on the overall approach.\\n\\nThanks for your time and review.\\n\\n--\\nBest regards,\\nVasuki M\\nC-DAC,Chennai\\n","threadId":"19be5000123f9d5e","snippet":"Hi llia, On Wed, Jan 21, 2026 at 4:19 PM Ilia Evdokimov <ilya.evdokimov@tantorlabs.com> wrote: On 21.01.2026 12:56, VASUKI M wrote: On Wed, Jan 21, 2026 at 3:21 PM Christoph Berg <myon@debian.","historyId":"5942","internalDate":"1769073540000","receivedAtUtc":"2026-01-22T09:19:00.000Z","from":"VASUKI M <vasukianand0119@gmail.com>"}]	VASUKI M presents a revised v2 patch introducing an optional SMART mode for ANALYZE that skips relations when they have been previously analyzed and have not been modified since (n_mod_since_analyze = 0). The feature aims to reduce unnecessary ANALYZE work in databases with many static tables while keeping behavior strictly opt-in. Key changes in v2 include ensuring never-analyzed tables are never skipped by checking last_analyze_time/last_autoanalyze_time, relying on pg_stat_user_tables counters for skip decisions, and adding regression tests. The patch intentionally limits scope to regular relations using existing pg_stat statistics, excluding partitioned tables, inheritance, foreign tables, and extended statistics for potential future work. Test examples demonstrate the feature working correctly with empty and populated tables, showing proper statistics creation behavior.	2026-01-22 09:19:00+00	\N
6	19be50d3045a0c0b	DOC: fixes multiple errors in alter table doc	["rob@xzilla.net"]	[{"id":"19be50d3045a0c0b","messageId":"<7D4CB5FF-6599-4157-A9E3-7B5E2CB96CEE@gmail.com>","subject":"Re: DOC: fixes multiple errors in alter table doc","body":"\\n\\n> On Jan 8, 2026, at 09:38, Chao Li <li.evan.chao@gmail.com> wrote:\\n> \\n> \\n> \\n>> On Jan 8, 2026, at 07:13, Robert Treat <rob@xzilla.net> wrote:\\n>> \\n>> On Sat, Jan 3, 2026 at 11:30 PM Chao Li <li.evan.chao@gmail.com> wrote:\\n>>> On Jan 2, 2026, at 10:54, Robert Treat <rob@xzilla.net> wrote:\\n>>> Hi Robert,\\n>>> \\n>>> Thanks you very much for your review.\\n>>> \\n>>> \\n>>> On Thu, Dec 18, 2025 at 2:22 AM Chao Li <li.evan.chao@gmail.com> wrote:\\n>>> Hi Hacker,\\n>> <snip>\\n>>> 2. In sub-command details section, \\"ADD COLUMN [ IF NOT EXISTS ]" missed "[]\\" with "COLUMN", which is misleading, because "COLUMN" is actually optional.\\n>>> \\n>>> Seems technically correct and potentially useful, and I see you\\n>>> handled this for the DROP COLUMN variant as well, so I could see a +1\\n>>> on this one.\\n>>> \\n>>> Thanks for confirming.\\n>>> \\n>>> \\n>>> 3. For all "alter column" sub-commands, \\"ALTER [ COLUMN ]" are omitted, which is also confusing, because none of other sub-commands omit their prefix part.\\n>>> \\n>>> \\n>>> Hmm... I'm curious what you find confusing about this. Is the\\n>>> confusion in trying to find or understand the information presented,\\n>>> or confusing as to why it isn't all documented the same way? The\\n>>> downside of your \\"fix\\" is that this introduces a lot of extra text\\n>>> that is more or less noise, especially for folks trying to skim the\\n>>> documents looking for very specific command references.  And while I\\n>>> agree that we aren't 100% consistent on this within the ALTER TABLE\\n>>> subcommands, we use this same mixed pattern of omission on other pages\\n>>> (see ALTER TYPE for instance). If we were to insist on making this\\n>>> consistent here, I think we'd probably need to look at other pages as\\n>>> well and evaluate or update them too. I'm not sure that would be an\\n>>> improvement though.\\n>>> \\n>>> \\n>>> The confusion came from my own first-time reading of the documentation. Since the page is quite long, when I was reading the action descriptions and wanted to confirm the exact sub-command syntax, I often had to scroll back up to the syntax section. That led me to think it might be helpful to include the full sub-command form directly with the action descriptions.\\n>>> \\n>>> That said, I understand your concern. The change did make the text longer and added noise. In v2, I've therefore reverted that broader change. As you pointed out, if we were to pursue this kind of consistency, it would need to be handled across other similar pages as well, which would be better done as a dedicated and more carefully scoped patch.\\n>>> \\n>>> So, v2's scope is significantly reduced, only a fix for my original point 2 is retained.\\n>>> \\n>> \\n>> Makes sense to me and seems like an improvement, so +1.\\n>> \\n> \\n> Hi Robert,\\n> \\n> Thank you very much for your review. This is the CF entry https://commitfest.postgresql.org/patch/6328/, you may add you as a reviewer. And I just changed the status to Ready for Committer.\\n> \\n> Best regards,\\n> --\\n> Chao Li (Evan)\\n> HighGo Software Co., Ltd.\\n> https://www.highgo.com/\\n\\nBump. This is a tiny doc fix.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be50d3045a0c0b","snippet":"> On Jan 8, 2026, at 09:38, Chao Li <li.evan.chao@gmail.com> wrote: > > > >> On Jan 8, 2026, at 07:13, Robert Treat <rob@xzilla.net> wrote: >> >> On Sat, Jan 3","historyId":"5943","internalDate":"1769074358000","receivedAtUtc":"2026-01-22T09:32:38.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be5120d38bb9eb","messageId":"<CAEoWx2mOW=JMjSNrNsc3b-+8w0wbT2f6FSsyudD_Q-0pe_fkfw@mail.gmail.com>","subject":"Re: DOC: fixes multiple errors in alter table doc","body":"On Thu, Jan 22, 2026 at 5:33 PM Chao Li <li.evan.chao@gmail.com> wrote:\\n\\n>\\n>\\n> > On Jan 8, 2026, at 09:38, Chao Li <li.evan.chao@gmail.com> wrote:\\n> >\\n> >\\n> >\\n> >> On Jan 8, 2026, at 07:13, Robert Treat <rob@xzilla.net> wrote:\\n> >>\\n> >> On Sat, Jan 3, 2026 at 11:30 PM Chao Li <li.evan.chao@gmail.com> wrote:\\n> >>> On Jan 2, 2026, at 10:54, Robert Treat <rob@xzilla.net> wrote:\\n> >>> Hi Robert,\\n> >>>\\n> >>> Thanks you very much for your review.\\n> >>>\\n> >>>\\n> >>> On Thu, Dec 18, 2025 at 2:22 AM Chao Li <li.evan.chao@gmail.com>\\n> wrote:\\n> >>> Hi Hacker,\\n> >> <snip>\\n> >>> 2. In sub-command details section, \\"ADD COLUMN [ IF NOT EXISTS ]"\\n> missed "[]\\" with "COLUMN", which is misleading, because "COLUMN" is\\n> actually optional.\\n> >>>\\n> >>> Seems technically correct and potentially useful, and I see you\\n> >>> handled this for the DROP COLUMN variant as well, so I could see a +1\\n> >>> on this one.\\n> >>>\\n> >>> Thanks for confirming.\\n> >>>\\n> >>>\\n> >>> 3. For all "alter column" sub-commands, \\"ALTER [ COLUMN ]" are\\n> omitted, which is also confusing, because none of other sub-commands omit\\n> their prefix part.\\n> >>>\\n> >>>\\n> >>> Hmm... I'm curious what you find confusing about this. Is the\\n> >>> confusion in trying to find or understand the information presented,\\n> >>> or confusing as to why it isn't all documented the same way? The\\n> >>> downside of your \\"fix\\" is that this introduces a lot of extra text\\n> >>> that is more or less noise, especially for folks trying to skim the\\n> >>> documents looking for very specific command references.  And while I\\n> >>> agree that we aren't 100% consistent on this within the ALTER TABLE\\n> >>> subcommands, we use this same mixed pattern of omission on other pages\\n> >>> (see ALTER TYPE for instance). If we were to insist on making this\\n> >>> consistent here, I think we'd probably need to look at other pages as\\n> >>> well and evaluate or update them too. I'm not sure that would be an\\n> >>> improvement though.\\n> >>>\\n> >>>\\n> >>> The confusion came from my own first-time reading of the\\n> documentation. Since the page is quite long, when I was reading the action\\n> descriptions and wanted to confirm the exact sub-command syntax, I often\\n> had to scroll back up to the syntax section. That led me to think it might\\n> be helpful to include the full sub-command form directly with the action\\n> descriptions.\\n> >>>\\n> >>> That said, I understand your concern. The change did make the text\\n> longer and added noise. In v2, I've therefore reverted that broader change.\\n> As you pointed out, if we were to pursue this kind of consistency, it would\\n> need to be handled across other similar pages as well, which would be\\n> better done as a dedicated and more carefully scoped patch.\\n> >>>\\n> >>> So, v2's scope is significantly reduced, only a fix for my original\\n> point 2 is retained.\\n> >>>\\n> >>\\n> >> Makes sense to me and seems like an improvement, so +1.\\n> >>\\n> >\\n> > Hi Robert,\\n> >\\n> > Thank you very much for your review. This is the CF entry\\n> https://commitfest.postgresql.org/patch/6328/, you may add you as a\\n> reviewer. And I just changed the status to Ready for Committer.\\n> >\\n> > Best regards,\\n> > --\\n> > Chao Li (Evan)\\n> > HighGo Software Co., Ltd.\\n> > https://www.highgo.com/\\n>\\n> Bump. This is a tiny doc fix.\\n>\\n\\nPFA v3: Rebased, and added reviewer and discussion information.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n","threadId":"19be50d3045a0c0b","snippet":"On Thu, Jan 22, 2026 at 5:33 PM Chao Li <li.evan.chao@gmail.com> wrote: > On Jan 8, 2026, at 09:38, Chao Li <li.evan.chao@gmail.com> wrote: > > > >> On Jan 8, 2026, at 07:","historyId":"5943","internalDate":"1769074694000","receivedAtUtc":"2026-01-22T09:38:14.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	Chao Li is proposing documentation fixes for the ALTER TABLE command page. The original patch addressed three issues: missing brackets around optional keywords, inconsistent formatting for "ADD COLUMN" and "DROP COLUMN" syntax, and omitted "ALTER [COLUMN]" prefixes in sub-command descriptions. After discussion with Robert Treat, who provided feedback about potential verbosity concerns, Chao Li reduced the scope to focus only on fixing the missing brackets around "COLUMN" in the "ADD COLUMN [IF NOT EXISTS]" syntax documentation, making it clear that "COLUMN" is optional. Robert Treat approved this narrower fix as technically correct and useful. The patch has been marked as "Ready for Committer" in the commitfest entry, and Chao Li has provided a v3 rebased patch with reviewer information included.	2026-01-22 09:38:14+00	\N
6	19be51407673170a	[PATCH] ANALYZE: hash-accelerate MCV tracking for equality-only types	["ilya.evdokimov@tantorlabs.com"]	[{"id":"19be51407673170a","messageId":"<FACC73B3-C4FC-4206-A887-1F3EE75AD37C@Outlook.com>","subject":"Re: [PATCH] ANALYZE: hash-accelerate MCV tracking for equality-only types","body":"Hi\\n\\n> On Jan 22, 2026, at 04:44, Ilia Evdokimov <ilya.evdokimov@tantorlabs.com> wrote:\\n>\\n> Nice catch - this is indeed not first time we run into an O(N^2) bottleneck in MCV array and address it with hash-based lookup. Thanks for working on this!\\n\\nThanks for the review. This change was actually inspired by your earlier\\npatch on a similar issue, so thanks a lot for that as well.\\n\\n> I have a couple of follow-up questions after a quick look at the patch:\\n> 1. The hash table is created but I do not see a corresponding destroy call.\\n\\nThe hash table is allocated in the per-column temporary memory context\\n(the "Analyze Column" context that is active while compute_stats()\\nruns). That context is MemoryContextReset() after each column and\\neventually deleted at the end of ANALYZE, so the table is reclaimed\\nautomatically.\\n\\nThis matches the existing convention noted at the end of\\ncompute_distinct_stats() ("We don't need to bother cleaning up any of\\nour temporary palloc's").\\n\\nThat said, I can add an explicit DistinctHash_destroy() before returning\\nfor clarity, although it shouldn't be required for correctness or leak\\nprevention.\\n\\n> 2. In the original code, when a value was not found using the nested-loop search, the singleton (count = 1) region was shifted to make room for the new entry. After the patch, I no longer see this shifting logic. I might be missing something, but it looks like the non-hash path now follows the same replacement behavior as the hash-based one.\\n\\nIn the original code, inserting a new distinct value into the singleton\\n(count = 1) region effectively evicted the oldest singleton (FIFO) by\\ninserting at the head of that region and shifting the tail, which is\\nO(n) per new distinct value.\\n\\nThe patch replaces this with a FIFO eviction cursor (effectively a\\ncircular / round-robin cursor) over the count = 1 region, avoiding\\nrepeated shifts. When hashing is enabled, this also avoids having to\\nupdate many hash→index mappings due to element shifts.\\n\\nI kept the non-hash path using the same mechanism so that the hash and\\nfallback paths follow the same replacement behavior, with the intention\\nof preserving the original FIFO semantics while avoiding the O(n) cost.\\n\\nI've also posted a v2 update. It adjusts the eviction cursor when a\\ncount = 1 value is promoted (via the existing bubble-up logic), so that\\nthe cursor-based eviction is now exactly equivalent to the original\\nshift-based FIFO behavior.\\n\\nI've also updated the relevant comments to clarify this behavior. The v2\\npatch is attached.\\n\\n\\n--\\nBest regards,\\nChengpeng Yan\\n","threadId":"19be51407673170a","snippet":"Hi > On Jan 22, 2026, at 04:44, Ilia Evdokimov <ilya.evdokimov@tantorlabs.com> wrote: > > Nice catch - this is indeed not first time we run into an O(N^2) bottleneck in MCV array and","historyId":"5944","internalDate":"1769074838000","receivedAtUtc":"2026-01-22T09:40:38.000Z","from":"Chengpeng Yan <chengpeng_yan@outlook.com>"}]	Chengpeng Yan addresses review feedback on their patch to optimize PostgreSQL's ANALYZE command by using hash-based lookup to accelerate MCV (Most Common Values) tracking for equality-only types. The patch addresses an O(N^2) bottleneck in MCV array processing. Regarding memory management concerns, Yan explains that the hash table is allocated in the per-column temporary memory context which is automatically reset after each column, following existing conventions. For the eviction logic concern, Yan clarifies that the original O(n) shifting behavior for singleton values has been replaced with a FIFO eviction cursor mechanism to avoid repeated shifts while preserving original FIFO semantics. A v2 patch was submitted that adjusts the eviction cursor when count=1 values are promoted, making the cursor-based eviction exactly equivalent to the original shift-based behavior with updated clarifying comments.	2026-01-22 09:40:38+00	\N
6	19be4bfe79e845a8	Add WALRCV_CONNECTING state to walreceiver	["li.evan.chao@gmail.com","michael@paquier.xyz","noah@leadboat.com","rahilasyed90@gmail.com","xunengzhou@gmail.com"]	[{"id":"19be4bfe79e845a8","messageId":"<aXHbCO9dwRO54duf@paquier.xyz>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"On Thu, Jan 22, 2026 at 12:37:42PM +0800, Xuneng Zhou wrote:\\n> So the view returns no row rather than a row with status = 'stopped'.\\n> But for completeness, maybe we should add it.\\n\\nYeah, you are making me doubt here, \\"stopped\\" is the only state that\\nwould never show up.  After pondering a bit on this one, I have\\nremoved this part, and applied the rest of 0001 on HEAD after some\\nreordering of the items and fixing a <para> markup which was at an\\nincorrect location.  That's one.\\n--\\nMichael\\n","threadId":"19be4bfe79e845a8","snippet":"On Thu, Jan 22, 2026 at 12:37:42PM +0800, Xuneng Zhou wrote: > So the view returns no row rather than a row with status = 'stopped'. > But for completeness, maybe we should add it. Yeah,","historyId":"5935","internalDate":"1769069320000","receivedAtUtc":"2026-01-22T08:08:40.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be4c6bdfa8b095","messageId":"<aXHcyyVzREVgQQdm@paquier.xyz>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"On Thu, Jan 22, 2026 at 03:34:32PM +0800, Chao Li wrote:\\n> \\"Is not running\\" appears twice in this short paragraph, looks redundant. Suggestion:\\n> ```\\n> <literal>stopped</literal>: WAL receiver process is not running.\\n> This state is normally not visible because the view returns no row in this case.\\n> ```\\n\\nI have removed this part at the end, see 1a1e733b6231.  Let's see\\nlater about the second episode of this saga.\\n--\\nMichael\\n","threadId":"19be4bfe79e845a8","snippet":"On Thu, Jan 22, 2026 at 03:34:32PM +0800, Chao Li wrote: > \\"Is not running\\" appears twice in this short paragraph, looks redundant. Suggestion: > ``` > <literal>stopped</literal>:","historyId":"5935","internalDate":"1769069771000","receivedAtUtc":"2026-01-22T08:16:11.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be528917535fc5","messageId":"<CABPTF7V2GFKwzeHSFKLQpdu9bU1qBh30X1rxgygSKdVhZnwTcw@mail.gmail.com>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"Hi Chao,\\n\\nThanks for looking into this.\\n\\n>\\n> Hi Xuneng,\\n>\\n> I just reviewed the patch. It splits the current STREAMING state into CONNECTING and STREAMING, where CONNECTING represents the connection establishing phase, which makes sense. The patch is solid, I have just a few small comments:\\n>\\n> 1 - 0001\\n> ```\\n> +         <para>\\n> +          <literal>stopped</literal>: WAL receiver process is not running.\\n> +          This state is normally not visible because the view returns no row\\n> +          when the WAL receiver is not running.\\n> +         </para>\\n> ```\\n>\\n> \\"Is not running\\" appears twice in this short paragraph, looks redundant. Suggestion:\\n> ```\\n> <literal>stopped</literal>: WAL receiver process is not running.\\n> This state is normally not visible because the view returns no row in this case.\\n> ```\\n>\\n> 2 - 0002\\n> ```\\n> +       WALRCV_CONNECTING,                      /* connecting to primary, replication not yet\\n> +                                                                * started */\\n> ```\\n>\\n> I think \\"primary\\" is inaccurate. A connection destination could be a primary, or the other standby, so maybe change \\"primary\\" to \\"upstream server\\".\\n\\nYeah, \\"upstream server\\" is more precise. There are multiple\\nuser-facing log messages in this file that also use \\"primary\\". I'm\\nwondering whether we should update those as well.\\n\\n>\\n>\\n> 3 - 0002\\n> ```\\n>      * Mark walreceiver as running in shared memory.\\n> ```\\n>\\n> I think we should update this comment, changing \\"running\\" to \\"connecting\\". There is not a \\"running\\" state, before this patch, \\"streaming\\" can roughly equal to \\"running\\", after this patch, \\"running\\" is kinda unclear.\\n>\\n\\nIt has been changed.\\n\\n> 4 - 0002\\n> ```\\n> +                       /* Connection established, switch to streaming state */\\n> +                       SpinLockAcquire(&walrcv->mutex);\\n> +                       Assert(walrcv->walRcvState == WALRCV_CONNECTING);\\n> +                       walrcv->walRcvState = WALRCV_STREAMING;\\n> +                       SpinLockRelease(&walrcv->mutex);\\n> ```\\n>\\n> I don't feel good with this Assert(). Looking at ShutdownWalRcv(), the startup process might set the state to STOPPING, so there is a race.\\n>\\n> Before this patch, this is no state change here, thus rest logic can handle STOPPING. After this patch, if the race occurs, in dev mode, the Assert is fired; in production mode, STOPPING is overwritten by STREAMING, which is wrong.\\n>\\n> So, instead of Assert(), I think we should check if current state is CONNECTING, if not, it should not proceed.\\n\\nIt makes sense to me. Please check the updated patch.\\n\\n--\\nBest,\\nXuneng\\n","threadId":"19be4bfe79e845a8","snippet":"Hi Chao, Thanks for looking into this. > > Hi Xuneng, > > I just reviewed the patch. It splits the current STREAMING state into CONNECTING and STREAMING, where CONNECTING represents the","historyId":"5935","internalDate":"1769076174000","receivedAtUtc":"2026-01-22T10:02:54.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>"},{"id":"19be52bb4e074e62","messageId":"<CABPTF7W+fMCK4JfdthtXF4gNSVrvoG_DaZ-1CBnDEvEVe4vKkQ@mail.gmail.com>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"Hi,\\n\\nOn Thu, Jan 22, 2026 at 4:08 PM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 12:37:42PM +0800, Xuneng Zhou wrote:\\n> > So the view returns no row rather than a row with status = 'stopped'.\\n> > But for completeness, maybe we should add it.\\n>\\n> Yeah, you are making me doubt here, \\"stopped\\" is the only state that\\n> would never show up.  After pondering a bit on this one, I have\\n> removed this part, and applied the rest of 0001 on HEAD after some\\n> reordering of the items and fixing a <para> markup which was at an\\n> incorrect location.  That's one.\\n> --\\n> Michael\\n\\nThanks for updating and pushing it.\\n\\n-- \\nBest,\\nXuneng\\n\\n\\n","threadId":"19be4bfe79e845a8","snippet":"Hi, On Thu, Jan 22, 2026 at 4:08 PM Michael Paquier <michael@paquier.xyz> wrote: > > On Thu, Jan 22, 2026 at 12:37:42PM +0800, Xuneng Zhou wrote: > > So the view returns no row rather","historyId":"5935","internalDate":"1769076381000","receivedAtUtc":"2026-01-22T10:06:21.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>"}]	The discussion focuses on adding a WALRCV_CONNECTING state to PostgreSQL's WAL receiver to split the current STREAMING state into distinct connection establishment and streaming phases. Chao Li provided code review feedback addressing documentation redundancy, suggesting "upstream server" instead of "primary" for accuracy, and identifying a race condition with Assert() in state transitions where the startup process might set STOPPING state. Xuneng Zhou agreed with the feedback and updated the patch to handle the race condition by checking current state before proceeding rather than using Assert(). Michael Paquier applied the first part of the patch (0001) to HEAD after removing documentation about the "stopped" state and fixing markup issues, noting that "stopped" would never show up in the view anyway.	2026-01-22 10:06:21+00	\N
6	19be5744042c7846	Remove redundant AssertVariableIsOfType uses in pg_upgrade	["nathandbossart@gmail.com"]	[{"id":"19be5744042c7846","messageId":"<c1b79178-ab7c-461e-8359-bf400d8f1684@eisentraut.org>","subject":"Re: Remove redundant AssertVariableIsOfType uses in pg_upgrade","body":"On 20.01.26 23:19, Nathan Bossart wrote:\\n> On Tue, Jan 20, 2026 at 11:07:47AM +0100, Peter Eisentraut wrote:\\n>> pg_upgrade code contains a number of lines like\\n>>\\n>>      AssertVariableIsOfType(&process_rel_infos, UpgradeTaskProcessCB);\\n>>\\n>> This is presumably to ensure that the function signature is fitting for\\n>> being used with upgrade_task_add_step().  But the signature of\\n>> upgrade_task_add_step() already checks that itself, so these additional\\n>> assertions are redundant, and I find them confusing.  So I propose to remove\\n>> them.\\n> > I think this was borrowed from logical decoding output plugins, but\\n> apparently I wrote the patch to remove these assertions from those, too\\n> (commit 30b789eafe).  So, I'm not sure what I was thinking...  If they are\\n> indeed redundant, I have no objection to their removal.\\n\\nAh, that is interesting context.  Anyway, change committed.\\n\\n\\n","threadId":"19be5744042c7846","snippet":"On 20.01.26 23:19, Nathan Bossart wrote: > On Tue, Jan 20, 2026 at 11:07:47AM +0100, Peter Eisentraut wrote: >> pg_upgrade code contains a number of lines like >> >>","historyId":"5950","internalDate":"1769080888000","receivedAtUtc":"2026-01-22T11:21:28.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	Peter Eisentraut proposed removing redundant AssertVariableIsOfType assertions from pg_upgrade code, which were used to verify function signatures for upgrade_task_add_step(). These assertions check that callback functions match the expected UpgradeTaskProcessCB signature, but upgrade_task_add_step() already performs this verification internally, making the additional checks unnecessary and confusing. Nathan Bossart noted these assertions were borrowed from logical decoding output plugins, where similar redundant checks were previously removed in commit 30b789eafe. After this discussion providing helpful context, Eisentraut committed the change to remove these redundant assertions from pg_upgrade.	2026-01-22 11:21:28+00	\N
6	19be5345d4172528	Import Statistics in postgres_fdw before resorting to sampling.	["corey.huinker@gmail.com","etsuro.fujita@gmail.com","jkatz@postgresql.org","michael@paquier.xyz","nathandbossart@gmail.com"]	[{"id":"19be5345d4172528","messageId":"<CAExHW5vmTR1DQKa6yCOt1bU4KY+AkMmWrAa_kd6RAPg5Hpaw=g@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":"On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>>\\n>> Changes in this release, aside from rebasing:\\n>>\\n>> - The generic analyze and fdw.h changes are in their own patch (0001) that ignores contrib/postgres_fdw entirely.\\n>> - The option for remote_analyze has been moved to its own patch (0003).\\n>> - The errors raised are now warnings, to ensure that we can always fall back to row sampling.\\n>> - All local attributes with attstatarget > 0 must get matching remote statistics or the import is considered a failure.\\n>> - The pg_restore_attribute_stats() call has been turned into a prepared statement, for clarity and some minor parsing savings.\\n>> - The calls to pg_restore_relation_stats() are parameterized, but not prepared as this is rarely called more than once.\\n>> - postgresStatisticsAreImportable will now disqualify a table if has extended statistics objects, because we can't compute those without a row sample.\\n>\\n\\nThanks Corey for breaking down these patches. It makes reviewing easier.\\n\\nanalyze_rel() and acquire_inherited_sample_rows() both call\\nfdwroutine->AnalyzeForeignTable() but only the first one uses the\\nstatistics import facility. Is that intentional? Typical use case of\\nsharding will create a partitioned table with foreign tables as\\npartitions. The partitions will be analyzed by the second function.\\nThus a big use case of postgres_fdw won't be able to use the import\\nstatistics facility. That seems like a major drawback of this patch.\\nThinking more about it, acquire_inherited_sample_rows() accumulates\\nthe sample rows from the child tables and extracts statistics from\\nthose rows and then updates corresponding pg_statistics rows. Doing\\nthat through import statistics seems a bit tricky since we need to be\\nable to combine statistics from multiple relations. Can we do that?\\nThere's an advantage if we can combine stats across multiple relations\\n- we don't have to sample children twice when analyzing the parent\\nwithout ONLY. Instead we could produce parent statistics by combining\\nstatistics across children and the parent. To me this looks like\\naltogether a different beast just like partial aggregates.\\n\\nIt will be good to fix this drawback. If not, at least we should\\nfigure out (plan/POC) how to deal with the child tables? We need to at\\nleast document this drawback - the documentation in the current patch\\nreads as if all foreign tables will use this facility when available.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n","threadId":"19be5345d4172528","snippet":"On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote: >> >> Changes in this release, aside from rebasing: >> >> - The generic analyze and fdw.h","historyId":"5947","internalDate":"1769076946000","receivedAtUtc":"2026-01-22T10:15:46.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19be57795c6119b8","messageId":"<CAExHW5uTy=xbdsjKO6kHE3Oc=5O5L_Fy-UPmBGkUW2aQPuiirA@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":"On Thu, Jan 22, 2026 at 3:45 PM Ashutosh Bapat\\n<ashutosh.bapat.oss@gmail.com> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote:\\n> >>\\n> >> Changes in this release, aside from rebasing:\\n> >>\\n> >> - The generic analyze and fdw.h changes are in their own patch (0001) that ignores contrib/postgres_fdw entirely.\\n> >> - The option for remote_analyze has been moved to its own patch (0003).\\n> >> - The errors raised are now warnings, to ensure that we can always fall back to row sampling.\\n> >> - All local attributes with attstatarget > 0 must get matching remote statistics or the import is considered a failure.\\n> >> - The pg_restore_attribute_stats() call has been turned into a prepared statement, for clarity and some minor parsing savings.\\n> >> - The calls to pg_restore_relation_stats() are parameterized, but not prepared as this is rarely called more than once.\\n> >> - postgresStatisticsAreImportable will now disqualify a table if has extended statistics objects, because we can't compute those without a row sample.\\n> >\\n\\nThe patches fail to build the document. Attached diff fixes that.\\n\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be5345d4172528","snippet":"On Thu, Jan 22, 2026 at 3:45 PM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> wrote: > > On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote: > >>","historyId":"5947","internalDate":"1769081352000","receivedAtUtc":"2026-01-22T11:29:12.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"}]	Ashutosh Bapat reviewed Corey Huinker's updated patchset for importing statistics in postgres_fdw before sampling. The patches split generic analyze changes from postgres_fdw-specific code, convert errors to warnings for fallback capability, and require all local attributes with attstatarget > 0 to have matching remote statistics. Bapat identified a significant limitation: the statistics import facility only works in analyze_rel() but not in acquire_inherited_sample_rows(), which handles partitioned tables with foreign table partitions. This excludes a major postgres_fdw use case involving sharding. Combining statistics from multiple child relations appears complex, requiring different handling similar to partial aggregates. Bapat suggests either fixing this drawback or documenting the limitation, as current documentation implies all foreign tables can use this facility. He also provided a documentation build fix.	2026-01-22 11:29:12+00	\N
6	19be4da9486dc0d1	Adding REPACK [concurrently]	["ah@cybertec.at","alvherre@alvh.no-ip.org","mihailnikalayeu@gmail.com","rob@xzilla.net"]	[{"id":"19be4da9486dc0d1","messageId":"<74802.1769071060@localhost>","subject":"Re: Adding REPACK [concurrently]","body":"Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote:\\n\\n> Some comments for 0006:\\n> \\n> > SnapBuildSnapshotForRepack(SnapBuild *builder)\\n> Does it also \\"replays\\" previously processed WAL to the position that snapshot is ready to use?\\n> I am afraid we may see some non-yet processed parts of WAL leading to duplicate insertion.\\n\\nThe changes present in WAL decoded prior the snapshot creation are not\\nreplayed - these changes are visible to the snapshot. (This is not really\\nspecific to the 0006 part.)\\n\\n> > first_block \\n> What is the reason for that variable? It seems to be always the first block\\n> of relation.\\n\\nAlthough scan usually starts at the first block, it does not have to,\\nespecially due to synchronized sequential scans.\\n\\n> Also, what if we have a huge amount of empty space at the start. In that case the first block will be the block of the first \\"filled\\" page. But\\n> insert may (and will) fill empty pages before first_block - out of the range.\\n\\nGood catch! I think I used this \\"lazy initialization\\" because I couldn't find\\nthe start block in TableScanDesc, and missed the problem that you describe\\nhere.\\n\\n> So, I think we should delete it and always use 0 instead.\\n\\nNo, we need to set first_block to heapScan->rs_startblock before the scan\\nstarts.\\n\\n> > tableScan = table_beginscan(OldHeap, SnapshotAny, 0, (ScanKey) NULL);\\n> With SnapshotAny we are going to check the same tuple multiple times. Better to let scan logic handle it (and change snapshots used by scan\\n> code).\\n\\nThe current API does not seem to support changing snapshot of an in-progress\\nscan and I don't want to change that. Plus note that the current\\nimplementation of CLUSTER also uses SnapshotAny and then checks the visibility\\nseparately. Finally, SnapshotAny is not really an expensive visibility check,\\nif it can be considered a visibility check at all.\\n\\n> > if (blkno >= range_end)\\n> I don't think it is legal to switch a snapshot while holding the tuple. Nothing is protecting it from being pruned\\\\reused.\\n\\nSnapshot protects the table as whole from pruning live (or recently dead)\\ntuples, but when you have fetched a tuple, the containing buffer remains\\npinned. The buffer pin itself makes prunning of the page impossible.\\n\\nAnd especially with REPACK (CONCURRENTLY), page pruning is also restricted by\\nthe replication slot's xmin. This is increased by calling\\nLogicalIncreaseXminForSlot() from the decoding worker, each time it has\\ncreated a new snapshot.\\n\\n> > PopActiveSnapshot();\\n> > InvalidateCatalogSnapshot();\\n> I think it is a good idea to add here assert for MyProc->xmin and MyProc->xid to be invalid. To ensure we really allow the horizon to advance.\\n\\nI've added it only for xmin. xid is valid because REPACK is executed in a\\ntransaction. That reminds me that PROC_IN_VACUUM should be present in\\nMyProc->statusFlags. Fixed.\\n\\n> > /* Set to request a snapshot. */\\n> > bool snapshot_requested;\\n> We know the end or region in advance, so it should be possible to filter before writing changes to file.\\n\\nYes, filtering before writing makes sense, I'll consider that.\\n\\n> So, it is some kind of \\"this is the end of region, create new file and store everything before + create new snapshot for me\\".\\n\\nThe last se of changes does not have to be followed by a snapshot - that's the\\npurpose of snapshot_requested.\\n\\n> > PopActiveSnapshot();\\n> Sometimes without InvalidateCatalogSnapshot().\\n\\n[ It'd be a bit easier to find the code if you included hunk headers. ]\\n\\nheapam_relation_copy_for_cluster() does not access catalogs after the first\\ninvalidation. The following comment is related:\\n\\n\\t/*\\n\\t * XXX It might be worth Assert(CatalogSnapshot == NULL) here,\\n\\t * however that symbol is not external.\\n\\t */\\n\\n\\n> > PushActiveSnapshot(GetTransactionSnapshot());\\n> GetLatestSnapshot() feels better here.\\n\\nWhat will then happen to code that uses GetActiveSnapshot() ?\\n\\n> > * The individual builds might still be a problem, but that's a\\n> > * separate issue.\\n> Opening the index may create a catalog snapshot, so it needs to be invalidated after.\\n\\nIt'll be invalidated in the next iteration. The point of this invalidation is\\nto use one snapshot per index.\\n\\n> > * TODO Can we somehow use the fact that the new heap is not yet\\n> > * visible to other transaction, and thus cannot be vacuumed?\\n> Snapshot resetting [0] may work here (without CIC, just as part of the scan + some code to ensure catalog snapshot is managed correctly).\\n> Also, to correctly build a unique index - some tech from [0] is required (building a unique index with multiple snapshots is a little bit tricky).\\n> Or we may implement some super lightweight way - just SnapshotAny without any visibility checks (just assume everything is ok since it\\n> copied from another relation with the same index set).\\n\\nok, I'll check your patch.\\n\\n> > This approach introduces one limitation though: if the USING INDEX clause is\\n> > specified, an explicit sort is always used. Index scan wouldn't work because\\n> > it does not return the tuples sorted by CTID.\\n> \\n> Technically we may just use keys (if they are comparable) as a way to specify regions. Instead of number of pages to switch snapshot -\\n> number of tuples or time.\\n> But because we don't know the region end in advance - we have to keep all the changes in file and filter only while applying.\\n\\nGood idea. Unfortunately it questions your proposal to filter the changes\\nbefore writing, as suggested above.\\n\\n> > range_end = repack_blocks_per_snapshot;\\n> Should be repack_blocks_per_snapshot + ctx->first_block ?\\n\\nIndeed, I also failed to avoid assuming first_block==0 :-)\\n\\n> > * XXX It might be worth Assert(CatalogSnapshot == NULL)\\n> > * here, however that symbol is not external.\\n> As said above - better assert for MyProc->xmin/xid + add InvalidateCatalogSnapshot.\\n\\nI proposed the Assert above, but still thinking about it.\\n\\n> > Is REPACKED (CONCURRENTLY) is being run by this backend?\\n> REPACK and double \\"is\\"\\n\\nOther comments accepted. Thanks.\\n\\n-- \\nAntonin Houska\\nWeb: https://www.cybertec-postgresql.com\\n\\n","threadId":"19be4da9486dc0d1","snippet":"Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote: > Some comments for 0006: > > > SnapBuildSnapshotForRepack(SnapBuild *builder) > Does it also \\"replays\\" previously","historyId":"5938","internalDate":"1769071060000","receivedAtUtc":"2026-01-22T08:37:40.000Z","from":"Antonin Houska <ah@cybertec.at>"},{"id":"19be57869b111101","messageId":"<CADzfLwVZ_DeU_3avD=G4ZHFJJgZ0EOFzxnmWxwyB23zsS-uxjA@mail.gmail.com>","subject":"Re: Adding REPACK [concurrently]","body":"Hello, Antonin!\\n\\n> The changes present in WAL decoded prior the snapshot creation are not\\n> replayed - these changes are visible to the snapshot. (This is not really\\n> specific to the 0006 part.)\\n\\nOK, just want to be sure it still works the same way if we build multiple\\nsnapshots for the same slot that way.\\n\\n> The current API does not seem to support changing snapshot of an\\nin-progress\\n> scan and I don't want to change that. Plus note that the current\\n> implementation of CLUSTER also uses SnapshotAny and then checks the\\nvisibility\\n> separately. Finally, SnapshotAny is not really an expensive visibility\\ncheck,\\n> if it can be considered a visibility check at all.\\n\\nBut we will require a real check for each tuple. Including dead one,\\nmultiple versions of the same HOT, etc.\\n\\n> I've added it only for xmin. xid is valid because REPACK is executed in a\\n> transaction. That reminds me that PROC_IN_VACUUM should be present in\\n> MyProc->statusFlags. Fixed.\\n\\nYes, xid is required for repack. I think it is better to introduce a new\\nflag instead of PROC_IN_VACCUUM.\\n\\n\\n> > > PushActiveSnapshot(GetTransactionSnapshot());\\n> > GetLatestSnapshot() feels better here.\\n> What will then happen to code that uses GetActiveSnapshot() ?\\n\\nO, I mean PushActiveSnapshot(GetLatestSnapshot())\\n\\n> > Also, to correctly build a unique index - some tech from [0] is\\nrequired (building a unique index with multiple snapshots is a little bit\\ntricky).\\n> ok, I'll check your patch.\\n\\nI realized building a unique index is still done with a single snapshot, so\\nit should be OK for that case. But still check the patch :)\\n\\n>  I proposed the Assert above, but still thinking about it.\\nHm... Do we really need these asserts if PROC_IN_VACUUM is set? I was\\nproposing a way it is used for index building (to ensure nothing is\\npropagated into xmin).\\n\\nBest regards,\\nMikhail.\\n","threadId":"19be4da9486dc0d1","snippet":"Hello, Antonin! > The changes present in WAL decoded prior the snapshot creation are not > replayed - these changes are visible to the snapshot. (This is not really > specific to the 0006 part","historyId":"5938","internalDate":"1769081400000","receivedAtUtc":"2026-01-22T11:30:00.000Z","from":"Mihail Nikalayeu <mihailnikalayeu@gmail.com>"}]	Antonin Houska addresses Mihail Nikalayeu's technical review comments on patch 0006 for concurrent REPACK functionality. Key discussion points include: WAL replay behavior with snapshot creation (changes prior to snapshot are visible, not replayed); proper handling of first_block variable to account for synchronized sequential scans and empty space issues; use of SnapshotAny with separate visibility checks following CLUSTER's approach; buffer pinning protection against tuple pruning during snapshot switches; addition of PROC_IN_VACUUM status flag and xmin assertions; filtering changes before writing to files; snapshot management with GetLatestSnapshot() vs GetTransactionSnapshot(); and unique index building considerations. Mihail suggests introducing a new flag instead of PROC_IN_VACUUM and confirms unique index building uses single snapshots. Several implementation details remain under consideration, including assertion placement and filtering optimization strategies.	2026-01-22 11:30:00+00	\N
6	19be62b5fc6b3dd8	Change COPY ... ON_ERROR ignore to ON_ERROR ignore_row	["david.g.johnston@gmail.com","jim.jones@uni-muenster.de","masao.fujii@oss.nttdata.com","matheusssilv97@gmail.com","nagata@sraoss.co.jp","reshkekirill@gmail.com","sawada.mshk@gmail.com","torikoshia@oss.nttdata.com","vignesh21@gmail.com"]	[{"id":"19be62b5fc6b3dd8","messageId":"<CACJufxGYPXQ_Jz1avF5eSh_XJRsxhPSUZ+=RzG3Hz4_XNAc32g@mail.gmail.com>","subject":"Re: Change COPY ... ON_ERROR ignore to ON_ERROR ignore_row","body":"On Thu, Jan 22, 2026 at 2:47 AM Matheus Alcantara\\n<matheusssilv97@gmail.com> wrote:\\n>\\n> Thanks for the new version. I have some comments on this first round of\\n> review:\\n>\\n> + errmsg_plural(\\"invalid values in %\\" PRIu64 \\" row was replaced with null due to data type incompatibility\\",\\n> +   \\"invalid values in %\\" PRIu64 \\" rows were replaced with null due to data type incompatibility\\",\\n>\\n> I think that we could remove the \\"invalid values in\\" to make it\\n> consistency with the COPY_ON_ERROR_IGNORE NOTICE\\n>\\nsure.\\n\\n> ----------\\n>\\n> +               cstate->domain_with_constraint = (bool *) palloc0(attr_count * sizeof(bool));\\n>\\n> I think that we can use palloc_array?\\n>\\nsure.\\n\\n> ----------\\n>\\n> Should FORCE_NOT_NULL be allowed to be used with ON_ERROR set_null? It\\n> seems to me that ON_ERROR set_null overwrite the FORCE_NOT_NULL\\n> behaviour:\\n>\\n> postgres=# create table t4(a int, b varchar(5));\\n> CREATE TABLE\\n>\\n> postgres=# copy t4 from 'data.csv' with (FORCE_NOT_NULL(b), format csv, delimiter ',', NULL 'NULL', ON_ERROR set_null);\\n> NOTICE:  invalid values in 2 rows were replaced with null due to data type incompatibility\\n> COPY 5\\n>\\n> postgres=# \\\\pset null 'NULL'\\n> Null display is \\"NULL\\".\\n> postgres=# select * from t4;\\n>  a |  b\\n> ---+------\\n>  1 | aaaa\\n>  2 | bbbb\\n>  2 | NULL\\n>  2 | NULL\\n>  5 | NULL\\n> (5 rows)\\n>\\n> Note that only the ccccc rows on .csv file was inserted with a NULL\\n> value on b column. The 5,NULL row was inserted with a \\"NULL\\" string as a\\n> value:\\n>\\n> postgres=# select * from t4 where b is null;\\n>  a |  b\\n> ---+------\\n>  2 | NULL\\n>  2 | NULL\\n> (2 rows)\\n>\\n> The contents of data.csv:\\n>     1,aaaa\\n>     2,bbbb\\n>     2,ccccc\\n>     2,ccccc\\n>     5,NULL\\n>\\n> Perhaps we should block the usage of FORCE_NOT_NULL with ON_ERROR\\n> SET_NULL?\\n>\\nFORCE_NOT_NULL is related to how we handle NULL string in column value.\\n\\nWe first process cstate->opts.force_notnull_flags, cstate->opts.force_null_flags\\nthen InputFunctionCallSafe.\\nsee copyfromparse.c, CopyFromTextLikeOneRow ``if (is_csv)``loop.\\n\\nI think these two are unrelated things, FORCE_NOT_NULL should be fine with\\nON_ERROR SET_NULL.\\nyou can see related tests in\\nhttps://git.postgresql.org/cgit/postgresql.git/tree/src/test/regress/sql/copy2.sql#n330\\n\\nAm I missing something?\\n\\n>\\n> On monitoring.sgml we have the following for pg_stat_progress_copy\\n> tuples_skipped:\\n>        Number of tuples skipped because they contain malformed data.\\n>        This counter only advances when a value other than\\n>        <literal>stop</literal> is specified to the <literal>ON_ERROR</literal>\\n>\\n> IIUC we are not updating this view if we set a column to NULL due to an\\n> error, perhaps this documentation should be updated to mention that it\\n> will not be updated with ON_ERROR set_null?\\n>\\n\\nIMHO, we don't need to mention ON_ERROR set_null, since we do not support it.\\nchange to the following should be ok, i think.\\n\\n      <para>\\n       Number of tuples skipped because they contain malformed data.\\n       This counter only advances when\\n       <literal>ignore</literal> is specified to the <literal>ON_ERROR</literal>\\n       option.\\n      </para></entry>\\n\\n>\\n> I may have missing something, but we are still considering implementing\\n> the REJECT_LIMIT + ON_ERROR set_null?\\nPossibly as a separate patch later.\\n\\n\\n\\n\\n--\\njian\\nhttps://www.enterprisedb.com/\\n\\n\\n","threadId":"19be62b5fc6b3dd8","snippet":"On Thu, Jan 22, 2026 at 2:47 AM Matheus Alcantara <matheusssilv97@gmail.com> wrote: > > Thanks for the new version. I have some comments on this first round of > review: > > +","historyId":"5958","internalDate":"1769093110000","receivedAtUtc":"2026-01-22T14:45:10.000Z","from":"jian he <jian.universality@gmail.com>"}]	Jian He responds to Matheus Alcantara's review comments on the COPY ON_ERROR set_null patch. He agrees to remove "invalid values in" from error messages for consistency and use palloc_array instead of palloc0. Regarding FORCE_NOT_NULL compatibility with ON_ERROR set_null, Jian argues they are unrelated features - FORCE_NOT_NULL handles NULL string processing while ON_ERROR set_null deals with data type incompatibility during InputFunctionCallSafe. He suggests updating pg_stat_progress_copy documentation to specify that tuples_skipped only advances when ON_ERROR ignore is used, removing references to unsupported set_null option. Jian indicates REJECT_LIMIT + ON_ERROR set_null combination could be implemented in a separate future patch.	2026-01-22 14:45:10+00	\N
6	19be59053caa9edb	commented out code	["hlinnaka@iki.fi","tgl@sss.pgh.pa.us"]	[{"id":"19be59053caa9edb","messageId":"<a690f6d3-c53e-41cf-8a26-756b1ef16442@eisentraut.org>","subject":"Re: commented out code","body":"On 20.01.26 19:55, Tom Lane wrote:\\n> Peter Eisentraut <peter@eisentraut.org> writes:\\n>> On 05.12.25 17:38, Heikki Linnakangas wrote:\\n>>> #if 0\\n>>>      Oid      subtype = PG_GETARG_OID(3);\\n>>> #endif\\n>>>\\n>>> is yet another option. It keeps the indentation, although you won't get\\n>>> the compiler checking.\\n> >> After some reflection, I like this approach.  It keeps the indentation\\n>> and enables syntax highlighting, so it makes some of these blocks much\\n>> easier to read.\\n> > I think \\"#ifdef NOT_USED\\" is our more common style.  +1 other than\\n> that nitpick.\\n\\nOk, committed like that.\\n\\n\\n\\n","threadId":"19be59053caa9edb","snippet":"On 20.01.26 19:55, Tom Lane wrote: > Peter Eisentraut <peter@eisentraut.org> writes: >> On 05.12.25 17:38, Heikki Linnakangas wrote: >>> #if 0 >>> Oid subtype =","historyId":"5952","internalDate":"1769082985000","receivedAtUtc":"2026-01-22T11:56:25.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	The discussion centers on the appropriate style for commenting out code in PostgreSQL. Heikki Linnakangas suggested using `#if 0` to comment out unused code, noting it preserves indentation but lacks compiler checking. Peter Eisentraut initially favored this approach for its readability benefits, particularly syntax highlighting and maintained indentation. Tom Lane agreed with the concept but recommended using `#ifdef NOT_USED` instead, stating this is PostgreSQL's more established convention for such cases. Peter Eisentraut accepted this feedback and committed the change using the `#ifdef NOT_USED` style as suggested by Tom Lane.	2026-01-22 11:56:25+00	\N
6	19be597e72b87c37	Skipping schema changes in publication	["1518981153@qq.com","amit.kapila16@gmail.com","barwick@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","houzj.fnst@fujitsu.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19be597e72b87c37","messageId":"<CANhcyEWTxqsrZsaqHwHO_eGD5=mrT=+RLGkCJ4cRvfua_fSdRQ@mail.gmail.com>","subject":"Re: Skipping schema changes in publication","body":"On Wed, 21 Jan 2026 at 17:11, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n>\\n> On Wed, Jan 21, 2026 at 4:57 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> >\\n> > On Wed, Jan 21, 2026 at 11:35 AM Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n> > >\\n> > > Thanks for explaining this, overall I like the Approach 1, and I also\\n> > > see the problem when publish via root is given in that case COPY FROM\\n> > > is executed on the root and it would be hard to exclude specific\\n> > > partitions.  What is the behavior when root of partition tree is added\\n> > > but publish via root is not true, it doesn't add any relation to\\n> > > publication rel or how does it manage to not copy data from\\n> > > partitions?\\n> > >\\n> >\\n> > So, I believe you are asking about the behavior of COPY on HEAD for\\n> > the following case:\\n> >\\n> > CREATE PUBLICATION pub1 FOR TABLE tab_root WITH\\n> > (publish_via_partition_root = false);\\n> >\\n> > In this scenario, pg_publication_rel contains an entry for tab_root,\\n> > while pg_publication_tables contains all leaf partitions (because\\n> > publish_via_partition_root = false). Consequently,\\n> > pg_subscription_rel, which is derived from pg_publication_tables, also\\n> > contains all corresponding leaf partitions.  As a result, on HEAD, a\\n> > separate tablesync worker is launched for each leaf partition, and\\n> > each leaf partition is copied independently.\\n> >\\n> > ~~\\n> >\\n> > Now, in Approach 4, when publish_via_partition_root is set to false,\\n> > we propose avoiding the inclusion of leaf partitions in\\n> > pg_publication_tables if their parent appears in the EXCEPT list.\\n> > Given the table hierarchy described in Approach1_challenges:\\n> >\\n> > tab_root\\n> > ├── tab_part_1\\n> > │   ├── tab_part_1_1\\n> > │   │   ├── tab_part_1_1_1\\n> > │   │   │   └── tab_part_1_1_1_1\\n> > │   │   └── tab_part_1_1_2\\n> > │   └── tab_part_1_2\\n> > │       ├── tab_part_1_2_1\\n> > │       └── tab_part_1_2_2\\n> > └── tab_part_2\\n> >\\n> > If tab_part_1_1 is specified in the EXCEPT list, then\\n> > pg_publication_tables will include only those leaf partitions that are\\n> > not in the partition-chain of tab_part_1_1. As a result, both\\n> > pg_publication_tables and pg_subscription_rel (which is built from\\n> > pg_publication_tables via fetch_relation_list) will contain:\\n> >\\n> > tab_part_1_2_1\\n> > tab_part_1_2_2\\n> > tab_part_2\\n> >\\n> > With this setup, any INSERT into tab_part_1 or tab_root that routes\\n> > rows to tab_part_1_1_1_1 or tab_part_1_1_2 will not be replicated.\\n> > However, rows routed to any of the three leaf partitions listed above\\n> > will be replicated.\\n> >\\n> > I hope it answers your query. If we have to go by Approach1, then do\\n> > you see any simpler way to overcome the challenges we mention for\\n> > publish_via_partition_root=true case. Or any other approach\\n> > altogether?\\n>\\n> Thanks for the explanation, that clears it up. I agree that Approach 3\\n> is the right path forward. And it makes sense to extend this with\\n> Approach 4. Logically, I think it's reasonable to say that if a user\\n> chooses to partition via the root, they are treating the entire\\n> partition tree as a single entity. Therefore, it makes sense to\\n> disallow the exclusion of individual child partitions in that context.\\n>\\nHi,\\n\\nI have prepared a patch for Approach-3. We are also checking the\\nfeasibility of other approaches.\\n\\nThanks,\\nShlok Kyal\\n","threadId":"19be597e72b87c37","snippet":"On Wed, 21 Jan 2026 at 17:11, Dilip Kumar <dilipbalaut@gmail.com> wrote: > > On Wed, Jan 21, 2026 at 4:57 PM shveta malik <shveta.malik@gmail.com> wrote: > > > > On Wed,","historyId":"5953","internalDate":"1769083465000","receivedAtUtc":"2026-01-22T12:04:25.000Z","from":"Shlok Kyal <shlok.kyal.oss@gmail.com>"}]	The discussion centers on implementing schema change exclusion in PostgreSQL publications, specifically for partitioned tables. The conversation evaluates different approaches to handle the "EXCEPT" clause when publish_via_partition_root is enabled. Shveta Malik explains that with publish_via_partition_root=false, each leaf partition gets its own tablesync worker and is copied independently. The proposed Approach 4 suggests excluding leaf partitions from pg_publication_tables when their parent appears in the EXCEPT list. Dilip Kumar agrees that Approach 3 is the right direction and supports extending it with Approach 4, noting that when partitioning via root, users treat the entire partition tree as a single entity, making individual child partition exclusion inappropriate. Shlok Kyal confirms they have prepared a patch for Approach-3 and are evaluating other approaches' feasibility.	2026-01-22 12:04:25+00	\N
6	19be5b38e1cd7b9b	let ALTER COLUMN SET DATA TYPE cope with trigger dependency	[]	[{"id":"19be5b38e1cd7b9b","messageId":"<CACJufxH-Ngr9e7_bT+7d-bFMACqd-efAV3YSgPJyfMp4T9P5AQ@mail.gmail.com>","subject":"Re: let ALTER COLUMN SET DATA TYPE cope with trigger dependency","body":"hi.\\n\\nV3 is attached. this should be more neat.\\nNow it looks very similar to how statistics cope with column data type change.\\n\\nFor statistics, in ATPostAlterTypeParse we will call\\ntransformStatsStmt, we need to do the similar thing for the trigger\\nWHEN clause.\\nI introduced transformTriggerStmt and placed it in\\nsrc/backend/commands/trigger.c, which should be fine, I think.\\nIt will be invoked from within CreateTriggerFiringOn.\\n\\n\\n\\n--\\njian\\nhttps://www.enterprisedb.com/\\n","threadId":"19be5b38e1cd7b9b","snippet":"hi. V3 is attached. this should be more neat. Now it looks very similar to how statistics cope with column data type change. For statistics, in ATPostAlterTypeParse we will call transformStatsStmt, we","historyId":"5954","internalDate":"1769085258000","receivedAtUtc":"2026-01-22T12:34:18.000Z","from":"jian he <jian.universality@gmail.com>"}]	This patch (V3) addresses handling trigger dependencies when using ALTER COLUMN SET DATA TYPE. The approach now mirrors how statistics handle column data type changes. In ATPostAlterTypeParse, statistics call transformStatsStmt, and similarly this patch requires calling an equivalent function for trigger WHEN clauses. The author introduced transformTriggerStmt in src/backend/commands/trigger.c, which will be invoked from within CreateTriggerFiringOn. This design follows the established pattern used by statistics functionality, making the implementation more consistent with existing PostgreSQL code structure for handling column type alterations that affect dependent database objects.	2026-01-22 12:34:18+00	\N
6	19be57f2bef34a1b	Assert the timestamp is available for ORIGN_DIFFERS conflicts	["amit.kapila16@gmail.com","kuroda.hayato@fujitsu.com","shveta.malik@gmail.com"]	[{"id":"19be57f2bef34a1b","messageId":"<CAJpy0uCLKRqi0vOJAEGKoOzj6WR32Dxi4mvewjE4_2SE3uEOug@mail.gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"On Wed, Jan 21, 2026 at 12:40 PM Hayato Kuroda (Fujitsu)\\n<kuroda.hayato@fujitsu.com> wrote:\\n>\\n> Dear Shveta,\\n>\\n> Thanks for ideas, I prefer first one. Also, pgindent told me that Line blank\\n> should be before the code comment. PSA the new version.\\n>\\n\\nThe patch LGTM.\\n\\nthanks\\nShveta\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"On Wed, Jan 21, 2026 at 12:40 PM Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > Dear Shveta, > > Thanks for ideas, I prefer first one. Also, pgindent told me that Line","historyId":"5951","internalDate":"1769081851000","receivedAtUtc":"2026-01-22T11:37:31.000Z","from":"shveta malik <shveta.malik@gmail.com>"},{"id":"19be5caa28727e61","messageId":"<60B254A7-A181-4983-A617-6B86E850F052@gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"\\n\\n> On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> \\n> Dear Shveta,\\n> \\n> Thanks for ideas, I prefer first one. Also, pgindent told me that Line blank\\n> should be before the code comment. PSA the new version.\\n> \\n> Best regards,\\n> Hayato Kuroda\\n> FUJITSU LIMITED\\n>> Shveta\\n> <v2-0001-Add-Assert-for-UPDATE-DELETE-_ORIGIN_DIFFERS.patch>\\n\\nHi Hayato-san,\\n\\nThanks for the patch. Though the change is simple, I see some problems:\\n\\n```\\n+\\t\\t\\t/*\\n+\\t\\t\\t * We reach this point only if track_commit_timestamp is enabled.\\n+\\t\\t\\t * Therefore, localts must contain a valid timestamp.\\n+\\t\\t\\t */\\n+\\t\\t\\tAssert(localts);\\n```\\n\\n1. The same code appears twice, so kinda redundant.\\n2. The comment is unclear. It asserts localts, but the comment talks about GUC track_commit_timestamp.\\n3. Assert(localts) technically works, because C treat un-zero integer as true, but as we are check localts is valid, it's better to be explicit as Assert(localts != 0).\\n\\nSo, I would suggest add the assert in the very beginning of the function as:\\n```\\n/*\\n * UPDATE_ORIGIN_DIFFERS and DELETE_ORIGIN_DIFFERS conflicts are only\\n * reported when track_commit_timestamp is enabled, and a valid local\\n * commit timestamp is available for the conflicting row.\\n */\\nAssert(type != CT_UPDATE_ORIGIN_DIFFERS && type != CT_DELETE_ORIGIN_DIFFERS || localts != 0);\\n\\n```\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"> On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > Dear Shveta, > > Thanks for ideas, I prefer first one. Also, pgindent told me that Line","historyId":"5951","internalDate":"1769086771000","receivedAtUtc":"2026-01-22T12:59:31.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	The discussion centers on a patch that adds assertions to ensure timestamp availability for UPDATE_ORIGIN_DIFFERS and DELETE_ORIGIN_DIFFERS conflicts in PostgreSQL logical replication. Shveta initially approved the patch after Hayato Kuroda addressed pgindent formatting requirements. However, Chao Li identified several issues with the current approach: the assertion code appears redundantly in two locations, the comment is unclear about the relationship between track_commit_timestamp GUC and localts validation, and the assertion should explicitly check "localts != 0" rather than just "Assert(localts)". Chao suggests consolidating the logic into a single assertion at the function's beginning with clearer commentary explaining that these conflict types only occur when track_commit_timestamp is enabled and valid local timestamps are available. The patch requires revision to address these concerns.	2026-01-22 12:59:31+00	\N
6	19be5ce498ae0e5b	[PATCH] psql: add \\dcs to list all constraints	["alvherre@kurilemu.de","jim.jones@uni-muenster.de","li.evan.chao@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19be5ce498ae0e5b","messageId":"<CAOKkKFuL-VGw+hUSdXwwnONB=t4BU+x6OJ38ian4XgJNDStAZg@mail.gmail.com>","subject":"Re: [PATCH] psql: add \\\\dcs to list all constraints","body":"Hi Chao, Álvaro, and all,\\n\\n>>I agree with another reviewer that said that having exec_command_d()\\n>>check only the third char is kinda pointless.  Just let\\n>>listConstraints() check everything seems easiest and more consistent.\\n>\\n>As I mentioned in a previous email, the reason exec_command_d() only\\n>checks the third character is that it follows the same implementation\\n>pattern as other existing commands.\\n>\\n>While I agree that this could be improved, since the current behavior is\\n>consistent with other commands, I do not consider it critical at the moment.\\n>If I were to change it, I would likely postpone that improvement to a later\\n>patch.\\n\\nAfter reviewing the code, I realized that the comment about passing\\neverything to listconstraints() instead of just checking the third string\\nwas correct. Therefore, I updated the code accordingly.\\nThanks to Chao and Alvaro for their comments.\\n\\nI created the new patch (v8).\\n\\nOther fixes included:\\n- Updated the documentation to clarify what the pattern string matches.\\n- Modified the case statement to use a predefined variable when converting\\n  contypes to strings.\\n\\nPlease find the attached file.\\n\\nThanks,\\nTatsuro Yamada\\n","threadId":"19be5ce498ae0e5b","snippet":"Hi Chao, Álvaro, and all, >>I agree with another reviewer that said that having exec_command_d() >>check only the third char is kinda pointless. Just let >>listConstraints() check","historyId":"5955","internalDate":"1769087032000","receivedAtUtc":"2026-01-22T13:03:52.000Z","from":"Tatsuro Yamada <yamatattsu@gmail.com>"}]	The discussion focuses on a proposed psql patch adding a `\\dcs` command to list database constraints. A key implementation detail was debated: whether `exec_command_d()` should only check the third character (consistent with existing commands) or pass full argument validation to `listConstraints()`. Initially, the patch author defended the third-character approach for consistency, but after review acknowledged the feedback was correct. Version 8 of the patch was created with updated argument handling, allowing `listConstraints()` to perform complete validation. Additional improvements include clarified documentation explaining what the pattern string matches and modified case statements using predefined variables when converting constraint types to strings. The patch appears ready for further review.	2026-01-22 13:03:52+00	\N
6	19be6149ae076a65	CREATE TABLE LIKE INCLUDING TRIGGERS	["jian.universality@gmail.com","x4mmm@yandex-team.ru"]	[{"id":"19be6149ae076a65","messageId":"<CAN4CZFNPE_UeTEy5TH9wwc6mBAtX7vnBhLSL47jRiHXA=6yXjQ@mail.gmail.com>","subject":"Re: CREATE TABLE LIKE INCLUDING TRIGGERS","body":"> > Shouldn't this preserve the enabled state of the triggers, or if it\\n> > doesn't, should the documentation include this limitations?\\n> >\\n>\\n> I intended to document it as ...\\n\\n\\nAfter looking into this a bit more, I am more on the side of copying\\nthis setting properly.\\n\\nThe already existing INCLUDING CONSTRAINTS copies the constraints,\\nincluding their enabled/disabled status, correctly marking them\\ndisabled if a CHECK constraint is defined but not enforced. Wouldn't\\nit be strange for INCLUDING TRIGGERS to work differently?\\n\\nFrom the test suite:\\n\\nCREATE TABLE ctlt1_inh (LIKE ctlt1 INCLUDING CONSTRAINTS INCLUDING\\nCOMMENTS) INHERITS (ctlt1);\\n\\\\d+ ctlt1_inh\\n                                Table \\"public.ctlt1_inh\\"\\n Column | Type | Collation | Nullable | Default | Storage  | Stats\\ntarget | Description\\n--------+------+-----------+----------+---------+----------+--------------+-------------\\n a      | text |           | not null |         | main     |              | A\\n b      | text |           |          |         | extended |              | B\\nCheck constraints:\\n    \\"cc\\" CHECK (length(b) > 100)\\n    \\"ctlt1_a_check\\" CHECK (length(a) > 2)\\n    \\"ctlt1_b_check\\" CHECK (length(b) > 100) NOT ENFORCED\\nNot-null constraints:\\n    \\"ctlt1_a_not_null\\" NOT NULL \\"a\\" (local, inherited)\\nInherits: ctlt1\\n\\n\\n","threadId":"19be6149ae076a65","snippet":"> > Shouldn't this preserve the enabled state of the triggers, or if it > > doesn't, should the documentation include this limitations? > > > > I intended to document it","historyId":"5957","internalDate":"1769091645000","receivedAtUtc":"2026-01-22T14:20:45.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	The discussion centers on whether CREATE TABLE LIKE INCLUDING TRIGGERS should preserve the enabled/disabled state of triggers when copying them to a new table. Initially, there was consideration to document this as a limitation, but after further analysis, the consensus shifts toward copying the trigger state properly. The key argument is consistency with existing behavior: INCLUDING CONSTRAINTS already correctly copies constraint enabled/disabled status, including marking CHECK constraints as disabled when not enforced. The participant argues it would be inconsistent for INCLUDING TRIGGERS to behave differently. Test suite examples demonstrate how INCLUDING CONSTRAINTS preserves states like "NOT ENFORCED" for check constraints. The discussion suggests implementing proper state preservation for triggers to maintain consistency with the existing constraint copying mechanism.	2026-01-22 14:20:45+00	\N
6	19be54eb66f3b399	SQL Property Graph Queries (SQL/PGQ)	["ajay.pal.k@gmail.com","amitlangote09@gmail.com","ashutosh.bapat.oss@gmail.com","assam258@gmail.com","imran.zhir@gmail.com","peter@eisentraut.org","vik@postgresfriends.org","zhjwpku@gmail.com"]	[{"id":"19be54eb66f3b399","messageId":"<CABRHmyvnDbm1s7ZZNzU9=XXzHRS41t3uMu9bezKhXeWymAC-Cg@mail.gmail.com>","subject":"Re: SQL Property Graph Queries (SQL/PGQ)","body":"Observation on patch v20260113-0001: GRAPH_TABLE queries are bypassing\\nRow-Level Security checks. A low_priv_user is able to access sensitive\\ndata across the entire table, even though the RLS policy should\\nrestrict the result set to one non-sensitive row.\\n\\nreproducible case:-\\n\\nCREATE TABLE parent_node (id int PRIMARY KEY, secret text);\\nCREATE TABLE child_node () INHERITS (parent_node);\\n\\nINSERT INTO child_node VALUES (1, 'Sensitive');\\nINSERT INTO child_node VALUES (2, 'not Sensitive');\\n\\nCREATE ROLE low_priv_user;\\nGRANT SELECT ON parent_node TO low_priv_user;\\nGRANT SELECT ON child_node TO low_priv_user;\\n\\nALTER TABLE child_node ENABLE ROW LEVEL SECURITY;\\n-- Policy: user cannot see rows where secret contains 'Sensitive'\\nCREATE POLICY p_hide_sensitive ON child_node TO low_priv_user USING\\n(secret !~ 'Sensitive');\\n\\nCREATE PROPERTY GRAPH security_graph VERTEX TABLES (parent_node);\\nGRANT SELECT ON PROPERTY GRAPH security_graph TO low_priv_user;\\n\\n-- TEST: As low_priv_user, this query should return 0 rows.\\nSET ROLE low_priv_user;\\npostgres=> SELECT * FROM GRAPH_TABLE (security_graph MATCH (n) COLUMNS\\n(n.secret));\\n    secret\\n---------------\\n Sensitive\\n not Sensitive\\n(2 rows)\\n\\nThanks\\nAjay\\n\\nOn Tue, Jan 13, 2026 at 9:44 PM Ashutosh Bapat\\n<ashutosh.bapat.oss@gmail.com> wrote:\\n>\\n> On Tue, Jan 13, 2026 at 3:53 PM Peter Eisentraut <peter@eisentraut.org> wrote:\\n> >\\n> > I have a small fixup patch for your 20260102 patches, attached.\\n> >\\n> > - needs additional #include because of recent changes elsewhere\\n> > - copyright year updates\\n> > - various typos\\n> > - some style changes related to palloc APIs\\n>\\n> All changes look good.\\n>\\n> Looks like you have reviewed patches 0002-onwards. I removed 0004\\n> which was erroneously removing the | handling from ecpg lexer as you\\n> pointed out earlier. Squashed all other patches along with your small\\n> fixup patch. Attached is the resultant single patch.\\n>\\n> --\\n> Best Wishes,\\n> Ashutosh Bapat\\n\\n\\n","threadId":"19be54eb66f3b399","snippet":"Observation on patch v20260113-0001: GRAPH_TABLE queries are bypassing Row-Level Security checks. A low_priv_user is able to access sensitive data across the entire table, even though the RLS policy","historyId":"5949","internalDate":"1769078676000","receivedAtUtc":"2026-01-22T10:44:36.000Z","from":"Ajay Pal <ajay.pal.k@gmail.com>"},{"id":"19be590843b6fa22","messageId":"<CAAAe_zCfUVeSQSEEW3bAvof1XEs-epS9FTJ78_E3dykYZ9qCdA@mail.gmail.com>","subject":"Re: SQL Property Graph Queries (SQL/PGQ)","body":"Hi Ajay,\\n\\nI looked into this and it appears to be expected PostgreSQL behavior rather\\nthan a GRAPH_TABLE-specific issue.\\n\\n2026년 1월 22일 (목) PM 7:44, Ajay Pal <ajay.pal.k@gmail.com>님이 작성:\\n\\n> Observation on patch v20260113-0001: GRAPH_TABLE queries are bypassing\\n> Row-Level Security checks. A low_priv_user is able to access sensitive\\n> data across the entire table, even though the RLS policy should\\n> restrict the result set to one non-sensitive row.\\n>\\n> reproducible case:-\\n>\\n> CREATE TABLE parent_node (id int PRIMARY KEY, secret text);\\n> CREATE TABLE child_node () INHERITS (parent_node);\\n>\\n> INSERT INTO child_node VALUES (1, 'Sensitive');\\n> INSERT INTO child_node VALUES (2, 'not Sensitive');\\n>\\n> CREATE ROLE low_priv_user;\\n> GRANT SELECT ON parent_node TO low_priv_user;\\n> GRANT SELECT ON child_node TO low_priv_user;\\n>\\n> ALTER TABLE child_node ENABLE ROW LEVEL SECURITY;\\n> -- Policy: user cannot see rows where secret contains 'Sensitive'\\n> CREATE POLICY p_hide_sensitive ON child_node TO low_priv_user USING\\n> (secret !~ 'Sensitive');\\n>\\n> CREATE PROPERTY GRAPH security_graph VERTEX TABLES (parent_node);\\n> GRANT SELECT ON PROPERTY GRAPH security_graph TO low_priv_user;\\n>\\n> -- TEST: As low_priv_user, this query should return 0 rows.\\n> SET ROLE low_priv_user;\\n> postgres=> SELECT * FROM GRAPH_TABLE (security_graph MATCH (n) COLUMNS\\n> (n.secret));\\n>     secret\\n> ---------------\\n>  Sensitive\\n>  not Sensitive\\n> (2 rows)\\n>\\n\\nRunning a plain SQL query on the same setup shows identical results:\\n\\nSELECT secret FROM parent_node;\\n    secret\\n---------------\\n Sensitive\\n not Sensitive\\n(2 rows)\\n\\nIn PostgreSQL, when querying a parent table, child table's RLS policies are\\nnot applied - only the parent's policies take effect. This is by design.\\n\\nThis behavior is tested in src/test/regress/sql/rowsecurity.sql (lines\\n374-414).\\n\\nThe fix would be to enable RLS on parent_node instead of child_node.\\n\\n\\n> Thanks\\n> Ajay\\n>\\n> On Tue, Jan 13, 2026 at 9:44 PM Ashutosh Bapat\\n> <ashutosh.bapat.oss@gmail.com> wrote:\\n> >\\n> > On Tue, Jan 13, 2026 at 3:53 PM Peter Eisentraut <peter@eisentraut.org>\\n> wrote:\\n> > >\\n> > > I have a small fixup patch for your 20260102 patches, attached.\\n> > >\\n> > > - needs additional #include because of recent changes elsewhere\\n> > > - copyright year updates\\n> > > - various typos\\n> > > - some style changes related to palloc APIs\\n> >\\n> > All changes look good.\\n> >\\n> > Looks like you have reviewed patches 0002-onwards. I removed 0004\\n> > which was erroneously removing the | handling from ecpg lexer as you\\n> > pointed out earlier. Squashed all other patches along with your small\\n> > fixup patch. Attached is the resultant single patch.\\n> >\\n> > --\\n> > Best Wishes,\\n> > Ashutosh Bapat\\n>\\n\\nThanks,\\nHenson\\n","threadId":"19be54eb66f3b399","snippet":"Hi Ajay, I looked into this and it appears to be expected PostgreSQL behavior rather than a GRAPH_TABLE-specific issue. 2026년 1월 22일 (목) PM 7:44, Ajay Pal <ajay.pal.k@gmail.com>님이 작성: Observation","historyId":"5949","internalDate":"1769082990000","receivedAtUtc":"2026-01-22T11:56:30.000Z","from":"Henson Choi <assam258@gmail.com>"},{"id":"19be63016674e4e3","messageId":"<CAExHW5uNa3m0bJtw4oJVh8=5Or71H4TDH0f5Mgz3CFf5B2YMmg@mail.gmail.com>","subject":"Re: SQL Property Graph Queries (SQL/PGQ)","body":"On Thu, Jan 22, 2026 at 5:26 PM Henson Choi <assam258@gmail.com> wrote:\\n>\\n> Hi Ajay,\\n>\\n> I looked into this and it appears to be expected PostgreSQL behavior rather than a GRAPH_TABLE-specific issue.\\n\\n+1. This behaviour is documented in [1]\\n\\n\\"\\nInherited queries perform access permission checks on the parent table\\nonly. Thus, for example, granting UPDATE permission on the cities\\ntable implies permission to update rows in the capitals table as well,\\nwhen they are accessed through cities. This preserves the appearance\\nthat the data is (also) in the parent table. But the capitals table\\ncould not be updated directly without an additional grant. In a\\nsimilar way, the parent table's row security policies (see Section\\n5.9) are applied to rows coming from child tables during an inherited\\nquery. A child table's policies, if any, are applied only when it is\\nthe table explicitly named in the query; and in that case, any\\npolicies attached to its parent(s) are ignored.\\n\\"\\n\\n[1] https://www.postgresql.org/docs/current/ddl-inherit.html#:~:text=In%20a%20similar%20way%2C%20the%20parent%20table's,policies%20attached%20to%20its%20parent(s)%20are%20ignored.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n","threadId":"19be54eb66f3b399","snippet":"On Thu, Jan 22, 2026 at 5:26 PM Henson Choi <assam258@gmail.com> wrote: > > Hi Ajay, > > I looked into this and it appears to be expected PostgreSQL behavior rather than a GRAPH_TABLE","historyId":"5949","internalDate":"1769093446000","receivedAtUtc":"2026-01-22T14:50:46.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"}]	Ajay Pal reported that GRAPH_TABLE queries in the SQL/PGQ patch v20260113-0001 appear to bypass Row-Level Security (RLS) checks, allowing a low-privilege user to access sensitive data that should be restricted by RLS policies. He provided a reproducible test case showing that a GRAPH_TABLE query returns all rows from a child table despite an RLS policy that should filter out sensitive rows. However, Henson Choi investigated and determined this is expected PostgreSQL behavior rather than a GRAPH_TABLE-specific issue. When querying a parent table, child table RLS policies are not applied - only the parent's policies take effect. Ashutosh Bapat confirmed this behavior is documented in PostgreSQL's inheritance documentation, noting that parent table row security policies apply to rows from child tables during inherited queries, while child table policies are ignored. The solution would be enabling RLS on the parent table instead of the child table.	2026-01-22 14:50:46+00	\N
6	19be64c7d5124d90	SQL:2011 Application Time Update & Delete	["li.evan.chao@gmail.com","pj@illuminatedcomputing.com","reshkekirill@gmail.com"]	[{"id":"19be64c7d5124d90","messageId":"<4606deaa-7d65-4f22-8a78-356c3180be9d@eisentraut.org>","subject":"Re: SQL:2011 Application Time Update & Delete","body":"I have committed the pg_range patch.\\n\\nOn 19.01.26 19:33, Paul A Jungwirth wrote:\\n> Do we want a regress test in rangetypes.sql to confirm that these are\\n> set correctly (especially for user-defined types)? I checked manually\\n> after `make installcheck`, and they look fine, but should it be in our\\n> test suite?\\n\\nI think the existing tests do that, since type_sanity runs after the rangetypes test.\\n\\n> Here is another thought I had: As we've talked about in the\\n> application-time threads, I would like temporal features to be\\n> extensible enough to support user-defined types. We almost achieve\\n> that, but we need something like a \\"type support function\\". For primary\\n> key and unique constraints, we need a way to reject invalid values like\\n> empty ranges. For foreign keys we need an intersect operator (which is\\n> not currently in pg_amop, since it is neither for search nor ordering,\\n> and isn't involved in indexes anyway). And for UPDATE/DELETE FOR\\n> PORTION OF we need a foo_minus_multi to compute the \\"temporal\\n> leftovers\\".\\n> > We could also ask for a constructor function, to build the targeted\\n> portion from the FROM/TO bounds. This is not strictly necessary, since\\n> we also have the FOR PORTION OF valid_at (...) syntax (which is used by\\n> multiranges). But it's something that would be nice to offer. In that\\n> case range types would not need these extra columns in pg_range.\\n> > But recording the constructor oids in pg_range still has inherent\\n> value, and doing it now doesn't *prevent* us from later adding a\\n> facility to get a constructor function for FOR PORTION OF bounds. So I\\n> don't think there is any downside to recording them here.\\n\\nRight, that sounds like a future project.\\n\\n\\n\\n","threadId":"19be64c7d5124d90","snippet":"I have committed the pg_range patch. On 19.01.26 19:33, Paul A Jungwirth wrote: > Do we want a regress test in rangetypes.sql to confirm that these are > set correctly (especially for user-","historyId":"5959","internalDate":"1769095314000","receivedAtUtc":"2026-01-22T15:21:54.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"},{"id":"19be64d737c189d1","messageId":"<b4216e13-0fc0-42ce-82e5-9feacd5537e1@eisentraut.org>","subject":"Re: SQL:2011 Application Time Update & Delete","body":"On 19.01.26 18:43, Kirill Reshke wrote:\\n> One stupid question from me: should we add\\n> > ````\\n>   t.typanalyze!='range_typanalyze'::regproc or t.typinput !=\\n> 'range_in'::regproc or t.typoutput != 'range_out'::regproc  or\\n> t.typreceive != 'range_recv'::regproc or typsend !=\\n> 'range_send'::regproc;\\n> > ````\\n\\nMaybe, but this seems to be outside of this patch.  There are also similar considerations for arrays, domains, etc.\\n\\n\\n","threadId":"19be64c7d5124d90","snippet":"On 19.01.26 18:43, Kirill Reshke wrote: > One stupid question from me: should we add > > ```` > t.typanalyze!='range_typanalyze'::regproc or t.typinput != > 'range_in'::","historyId":"5959","internalDate":"1769095381000","receivedAtUtc":"2026-01-22T15:23:01.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	Peter Eisentraut has committed the pg_range patch for SQL:2011 Application Time functionality. Paul Jungwirth questioned whether regression tests should verify that range type properties are set correctly for user-defined types, but Eisentraut noted existing type_sanity tests already cover this. Jungwirth discussed future extensibility needs for temporal features, including type support functions for primary/unique constraints to reject invalid values like empty ranges, intersect operators for foreign keys, and foo_minus_multi functions for UPDATE/DELETE FOR PORTION OF operations. He suggested adding constructor functions for building targeted portions from FROM/TO bounds, though acknowledged this isn't strictly necessary given existing syntax. Eisentraut agreed these represent future project opportunities. Kirill Reshke proposed adding additional validation checks for range type functions, but Eisentraut suggested this falls outside the current patch scope.	2026-01-22 15:23:01+00	\N
6	19be67781ef21b94	AIX support	["peter@eisentraut.org"]	[{"id":"19be67781ef21b94","messageId":"<SJ4PPFB81778326E995FAD5945ECF752FA1DB96A@SJ4PPFB81778326.namprd15.prod.outlook.com>","subject":"RE: AIX support","body":"Hi Peter,\\nThanks for looking into this and providing your feedback.\\n\\n> I took this idea of disabling static libraries in meson and made it a\\n> separate patch; see [0].  It looks like this patch is getting close to\\n> consensus, so we could commit it soon.  Then you could rebase your patch\\n> over it, which would make it quite a bit simpler.\\n\\n\\nThat's a great idea and will definitely help simplify the overall changes.\\n\\nOnce that patch is committed, I'll rebase my changes accordingly to align with the new approach.\\n\\n> I think in general, the meson changes are ok.  But I needed some\\n> changes, for example, your patch contains\\n\\nThanks for reviewing the changes.\\n\\n\\n> but the method .disabled() doesn't exist, it should be .found().  So I'm\\n> wondering how this patch was tested.\\n\\nYou're correct — the method .disabled() doesn't exist; it should be .found(). We initially tried to follow the same approach used for other dependencies (like docs, docs_pdf, gssapi), and didn't encounter any errors during testing.\\n\\nIn Meson, the option() class implements disabled(), but the disabler() object does not. When we ran a sample test, we observed that Meson's behaviour on AIX/Linux seems to ignore any unknown methods. As a result, the .disabled() conditional check was silently skipped, which explains why it didn't fail during our tests.\\n\\n\\n> Another patch of interest to you could be [1], which moves the\\n> MAXIMUM_ALIGNOF computation into c.h.  This should also simplify your\\n> patch.  But that patch has not received any discussion so far.\\nThis is a better approach. This would simplify the changes in both configure and meson.build.\\n\\n\\n> It's ok to split changes into multiple patches, and then recommend which parts you want\\n> reviewed first.  But we need to see at least a rough outline of the\\n> complete plan before spending significant effort on reviewing the pieces.\\nSure. We are working on the changes. I'll submit the full patch accordingly.\\n\\n\\nThanks again for your guidance and support!\\n\\n\\n\\nWarm regards,\\n\\nSriram.\\n\\n\\n","threadId":"19be67781ef21b94","snippet":"Hi Peter, Thanks for looking into this and providing your feedback. > I took this idea of disabling static libraries in meson and made it a > separate patch; see [0]. It looks like this patch is getting close to consensus, so we could commit it soon. Then you could rebase your patch","historyId":"5961","internalDate":"1769098116000","receivedAtUtc":"2026-01-22T16:08:36.000Z","from":"Srirama Kucherlapati <sriram.rk@in.ibm.com>"}]	Sriram acknowledges Peter's feedback on AIX support patch development. Peter has created a separate patch for disabling static libraries in meson that's nearing consensus, which will simplify Sriram's upcoming rebase. A critical bug was identified where `.disabled()` method was incorrectly used instead of `.found()` for meson dependency checking. Sriram explains this went unnoticed because Meson silently ignores unknown methods on AIX/Linux during testing. Peter also referenced another relevant patch moving MAXIMUM_ALIGNOF computation into c.h, which would further simplify both configure and meson.build changes. Sriram commits to submitting a complete patch with full outline as requested, acknowledging the need for reviewers to see the complete plan before investing significant review effort.	2026-01-22 16:08:36+00	\N
6	19be5f3e577e5d69	Mystery with REVOKE PRIVILEGE	["knizhnik@garret.ru","nathandbossart@gmail.com","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19be5f3e577e5d69","messageId":"<c8e166a6-173b-4637-8e94-4b447b49adab@garret.ru>","subject":"Re: Mystery with REVOKE PRIVILEGE","body":"\\nOn 21/01/2026 1:07 AM, Tom Lane wrote:\\n> Nathan Bossart <nathandbossart@gmail.com> writes:\\n>> On Tue, Jan 20, 2026 at 04:32:31PM -0500, Tom Lane wrote:\\n>>> I don't think \\"let's make select_best_grantor even more magic\\"\\n>>> is the right approach.  IMO, if there is a GRANTED BY clause,\\n>>> we should use exactly that grantor and not apply select_best_grantor\\n>>> at all.  This is, for example, certainly the behavior needed for\\n>>> pg_dump.\\n>> I started on something like that here:\\n>> \\thttps://postgr.es/m/aRYLkTpazxKhnS_w%40nathan\\n> Ah, I wonder if that discussion was lurking in my hindbrain.\\n> I just posted a different take on how to do it in that thread,\\n> but the behavioral change should be the same.\\n>\\n> \\t\\t\\tregards, tom lane\\n\\n\\nThank you.\\nFixing explicit grantor case is definitely the most critical thing.\\nAnd I completely agree with your patch.\\nBut I wonder if we do refactoring of this revoke privileges stuff, should we also provide correct (expected) behaviour in case of missing grantor specification. i.e.\\n\\n     revoke all privileges on table <T> from <role>;\\n\\nIf privileges to access this table were granted to this role by multiple grantors, then it is natural to expect that the statement above will remove all such grants and so as a result <role> can not access this table any more, rather than try to find best grantor and finally still leave privileges for this role, isn't it?\\n\\n\\n\\n\\n","threadId":"19be5f3e577e5d69","snippet":"On 21/01/2026 1:07 AM, Tom Lane wrote: > Nathan Bossart <nathandbossart@gmail.com> writes: >> On Tue, Jan 20, 2026 at 04:32:31PM -0500, Tom Lane wrote: >>> I don't think","historyId":"5956","internalDate":"1769089509000","receivedAtUtc":"2026-01-22T13:45:09.000Z","from":"Konstantin Knizhnik <knizhnik@garret.ru>"},{"id":"19be68fabb9e1531","messageId":"<2716313.1769099716@sss.pgh.pa.us>","subject":"Re: Mystery with REVOKE PRIVILEGE","body":"Konstantin Knizhnik <knizhnik@garret.ru> writes:\\n> But I wonder if we do refactoring of this revoke privileges stuff, \\n> should we also provide correct (expected) behaviour in case of missing \\n> grantor specification. i.e.\\n\\n>       revoke all privileges on table <T> from <role>;\\n\\n> If privileges to access this table were granted to this role by multiple \\n> grantors, then it is natural to expect that the statement above will \\n> remove all such grants and so as a result <role> can not access this \\n> table any more, rather than try to find best grantor and finally still \\n> leave privileges for this role, isn't it?\\n\\nUnfortunately, the SQL spec is quite clear that REVOKE revokes only\\nprivileges granted directly by the calling user (or the GRANTED BY\\nrole, if that's given).  We're already far outside the spec by\\nallowing select_best_grantor to locate an inherited role to do the\\nrevoke as.  I can't see reinterpreting it as \\"revoke all privileges\\ngranted by anybody\\", even assuming that the calling user has\\nsufficient permissions to do that.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19be5f3e577e5d69","snippet":"Konstantin Knizhnik <knizhnik@garret.ru> writes: > But I wonder if we do refactoring of this revoke privileges stuff, > should we also provide correct (expected) behaviour in case of","historyId":"5956","internalDate":"1769099716000","receivedAtUtc":"2026-01-22T16:35:16.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	The discussion focuses on fixing PostgreSQL's REVOKE PRIVILEGE behavior when an explicit GRANTED BY clause is specified. Tom Lane proposes that when GRANTED BY is explicitly provided, the system should use exactly that grantor without applying select_best_grantor logic, which is essential for pg_dump functionality. Nathan Bossart had started work on a similar approach. Konstantin Knizhnik agrees with fixing the explicit grantor case but suggests also addressing the behavior when no grantor is specified - proposing that "REVOKE ALL PRIVILEGES" should remove all grants from multiple grantors, completely revoking access. However, Tom Lane responds that the SQL specification clearly states REVOKE only removes privileges granted directly by the calling user (or specified GRANTED BY role), and reinterpreting it as "revoke all privileges granted by anybody" would be problematic, even if the user had sufficient permissions.	2026-01-22 16:35:16+00	\N
6	19be6a499e8b09ae	Likely undefined behavior with some flexible arrays	["tgl@sss.pgh.pa.us","x4mmm@yandex-team.ru"]	[{"id":"19be6a499e8b09ae","messageId":"<yjtlufdn6kaoctydjrryzt267xnls2t4lizslnbgqzhtsnohkj@fvvr3dbtvbrc>","subject":"Re: Likely undefined behavior with some flexible arrays","body":"Hi,\\n\\nOn 2026-01-22 11:09:37 +0500, Andrey Borodin wrote:\\n> > On 22 Jan 2026, at 06:56, Andres Freund <andres@anarazel.de> wrote:\\n> > \\n> > It'd be nice to teach\\n> > the compile that palloc allocates, to a) get compiler warnings for things like\\n> > use-after-free b) warnings for things like access-beyond-allocation.\\n> \\n> Is there any chance to teach a compiler about short lived memory contexts?\\n\\nI doubt that we can teach static analysis that anytime soon - I think you'd\\nneed a compiler plugin for that. However I'd already be happy with getting\\nwarnings for obvious stuff like using variables after being pfreed (even\\nindirectly) or running off the end of an allocation.\\n\\nWe certainly could improve the sanitizer integration with memory contexts, but\\nthat obviously requires reaching the relevant paths in a problematic scenario\\nto be effective.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19be6a499e8b09ae","snippet":"Hi, On 2026-01-22 11:09:37 +0500, Andrey Borodin wrote: > > On 22 Jan 2026, at 06:56, Andres Freund <andres@anarazel.de> wrote: > > > > It'd be nice to teach > > the","historyId":"5963","internalDate":"1769101094000","receivedAtUtc":"2026-01-22T16:58:14.000Z","from":"Andres Freund <andres@anarazel.de>"}]	The discussion centers on improving compiler detection of undefined behavior related to flexible arrays in PostgreSQL. Andres Freund suggests teaching the compiler about palloc allocations to generate warnings for use-after-free bugs and access-beyond-allocation errors. Andrey Borodin asks about extending this to short-lived memory contexts. Freund acknowledges that teaching static analysis about memory contexts would likely require a compiler plugin, which is not feasible in the near term. However, he emphasizes that even basic warnings for obvious issues like using variables after pfree or buffer overruns would be valuable. He also mentions that improving sanitizer integration with memory contexts could help, though this approach only catches problems when the problematic code paths are actually executed during testing.	2026-01-22 16:58:14+00	\N
6	19be6ab0ee643388	Patch: dumping tables data in multiple chunks in pg_dump	["ashutosh.bapat.oss@gmail.com","dgrowleyml@gmail.com","nathandbossart@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be6ab0ee643388","messageId":"<CAMT0RQQ8DX+K7OTw3Lg+Yp2ew8TsZduiqtPszfiBixcpxKbz-A@mail.gmail.com>","subject":"Re: Patch: dumping tables data in multiple chunks in pg_dump","body":"Fixing all the warnings\\n\\n\\nOn Wed, Jan 21, 2026 at 2:05 PM Hannu Krosing <hannuk@google.com> wrote:\\n>\\n> Please find the latest patch attached which incorporates the feedback received.\\n>\\n> * changed flag name to --max-table-segment-pages\\n> * added check for amname = \\"heap\\"\\n> * switched to using of\\n> pg_relation_size(c.oid)/current_setting('block_size')::int when\\n> --max-table-segment-pages is set\\n> * added option_parse_uint32(...) to be used for full range of pages numbers\\n> * The COPY SELECTs now use <= , BETWEEN or >= depending on the segment position\\n>\\n> * added documentation\\n>\\n> * TESTS:\\n>   * added simple chunked dump and restore test\\n>   * added a WARNING with count and table data hash to source and\\n> chunked restore database\\n>\\n> I left in the boolean to indicate if this is a full table or chunk\\n> (was named chunking, nor is_segment)\\n>\\n> An a lternative would be to use an expression like (td->startPage != 0\\n> || td->endPage != InvalidBlockNumber) whenever td->is_segment is\\n> needed\\n>\\n> If you insist on not having a separate structure member we could turn\\n> this into something like this\\n>\\n> #define is_segment(td) ((td->startPage != 0 || td->endPage !=\\n> InvalidBlockNumber))\\n>\\n> and then use is_segment(td) instead of td->is_segment where needed.\\n","threadId":"19be6ab0ee643388","snippet":"Fixing all the warnings On Wed, Jan 21, 2026 at 2:05 PM Hannu Krosing <hannuk@google.com> wrote: > > Please find the latest patch attached which incorporates the feedback received. >","historyId":"4697","internalDate":"1769101504000","receivedAtUtc":"2026-01-22T17:05:04.000Z","from":"Hannu Krosing <hannuk@google.com>"}]	The patch for enabling chunked table dumps in pg_dump has been updated to address previous feedback. Key changes include renaming the flag to --max-table-segment-pages, adding heap table validation through amname checking, and switching to pg_relation_size calculations for page counting. The implementation now uses appropriate COPY SELECT operators (<=, BETWEEN, >=) based on segment position and includes option_parse_uint32 for handling the full range of page numbers. Documentation and tests have been added, including a chunked dump/restore test with hash verification warnings. The patch retains a boolean is_segment indicator, though alternatives using expression-based detection were proposed as potential replacements.	2026-01-22 17:05:04+00	\N
6	19be4dac85c04761	ReadRecentBuffer() doesn't scale well	["amitlangote09@gmail.com","andres@anarazel.de","ianilyasov@outlook.com","thomas.munro@gmail.com"]	[{"id":"19be4dac85c04761","messageId":"<ZR5P278MB182126C2A7ED081EF69E8644CD96A@ZR5P278MB1821.CHEP278.PROD.OUTLOOK.COM>","subject":"RE: ReadRecentBuffer() doesn't scale well","body":"Hello hackers!\\n\\nSpeaking of this patch, I've done a benchmark test on a master branch on 34740b90bc123d645a3a71231b765b778bdcf049 commit with a patch by Thomas Munro: https://www.postgresql.org/message-id/attachment/148040/0002-Use-ReadRecentBuffer-for-btree-root-page.patch and without it. The configuration of the server was 96 cores and 1.5 TB of RAM.\\n\\nThe steps I did were:\\n1. Change the NUM_BUFFER_PARTITIONS to 1024:\\n/* Number of partitions of the shared buffer mapping hashtable */\\n#define NUM_BUFFER_PARTITIONS  1024\\n\\n2. Build with O2 optimization:\\nCFLAGS='-g -O2 -fno-omit-frame-pointer' ./configure\\n\\n3. Set up postgresql.conf to:\\nmax_connections = 300\\nshared_buffers = 2GB\\n\\n4. Run a pgbench:\\npsql -U postgres -c \\"CREATE DATABASE test;\\"\\npgbench -i -s100 -IdtGpv --unlogged-tables -U postgres -d test\\npsql -U postgres -d test -c \\"create extension pg_prewarm;\\"\\n./bin/pgbench -n -j96 -c300 -T30 -P1 -M prepared -f script.sql -d test\\n\\nscript.sql is attached.\\nThe idea was to address to different blocks in index and see whether it will affect PinBuffer efficiency.\\n\\nUsing a Wilcoxon signed-rank test I showed myself on 10 runs for each version that patch by Thomas speeds up the TPS by median 17k TPS in this benchmark with the possibility of error less than 5% on this configuration. Adding +34% TPS comparing the vanilla.\\n\\nMy conclusion is that this patch looks excellent on multicore systems and it would be great if it is committed.\\nAlso I have a question if committed whether this patch would be backported to 18th version?\\n\\nKind regards,\\nIan Ilyasov.","threadId":"19be4dac85c04761","snippet":"Hello hackers! Speaking of this patch, I've done a benchmark test on a master branch on 34740b90bc123d645a3a71231b765b778bdcf049 commit with a patch by Thomas Munro: https://www.postgresql.org/","historyId":"5939","internalDate":"1769071076000","receivedAtUtc":"2026-01-22T08:37:56.000Z","from":"Ilyasov Ian <ianilyasov@outlook.com>"},{"id":"19be6a27cf366076","messageId":"<wbmtz3b4cm3zwcsfunymbaauu7dlwbimzma7tsyjtg3npqy546@tj6oqcktgjvh>","subject":"Re: ReadRecentBuffer() doesn't scale well","body":"Hi,\\n\\nOn 2026-01-22 08:37:56 +0000, Ilyasov Ian wrote:\\n> Speaking of this patch, I've done a benchmark test on a master branch on 34740b90bc123d645a3a71231b765b778bdcf049 commit with a patch by Thomas Munro: https://www.postgresql.org/message-id/attachment/148040/0002-Use-ReadRecentBuffer-for-btree-root-page.patch and without it. The configuration of the server was 96 cores and 1.5 TB of RAM.\\n\\nWhich patch specifically do you mean?\\n\\nAn evolved version of 0001 from\\nhttps://postgr.es/m/CA%2BhUKGJ8N_DRSB0YioinWjS2ycMpmOLy32mbBqVVztwBvXgyJA%40mail.gmail.com\\nhas already been applied (see 819dc118c0f).\\n\\nSo I guess you were testing 0002 from that email?\\n\\nOr were you testing 0002 from\\nhttps://postgr.es/m/CA%2BhUKGLMFtNqei9nfcJy2SQMLWyYuO9E8NLYrb%3D4Gs1HgkAS7Q%40mail.gmail.com\\nwhich is a completely different patch?\\n\\n\\n> My conclusion is that this patch looks excellent on multicore systems and it would be great if it is committed.\\n> Also I have a question if committed whether this patch would be backported to 18th version?\\n\\nWe don't backpatch performance improvements unless they are addressing\\nperformance issues that are so severe that they basically amount to a bug.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19be4dac85c04761","snippet":"Hi, On 2026-01-22 08:37:56 +0000, Ilyasov Ian wrote: > Speaking of this patch, I've done a benchmark test on a master branch on 34740b90bc123d645a3a71231b765b778bdcf049 commit with a patch by","historyId":"5939","internalDate":"1769100955000","receivedAtUtc":"2026-01-22T16:55:55.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19be6acf1d9d4942","messageId":"<ZR5P278MB182101CD2C00CE5713CB7902CD97A@ZR5P278MB1821.CHEP278.PROD.OUTLOOK.COM>","subject":"RE: ReadRecentBuffer() doesn't scale well","body":"> Or were you testing 0002 from\\n> https://postgr.es/m/CA%2BhUKGLMFtNqei9nfcJy2SQMLWyYuO9E8NLYrb%3D4Gs1HgkAS7Q%40mail.gmail.com\\n> which is a completely different patch?\\n\\nYes, I tested the aforementioned patch under the name: 0002-Use-ReadRecentBuffer-for-btree-root-page.patch in this thread.\\n\\n> We don't backpatch performance improvements unless they are addressing\\n> performance issues that are so severe that they basically amount to a bug.\\n\\nThank you for your answer. Will keep it in mind for the future.\\n\\nKind regards,\\nIan Ilyasov.\\n\\n","threadId":"19be4dac85c04761","snippet":"> Or were you testing 0002 from > https://postgr.es/m/CA%2BhUKGLMFtNqei9nfcJy2SQMLWyYuO9E8NLYrb%3D4Gs1HgkAS7Q%40mail.gmail.com > which is a completely different patch? Yes, I tested the","historyId":"5939","internalDate":"1769101639000","receivedAtUtc":"2026-01-22T17:07:19.000Z","from":"Ilyasov Ian <ianilyasov@outlook.com>"}]	Ian Ilyasov tested Thomas Munro's patch "0002-Use-ReadRecentBuffer-for-btree-root-page.patch" on a 96-core, 1.5TB RAM system using PostgreSQL master branch. The benchmark involved modifying NUM_BUFFER_PARTITIONS to 1024, configuring 2GB shared_buffers with 300 max_connections, and running pgbench with 96 jobs and 300 clients. Using Wilcoxon signed-rank test over 10 runs, Ian found the patch increased TPS by median 17k (+34% improvement) compared to vanilla PostgreSQL. Andres Freund clarified which specific patch was tested, noting that an evolved version of a related patch (0001) was already committed as 819dc118c0f. Andres also explained that performance improvements are typically not backported to stable versions unless they address severe bugs. Ian confirmed testing the btree root page optimization patch and acknowledged the backporting policy.	2026-01-22 17:07:19+00	\N
6	19be51f046352557	Flush some statistics within running transactions	["bertranddrouvot.pg@gmail.com","masao.fujii@gmail.com","michael@paquier.xyz","samimseih@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be51f046352557","messageId":"<aXHzafdxaklDSWXp@ip-10-97-1-34.eu-west-3.compute.internal>","subject":"Re: Flush some statistics within running transactions","body":"Hi,\\n\\nOn Wed, Jan 21, 2026 at 05:41:13PM -0600, Sami Imseih wrote:\\n> Thanks for the updated patches!\\n> \\n> > No, 0003 also changes the flush mode for the database KIND. All the fields that\\n> > I mentioned are inherited from relations stats and are flushed only at transaction\\n> > boundaries (so they don't appear in pg_stat_database until the transaction\\n> > finishes). Does that make sense?\\n> \\n> yes, I understand it clearly now.\\n> \\n> But, the Note under pg_stat_database reads like this:\\n> \\n> \\"All the statistics are updated while the transactions are in progress,\\n> except for xact_commit, xact_rollback, tup_inserted, tup_updated\\n> and tup_deleted that are updated only when the transactions finish.\\"\\n> \\n> But that is not true for all pg_stat_database fields, such as session_time,\\n> active_time, idle_in_transaction_time, etc. From what I can tell some of their\\n> fields are updated when the connection is closed. For example\\n> in one session run \\"select pg_sleep(10)\\" and in another session monitor\\n> pg_stat_database.active_time. That will not be updated until the session\\n> is closed.\\n> \\n> This is because these are not relation stats, which makes sense. The\\n> Note section should elaborate more on this, right?\\n\\nYeah, so, while pgstat_database_flush_cb() is now called every second (if there\\nare pending stats), not all the stats would have their pending entries updated.\\n\\nFor example, pgstat_update_dbstats() updates some of them: xact_commit, xact_rollback,\\nblk_read_time, blk_write_time, session_time, active_time and idle_in_transaction_time\\nbut only at transaction boundaries. Indeed, pgstat_update_dbstats() is only called\\nduring pgstat_report_stat() and not during pgstat_report_anytime_stat().\\n\\nI think that we could:\\n\\n1. Update the doc as you suggest\\n\\nor\\n\\n2. Call a modified version of pgstat_update_dbstats() in pgstat_report_anytime_stat()\\nthat would update blk_read_time, blk_write_time, session_time, active_time and\\nidle_in_transaction_time but that would require an extra GetCurrentTimestamp()\\ncall.\\n\\nor\\n\\n3. Call a modified version of pgstat_update_dbstats() in pgstat_report_anytime_stat()\\nthat would update the same as in 2. except session_time then avoiding the need\\nof a GetCurrentTimestamp() extra call.\\n\\nI'm tempted to vote for 1. as I'm not sure of the added value of 2. and 3.,\\nthoughts?\\n\\nRegards,\\n\\n-- \\nBertrand Drouvot\\nPostgreSQL Contributors Team\\nRDS Open Source Databases\\nAmazon Web Services: https://aws.amazon.com\\n\\n\\n","threadId":"19be51f046352557","snippet":"Hi, On Wed, Jan 21, 2026 at 05:41:13PM -0600, Sami Imseih wrote: > Thanks for the updated patches! > > > No, 0003 also changes the flush mode for the database KIND. All the fields that >","historyId":"5946","internalDate":"1769075561000","receivedAtUtc":"2026-01-22T09:52:41.000Z","from":"Bertrand Drouvot <bertranddrouvot.pg@gmail.com>"},{"id":"19be59f0aff6b191","messageId":"<CAHGQGwHttst8tv_WWYNoGGfL1UAq4kiy6dpFXoxEkJwHMS9FtQ@mail.gmail.com>","subject":"Re: Flush some statistics within running transactions","body":"On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot\\n<bertranddrouvot.pg@gmail.com> wrote:\\n>\\n> Hi,\\n>\\n> On Thu, Jan 22, 2026 at 10:56:48AM +0900, Fujii Masao wrote:\\n> > On Thu, Jan 22, 2026 at 10:41 AM Sami Imseih <samimseih@gmail.com> wrote:\\n> > >\\n> > > Sure, Bertrand mentioned early in the thread that the anytime flushes\\n> > > could be made configurable. Perhaps that is a good idea where we can\\n> > > default with something large like 10s intervals for anytime flushes, but allow\\n> > > the user to configure a more frequent flushes ( although I would think\\n> > > that 1 sec is the minimum we should allow ).\\n> >\\n> > +1 on adding an option to control the interval. With a fixed interval\\n> > (for example, 1s), log_lock_waits messages could be emitted that frequently,\\n> > which may be annoying for some users.\\n> >\\n> > Of course, it would be even better if these periodic wakeups did not trigger\\n> > log_lock_waits messages at all, though.\\n>\\n> pgstat_report_anytime_stat() is called with the force parameter set to false,\\n> means that the flushes are done with nowait = true means that LWLockConditionalAcquire()\\n> is used. In that case, do you still see cases where log_lock_waits messages could\\n> be triggered due to the new flush?\\n\\nI haven't read the patch in detail yet, but after applying patch 0001 and\\ncausing a lock wait (for example, using the steps below), I observed that\\nlog_lock_waits messages are emitted every second.\\n\\n    [session 1]\\n    create table tbl as select id from generate_series(1, 10) id;\\n    begin;\\n    select * from tbl where id = 1 for update;\\n\\n    [session 2]\\n    begin;\\n    select * from tbl where id = 1 for update;\\n\\nWith this setup, the following messages were logged once per second:\\n\\n    LOG:  process 72199 still waiting for ShareLock on transaction 771\\nafter 63034.119 ms\\n    DETAIL:  Process holding the lock: 72190. Wait queue: 72199.\\n\\nRegards,\\n\\n-- \\nFujii Masao\\n\\n\\n","threadId":"19be51f046352557","snippet":"On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot <bertranddrouvot.pg@gmail.com> wrote: > > Hi, > > On Thu, Jan 22, 2026 at 10:56:48AM +0900, Fujii Masao wrote: > > On Thu, Jan","historyId":"5946","internalDate":"1769083938000","receivedAtUtc":"2026-01-22T12:12:18.000Z","from":"Fujii Masao <masao.fujii@gmail.com>"},{"id":"19be698fe769047d","messageId":"<aXJUK90lKXw3wrZn@ip-10-97-1-34.eu-west-3.compute.internal>","subject":"Re: Flush some statistics within running transactions","body":"Hi,\\n\\nOn Thu, Jan 22, 2026 at 09:12:18PM +0900, Fujii Masao wrote:\\n> On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot\\n> <bertranddrouvot.pg@gmail.com> wrote:\\n> >\\n> > pgstat_report_anytime_stat() is called with the force parameter set to false,\\n> > means that the flushes are done with nowait = true means that LWLockConditionalAcquire()\\n> > is used. In that case, do you still see cases where log_lock_waits messages could\\n> > be triggered due to the new flush?\\n> \\n> I haven't read the patch in detail yet, but after applying patch 0001 and\\n> causing a lock wait (for example, using the steps below), I observed that\\n> log_lock_waits messages are emitted every second.\\n> \\n>     [session 1]\\n>     create table tbl as select id from generate_series(1, 10) id;\\n>     begin;\\n>     select * from tbl where id = 1 for update;\\n> \\n>     [session 2]\\n>     begin;\\n>     select * from tbl where id = 1 for update;\\n> \\n> With this setup, the following messages were logged once per second:\\n> \\n>     LOG:  process 72199 still waiting for ShareLock on transaction 771\\n> after 63034.119 ms\\n>     DETAIL:  Process holding the lock: 72190. Wait queue: 72199.\\n> \\n\\nThanks!\\n\\nI see, the WaitLatch() in ProcSleep() is \\"woken up\\" every 1s due to the \\nenable_timeout_after(ANYTIME_STATS_UPDATE_TIMEOUT,...) being set unconditionally\\nin ProcessInterrupts(). We need to be more restrictive as to when to enable the\\ntimeout, I'll fix in the next version.\\n\\nRegards,\\n\\n-- \\nBertrand Drouvot\\nPostgreSQL Contributors Team\\nRDS Open Source Databases\\nAmazon Web Services: https://aws.amazon.com\\n\\n\\n","threadId":"19be51f046352557","snippet":"Hi, On Thu, Jan 22, 2026 at 09:12:18PM +0900, Fujii Masao wrote: > On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot > <bertranddrouvot.pg@gmail.com> wrote: > > > >","historyId":"5946","internalDate":"1769100331000","receivedAtUtc":"2026-01-22T16:45:31.000Z","from":"Bertrand Drouvot <bertranddrouvot.pg@gmail.com>"},{"id":"19be6bbe9d8d573e","messageId":"<CAA5RZ0vbL8fw4h7JQEuLE5JqLqVbG+7oBKkM_4eONMe=yJ=Veg@mail.gmail.com>","subject":"Re: Flush some statistics within running transactions","body":"> For example, pgstat_update_dbstats() updates some of them: xact_commit, xact_rollback,\\n> blk_read_time, blk_write_time, session_time, active_time and idle_in_transaction_time\\n> but only at transaction boundaries. Indeed, pgstat_update_dbstats() is only called\\n> during pgstat_report_stat() and not during pgstat_report_anytime_stat().\\n>\\n> I think that we could:\\n>\\n> 1. Update the doc as you suggest\\n\\nI am thinking the _time related fields are OK to be non-anytime\\nfields, since they\\nhave overhead and also they can be actively monitored from pg_stat_activity\\nif someone really needs real time information.\\n\\nThe other session related counters don't need need special consideration.\\n\\nparallel counters are anytime.\\n\\nSo, the documentation can mention the _time related fields that are flushed\\nonly at their appropriate times.\\n\\nMaybe something general like this:\\n\\n\\"Some statistics are updated while a transaction is in progress.\\nStatistics that either do\\nnot depend on transactions or require transactional consistency are\\nupdated only\\nwhen the transaction ends. Statistics that require transactional consistency\\ninclude xact_commit, xact_rollback, tup_inserted, tup_updated, and tup_deleted.\\"\\n\\nWhat do you think?\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be51f046352557","snippet":"> For example, pgstat_update_dbstats() updates some of them: xact_commit, xact_rollback, > blk_read_time, blk_write_time, session_time, active_time and idle_in_transaction_time > but only at","historyId":"5946","internalDate":"1769102609000","receivedAtUtc":"2026-01-22T17:23:29.000Z","from":"Sami Imseih <samimseih@gmail.com>"}]	The discussion focuses on a patch to flush PostgreSQL statistics within running transactions, addressing inconsistencies in pg_stat_database documentation and behavior. Bertrand Drouvot explains that while some database statistics like xact_commit and relation-based fields are flushed at transaction boundaries, timing-related fields (session_time, active_time, idle_in_transaction_time) are only updated when connections close. The patch introduces anytime statistics flushing but causes unintended side effects. Fujii Masao reports that the patch triggers log_lock_waits messages every second due to unconditional timeout enabling in ProcessInterrupts(), which wakes up WaitLatch() during lock waits. Bertrand acknowledges this issue and commits to fixing it by making timeout enabling more restrictive. Sami Imseih suggests updating documentation to clarify which statistics require transactional consistency versus those that can be updated during transactions, proposing clearer language about timing-related fields being flushed at appropriate intervals rather than continuously.	2026-01-22 17:23:29+00	\N
6	19be696a3fcf6343	Fix rounding method used to compute huge pages	["anthonin.bonnefoy@datadoghq.com"]	[{"id":"19be696a3fcf6343","messageId":"<CAO6_Xqq2vZbva0R9eQSY0p2kfksX2aP4r=+Z_q1HBYNU=m8bBg@mail.gmail.com>","subject":"Fix rounding method used to compute huge pages","body":"Hi,\\n\\nWhen computing the dynamic value of shared_memory_size_in_huge_pages,\\n(1+size_b/hp_size) is currently used. This works when size_b is not\\ndivisible by hp_size. However, it will yield an additional huge page\\nwhen size_b is divisible by hp_size.\\n\\nOn CreateAnonymousSegment's side, the allocation size is rounded up to\\nthe next required huge pages when necessary. However, there's no\\noverflow check when doing this round up.\\n\\n0001: This patch replicates CreateAnonymousSegment's rounding method\\nto InitializeShmemGUCs, only rounding up when the value is not\\ndivisible by hp_size.\\n\\n0002: This patch uses add_size in CreateAnonymousSegment when the\\nallocation size is rounded up, to check for possible overflow.\\n\\nRegards,\\nAnthonin Bonnefoy\\n","threadId":"19be696a3fcf6343","snippet":"Hi, When computing the dynamic value of shared_memory_size_in_huge_pages, (1+size_b/hp_size) is currently used. This works when size_b is not divisible by hp_size. However, it will yield an additional","historyId":"5962","internalDate":"1769100164000","receivedAtUtc":"2026-01-22T16:42:44.000Z","from":"Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com>"},{"id":"19be6c2d55989191","messageId":"<CAExHW5tSm7=dH9wnV6McXeqw5C6_Kcv1Oa3QPsroSOpeoLA8xA@mail.gmail.com>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Thu, Jan 22, 2026 at 10:13 PM Anthonin Bonnefoy\\n<anthonin.bonnefoy@datadoghq.com> wrote:\\n>\\n> Hi,\\n>\\n> When computing the dynamic value of shared_memory_size_in_huge_pages,\\n> (1+size_b/hp_size) is currently used. This works when size_b is not\\n> divisible by hp_size. However, it will yield an additional huge page\\n> when size_b is divisible by hp_size.\\n>\\n> On CreateAnonymousSegment's side, the allocation size is rounded up to\\n> the next required huge pages when necessary. However, there's no\\n> overflow check when doing this round up.\\n>\\n> 0001: This patch replicates CreateAnonymousSegment's rounding method\\n> to InitializeShmemGUCs, only rounding up when the value is not\\n> divisible by hp_size.\\n>\\n> 0002: This patch uses add_size in CreateAnonymousSegment when the\\n> allocation size is rounded up, to check for possible overflow.\\n\\nWe have similar incantation in CalculateShmemSize()\\nsize = add_size(size, 8192 - (size % 8192));\\n\\nI think we should just introduce a method ceil_size() and place it\\nnear add_size() and mul_size() and use wherever we are rounding the\\nsizes.\\nSize\\nceil_size(size, base)\\n{\\nreturn add_size(size, base - (size % base))\\n}\\n\\nInitializeShmemGUCs() also has following line, which can can be\\nreplaced with ceil_size(size_b, 1024 * 1024)\\nsize_mb = add_size(size_b, (1024 * 1024) - 1) / (1024 * 1024);\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"On Thu, Jan 22, 2026 at 10:13 PM Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com> wrote: > > Hi, > > When computing the dynamic value of shared_memory_size_in_huge_pages, > (1+","historyId":"5962","internalDate":"1769103061000","receivedAtUtc":"2026-01-22T17:31:01.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"}]	Anthonin Bonnefoy identified a bug in PostgreSQL's huge page memory computation where the formula (1+size_b/hp_size) incorrectly allocates an extra huge page when size_b is divisible by hp_size. The issue also exists in CreateAnonymousSegment which lacks overflow checking when rounding up allocation sizes. Bonnefoy proposed two patches: one to replicate CreateAnonymousSegment's rounding method in InitializeShmemGUCs (only rounding up when not divisible), and another to add overflow checking using add_size. Ashutosh Bapat suggested a broader solution by introducing a general-purpose ceil_size() function to be placed alongside existing add_size() and mul_size() functions, which could replace similar rounding patterns found in CalculateShmemSize() and other locations throughout the codebase.	2026-01-22 17:31:01+00	\N
6	19be66940c5bb07c	Inval reliability, especially for inplace updates	["andres@anarazel.de","mark.dilger@enterprisedb.com","nitinmotiani@google.com","noah@leadboat.com"]	[{"id":"19be66940c5bb07c","messageId":"<CAHgHdKvTv6knvzmtumdzAqF9_PykaUc6b-6c80VpMZEV0UuyZQ@mail.gmail.com>","subject":"Re: Inval reliability, especially for inplace updates","body":"On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote:\\n\\n> On Wed, Jan 21, 2026 at 08:59:51AM -0800, Mark Dilger wrote:\\n> > On Wed, Oct 23, 2024 at 7:54 PM Noah Misch <noah@leadboat.com> wrote:\\n> > > I'm attaching the branch-specific patches for that and for the main\\n> fix.\\n> > > Other notes from back-patching:\\n> > >\\n> > > - All branches change the ABI of PrepareToInvalidateCacheTuple(), a\\n> > > function\\n> > >   catcache.c exports for the benefit of inval.c.  No PGXN extension\\n> calls\\n> > >   that, and I can't think of a use case in extensions.\\n> >\\n> > Unfortunately, I can think of four.\\n>\\n> Those are non-PGXN extensions, right?\\n>\\n\\nRight.\\n\\nBased on your experience, I probably should encourage packagers to do an\\n> early\\n> check of the packages they build, especially if they build tableam modules\\n> not\\n> found in PGXN.  How do you see it?\\n>\\n\\nI don't know what you mean by \\"early\\".  18.2 hasn't stamped yet.  18.1\\ndoesn't have the change.  So, I'd say that I'm building pretty early, and I\\nnoticed the change will be coming in 18.2.\\n\\n\\n> > I have four Table Access Methods that\\n> > I now need to fork to be compatible with 18.0 and 18.1 on the one hand,\\n> and\\n> > 18.2 onward on the other.\\n>\\n> For what it's worth, the ABI break you quoted is the v14-v17 break, not the\\n> v18 break:\\n>\\n> - v18.2 (06b030e) is changing the CacheInvalidateHeapTupleInplace() ABI\\n> - v14-v17 (e.g. 2e58802) is changing the PrepareToInvalidateCacheTuple()\\n> ABI\\n>\\n\\nI'll have to work around both.  I maintain TAM packages going back multiple\\nmajor versions.\\n\\n\\n> > I'm sorry I didn't follow this thread before it got pushed.\\n> >\\n> > Is there a reason for doing this change in back branches?  The thread is\\n> > pretty long, and I'm struggling to find a security or stability\\n> > justification for the ABI break, but perhaps there is one.\\n>\\n> Chiefly, the fix prevents data loss that arose via losing a relhasindex,\\n> relfrozenxid, or datfrozenxid update.  (The log message of 0f69bed says\\n> \\"another backend's DDL could then update the row without incorporating the\\n> inplace update\\".)  For an example, see where that commit edits\\n> src/test/isolation/expected/inplace-inval.out.\\n>\\n\\nOh, I don't mean to question the overall purpose of the patch.  I was\\nquestioning whether it needed to have breaking changes which are mere \\"code\\ncleanup\\".  The change to CacheInvalidateHeapTupleInplace to remove the\\nunused third argument seemed inappropriate for backpatching, so I spoke up\\nbefore 18.2 is stamped.  Doing this one piece of code cleanup in the back\\nbranches will cause a lot of packaging pain for no real benefit.\\n\\n\\n-- \\n\\n*Mark Dilger*\\n","threadId":"19be66940c5bb07c","snippet":"On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote: On Wed, Jan 21, 2026 at 08:59:51AM -0800, Mark Dilger wrote: > On Wed, Oct 23, 2024 at 7:54 PM Noah Misch <noah@","historyId":"5960","internalDate":"1769097201000","receivedAtUtc":"2026-01-22T15:53:21.000Z","from":"Mark Dilger <mark.dilger@enterprisedb.com>"},{"id":"19be6cd7b0f8ed2e","messageId":"<20260122174250.bf@rfd.leadboat.com>","subject":"Re: Inval reliability, especially for inplace updates","body":"On Thu, Jan 22, 2026 at 07:53:21AM -0800, Mark Dilger wrote:\\n> On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote:\\n> > Based on your experience, I probably should encourage packagers to do an\\n> > early check of the packages they build, especially if they build tableam\\n> > modules not found in PGXN.  How do you see it?\\n> \\n> I don't know what you mean by \\"early\\".  18.2 hasn't stamped yet.  18.1\\n> doesn't have the change.  So, I'd say that I'm building pretty early, and I\\n> noticed the change will be coming in 18.2.\\n\\nI'll probably say:\\n\\n  If you've tested your packaging builds against REL_17_STABLE and\\n  REL_18_STABLE since 2025-12-16 *or* you package only modules present in\\n  PGXN, you can stop reading.\\n\\n  Mark Dilger reported non-PGXN tableam modules that needed changes to cope\\n  with back-patched signature changes in functions\\n  CacheInvalidateHeapTupleInplace() (commit 06b030e) and\\n  PrepareToInvalidateCacheTuple() (commit 2e58802).  Consider trying a rebuild\\n  against REL_17_STABLE and REL_18_STABLE now, so you learn about any similar\\n  need for changes in your modules.\\n\\n> Oh, I don't mean to question the overall purpose of the patch.  I was\\n> questioning whether it needed to have breaking changes which are mere \\"code\\n> cleanup\\".  The change to CacheInvalidateHeapTupleInplace to remove the\\n> unused third argument seemed inappropriate for backpatching, so I spoke up\\n> before 18.2 is stamped.  Doing this one piece of code cleanup in the back\\n> branches will cause a lot of packaging pain for no real benefit.\\n\\nIs the source code for one of these modules published?  I'm not picturing how\\na module could need a CacheInvalidateHeapTupleInplace() call, so your code may\\nilluminate that for me.\\n\\nIf you upload one of these modules to PGXN, my scans before future ABI breaks\\nwill find its calls and will block avoidable ABI breaks like the\\nCacheInvalidateHeapTupleInplace() one.\\n\\n\\n","threadId":"19be66940c5bb07c","snippet":"On Thu, Jan 22, 2026 at 07:53:21AM -0800, Mark Dilger wrote: > On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote: > > Based on your experience, I probably should","historyId":"5960","internalDate":"1769103770000","receivedAtUtc":"2026-01-22T17:42:50.000Z","from":"Noah Misch <noah@leadboat.com>"}]	The discussion centers on ABI-breaking changes in PostgreSQL's back-patched inval reliability fixes that affect Table Access Method (TAM) modules. Mark Dilger reports that four non-PGXN TAM extensions require forking due to signature changes in CacheInvalidateHeapTupleInplace() (commit 06b030e) and PrepareToInvalidateCacheTuple() (commit 2e58802). While the main fix addresses data loss issues with relhasindex, relfrozenxid, and datfrozenxid updates, Dilger questions whether the code cleanup removing unused parameters was necessary for backpatching, arguing it causes packaging pain without real benefit. Noah Misch acknowledges the concern and suggests encouraging packagers to test builds against stable branches early. He requests source code examples to better understand TAM module usage patterns and suggests PGXN publication to help detect future ABI breaks. The fix prevents data corruption but creates compatibility challenges for external modules.	2026-01-22 17:42:50+00	\N
6	19be51d175b3789d	refactor architecture-specific popcount code	["hlinnaka@iki.fi","johncnaylorls@gmail.com","nathandbossart@gmail.com"]	[{"id":"19be51d175b3789d","messageId":"<CANWCAZY7R+iy+r9YM_sySNydHzNqUirx1xk0tB3ej5HO62GdgQ@mail.gmail.com>","subject":"Re: refactor architecture-specific popcount code","body":"On Thu, Jan 22, 2026 at 3:23 AM Nathan Bossart <nathandbossart@gmail.com> wrote:\\n>\\n> Committed, thanks for reviewing.\\n\\nSure. Now that that's in place, I wanted to brainstorm more\\nrefactoring/rationalization ideas that seem on-topic for the thread\\nbut have less clear payoff:\\n\\n1) Nowadays, the only global call sites of the word-sized functions\\nare select_best_grantor() and in bitmapsets. The latter calls the\\nword-sized functions in a loop (could be just one word). It may be\\nmore efficient to calculate the size in bytes and call pg_popcount().\\nThen we could get rid of all the pointer indirection for the\\nword-sized functions.\\n\\n2) The x86 byte buffer variants expend a lot of effort to detect\\nwhether the buffer is aligned on both 64- and 32-bit platforms, with\\nan optimized path for each. At least 64-bit doesn't care about\\nalignment, and 32-bit doesn't warrant anything fancier than pure C.\\nSimultaneously, the aarch64 equivalent doesn't seem to take care about\\nalignment. (I think Nathan mentioned he didn't see a difference during\\ntesting, but I wonder how universal that is).\\n\\n3) There is repeated code for the <8 bytes case, and the tail of the\\n\\"optimized\\" functions. I'm also not sure why the small case is inlined\\neverywhere.\\n\\n--\\nJohn Naylor\\nAmazon Web Services\\n\\n\\n","threadId":"19be51d175b3789d","snippet":"On Thu, Jan 22, 2026 at 3:23 AM Nathan Bossart <nathandbossart@gmail.com> wrote: > > Committed, thanks for reviewing. Sure. Now that that's in place, I wanted to brainstorm more","historyId":"5945","internalDate":"1769075426000","receivedAtUtc":"2026-01-22T09:50:26.000Z","from":"John Naylor <johncnaylorls@gmail.com>"},{"id":"19be6d49c9d6d659","messageId":"<aXJjbkp2_glyfy6z@nathan>","subject":"Re: refactor architecture-specific popcount code","body":"On Thu, Jan 22, 2026 at 04:50:26PM +0700, John Naylor wrote:\\n> 1) Nowadays, the only global call sites of the word-sized functions\\n> are select_best_grantor() and in bitmapsets. The latter calls the\\n> word-sized functions in a loop (could be just one word). It may be\\n> more efficient to calculate the size in bytes and call pg_popcount().\\n\\nYeah, these seem like obvious places to use pg_popcount().  Note that\\nbms_member_index() does a final popcount on a masked version of the last\\nword.  We could swap that with pg_popcount(), too, but it might be slower\\nthan just calling the word-sized function.  However, it could be hard to\\ntell the difference, as we'd be trading a function or function pointer call\\nwith an inlined loop over pg_number_of_ones.  And even if it is slower, I'm\\nnot sure it matters all that much in the grand scheme of things.\\n\\nIn any case, 0001 gets the easy ones out of the way.\\n\\n> Then we could get rid of all the pointer indirection for the\\n> word-sized functions.\\n\\nDo you mean that we'd just keep the portable ones around?  I see some code\\nin pgvector that might be negatively impacted by that, but if I understand\\ncorrectly it would require an unusual setup.\\n\\n> 2) The x86 byte buffer variants expend a lot of effort to detect\\n> whether the buffer is aligned on both 64- and 32-bit platforms, with\\n> an optimized path for each. At least 64-bit doesn't care about\\n> alignment, and 32-bit doesn't warrant anything fancier than pure C.\\n> Simultaneously, the aarch64 equivalent doesn't seem to take care about\\n> alignment. (I think Nathan mentioned he didn't see a difference during\\n> testing, but I wonder how universal that is).\\n\\n0002 makes these changes for pg_popcount_sse42() and\\npg_popcount_masked_sse42().  It does seem strange to prefer a loop over\\npg_number_of_ones instead of using POPCNTQ when unaligned, but perhaps it's\\nworth testing.  I do recall the alignment stuff in the AVX-512 code showing\\nbenefits in tests because it avoids double-load overhead, so I think we\\nshould keep that for now.\\n\\n> 3) There is repeated code for the <8 bytes case, and the tail of the\\n> \\"optimized\\" functions. I'm also not sure why the small case is inlined\\n> everywhere.\\n\\nThis is intended to help avoid function call and SIMD instruction overhead\\nwhen it doesn't make sense to take it.  I recall this showing a rather big\\ndifference in benchmarks when we were working on the AVX-512 versions.\\nRegarding the duplicated code, sure, we could add some static inline\\nfunctions or something.  I think the only reason I haven't done so is\\nbecause it's ~2 lines of code.\\n\\n-- \\nnathan\\n","threadId":"19be51d175b3789d","snippet":"On Thu, Jan 22, 2026 at 04:50:26PM +0700, John Naylor wrote: > 1) Nowadays, the only global call sites of the word-sized functions > are select_best_grantor() and in bitmapsets. The latter calls","historyId":"5945","internalDate":"1769104238000","receivedAtUtc":"2026-01-22T17:50:38.000Z","from":"Nathan Bossart <nathandbossart@gmail.com>"}]	Following the completion of initial refactoring work, John Naylor proposes three additional optimization ideas for PostgreSQL's popcount implementation. First, replacing word-sized function calls in select_best_grantor() and bitmapsets with pg_popcount() calls on byte-sized data, potentially eliminating pointer indirection. Second, simplifying x86 alignment detection logic since 64-bit platforms don't require alignment checks and 32-bit doesn't need complex optimizations, contrasting with simpler aarch64 implementation. Third, consolidating duplicated code for cases under 8 bytes and function tails. Nathan Bossart responds positively to the first suggestion, providing patch 0001 for obvious conversions while noting performance trade-offs in bms_member_index(). He implements alignment simplification in patch 0002 for SSE4.2 functions but retains AVX-512 alignment optimizations due to proven benefits. Regarding code duplication, Nathan acknowledges the possibility of static inline functions but notes the minimal code involved is only about 2 lines.	2026-01-22 17:50:38+00	\N
6	19be6f25752a8025	Speed up COPY FROM text/CSV parsing using SIMD	["andrew@dunslane.net","byavuz81@gmail.com","manni.wood@enterprisedb.com","markwkm@gmail.com","nathandbossart@gmail.com","shinya11.kato@gmail.com"]	[{"id":"19be6f25752a8025","messageId":"<CA+K2RumUD+aJ3vuD+05aDWj6geek5DCPYD5peXrRU41QjtORFA@mail.gmail.com>","subject":"Re: Speed up COPY FROM text/CSV parsing using SIMD","body":"Hello,\\n\\nOn Tue, Jan 20, 2026 at 9:49 PM Manni Wood <manni.wood@enterprisedb.com>\\nwrote:\\n\\n> Hello, all I have more benchmarks.\\n>\\n> These benchmarks are from a Raspberry Pi 5 that I bought. It has an Arm\\n> Cortex A76 processor.\\n>\\n> (I was so impressed with the stability of the results I got on my\\n> standalone Intel tower PC that I figured I needed a standalone Arm-based\\n> machine that was not a laptop and not a VM at a cloud service provider. The\\n> run-to-run results were indeed more stable, just like with my standalone\\n> tower PC.)\\n>\\n> COPY FROM\\n>\\n> master: (852558b9)\\n>\\n> text, no special: 9111\\n> text, 1/3 special: 10302\\n> csv, no special: 11147\\n> csv, 1/3 special: 13375\\n>\\n> v3\\n>\\n> text, no special: 7351 (19.3% speedup)\\n> text, 1/3 special: 10397 (0.9% regression)\\n> csv, no special: 7272 (34.7% speedup)\\n> csv, 1/3 special: 13472 (0.7% regression)\\n>\\n> v4.2\\n>\\n> text, no special: 7300 (19.6% speedup)\\n> text, 1/3 special: 10537 (2.3% regression)\\n> csv, no special: 7260 (34.8% speedup)\\n> csv, 1/3 special: 13881 (3.8% regression)\\n>\\n> COPY TO\\n>\\n> master: (852558b9)\\n>\\n> text, no special: 2446\\n> text, 1/3 special: 6988\\n> csv, no special: 2822\\n> csv, 1/3 special: 6967\\n>\\n> v4 (copy to)\\n>\\n> text, no special: 1533 (37.3% speedup)\\n> text, 1/3 special: 5949 (14.8% speedup)\\n> csv, no special: 1560 (44.7% speedup)\\n> csv, 1/3 special: 6006 (13.8% speedup)\\n>\\n> I find these results particularly exciting because with the COPY FROM v3\\n> patch, the worst-case scenarios are just under 1% regression. The v4 COPY\\n> TO patch is a win across the board.\\n>\\n> Note that I ran these benchmarks with everything in RAM disk and using the\\n> cpupower instructions that Nazir suggested.\\n>\\n> So on Arm, the v3 COPY FROM patch is almost all upside, and the v4 COPY TO\\n> patch is all upside. The same is almost true for Intel, but the CSV COPY\\n> FROM regression, even from the V3 COPY FROM patch, is about 5%. The v4.2\\n> COPY FROM patch always performs worse than the v3 COPY FROM patch in\\n> worst-case scenarios.\\n>\\n> Does it seem reasonable to stop performance testing the v4.2 COPY FROM\\n> patch? Have we collected enough benchmark data to be confident that the v3\\n> COPY FROM patch is the one we should be moving forward with?\\n>\\nFor the case of v4.2 using the 1/3 specials benchmark, it will always take\\nthe decision to not use SIMD after sampling and that 3%-4% regression is\\nthe combination of the small overhead of counting special characters and\\n2-4 branches and its effect on the general layout, branch prediction,\\npipeline ..etc, while i don't think it's more complex than v3 but this is\\nthe only thing i can think of.\\nAnd since it assumes uniformity of special characters between lines so yes\\nIMHO v3 is generally better.\\n\\nRegards,\\nAyoub\\n","threadId":"19be6f25752a8025","snippet":"Hello, On Tue, Jan 20, 2026 at 9:49 PM Manni Wood <manni.wood@enterprisedb.com> wrote: Hello, all I have more benchmarks. These benchmarks are from a Raspberry Pi 5 that I bought. It has an Arm","historyId":"5965","internalDate":"1769106176000","receivedAtUtc":"2026-01-22T18:22:56.000Z","from":"KAZAR Ayoub <ma_kazar@esi.dz>"}]	Manni Wood provided new benchmark results from a Raspberry Pi 5 with Arm Cortex A76 processor, comparing SIMD-accelerated COPY FROM/TO performance across different patch versions (v3, v4.2) against master. For COPY FROM on Arm, v3 shows significant speedups (19.3-34.8%) with minimal regression (<1%) in worst-case scenarios, while v4.2 exhibits slightly higher regressions (2.3-3.8%). COPY TO v4 demonstrates consistent improvements (13.8-44.7%) across all test cases. Ayoub Kazar explains that v4.2's regression in 1/3 specials benchmark stems from overhead in special character counting and branching effects when SIMD is bypassed after sampling, noting v3's assumption of uniform special character distribution makes it generally superior. The discussion centers on whether to discontinue v4.2 COPY FROM testing and proceed with v3, given consistent evidence favoring v3's performance profile.	2026-01-22 18:22:56+00	\N
6	19be543e22dcee9b	Race conditions in logical decoding	["ah@cybertec.at","andres@anarazel.de","mihailnikalayeu@gmail.com"]	[{"id":"19be543e22dcee9b","messageId":"<124728.1769077978@localhost>","subject":"Re: Race conditions in logical decoding","body":"Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote:\\n\\n> Hello, Andres.\\n> \\n> On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <andres@anarazel.de> wrote:\\n> > I don't think that's enough - during non-timetravel visibility semantics, you\\n> > can only look at the clog if the transaction isn't marked as in-progress in\\n> > the procarray.  ISTM that we need to do that here too?\\n> \\n> Do you mean replace\\n> > if (unlikely(!TransactionIdDidCommit(builder->committed.xip[i])))\\n> to\\n> > if (unlikely(TransactionIdIsInProgress(builder->committed.xip[i]) || !TransactionIdDidCommit(builder->committed.xip[i])))\\n\\nThis way the synchronous replication gets stuck, as it did when I tried to use\\nXactLockTableWait(): subscriber cannot confirm replication of certain LSN\\nbecause publisher is not able to even finalize the commit (due to the waiting\\nfor the subscriber's confirmation), and therefore publisher it's not able to\\ndecode the data and send it to the subscriber.\\n\\n-- \\nAntonin Houska\\nWeb: https://www.cybertec-postgresql.com\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote: > Hello, Andres. > > On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <andres@anarazel.de> wrote: > > I don't think","historyId":"5948","internalDate":"1769077978000","receivedAtUtc":"2026-01-22T10:32:58.000Z","from":"Antonin Houska <ah@cybertec.at>"},{"id":"19be7126d277a089","messageId":"<202601221804.nbrvjquik7qp@alvherre.pgsql>","subject":"Re: Race conditions in logical decoding","body":"On 2026-Jan-22, Antonin Houska wrote:\\n\\n> Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote:\\n> \\n> > Hello, Andres.\\n> > \\n> > On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <andres@anarazel.de> wrote:\\n> > > I don't think that's enough - during non-timetravel visibility semantics, you\\n> > > can only look at the clog if the transaction isn't marked as in-progress in\\n> > > the procarray.  ISTM that we need to do that here too?\\n> > \\n> > Do you mean replace\\n> > > if (unlikely(!TransactionIdDidCommit(builder->committed.xip[i])))\\n> > to\\n> > > if (unlikely(TransactionIdIsInProgress(builder->committed.xip[i]) || !TransactionIdDidCommit(builder->committed.xip[i])))\\n> \\n> This way the synchronous replication gets stuck, as it did when I tried to use\\n> XactLockTableWait(): subscriber cannot confirm replication of certain LSN\\n> because publisher is not able to even finalize the commit (due to the waiting\\n> for the subscriber's confirmation), and therefore publisher it's not able to\\n> decode the data and send it to the subscriber.\\n\\nThe layering here is wild, but if I understand it correctly, these XIDs\\nare all added to an array by SnapBuildAddCommittedTxn(), which in turn\\nis only called by SnapBuildCommitTxn(), which is only called by\\nDecodeCommit(), which is only called by xact_decode() when it sees a\\nXLOG_XACT_COMMIT or XLOG_XACT_COMMIT_PREPARED record by reading WAL.\\n\\nCrucially, RecordTransactionCommit() writes the WAL first, then marks\\neverything as committed in CLOG, and finally does the waiting for\\nthe synchronous replica to ACK the commit if necessary.  However, the\\ntransaction is only removed from procarray after RecordTransactionCommit\\nhas returned.\\n\\nThis means that DecodeCommit() could add a transaction to the\\nSnapBuilder (that needs to be waited for) while that transaction is\\nstill shown as running in ProcArray.  This sounds problematic in itself,\\nso I'm wondering whether we should do anything (namely, wait) on\\nDecodeCommit() instead of hacking SnapBuildBuildSnapshot() to patch it\\nup by waiting after the fact.\\n\\n-- \\nÁlvaro Herrera         PostgreSQL Developer  —  https://www.EnterpriseDB.com/\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"On 2026-Jan-22, Antonin Houska wrote: > Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote: > > > Hello, Andres. > > > > On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <","historyId":"5948","internalDate":"1769108285000","receivedAtUtc":"2026-01-22T18:58:05.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"}]	The discussion addresses race conditions in logical decoding's snapshot building mechanism. Andres Freund suggested checking both TransactionIdIsInProgress() and TransactionIdDidCommit() to prevent accessing the commit log for in-progress transactions. However, Antonin Houska reports this approach causes synchronous replication deadlocks, where the subscriber cannot confirm LSN replication because the publisher waits for subscriber confirmation while being unable to finalize commits. Álvaro Herrera analyzes the layering issue, noting that DecodeCommit() can add transactions to SnapBuilder while they're still in the procarray, suggesting the waiting logic should be moved to DecodeCommit() rather than patching SnapBuildBuildSnapshot() after the fact. The core problem involves timing conflicts between WAL processing, CLOG updates, and procarray management.	2026-01-22 18:58:05+00	\N
6	19be6bab3032bd29	Remove PG_MMAP_FLAGS	["ashutosh.bapat.oss@gmail.com","peter@eisentraut.org"]	[{"id":"19be6bab3032bd29","messageId":"<CAExHW5vTWABxuM5fbQcFkGuTLwaxuZDEE2vtx2WuMUWk6JnF4g@mail.gmail.com>","subject":"Remove PG_MMAP_FLAGS","body":"Hi,\\nOver [1] Peter mentioned that PG_MMAP_FLAGS is not used for\\nportability even though it's placed in portability/mem.h. That might\\nhave been the intention when it was added in\\nb0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67. But history does not show it\\nbeing used that way at any point in time. Per suggestion removing that\\nmacro and instead using the flags directly in CreateAnonymousSegment()\\nwhich is the only place where it's used.\\n\\nPFA patch for the same.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be6bab3032bd29","snippet":"Hi, Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for portability even though it's placed in portability/mem.h. That might have been the intention when it was added in","historyId":"5964","internalDate":"1769102528000","receivedAtUtc":"2026-01-22T17:22:08.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19be723d4b961c2d","messageId":"<2772065.1769109428@sss.pgh.pa.us>","subject":"Re: Remove PG_MMAP_FLAGS","body":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes:\\n> Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for\\n> portability even though it's placed in portability/mem.h. That might\\n> have been the intention when it was added in\\n> b0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67. But history does not show it\\n> being used that way at any point in time. Per suggestion removing that\\n> macro and instead using the flags directly in CreateAnonymousSegment()\\n> which is the only place where it's used.\\n\\nI think you attached the wrong patch?  This one doesn't touch\\nPG_MMAP_FLAGS.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19be6bab3032bd29","snippet":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes: > Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for > portability even though it's placed in portability/mem.h. That","historyId":"5964","internalDate":"1769109428000","receivedAtUtc":"2026-01-22T19:17:08.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	Ashutosh Bapat proposes removing the PG_MMAP_FLAGS macro from portability/mem.h, following Peter's observation that it's not actually used for portability purposes despite its placement. The macro was added in commit b0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67 but has never been used as intended for portability. Instead of the macro, Bapat suggests using the flags directly in CreateAnonymousSegment(), which is the only location where PG_MMAP_FLAGS is currently used. However, Tom Lane points out that the attached patch appears to be incorrect, as it doesn't actually touch PG_MMAP_FLAGS. This indicates the wrong patch was submitted, and the discussion remains unresolved pending the correct patch.	2026-01-22 19:17:08+00	\N
6	19be72cf98864068	ALTER TABLE: warn when actions do not recurse to partitions	["david.g.johnston@gmail.com","htamfids@gmail.com","li.evan.chao@gmail.com"]	[{"id":"19be72cf98864068","messageId":"<fb70022a-5403-4e16-9efc-28b041f35d9a@uni-muenster.de>","subject":"Re: ALTER TABLE: warn when actions do not recurse to partitions","body":"Hi Chao\\n\\nOn 22/01/2026 06:45, Chao Li wrote:\\n> evantest=# alter table p_test replica identity full, alter column\\n> username set (n_distinct = 0.1);\\n> NOTICE:  ALTER action REPLICA IDENTITY on relation \\"p_test\\" does not\\n> affect present partitions\\n> HINT:  partitions may be modified individually, or specify ONLY to\\n> suppress this message\\n> NOTICE:  ALTER action ALTER COLUMN ... SET on relation \\"p_test\\" does not\\n> affect present partitions\\n> HINT:  partitions may be modified individually, or specify ONLY to\\n> suppress this message\\n> ALTER TABLE\\n\\n\\nOne could argue that encapsulating all conditions in\\nEmitPartitionNoRecurseNotice(), meaning it is called all the time, is\\nslightly inefficient, but the impact is really negligible in this case -\\nand it is how it is done in similar functions in tablecmds.c :) The code\\nLGTM.\\n\\nOne small thing:\\n\\nerrhint is supposed to be capitalised - see Error Message Style Guide[1]\\n\\n\\"Detail and hint messages: Use complete sentences, and end each with a\\nperiod. Capitalize the first word of sentences. Put two spaces after the\\nperiod if another sentence follows (for English text; might be\\ninappropriate in other languages).\\"\\n\\nereport(NOTICE,\\n\\terrmsg(\\"ALTER action %s on relation \\\\\\"%s\\\\\\" does not affect present\\npartitions\\",\\n\\t\\t   action_str,\\n\\t\\t   RelationGetRelationName(rel)),\\n\\terrhint(\\"partitions may be modified individually, or specify ONLY to\\nsuppress this message\\"));\\n\\nWhat about this?\\n\\nHINT: To update partitions, apply the command to each one individually,\\nor specify ONLY to suppress this message.\\n\\nI'll test the newly covered subcomands tomorrow.\\n\\nBest, Jim\\n\\n1 - https://www.postgresql.org/docs/current/error-style-guide.html\\n\\n\\n","threadId":"19be72cf98864068","snippet":"Hi Chao On 22/01/2026 06:45, Chao Li wrote: > evantest=# alter table p_test replica identity full, alter column > username set (n_distinct = 0.1); > NOTICE: ALTER action REPLICA IDENTITY on","historyId":"6221","internalDate":"1769110031000","receivedAtUtc":"2026-01-22T19:27:11.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"}]	Jim Jones reviews a patch for ALTER TABLE warning when actions don't recurse to partitions. The patch successfully adds NOTICE messages when ALTER TABLE commands like REPLICA IDENTITY and ALTER COLUMN SET don't affect existing partitions, providing hints that partitions can be modified individually or ONLY can be specified to suppress warnings. Jim approves the code structure, noting that calling EmitPartitionNoRecurseNotice() for all conditions follows existing patterns in tablecmds.c with negligible performance impact. He suggests improving the hint message capitalization per PostgreSQL's Error Message Style Guide, proposing "To update partitions, apply the command to each one individually, or specify ONLY to suppress this message" instead of the current lowercase version. Jim plans to test newly covered subcommands.	2026-01-22 19:27:11+00	\N
12	19be5744042c7846	Remove redundant AssertVariableIsOfType uses in pg_upgrade	["nathandbossart@gmail.com","peter@eisentraut.org"]	[{"id":"19be5744042c7846","messageId":"<c1b79178-ab7c-461e-8359-bf400d8f1684@eisentraut.org>","subject":"Re: Remove redundant AssertVariableIsOfType uses in pg_upgrade","body":"On 20.01.26 23:19, Nathan Bossart wrote:\\n> On Tue, Jan 20, 2026 at 11:07:47AM +0100, Peter Eisentraut wrote:\\n>> pg_upgrade code contains a number of lines like\\n>>\\n>>      AssertVariableIsOfType(&process_rel_infos, UpgradeTaskProcessCB);\\n>>\\n>> This is presumably to ensure that the function signature is fitting for\\n>> being used with upgrade_task_add_step().  But the signature of\\n>> upgrade_task_add_step() already checks that itself, so these additional\\n>> assertions are redundant, and I find them confusing.  So I propose to remove\\n>> them.\\n> > I think this was borrowed from logical decoding output plugins, but\\n> apparently I wrote the patch to remove these assertions from those, too\\n> (commit 30b789eafe).  So, I'm not sure what I was thinking...  If they are\\n> indeed redundant, I have no objection to their removal.\\n\\nAh, that is interesting context.  Anyway, change committed.\\n\\n\\n","threadId":"19be5744042c7846","snippet":"On 20.01.26 23:19, Nathan Bossart wrote: > On Tue, Jan 20, 2026 at 11:07:47AM +0100, Peter Eisentraut wrote: >> pg_upgrade code contains a number of lines like >> >>","historyId":"5950","internalDate":"1769080888000","receivedAtUtc":"2026-01-22T11:21:28.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	Peter Eisentraut proposed removing redundant AssertVariableIsOfType uses in pg_upgrade code. These assertions were meant to ensure function signatures match upgrade_task_add_step() requirements, but the function already performs this check internally, making the additional assertions unnecessary and confusing. Nathan Bossart noted that similar assertions were previously removed from logical decoding output plugins in commit 30b789eafe, providing supportive context. Both developers agreed the assertions are redundant, and Peter confirmed the change has been committed to remove them.\n\nPeter Eisentraut提议移除pg_upgrade代码中冗余的AssertVariableIsOfType用法。这些断言原本用于确保函数签名符合upgrade_task_add_step()的要求，但该函数内部已经执行此检查，使得额外的断言变得不必要且令人困惑。Nathan Bossart指出类似的断言之前已在提交30b789eafe中从逻辑解码输出插件中移除，提供了支持性背景。两位开发者都同意这些断言是冗余的，Peter确认已提交更改将其移除。	2026-01-22 11:21:28+00	\N
12	19be4da9486dc0d1	Adding REPACK [concurrently]	["ah@cybertec.at","alvherre@alvh.no-ip.org","mihailnikalayeu@gmail.com","rob@xzilla.net"]	[{"id":"19be57869b111101","messageId":"<CADzfLwVZ_DeU_3avD=G4ZHFJJgZ0EOFzxnmWxwyB23zsS-uxjA@mail.gmail.com>","subject":"Re: Adding REPACK [concurrently]","body":"Hello, Antonin!\\n\\n> The changes present in WAL decoded prior the snapshot creation are not\\n> replayed - these changes are visible to the snapshot. (This is not really\\n> specific to the 0006 part.)\\n\\nOK, just want to be sure it still works the same way if we build multiple\\nsnapshots for the same slot that way.\\n\\n> The current API does not seem to support changing snapshot of an\\nin-progress\\n> scan and I don't want to change that. Plus note that the current\\n> implementation of CLUSTER also uses SnapshotAny and then checks the\\nvisibility\\n> separately. Finally, SnapshotAny is not really an expensive visibility\\ncheck,\\n> if it can be considered a visibility check at all.\\n\\nBut we will require a real check for each tuple. Including dead one,\\nmultiple versions of the same HOT, etc.\\n\\n> I've added it only for xmin. xid is valid because REPACK is executed in a\\n> transaction. That reminds me that PROC_IN_VACUUM should be present in\\n> MyProc->statusFlags. Fixed.\\n\\nYes, xid is required for repack. I think it is better to introduce a new\\nflag instead of PROC_IN_VACCUUM.\\n\\n\\n> > > PushActiveSnapshot(GetTransactionSnapshot());\\n> > GetLatestSnapshot() feels better here.\\n> What will then happen to code that uses GetActiveSnapshot() ?\\n\\nO, I mean PushActiveSnapshot(GetLatestSnapshot())\\n\\n> > Also, to correctly build a unique index - some tech from [0] is\\nrequired (building a unique index with multiple snapshots is a little bit\\ntricky).\\n> ok, I'll check your patch.\\n\\nI realized building a unique index is still done with a single snapshot, so\\nit should be OK for that case. But still check the patch :)\\n\\n>  I proposed the Assert above, but still thinking about it.\\nHm... Do we really need these asserts if PROC_IN_VACUUM is set? I was\\nproposing a way it is used for index building (to ensure nothing is\\npropagated into xmin).\\n\\nBest regards,\\nMikhail.\\n","threadId":"19be4da9486dc0d1","snippet":"Hello, Antonin! > The changes present in WAL decoded prior the snapshot creation are not > replayed - these changes are visible to the snapshot. (This is not really > specific to the 0006 part","historyId":"5938","internalDate":"1769081400000","receivedAtUtc":"2026-01-22T11:30:00.000Z","from":"Mihail Nikalayeu <mihailnikalayeu@gmail.com>"}]	The discussion focuses on implementing a REPACK feature with concurrent execution capabilities in PostgreSQL. Mikhail raises technical concerns about snapshot handling, particularly regarding WAL decoding and visibility checks when building multiple snapshots for the same slot. He suggests using GetLatestSnapshot() instead of GetTransactionSnapshot() and proposes introducing a new process flag rather than reusing PROC_IN_VACUUM. The conversation addresses visibility checking complexities, including handling dead tuples and HOT versions with SnapshotAny. Mikhail clarifies that unique index building uses a single snapshot, making it acceptable for the current approach, while referencing related patch work on building unique indexes with multiple snapshots.\n\n讨论重点是在PostgreSQL中实现具有并发执行能力的REPACK功能。Mikhail提出了关于快照处理的技术问题，特别是在为同一个槽构建多个快照时的WAL解码和可见性检查。他建议使用GetLatestSnapshot()而不是GetTransactionSnapshot()，并提议引入新的进程标志而不是重用PROC_IN_VACUUM。对话涉及可见性检查的复杂性，包括使用SnapshotAny处理死元组和HOT版本。Mikhail澄清了唯一索引构建使用单一快照，使其适用于当前方法，同时引用了关于使用多个快照构建唯一索引的相关补丁工作。	2026-01-22 11:30:00+00	\N
12	19be59053caa9edb	commented out code	["hlinnaka@iki.fi","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19be59053caa9edb","messageId":"<a690f6d3-c53e-41cf-8a26-756b1ef16442@eisentraut.org>","subject":"Re: commented out code","body":"On 20.01.26 19:55, Tom Lane wrote:\\n> Peter Eisentraut <peter@eisentraut.org> writes:\\n>> On 05.12.25 17:38, Heikki Linnakangas wrote:\\n>>> #if 0\\n>>>      Oid      subtype = PG_GETARG_OID(3);\\n>>> #endif\\n>>>\\n>>> is yet another option. It keeps the indentation, although you won't get\\n>>> the compiler checking.\\n> >> After some reflection, I like this approach.  It keeps the indentation\\n>> and enables syntax highlighting, so it makes some of these blocks much\\n>> easier to read.\\n> > I think \\"#ifdef NOT_USED\\" is our more common style.  +1 other than\\n> that nitpick.\\n\\nOk, committed like that.\\n\\n\\n\\n","threadId":"19be59053caa9edb","snippet":"On 20.01.26 19:55, Tom Lane wrote: > Peter Eisentraut <peter@eisentraut.org> writes: >> On 05.12.25 17:38, Heikki Linnakangas wrote: >>> #if 0 >>> Oid subtype =","historyId":"5952","internalDate":"1769082985000","receivedAtUtc":"2026-01-22T11:56:25.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	The PostgreSQL development team discussed approaches for handling commented-out code in the codebase. Heikki Linnakangas proposed using "#if 0" to disable code blocks while preserving indentation and syntax highlighting, making them easier to read compared to traditional comment blocks. Peter Eisentraut initially supported this approach after reflection, appreciating how it maintains code readability. However, Tom Lane suggested using "#ifdef NOT_USED" instead, noting this as the project's more established convention. Following this feedback, Peter Eisentraut committed the changes using the "#ifdef NOT_USED" style as recommended by Tom Lane.\n\nPostgreSQL开发团队讨论了处理代码库中注释代码的方法。Heikki Linnakangas提议使用"#if 0"来禁用代码块，同时保持缩进和语法高亮，使其比传统注释块更易阅读。Peter Eisentraut经过思考后最初支持这种方法，认为它能保持代码可读性。然而，Tom Lane建议使用"#ifdef NOT_USED"，指出这是项目更为成熟的惯例。根据这一反馈，Peter Eisentraut按照Tom Lane的建议使用"#ifdef NOT_USED"样式提交了更改。	2026-01-22 11:56:25+00	\N
12	19be5b38e1cd7b9b	let ALTER COLUMN SET DATA TYPE cope with trigger dependency	["jian.universality@gmail.com"]	[{"id":"19be5b38e1cd7b9b","messageId":"<CACJufxH-Ngr9e7_bT+7d-bFMACqd-efAV3YSgPJyfMp4T9P5AQ@mail.gmail.com>","subject":"Re: let ALTER COLUMN SET DATA TYPE cope with trigger dependency","body":"hi.\\n\\nV3 is attached. this should be more neat.\\nNow it looks very similar to how statistics cope with column data type change.\\n\\nFor statistics, in ATPostAlterTypeParse we will call\\ntransformStatsStmt, we need to do the similar thing for the trigger\\nWHEN clause.\\nI introduced transformTriggerStmt and placed it in\\nsrc/backend/commands/trigger.c, which should be fine, I think.\\nIt will be invoked from within CreateTriggerFiringOn.\\n\\n\\n\\n--\\njian\\nhttps://www.enterprisedb.com/\\n","threadId":"19be5b38e1cd7b9b","snippet":"hi. V3 is attached. this should be more neat. Now it looks very similar to how statistics cope with column data type change. For statistics, in ATPostAlterTypeParse we will call transformStatsStmt, we","historyId":"5954","internalDate":"1769085258000","receivedAtUtc":"2026-01-22T12:34:18.000Z","from":"jian he <jian.universality@gmail.com>"}]	The patch proposes making ALTER COLUMN SET DATA TYPE handle trigger dependencies more elegantly. Version 3 introduces a cleaner approach that mirrors how PostgreSQL handles statistics during column data type changes. The solution involves calling transformStatsStmt in ATPostAlterTypeParse for statistics, and similarly implementing transformTriggerStmt for trigger WHEN clauses. The new transformTriggerStmt function is placed in src/backend/commands/trigger.c and will be invoked from CreateTriggerFiringOn. This architectural approach provides consistency with existing PostgreSQL mechanisms for handling dependencies during schema changes, specifically addressing how triggers with WHEN clauses should be processed when their referenced column types are altered.\n\n该补丁提议让 ALTER COLUMN SET DATA TYPE 更优雅地处理触发器依赖关系。第3版引入了一种更清洁的方法，模仿了PostgreSQL在列数据类型更改期间处理统计信息的方式。解决方案涉及在ATPostAlterTypeParse中为统计信息调用transformStatsStmt，并类似地为触发器WHEN子句实现transformTriggerStmt。新的transformTriggerStmt函数放置在src/backend/commands/trigger.c中，将从CreateTriggerFiringOn调用。这种架构方法与现有的PostgreSQL机制保持一致，用于处理模式更改期间的依赖关系，特别解决了当引用列类型被更改时，带有WHEN子句的触发器应如何处理的问题。	2026-01-22 12:34:18+00	\N
12	19be5ce498ae0e5b	[PATCH] psql: add \\dcs to list all constraints	["alvherre@kurilemu.de","jim.jones@uni-muenster.de","li.evan.chao@gmail.com","tgl@sss.pgh.pa.us","yamatattsu@gmail.com"]	[{"id":"19be5ce498ae0e5b","messageId":"<CAOKkKFuL-VGw+hUSdXwwnONB=t4BU+x6OJ38ian4XgJNDStAZg@mail.gmail.com>","subject":"Re: [PATCH] psql: add \\\\dcs to list all constraints","body":"Hi Chao, Álvaro, and all,\\n\\n>>I agree with another reviewer that said that having exec_command_d()\\n>>check only the third char is kinda pointless.  Just let\\n>>listConstraints() check everything seems easiest and more consistent.\\n>\\n>As I mentioned in a previous email, the reason exec_command_d() only\\n>checks the third character is that it follows the same implementation\\n>pattern as other existing commands.\\n>\\n>While I agree that this could be improved, since the current behavior is\\n>consistent with other commands, I do not consider it critical at the moment.\\n>If I were to change it, I would likely postpone that improvement to a later\\n>patch.\\n\\nAfter reviewing the code, I realized that the comment about passing\\neverything to listconstraints() instead of just checking the third string\\nwas correct. Therefore, I updated the code accordingly.\\nThanks to Chao and Alvaro for their comments.\\n\\nI created the new patch (v8).\\n\\nOther fixes included:\\n- Updated the documentation to clarify what the pattern string matches.\\n- Modified the case statement to use a predefined variable when converting\\n  contypes to strings.\\n\\nPlease find the attached file.\\n\\nThanks,\\nTatsuro Yamada\\n","threadId":"19be5ce498ae0e5b","snippet":"Hi Chao, Álvaro, and all, >>I agree with another reviewer that said that having exec_command_d() >>check only the third char is kinda pointless. Just let >>listConstraints() check","historyId":"5955","internalDate":"1769087032000","receivedAtUtc":"2026-01-22T13:03:52.000Z","from":"Tatsuro Yamada <yamatattsu@gmail.com>"}]	Tatsuro Yamada submitted v8 of a patch adding \\dcs command to psql for listing constraints. The patch addresses reviewer feedback from Chao and Álvaro about the exec_command_d() function's argument parsing approach. Initially, exec_command_d() only checked the third character following existing command patterns, but reviewers suggested passing all arguments to listConstraints() for more comprehensive validation. Yamada acknowledged this feedback and updated the implementation accordingly. Additional improvements in v8 include clarified documentation specifying what the pattern string matches and modifications to the case statement using predefined variables when converting constraint types to strings. The patch continues the review process with these refinements.\n山田达郎提交了为psql添加\\dcs命令以列出约束的补丁v8版本。该补丁解决了Chao和Álvaro关于exec_command_d()函数参数解析方法的审查反馈。最初，exec_command_d()仅检查第三个字符以遵循现有命令模式，但审查者建议将所有参数传递给listConstraints()以进行更全面的验证。山田认可了这一反馈并相应更新了实现。v8版本的其他改进包括：澄清了文档中模式字符串匹配的内容，以及修改case语句在将约束类型转换为字符串时使用预定义变量。该补丁在这些改进基础上继续审查过程。	2026-01-22 13:03:52+00	\N
12	19be6149ae076a65	CREATE TABLE LIKE INCLUDING TRIGGERS	["jian.universality@gmail.com","x4mmm@yandex-team.ru","zsolt.parragi@percona.com"]	[{"id":"19be6149ae076a65","messageId":"<CAN4CZFNPE_UeTEy5TH9wwc6mBAtX7vnBhLSL47jRiHXA=6yXjQ@mail.gmail.com>","subject":"Re: CREATE TABLE LIKE INCLUDING TRIGGERS","body":"> > Shouldn't this preserve the enabled state of the triggers, or if it\\n> > doesn't, should the documentation include this limitations?\\n> >\\n>\\n> I intended to document it as ...\\n\\n\\nAfter looking into this a bit more, I am more on the side of copying\\nthis setting properly.\\n\\nThe already existing INCLUDING CONSTRAINTS copies the constraints,\\nincluding their enabled/disabled status, correctly marking them\\ndisabled if a CHECK constraint is defined but not enforced. Wouldn't\\nit be strange for INCLUDING TRIGGERS to work differently?\\n\\nFrom the test suite:\\n\\nCREATE TABLE ctlt1_inh (LIKE ctlt1 INCLUDING CONSTRAINTS INCLUDING\\nCOMMENTS) INHERITS (ctlt1);\\n\\\\d+ ctlt1_inh\\n                                Table \\"public.ctlt1_inh\\"\\n Column | Type | Collation | Nullable | Default | Storage  | Stats\\ntarget | Description\\n--------+------+-----------+----------+---------+----------+--------------+-------------\\n a      | text |           | not null |         | main     |              | A\\n b      | text |           |          |         | extended |              | B\\nCheck constraints:\\n    \\"cc\\" CHECK (length(b) > 100)\\n    \\"ctlt1_a_check\\" CHECK (length(a) > 2)\\n    \\"ctlt1_b_check\\" CHECK (length(b) > 100) NOT ENFORCED\\nNot-null constraints:\\n    \\"ctlt1_a_not_null\\" NOT NULL \\"a\\" (local, inherited)\\nInherits: ctlt1\\n\\n\\n","threadId":"19be6149ae076a65","snippet":"> > Shouldn't this preserve the enabled state of the triggers, or if it > > doesn't, should the documentation include this limitations? > > > > I intended to document it","historyId":"5957","internalDate":"1769091645000","receivedAtUtc":"2026-01-22T14:20:45.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	The discussion focuses on whether CREATE TABLE LIKE INCLUDING TRIGGERS should preserve the enabled/disabled state of triggers when copying them to a new table. Initially, there was consideration to document this as a limitation, but after further analysis, the consensus shifted toward properly copying the trigger state. The key argument is consistency with existing behavior: INCLUDING CONSTRAINTS already correctly preserves the enabled/disabled status of constraints, including marking CHECK constraints as "NOT ENFORCED" when appropriate. The participant argues it would be inconsistent for INCLUDING TRIGGERS to behave differently, suggesting the feature should maintain trigger states rather than documenting it as a limitation.\n\n讨论的焦点是CREATE TABLE LIKE INCLUDING TRIGGERS在将触发器复制到新表时是否应该保留触发器的启用/禁用状态。最初考虑将此记录为限制，但经过进一步分析后，共识转向正确复制触发器状态。关键论点是与现有行为的一致性：INCLUDING CONSTRAINTS已经正确保留约束的启用/禁用状态，包括在适当时将CHECK约束标记为"NOT ENFORCED"。参与者认为INCLUDING TRIGGERS的行为不同会不一致，建议该功能应该维护触发器状态而不是将其记录为限制。	2026-01-22 14:20:45+00	\N
12	19be62b5fc6b3dd8	Change COPY ... ON_ERROR ignore to ON_ERROR ignore_row	["david.g.johnston@gmail.com","jian.universality@gmail.com","jim.jones@uni-muenster.de","masao.fujii@oss.nttdata.com","matheusssilv97@gmail.com","nagata@sraoss.co.jp","reshkekirill@gmail.com","sawada.mshk@gmail.com","torikoshia@oss.nttdata.com","vignesh21@gmail.com"]	[{"id":"19be62b5fc6b3dd8","messageId":"<CACJufxGYPXQ_Jz1avF5eSh_XJRsxhPSUZ+=RzG3Hz4_XNAc32g@mail.gmail.com>","subject":"Re: Change COPY ... ON_ERROR ignore to ON_ERROR ignore_row","body":"On Thu, Jan 22, 2026 at 2:47 AM Matheus Alcantara\\n<matheusssilv97@gmail.com> wrote:\\n>\\n> Thanks for the new version. I have some comments on this first round of\\n> review:\\n>\\n> + errmsg_plural(\\"invalid values in %\\" PRIu64 \\" row was replaced with null due to data type incompatibility\\",\\n> +   \\"invalid values in %\\" PRIu64 \\" rows were replaced with null due to data type incompatibility\\",\\n>\\n> I think that we could remove the \\"invalid values in\\" to make it\\n> consistency with the COPY_ON_ERROR_IGNORE NOTICE\\n>\\nsure.\\n\\n> ----------\\n>\\n> +               cstate->domain_with_constraint = (bool *) palloc0(attr_count * sizeof(bool));\\n>\\n> I think that we can use palloc_array?\\n>\\nsure.\\n\\n> ----------\\n>\\n> Should FORCE_NOT_NULL be allowed to be used with ON_ERROR set_null? It\\n> seems to me that ON_ERROR set_null overwrite the FORCE_NOT_NULL\\n> behaviour:\\n>\\n> postgres=# create table t4(a int, b varchar(5));\\n> CREATE TABLE\\n>\\n> postgres=# copy t4 from 'data.csv' with (FORCE_NOT_NULL(b), format csv, delimiter ',', NULL 'NULL', ON_ERROR set_null);\\n> NOTICE:  invalid values in 2 rows were replaced with null due to data type incompatibility\\n> COPY 5\\n>\\n> postgres=# \\\\pset null 'NULL'\\n> Null display is \\"NULL\\".\\n> postgres=# select * from t4;\\n>  a |  b\\n> ---+------\\n>  1 | aaaa\\n>  2 | bbbb\\n>  2 | NULL\\n>  2 | NULL\\n>  5 | NULL\\n> (5 rows)\\n>\\n> Note that only the ccccc rows on .csv file was inserted with a NULL\\n> value on b column. The 5,NULL row was inserted with a \\"NULL\\" string as a\\n> value:\\n>\\n> postgres=# select * from t4 where b is null;\\n>  a |  b\\n> ---+------\\n>  2 | NULL\\n>  2 | NULL\\n> (2 rows)\\n>\\n> The contents of data.csv:\\n>     1,aaaa\\n>     2,bbbb\\n>     2,ccccc\\n>     2,ccccc\\n>     5,NULL\\n>\\n> Perhaps we should block the usage of FORCE_NOT_NULL with ON_ERROR\\n> SET_NULL?\\n>\\nFORCE_NOT_NULL is related to how we handle NULL string in column value.\\n\\nWe first process cstate->opts.force_notnull_flags, cstate->opts.force_null_flags\\nthen InputFunctionCallSafe.\\nsee copyfromparse.c, CopyFromTextLikeOneRow ``if (is_csv)``loop.\\n\\nI think these two are unrelated things, FORCE_NOT_NULL should be fine with\\nON_ERROR SET_NULL.\\nyou can see related tests in\\nhttps://git.postgresql.org/cgit/postgresql.git/tree/src/test/regress/sql/copy2.sql#n330\\n\\nAm I missing something?\\n\\n>\\n> On monitoring.sgml we have the following for pg_stat_progress_copy\\n> tuples_skipped:\\n>        Number of tuples skipped because they contain malformed data.\\n>        This counter only advances when a value other than\\n>        <literal>stop</literal> is specified to the <literal>ON_ERROR</literal>\\n>\\n> IIUC we are not updating this view if we set a column to NULL due to an\\n> error, perhaps this documentation should be updated to mention that it\\n> will not be updated with ON_ERROR set_null?\\n>\\n\\nIMHO, we don't need to mention ON_ERROR set_null, since we do not support it.\\nchange to the following should be ok, i think.\\n\\n      <para>\\n       Number of tuples skipped because they contain malformed data.\\n       This counter only advances when\\n       <literal>ignore</literal> is specified to the <literal>ON_ERROR</literal>\\n       option.\\n      </para></entry>\\n\\n>\\n> I may have missing something, but we are still considering implementing\\n> the REJECT_LIMIT + ON_ERROR set_null?\\nPossibly as a separate patch later.\\n\\n\\n\\n\\n--\\njian\\nhttps://www.enterprisedb.com/\\n\\n\\n","threadId":"19be62b5fc6b3dd8","snippet":"On Thu, Jan 22, 2026 at 2:47 AM Matheus Alcantara <matheusssilv97@gmail.com> wrote: > > Thanks for the new version. I have some comments on this first round of > review: > > +","historyId":"5958","internalDate":"1769093110000","receivedAtUtc":"2026-01-22T14:45:10.000Z","from":"jian he <jian.universality@gmail.com>"}]	The PostgreSQL development team is reviewing changes to the COPY command's ON_ERROR functionality, specifically transitioning from "ignore" to "ignore_row" and implementing a new "set_null" option. The discussion focuses on code review feedback including error message consistency, memory allocation improvements using palloc_array, and the interaction between FORCE_NOT_NULL and ON_ERROR set_null options. A key debate centers on whether FORCE_NOT_NULL should be blocked when using ON_ERROR set_null, with the author arguing they are unrelated features that can coexist. Documentation updates are needed for pg_stat_progress_copy to clarify that tuples_skipped only advances with the "ignore" option, not "set_null". The REJECT_LIMIT feature with ON_ERROR set_null is being considered for a separate future patch.\nPostgreSQL开发团队正在审查COPY命令的ON_ERROR功能更改，特别是从"ignore"过渡到"ignore_row"并实现新的"set_null"选项。讨论集中在代码审查反馈上，包括错误消息一致性、使用palloc_array改进内存分配，以及FORCE_NOT_NULL与ON_ERROR set_null选项之间的交互。关键争议在于使用ON_ERROR set_null时是否应该阻止FORCE_NOT_NULL，作者认为它们是可以共存的不相关功能。需要更新pg_stat_progress_copy的文档以明确tuples_skipped仅在"ignore"选项下前进，而非"set_null"。带有ON_ERROR set_null的REJECT_LIMIT功能正在考虑作为单独的未来补丁。	2026-01-22 14:45:10+00	\N
12	19be54eb66f3b399	SQL Property Graph Queries (SQL/PGQ)	["ajay.pal.k@gmail.com","amitlangote09@gmail.com","ashutosh.bapat.oss@gmail.com","assam258@gmail.com","imran.zhir@gmail.com","peter@eisentraut.org","vik@postgresfriends.org","zhjwpku@gmail.com"]	[{"id":"19be54eb66f3b399","messageId":"<CABRHmyvnDbm1s7ZZNzU9=XXzHRS41t3uMu9bezKhXeWymAC-Cg@mail.gmail.com>","subject":"Re: SQL Property Graph Queries (SQL/PGQ)","body":"Observation on patch v20260113-0001: GRAPH_TABLE queries are bypassing\\nRow-Level Security checks. A low_priv_user is able to access sensitive\\ndata across the entire table, even though the RLS policy should\\nrestrict the result set to one non-sensitive row.\\n\\nreproducible case:-\\n\\nCREATE TABLE parent_node (id int PRIMARY KEY, secret text);\\nCREATE TABLE child_node () INHERITS (parent_node);\\n\\nINSERT INTO child_node VALUES (1, 'Sensitive');\\nINSERT INTO child_node VALUES (2, 'not Sensitive');\\n\\nCREATE ROLE low_priv_user;\\nGRANT SELECT ON parent_node TO low_priv_user;\\nGRANT SELECT ON child_node TO low_priv_user;\\n\\nALTER TABLE child_node ENABLE ROW LEVEL SECURITY;\\n-- Policy: user cannot see rows where secret contains 'Sensitive'\\nCREATE POLICY p_hide_sensitive ON child_node TO low_priv_user USING\\n(secret !~ 'Sensitive');\\n\\nCREATE PROPERTY GRAPH security_graph VERTEX TABLES (parent_node);\\nGRANT SELECT ON PROPERTY GRAPH security_graph TO low_priv_user;\\n\\n-- TEST: As low_priv_user, this query should return 0 rows.\\nSET ROLE low_priv_user;\\npostgres=> SELECT * FROM GRAPH_TABLE (security_graph MATCH (n) COLUMNS\\n(n.secret));\\n    secret\\n---------------\\n Sensitive\\n not Sensitive\\n(2 rows)\\n\\nThanks\\nAjay\\n\\nOn Tue, Jan 13, 2026 at 9:44 PM Ashutosh Bapat\\n<ashutosh.bapat.oss@gmail.com> wrote:\\n>\\n> On Tue, Jan 13, 2026 at 3:53 PM Peter Eisentraut <peter@eisentraut.org> wrote:\\n> >\\n> > I have a small fixup patch for your 20260102 patches, attached.\\n> >\\n> > - needs additional #include because of recent changes elsewhere\\n> > - copyright year updates\\n> > - various typos\\n> > - some style changes related to palloc APIs\\n>\\n> All changes look good.\\n>\\n> Looks like you have reviewed patches 0002-onwards. I removed 0004\\n> which was erroneously removing the | handling from ecpg lexer as you\\n> pointed out earlier. Squashed all other patches along with your small\\n> fixup patch. Attached is the resultant single patch.\\n>\\n> --\\n> Best Wishes,\\n> Ashutosh Bapat\\n\\n\\n","threadId":"19be54eb66f3b399","snippet":"Observation on patch v20260113-0001: GRAPH_TABLE queries are bypassing Row-Level Security checks. A low_priv_user is able to access sensitive data across the entire table, even though the RLS policy","historyId":"5949","internalDate":"1769078676000","receivedAtUtc":"2026-01-22T10:44:36.000Z","from":"Ajay Pal <ajay.pal.k@gmail.com>"},{"id":"19be590843b6fa22","messageId":"<CAAAe_zCfUVeSQSEEW3bAvof1XEs-epS9FTJ78_E3dykYZ9qCdA@mail.gmail.com>","subject":"Re: SQL Property Graph Queries (SQL/PGQ)","body":"Hi Ajay,\\n\\nI looked into this and it appears to be expected PostgreSQL behavior rather\\nthan a GRAPH_TABLE-specific issue.\\n\\n2026년 1월 22일 (목) PM 7:44, Ajay Pal <ajay.pal.k@gmail.com>님이 작성:\\n\\n> Observation on patch v20260113-0001: GRAPH_TABLE queries are bypassing\\n> Row-Level Security checks. A low_priv_user is able to access sensitive\\n> data across the entire table, even though the RLS policy should\\n> restrict the result set to one non-sensitive row.\\n>\\n> reproducible case:-\\n>\\n> CREATE TABLE parent_node (id int PRIMARY KEY, secret text);\\n> CREATE TABLE child_node () INHERITS (parent_node);\\n>\\n> INSERT INTO child_node VALUES (1, 'Sensitive');\\n> INSERT INTO child_node VALUES (2, 'not Sensitive');\\n>\\n> CREATE ROLE low_priv_user;\\n> GRANT SELECT ON parent_node TO low_priv_user;\\n> GRANT SELECT ON child_node TO low_priv_user;\\n>\\n> ALTER TABLE child_node ENABLE ROW LEVEL SECURITY;\\n> -- Policy: user cannot see rows where secret contains 'Sensitive'\\n> CREATE POLICY p_hide_sensitive ON child_node TO low_priv_user USING\\n> (secret !~ 'Sensitive');\\n>\\n> CREATE PROPERTY GRAPH security_graph VERTEX TABLES (parent_node);\\n> GRANT SELECT ON PROPERTY GRAPH security_graph TO low_priv_user;\\n>\\n> -- TEST: As low_priv_user, this query should return 0 rows.\\n> SET ROLE low_priv_user;\\n> postgres=> SELECT * FROM GRAPH_TABLE (security_graph MATCH (n) COLUMNS\\n> (n.secret));\\n>     secret\\n> ---------------\\n>  Sensitive\\n>  not Sensitive\\n> (2 rows)\\n>\\n\\nRunning a plain SQL query on the same setup shows identical results:\\n\\nSELECT secret FROM parent_node;\\n    secret\\n---------------\\n Sensitive\\n not Sensitive\\n(2 rows)\\n\\nIn PostgreSQL, when querying a parent table, child table's RLS policies are\\nnot applied - only the parent's policies take effect. This is by design.\\n\\nThis behavior is tested in src/test/regress/sql/rowsecurity.sql (lines\\n374-414).\\n\\nThe fix would be to enable RLS on parent_node instead of child_node.\\n\\n\\n> Thanks\\n> Ajay\\n>\\n> On Tue, Jan 13, 2026 at 9:44 PM Ashutosh Bapat\\n> <ashutosh.bapat.oss@gmail.com> wrote:\\n> >\\n> > On Tue, Jan 13, 2026 at 3:53 PM Peter Eisentraut <peter@eisentraut.org>\\n> wrote:\\n> > >\\n> > > I have a small fixup patch for your 20260102 patches, attached.\\n> > >\\n> > > - needs additional #include because of recent changes elsewhere\\n> > > - copyright year updates\\n> > > - various typos\\n> > > - some style changes related to palloc APIs\\n> >\\n> > All changes look good.\\n> >\\n> > Looks like you have reviewed patches 0002-onwards. I removed 0004\\n> > which was erroneously removing the | handling from ecpg lexer as you\\n> > pointed out earlier. Squashed all other patches along with your small\\n> > fixup patch. Attached is the resultant single patch.\\n> >\\n> > --\\n> > Best Wishes,\\n> > Ashutosh Bapat\\n>\\n\\nThanks,\\nHenson\\n","threadId":"19be54eb66f3b399","snippet":"Hi Ajay, I looked into this and it appears to be expected PostgreSQL behavior rather than a GRAPH_TABLE-specific issue. 2026년 1월 22일 (목) PM 7:44, Ajay Pal <ajay.pal.k@gmail.com>님이 작성: Observation","historyId":"5949","internalDate":"1769082990000","receivedAtUtc":"2026-01-22T11:56:30.000Z","from":"Henson Choi <assam258@gmail.com>"},{"id":"19be63016674e4e3","messageId":"<CAExHW5uNa3m0bJtw4oJVh8=5Or71H4TDH0f5Mgz3CFf5B2YMmg@mail.gmail.com>","subject":"Re: SQL Property Graph Queries (SQL/PGQ)","body":"On Thu, Jan 22, 2026 at 5:26 PM Henson Choi <assam258@gmail.com> wrote:\\n>\\n> Hi Ajay,\\n>\\n> I looked into this and it appears to be expected PostgreSQL behavior rather than a GRAPH_TABLE-specific issue.\\n\\n+1. This behaviour is documented in [1]\\n\\n\\"\\nInherited queries perform access permission checks on the parent table\\nonly. Thus, for example, granting UPDATE permission on the cities\\ntable implies permission to update rows in the capitals table as well,\\nwhen they are accessed through cities. This preserves the appearance\\nthat the data is (also) in the parent table. But the capitals table\\ncould not be updated directly without an additional grant. In a\\nsimilar way, the parent table's row security policies (see Section\\n5.9) are applied to rows coming from child tables during an inherited\\nquery. A child table's policies, if any, are applied only when it is\\nthe table explicitly named in the query; and in that case, any\\npolicies attached to its parent(s) are ignored.\\n\\"\\n\\n[1] https://www.postgresql.org/docs/current/ddl-inherit.html#:~:text=In%20a%20similar%20way%2C%20the%20parent%20table's,policies%20attached%20to%20its%20parent(s)%20are%20ignored.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n","threadId":"19be54eb66f3b399","snippet":"On Thu, Jan 22, 2026 at 5:26 PM Henson Choi <assam258@gmail.com> wrote: > > Hi Ajay, > > I looked into this and it appears to be expected PostgreSQL behavior rather than a GRAPH_TABLE","historyId":"5949","internalDate":"1769093446000","receivedAtUtc":"2026-01-22T14:50:46.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"}]	Ajay Pal reported a potential security vulnerability in the SQL/PGQ GRAPH_TABLE implementation, where row-level security (RLS) policies appeared to be bypassed. He demonstrated that a low-privilege user could access sensitive data through GRAPH_TABLE queries despite RLS restrictions. Henson Choi investigated and determined this is not a GRAPH_TABLE-specific bug but expected PostgreSQL behavior with table inheritance. When querying a parent table, only the parent's RLS policies apply, not the child table's policies. Ashutosh Bapat confirmed this explanation, referencing the PostgreSQL documentation on inheritance behavior. The issue stems from the test setup using inheritance where RLS was enabled only on the child table, not the parent.\n\nAjay Pal报告了SQL/PGQ GRAPH_TABLE实现中的一个潜在安全漏洞，其中行级安全(RLS)策略似乎被绕过。他演示了低权限用户尽管有RLS限制，仍可通过GRAPH_TABLE查询访问敏感数据。Henson Choi调查后确定这不是GRAPH_TABLE特有的错误，而是PostgreSQL表继承的预期行为。查询父表时，只应用父表的RLS策略，不应用子表的策略。Ashutosh Bapat确认了这一解释，引用了PostgreSQL继承行为的文档。问题源于测试设置使用了继承，其中RLS仅在子表而非父表上启用。	2026-01-22 14:50:46+00	\N
12	19be64c7d5124d90	SQL:2011 Application Time Update & Delete	["li.evan.chao@gmail.com","peter@eisentraut.org","pj@illuminatedcomputing.com","reshkekirill@gmail.com"]	[{"id":"19be64c7d5124d90","messageId":"<4606deaa-7d65-4f22-8a78-356c3180be9d@eisentraut.org>","subject":"Re: SQL:2011 Application Time Update & Delete","body":"I have committed the pg_range patch.\\n\\nOn 19.01.26 19:33, Paul A Jungwirth wrote:\\n> Do we want a regress test in rangetypes.sql to confirm that these are\\n> set correctly (especially for user-defined types)? I checked manually\\n> after `make installcheck`, and they look fine, but should it be in our\\n> test suite?\\n\\nI think the existing tests do that, since type_sanity runs after the rangetypes test.\\n\\n> Here is another thought I had: As we've talked about in the\\n> application-time threads, I would like temporal features to be\\n> extensible enough to support user-defined types. We almost achieve\\n> that, but we need something like a \\"type support function\\". For primary\\n> key and unique constraints, we need a way to reject invalid values like\\n> empty ranges. For foreign keys we need an intersect operator (which is\\n> not currently in pg_amop, since it is neither for search nor ordering,\\n> and isn't involved in indexes anyway). And for UPDATE/DELETE FOR\\n> PORTION OF we need a foo_minus_multi to compute the \\"temporal\\n> leftovers\\".\\n> > We could also ask for a constructor function, to build the targeted\\n> portion from the FROM/TO bounds. This is not strictly necessary, since\\n> we also have the FOR PORTION OF valid_at (...) syntax (which is used by\\n> multiranges). But it's something that would be nice to offer. In that\\n> case range types would not need these extra columns in pg_range.\\n> > But recording the constructor oids in pg_range still has inherent\\n> value, and doing it now doesn't *prevent* us from later adding a\\n> facility to get a constructor function for FOR PORTION OF bounds. So I\\n> don't think there is any downside to recording them here.\\n\\nRight, that sounds like a future project.\\n\\n\\n\\n","threadId":"19be64c7d5124d90","snippet":"I have committed the pg_range patch. On 19.01.26 19:33, Paul A Jungwirth wrote: > Do we want a regress test in rangetypes.sql to confirm that these are > set correctly (especially for user-","historyId":"5959","internalDate":"1769095314000","receivedAtUtc":"2026-01-22T15:21:54.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"},{"id":"19be64d737c189d1","messageId":"<b4216e13-0fc0-42ce-82e5-9feacd5537e1@eisentraut.org>","subject":"Re: SQL:2011 Application Time Update & Delete","body":"On 19.01.26 18:43, Kirill Reshke wrote:\\n> One stupid question from me: should we add\\n> > ````\\n>   t.typanalyze!='range_typanalyze'::regproc or t.typinput !=\\n> 'range_in'::regproc or t.typoutput != 'range_out'::regproc  or\\n> t.typreceive != 'range_recv'::regproc or typsend !=\\n> 'range_send'::regproc;\\n> > ````\\n\\nMaybe, but this seems to be outside of this patch.  There are also similar considerations for arrays, domains, etc.\\n\\n\\n","threadId":"19be64c7d5124d90","snippet":"On 19.01.26 18:43, Kirill Reshke wrote: > One stupid question from me: should we add > > ```` > t.typanalyze!='range_typanalyze'::regproc or t.typinput != > 'range_in'::","historyId":"5959","internalDate":"1769095381000","receivedAtUtc":"2026-01-22T15:23:01.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	Peter Eisentraut has committed the pg_range patch related to SQL:2011 Application Time features. Paul Jungwirth asked about adding regression tests to confirm proper setup for user-defined types, but Eisentraut noted existing tests in type_sanity should cover this. Jungwirth outlined future extensibility needs for temporal features including type support functions for primary/unique constraints to reject invalid values like empty ranges, intersect operators for foreign keys, and foo_minus_multi functions for UPDATE/DELETE FOR PORTION OF operations. He suggested a constructor function facility could be added later. Kirill Reshke proposed adding additional type validation checks, but Eisentraut considered this outside the current patch scope, noting similar considerations exist for arrays and domains.\n\nPeter Eisentraut 已提交与 SQL:2011 应用时间功能相关的 pg_range 补丁。Paul Jungwirth 询问是否应添加回归测试来确认用户定义类型的正确设置，但 Eisentraut 指出 type_sanity 中的现有测试应该涵盖这一点。Jungwirth 概述了时态功能未来的扩展性需求，包括用于主键/唯一约束的类型支持函数以拒绝空范围等无效值、用于外键的交集运算符，以及用于 UPDATE/DELETE FOR PORTION OF 操作的 foo_minus_multi 函数。他建议稍后可以添加构造函数功能。Kirill Reshke 提议添加额外的类型验证检查，但 Eisentraut 认为这超出了当前补丁的范围，并指出对数组和域也存在类似考虑。	2026-01-22 15:23:01+00	\N
12	19be5f3e577e5d69	Mystery with REVOKE PRIVILEGE	["knizhnik@garret.ru","nathandbossart@gmail.com","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19be5f3e577e5d69","messageId":"<c8e166a6-173b-4637-8e94-4b447b49adab@garret.ru>","subject":"Re: Mystery with REVOKE PRIVILEGE","body":"\\nOn 21/01/2026 1:07 AM, Tom Lane wrote:\\n> Nathan Bossart <nathandbossart@gmail.com> writes:\\n>> On Tue, Jan 20, 2026 at 04:32:31PM -0500, Tom Lane wrote:\\n>>> I don't think \\"let's make select_best_grantor even more magic\\"\\n>>> is the right approach.  IMO, if there is a GRANTED BY clause,\\n>>> we should use exactly that grantor and not apply select_best_grantor\\n>>> at all.  This is, for example, certainly the behavior needed for\\n>>> pg_dump.\\n>> I started on something like that here:\\n>> \\thttps://postgr.es/m/aRYLkTpazxKhnS_w%40nathan\\n> Ah, I wonder if that discussion was lurking in my hindbrain.\\n> I just posted a different take on how to do it in that thread,\\n> but the behavioral change should be the same.\\n>\\n> \\t\\t\\tregards, tom lane\\n\\n\\nThank you.\\nFixing explicit grantor case is definitely the most critical thing.\\nAnd I completely agree with your patch.\\nBut I wonder if we do refactoring of this revoke privileges stuff, should we also provide correct (expected) behaviour in case of missing grantor specification. i.e.\\n\\n     revoke all privileges on table <T> from <role>;\\n\\nIf privileges to access this table were granted to this role by multiple grantors, then it is natural to expect that the statement above will remove all such grants and so as a result <role> can not access this table any more, rather than try to find best grantor and finally still leave privileges for this role, isn't it?\\n\\n\\n\\n\\n","threadId":"19be5f3e577e5d69","snippet":"On 21/01/2026 1:07 AM, Tom Lane wrote: > Nathan Bossart <nathandbossart@gmail.com> writes: >> On Tue, Jan 20, 2026 at 04:32:31PM -0500, Tom Lane wrote: >>> I don't think","historyId":"5956","internalDate":"1769089509000","receivedAtUtc":"2026-01-22T13:45:09.000Z","from":"Konstantin Knizhnik <knizhnik@garret.ru>"},{"id":"19be68fabb9e1531","messageId":"<2716313.1769099716@sss.pgh.pa.us>","subject":"Re: Mystery with REVOKE PRIVILEGE","body":"Konstantin Knizhnik <knizhnik@garret.ru> writes:\\n> But I wonder if we do refactoring of this revoke privileges stuff, \\n> should we also provide correct (expected) behaviour in case of missing \\n> grantor specification. i.e.\\n\\n>       revoke all privileges on table <T> from <role>;\\n\\n> If privileges to access this table were granted to this role by multiple \\n> grantors, then it is natural to expect that the statement above will \\n> remove all such grants and so as a result <role> can not access this \\n> table any more, rather than try to find best grantor and finally still \\n> leave privileges for this role, isn't it?\\n\\nUnfortunately, the SQL spec is quite clear that REVOKE revokes only\\nprivileges granted directly by the calling user (or the GRANTED BY\\nrole, if that's given).  We're already far outside the spec by\\nallowing select_best_grantor to locate an inherited role to do the\\nrevoke as.  I can't see reinterpreting it as \\"revoke all privileges\\ngranted by anybody\\", even assuming that the calling user has\\nsufficient permissions to do that.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19be5f3e577e5d69","snippet":"Konstantin Knizhnik <knizhnik@garret.ru> writes: > But I wonder if we do refactoring of this revoke privileges stuff, > should we also provide correct (expected) behaviour in case of","historyId":"5956","internalDate":"1769099716000","receivedAtUtc":"2026-01-22T16:35:16.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	The discussion focuses on fixing PostgreSQL's REVOKE privilege behavior, specifically addressing issues with the GRANTED BY clause and grantor selection. Tom Lane and Nathan Bossart are working on a patch to ensure that when GRANTED BY is explicitly specified, the system uses exactly that grantor without applying select_best_grantor logic. This change is particularly important for pg_dump functionality. Konstantin Knizhnik suggests extending the fix to handle cases where no grantor is specified, proposing that "REVOKE ALL PRIVILEGES" should remove all grants from any grantor. However, Tom Lane explains this would violate SQL specification, which mandates REVOKE only affects privileges granted directly by the calling user or specified GRANTED BY role. The current select_best_grantor behavior already extends beyond the spec by allowing inherited role privileges.\n\n讨论重点是修复PostgreSQL的REVOKE权限行为，特别是解决GRANTED BY子句和授权者选择的问题。Tom Lane和Nathan Bossart正在开发一个补丁，确保当明确指定GRANTED BY时，系统准确使用该授权者而不应用select_best_grantor逻辑。这个更改对pg_dump功能特别重要。Konstantin Knizhnik建议扩展修复以处理未指定授权者的情况，提议"REVOKE ALL PRIVILEGES"应该移除来自任何授权者的所有授权。然而，Tom Lane解释这会违反SQL规范，规范要求REVOKE只影响调用用户或指定GRANTED BY角色直接授予的权限。当前的select_best_grantor行为通过允许继承角色权限已经超出了规范范围。	2026-01-22 16:35:16+00	\N
12	19be6a499e8b09ae	Likely undefined behavior with some flexible arrays	["andres@anarazel.de","tgl@sss.pgh.pa.us","x4mmm@yandex-team.ru"]	[{"id":"19be6a499e8b09ae","messageId":"<yjtlufdn6kaoctydjrryzt267xnls2t4lizslnbgqzhtsnohkj@fvvr3dbtvbrc>","subject":"Re: Likely undefined behavior with some flexible arrays","body":"Hi,\\n\\nOn 2026-01-22 11:09:37 +0500, Andrey Borodin wrote:\\n> > On 22 Jan 2026, at 06:56, Andres Freund <andres@anarazel.de> wrote:\\n> > \\n> > It'd be nice to teach\\n> > the compile that palloc allocates, to a) get compiler warnings for things like\\n> > use-after-free b) warnings for things like access-beyond-allocation.\\n> \\n> Is there any chance to teach a compiler about short lived memory contexts?\\n\\nI doubt that we can teach static analysis that anytime soon - I think you'd\\nneed a compiler plugin for that. However I'd already be happy with getting\\nwarnings for obvious stuff like using variables after being pfreed (even\\nindirectly) or running off the end of an allocation.\\n\\nWe certainly could improve the sanitizer integration with memory contexts, but\\nthat obviously requires reaching the relevant paths in a problematic scenario\\nto be effective.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19be6a499e8b09ae","snippet":"Hi, On 2026-01-22 11:09:37 +0500, Andrey Borodin wrote: > > On 22 Jan 2026, at 06:56, Andres Freund <andres@anarazel.de> wrote: > > > > It'd be nice to teach > > the","historyId":"5963","internalDate":"1769101094000","receivedAtUtc":"2026-01-22T16:58:14.000Z","from":"Andres Freund <andres@anarazel.de>"}]	Andres Freund discusses challenges in teaching compilers about PostgreSQL's palloc memory allocation to enable better static analysis warnings for memory safety issues. He responds to Andrey Borodin's question about compiler awareness of short-lived memory contexts, explaining that this would likely require a compiler plugin and isn't feasible in the near term. However, Freund expresses interest in achieving more basic compiler warnings for obvious memory errors such as use-after-free bugs (including indirect cases through pfree) and buffer overruns beyond allocated memory boundaries. He also mentions that improving sanitizer integration with memory contexts could help, though this approach requires actually triggering problematic code paths during testing to be effective.\n\nAndres Freund讨论了在教导编译器理解PostgreSQL的palloc内存分配方面的挑战，以便启用更好的内存安全问题静态分析警告。他回应了Andrey Borodin关于编译器对短生命周期内存上下文感知的问题，解释说这可能需要编译器插件，在近期内不太可行。然而，Freund表示有兴趣实现更基本的编译器警告，用于检测明显的内存错误，如释放后使用的错误（包括通过pfree的间接情况）和超出分配内存边界的缓冲区溢出。他还提到改进与内存上下文的清理器集成可能有帮助，尽管这种方法需要在测试期间实际触发有问题的代码路径才能生效。	2026-01-22 16:58:14+00	\N
12	19be4dac85c04761	ReadRecentBuffer() doesn't scale well	["amitlangote09@gmail.com","andres@anarazel.de","ianilyasov@outlook.com","thomas.munro@gmail.com"]	[{"id":"19be6a27cf366076","messageId":"<wbmtz3b4cm3zwcsfunymbaauu7dlwbimzma7tsyjtg3npqy546@tj6oqcktgjvh>","subject":"Re: ReadRecentBuffer() doesn't scale well","body":"Hi,\\n\\nOn 2026-01-22 08:37:56 +0000, Ilyasov Ian wrote:\\n> Speaking of this patch, I've done a benchmark test on a master branch on 34740b90bc123d645a3a71231b765b778bdcf049 commit with a patch by Thomas Munro: https://www.postgresql.org/message-id/attachment/148040/0002-Use-ReadRecentBuffer-for-btree-root-page.patch and without it. The configuration of the server was 96 cores and 1.5 TB of RAM.\\n\\nWhich patch specifically do you mean?\\n\\nAn evolved version of 0001 from\\nhttps://postgr.es/m/CA%2BhUKGJ8N_DRSB0YioinWjS2ycMpmOLy32mbBqVVztwBvXgyJA%40mail.gmail.com\\nhas already been applied (see 819dc118c0f).\\n\\nSo I guess you were testing 0002 from that email?\\n\\nOr were you testing 0002 from\\nhttps://postgr.es/m/CA%2BhUKGLMFtNqei9nfcJy2SQMLWyYuO9E8NLYrb%3D4Gs1HgkAS7Q%40mail.gmail.com\\nwhich is a completely different patch?\\n\\n\\n> My conclusion is that this patch looks excellent on multicore systems and it would be great if it is committed.\\n> Also I have a question if committed whether this patch would be backported to 18th version?\\n\\nWe don't backpatch performance improvements unless they are addressing\\nperformance issues that are so severe that they basically amount to a bug.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19be4dac85c04761","snippet":"Hi, On 2026-01-22 08:37:56 +0000, Ilyasov Ian wrote: > Speaking of this patch, I've done a benchmark test on a master branch on 34740b90bc123d645a3a71231b765b778bdcf049 commit with a patch by","historyId":"5939","internalDate":"1769100955000","receivedAtUtc":"2026-01-22T16:55:55.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19be6acf1d9d4942","messageId":"<ZR5P278MB182101CD2C00CE5713CB7902CD97A@ZR5P278MB1821.CHEP278.PROD.OUTLOOK.COM>","subject":"RE: ReadRecentBuffer() doesn't scale well","body":"> Or were you testing 0002 from\\n> https://postgr.es/m/CA%2BhUKGLMFtNqei9nfcJy2SQMLWyYuO9E8NLYrb%3D4Gs1HgkAS7Q%40mail.gmail.com\\n> which is a completely different patch?\\n\\nYes, I tested the aforementioned patch under the name: 0002-Use-ReadRecentBuffer-for-btree-root-page.patch in this thread.\\n\\n> We don't backpatch performance improvements unless they are addressing\\n> performance issues that are so severe that they basically amount to a bug.\\n\\nThank you for your answer. Will keep it in mind for the future.\\n\\nKind regards,\\nIan Ilyasov.\\n\\n","threadId":"19be4dac85c04761","snippet":"> Or were you testing 0002 from > https://postgr.es/m/CA%2BhUKGLMFtNqei9nfcJy2SQMLWyYuO9E8NLYrb%3D4Gs1HgkAS7Q%40mail.gmail.com > which is a completely different patch? Yes, I tested the","historyId":"5939","internalDate":"1769101639000","receivedAtUtc":"2026-01-22T17:07:19.000Z","from":"Ilyasov Ian <ianilyasov@outlook.com>"}]	Andres Freund seeks clarification on which ReadRecentBuffer() patch Ian Ilyasov tested in his benchmark. Ian had reported excellent performance results on a 96-core, 1.5TB RAM system but referenced multiple different patches from various email threads. Freund notes that one patch (0001) has already been committed as 819dc118c0f, and asks whether Ian tested the btree root page patch (0002) from a specific thread. Ian confirms he tested the "0002-Use-ReadRecentBuffer-for-btree-root-page.patch" from the second thread mentioned. Regarding backporting to PostgreSQL 18, Freund explains that performance improvements are only backpatched when they address severe performance issues that essentially constitute bugs.\n\nAndres Freund寻求澄清Ian Ilyasov在基准测试中测试了哪个ReadRecentBuffer()补丁。Ian在96核心、1.5TB内存的系统上报告了出色的性能结果，但引用了来自不同邮件线程的多个不同补丁。Freud指出一个补丁(0001)已作为819dc118c0f提交，并询问Ian是否测试了特定线程中的btree根页补丁(0002)。Ian确认他测试了第二个线程中提到的"0002-Use-ReadRecentBuffer-for-btree-root-page.patch"。关于向PostgreSQL 18反向移植，Freund解释性能改进只有在解决本质上构成错误的严重性能问题时才会被反向移植。	2026-01-22 17:07:19+00	\N
12	19be51f046352557	Flush some statistics within running transactions	["bertranddrouvot.pg@gmail.com","masao.fujii@gmail.com","michael@paquier.xyz","samimseih@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be59f0aff6b191","messageId":"<CAHGQGwHttst8tv_WWYNoGGfL1UAq4kiy6dpFXoxEkJwHMS9FtQ@mail.gmail.com>","subject":"Re: Flush some statistics within running transactions","body":"On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot\\n<bertranddrouvot.pg@gmail.com> wrote:\\n>\\n> Hi,\\n>\\n> On Thu, Jan 22, 2026 at 10:56:48AM +0900, Fujii Masao wrote:\\n> > On Thu, Jan 22, 2026 at 10:41 AM Sami Imseih <samimseih@gmail.com> wrote:\\n> > >\\n> > > Sure, Bertrand mentioned early in the thread that the anytime flushes\\n> > > could be made configurable. Perhaps that is a good idea where we can\\n> > > default with something large like 10s intervals for anytime flushes, but allow\\n> > > the user to configure a more frequent flushes ( although I would think\\n> > > that 1 sec is the minimum we should allow ).\\n> >\\n> > +1 on adding an option to control the interval. With a fixed interval\\n> > (for example, 1s), log_lock_waits messages could be emitted that frequently,\\n> > which may be annoying for some users.\\n> >\\n> > Of course, it would be even better if these periodic wakeups did not trigger\\n> > log_lock_waits messages at all, though.\\n>\\n> pgstat_report_anytime_stat() is called with the force parameter set to false,\\n> means that the flushes are done with nowait = true means that LWLockConditionalAcquire()\\n> is used. In that case, do you still see cases where log_lock_waits messages could\\n> be triggered due to the new flush?\\n\\nI haven't read the patch in detail yet, but after applying patch 0001 and\\ncausing a lock wait (for example, using the steps below), I observed that\\nlog_lock_waits messages are emitted every second.\\n\\n    [session 1]\\n    create table tbl as select id from generate_series(1, 10) id;\\n    begin;\\n    select * from tbl where id = 1 for update;\\n\\n    [session 2]\\n    begin;\\n    select * from tbl where id = 1 for update;\\n\\nWith this setup, the following messages were logged once per second:\\n\\n    LOG:  process 72199 still waiting for ShareLock on transaction 771\\nafter 63034.119 ms\\n    DETAIL:  Process holding the lock: 72190. Wait queue: 72199.\\n\\nRegards,\\n\\n-- \\nFujii Masao\\n\\n\\n","threadId":"19be51f046352557","snippet":"On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot <bertranddrouvot.pg@gmail.com> wrote: > > Hi, > > On Thu, Jan 22, 2026 at 10:56:48AM +0900, Fujii Masao wrote: > > On Thu, Jan","historyId":"5946","internalDate":"1769083938000","receivedAtUtc":"2026-01-22T12:12:18.000Z","from":"Fujii Masao <masao.fujii@gmail.com>"},{"id":"19be698fe769047d","messageId":"<aXJUK90lKXw3wrZn@ip-10-97-1-34.eu-west-3.compute.internal>","subject":"Re: Flush some statistics within running transactions","body":"Hi,\\n\\nOn Thu, Jan 22, 2026 at 09:12:18PM +0900, Fujii Masao wrote:\\n> On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot\\n> <bertranddrouvot.pg@gmail.com> wrote:\\n> >\\n> > pgstat_report_anytime_stat() is called with the force parameter set to false,\\n> > means that the flushes are done with nowait = true means that LWLockConditionalAcquire()\\n> > is used. In that case, do you still see cases where log_lock_waits messages could\\n> > be triggered due to the new flush?\\n> \\n> I haven't read the patch in detail yet, but after applying patch 0001 and\\n> causing a lock wait (for example, using the steps below), I observed that\\n> log_lock_waits messages are emitted every second.\\n> \\n>     [session 1]\\n>     create table tbl as select id from generate_series(1, 10) id;\\n>     begin;\\n>     select * from tbl where id = 1 for update;\\n> \\n>     [session 2]\\n>     begin;\\n>     select * from tbl where id = 1 for update;\\n> \\n> With this setup, the following messages were logged once per second:\\n> \\n>     LOG:  process 72199 still waiting for ShareLock on transaction 771\\n> after 63034.119 ms\\n>     DETAIL:  Process holding the lock: 72190. Wait queue: 72199.\\n> \\n\\nThanks!\\n\\nI see, the WaitLatch() in ProcSleep() is \\"woken up\\" every 1s due to the \\nenable_timeout_after(ANYTIME_STATS_UPDATE_TIMEOUT,...) being set unconditionally\\nin ProcessInterrupts(). We need to be more restrictive as to when to enable the\\ntimeout, I'll fix in the next version.\\n\\nRegards,\\n\\n-- \\nBertrand Drouvot\\nPostgreSQL Contributors Team\\nRDS Open Source Databases\\nAmazon Web Services: https://aws.amazon.com\\n\\n\\n","threadId":"19be51f046352557","snippet":"Hi, On Thu, Jan 22, 2026 at 09:12:18PM +0900, Fujii Masao wrote: > On Thu, Jan 22, 2026 at 4:43 PM Bertrand Drouvot > <bertranddrouvot.pg@gmail.com> wrote: > > > >","historyId":"5946","internalDate":"1769100331000","receivedAtUtc":"2026-01-22T16:45:31.000Z","from":"Bertrand Drouvot <bertranddrouvot.pg@gmail.com>"},{"id":"19be6bbe9d8d573e","messageId":"<CAA5RZ0vbL8fw4h7JQEuLE5JqLqVbG+7oBKkM_4eONMe=yJ=Veg@mail.gmail.com>","subject":"Re: Flush some statistics within running transactions","body":"> For example, pgstat_update_dbstats() updates some of them: xact_commit, xact_rollback,\\n> blk_read_time, blk_write_time, session_time, active_time and idle_in_transaction_time\\n> but only at transaction boundaries. Indeed, pgstat_update_dbstats() is only called\\n> during pgstat_report_stat() and not during pgstat_report_anytime_stat().\\n>\\n> I think that we could:\\n>\\n> 1. Update the doc as you suggest\\n\\nI am thinking the _time related fields are OK to be non-anytime\\nfields, since they\\nhave overhead and also they can be actively monitored from pg_stat_activity\\nif someone really needs real time information.\\n\\nThe other session related counters don't need need special consideration.\\n\\nparallel counters are anytime.\\n\\nSo, the documentation can mention the _time related fields that are flushed\\nonly at their appropriate times.\\n\\nMaybe something general like this:\\n\\n\\"Some statistics are updated while a transaction is in progress.\\nStatistics that either do\\nnot depend on transactions or require transactional consistency are\\nupdated only\\nwhen the transaction ends. Statistics that require transactional consistency\\ninclude xact_commit, xact_rollback, tup_inserted, tup_updated, and tup_deleted.\\"\\n\\nWhat do you think?\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be51f046352557","snippet":"> For example, pgstat_update_dbstats() updates some of them: xact_commit, xact_rollback, > blk_read_time, blk_write_time, session_time, active_time and idle_in_transaction_time > but only at","historyId":"5946","internalDate":"1769102609000","receivedAtUtc":"2026-01-22T17:23:29.000Z","from":"Sami Imseih <samimseih@gmail.com>"}]	The discussion centers on a patch to flush PostgreSQL statistics within running transactions rather than only at transaction boundaries. Fujii Masao tested patch 0001 and discovered an unintended side effect: log_lock_waits messages are emitted every second during lock waits. He demonstrated this by creating a scenario where two sessions compete for the same row lock, resulting in frequent "process still waiting for ShareLock" messages. Bertrand Drouvot acknowledged the issue, explaining that WaitLatch() in ProcSleep() is being awakened every second due to ANYTIME_STATS_UPDATE_TIMEOUT being set unconditionally in ProcessInterrupts(). He committed to fixing this by being more restrictive about when to enable the timeout. Sami Imseih contributed to documentation discussions, suggesting that time-related statistics fields should remain non-anytime fields due to overhead concerns, while proposing clearer documentation about which statistics require transactional consistency versus those that can be updated during transactions.\n\n讨论围绕一个在运行事务中刷新PostgreSQL统计信息而不是仅在事务边界处刷新的补丁展开。Fujii Masao测试了补丁0001并发现了意外的副作用：在锁等待期间每秒都会发出log_lock_waits消息。他通过创建两个会话竞争同一行锁的场景演示了这个问题，导致频繁出现"进程仍在等待ShareLock"消息。Bertrand Drouvot承认了这个问题，解释说WaitLatch()在ProcSleep()中每秒被唤醒是因为ANYTIME_STATS_UPDATE_TIMEOUT在ProcessInterrupts()中被无条件设置。他承诺通过更严格地限制何时启用超时来修复此问题。Sami Imseih参与了文档讨论，建议时间相关的统计字段由于开销问题应保持为非随时字段，同时提议更清楚地记录哪些统计信息需要事务一致性而哪些可以在事务期间更新。	2026-01-22 17:23:29+00	\N
12	19be66940c5bb07c	Inval reliability, especially for inplace updates	["andres@anarazel.de","mark.dilger@enterprisedb.com","nitinmotiani@google.com","noah@leadboat.com"]	[{"id":"19be66940c5bb07c","messageId":"<CAHgHdKvTv6knvzmtumdzAqF9_PykaUc6b-6c80VpMZEV0UuyZQ@mail.gmail.com>","subject":"Re: Inval reliability, especially for inplace updates","body":"On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote:\\n\\n> On Wed, Jan 21, 2026 at 08:59:51AM -0800, Mark Dilger wrote:\\n> > On Wed, Oct 23, 2024 at 7:54 PM Noah Misch <noah@leadboat.com> wrote:\\n> > > I'm attaching the branch-specific patches for that and for the main\\n> fix.\\n> > > Other notes from back-patching:\\n> > >\\n> > > - All branches change the ABI of PrepareToInvalidateCacheTuple(), a\\n> > > function\\n> > >   catcache.c exports for the benefit of inval.c.  No PGXN extension\\n> calls\\n> > >   that, and I can't think of a use case in extensions.\\n> >\\n> > Unfortunately, I can think of four.\\n>\\n> Those are non-PGXN extensions, right?\\n>\\n\\nRight.\\n\\nBased on your experience, I probably should encourage packagers to do an\\n> early\\n> check of the packages they build, especially if they build tableam modules\\n> not\\n> found in PGXN.  How do you see it?\\n>\\n\\nI don't know what you mean by \\"early\\".  18.2 hasn't stamped yet.  18.1\\ndoesn't have the change.  So, I'd say that I'm building pretty early, and I\\nnoticed the change will be coming in 18.2.\\n\\n\\n> > I have four Table Access Methods that\\n> > I now need to fork to be compatible with 18.0 and 18.1 on the one hand,\\n> and\\n> > 18.2 onward on the other.\\n>\\n> For what it's worth, the ABI break you quoted is the v14-v17 break, not the\\n> v18 break:\\n>\\n> - v18.2 (06b030e) is changing the CacheInvalidateHeapTupleInplace() ABI\\n> - v14-v17 (e.g. 2e58802) is changing the PrepareToInvalidateCacheTuple()\\n> ABI\\n>\\n\\nI'll have to work around both.  I maintain TAM packages going back multiple\\nmajor versions.\\n\\n\\n> > I'm sorry I didn't follow this thread before it got pushed.\\n> >\\n> > Is there a reason for doing this change in back branches?  The thread is\\n> > pretty long, and I'm struggling to find a security or stability\\n> > justification for the ABI break, but perhaps there is one.\\n>\\n> Chiefly, the fix prevents data loss that arose via losing a relhasindex,\\n> relfrozenxid, or datfrozenxid update.  (The log message of 0f69bed says\\n> \\"another backend's DDL could then update the row without incorporating the\\n> inplace update\\".)  For an example, see where that commit edits\\n> src/test/isolation/expected/inplace-inval.out.\\n>\\n\\nOh, I don't mean to question the overall purpose of the patch.  I was\\nquestioning whether it needed to have breaking changes which are mere \\"code\\ncleanup\\".  The change to CacheInvalidateHeapTupleInplace to remove the\\nunused third argument seemed inappropriate for backpatching, so I spoke up\\nbefore 18.2 is stamped.  Doing this one piece of code cleanup in the back\\nbranches will cause a lot of packaging pain for no real benefit.\\n\\n\\n-- \\n\\n*Mark Dilger*\\n","threadId":"19be66940c5bb07c","snippet":"On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote: On Wed, Jan 21, 2026 at 08:59:51AM -0800, Mark Dilger wrote: > On Wed, Oct 23, 2024 at 7:54 PM Noah Misch <noah@","historyId":"5960","internalDate":"1769097201000","receivedAtUtc":"2026-01-22T15:53:21.000Z","from":"Mark Dilger <mark.dilger@enterprisedb.com>"},{"id":"19be6cd7b0f8ed2e","messageId":"<20260122174250.bf@rfd.leadboat.com>","subject":"Re: Inval reliability, especially for inplace updates","body":"On Thu, Jan 22, 2026 at 07:53:21AM -0800, Mark Dilger wrote:\\n> On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote:\\n> > Based on your experience, I probably should encourage packagers to do an\\n> > early check of the packages they build, especially if they build tableam\\n> > modules not found in PGXN.  How do you see it?\\n> \\n> I don't know what you mean by \\"early\\".  18.2 hasn't stamped yet.  18.1\\n> doesn't have the change.  So, I'd say that I'm building pretty early, and I\\n> noticed the change will be coming in 18.2.\\n\\nI'll probably say:\\n\\n  If you've tested your packaging builds against REL_17_STABLE and\\n  REL_18_STABLE since 2025-12-16 *or* you package only modules present in\\n  PGXN, you can stop reading.\\n\\n  Mark Dilger reported non-PGXN tableam modules that needed changes to cope\\n  with back-patched signature changes in functions\\n  CacheInvalidateHeapTupleInplace() (commit 06b030e) and\\n  PrepareToInvalidateCacheTuple() (commit 2e58802).  Consider trying a rebuild\\n  against REL_17_STABLE and REL_18_STABLE now, so you learn about any similar\\n  need for changes in your modules.\\n\\n> Oh, I don't mean to question the overall purpose of the patch.  I was\\n> questioning whether it needed to have breaking changes which are mere \\"code\\n> cleanup\\".  The change to CacheInvalidateHeapTupleInplace to remove the\\n> unused third argument seemed inappropriate for backpatching, so I spoke up\\n> before 18.2 is stamped.  Doing this one piece of code cleanup in the back\\n> branches will cause a lot of packaging pain for no real benefit.\\n\\nIs the source code for one of these modules published?  I'm not picturing how\\na module could need a CacheInvalidateHeapTupleInplace() call, so your code may\\nilluminate that for me.\\n\\nIf you upload one of these modules to PGXN, my scans before future ABI breaks\\nwill find its calls and will block avoidable ABI breaks like the\\nCacheInvalidateHeapTupleInplace() one.\\n\\n\\n","threadId":"19be66940c5bb07c","snippet":"On Thu, Jan 22, 2026 at 07:53:21AM -0800, Mark Dilger wrote: > On Wed, Jan 21, 2026 at 9:47 AM Noah Misch <noah@leadboat.com> wrote: > > Based on your experience, I probably should","historyId":"5960","internalDate":"1769103770000","receivedAtUtc":"2026-01-22T17:42:50.000Z","from":"Noah Misch <noah@leadboat.com>"}]	Mark Dilger reports that recent PostgreSQL back-patches fixing invalidation reliability for inplace updates have broken the ABI for four Table Access Methods he maintains. The changes affect CacheInvalidateHeapTupleInplace() and PrepareToInvalidateCacheTuple() functions across multiple major versions (v14-v18). While the patches address serious data loss issues involving relhasindex, relfrozenxid, and datfrozenxid updates, Dilger questions whether code cleanup aspects like removing unused function parameters should be back-patched, causing packaging difficulties without clear benefit. Noah Misch acknowledges the concern and suggests encouraging packagers to test builds early against stable branches. He also requests source code examples to better understand tableam module usage of these functions and recommends uploading modules to PGXN for future ABI break detection.\n\nMark Dilger 报告称，最近 PostgreSQL 修复就地更新失效可靠性的反向移植破坏了他维护的四个表访问方法的 ABI。这些更改影响多个主要版本（v14-v18）中的 CacheInvalidateHeapTupleInplace() 和 PrepareToInvalidateCacheTuple() 函数。虽然这些补丁解决了涉及 relhasindex、relfrozenxid 和 datfrozenxid 更新的严重数据丢失问题，但 Dilger 质疑是否应该反向移植代码清理方面的内容（如删除未使用的函数参数），这会在没有明确好处的情况下造成打包困难。Noah Misch 承认了这一担忧，并建议鼓励打包人员尽早针对稳定分支测试构建。他还请求源代码示例以更好地理解表访问方法模块对这些函数的使用，并建议将模块上传到 PGXN 以便将来检测 ABI 破坏。	2026-01-22 17:42:50+00	\N
12	19be51d175b3789d	refactor architecture-specific popcount code	["hlinnaka@iki.fi","johncnaylorls@gmail.com","nathandbossart@gmail.com"]	[{"id":"19be6d49c9d6d659","messageId":"<aXJjbkp2_glyfy6z@nathan>","subject":"Re: refactor architecture-specific popcount code","body":"On Thu, Jan 22, 2026 at 04:50:26PM +0700, John Naylor wrote:\\n> 1) Nowadays, the only global call sites of the word-sized functions\\n> are select_best_grantor() and in bitmapsets. The latter calls the\\n> word-sized functions in a loop (could be just one word). It may be\\n> more efficient to calculate the size in bytes and call pg_popcount().\\n\\nYeah, these seem like obvious places to use pg_popcount().  Note that\\nbms_member_index() does a final popcount on a masked version of the last\\nword.  We could swap that with pg_popcount(), too, but it might be slower\\nthan just calling the word-sized function.  However, it could be hard to\\ntell the difference, as we'd be trading a function or function pointer call\\nwith an inlined loop over pg_number_of_ones.  And even if it is slower, I'm\\nnot sure it matters all that much in the grand scheme of things.\\n\\nIn any case, 0001 gets the easy ones out of the way.\\n\\n> Then we could get rid of all the pointer indirection for the\\n> word-sized functions.\\n\\nDo you mean that we'd just keep the portable ones around?  I see some code\\nin pgvector that might be negatively impacted by that, but if I understand\\ncorrectly it would require an unusual setup.\\n\\n> 2) The x86 byte buffer variants expend a lot of effort to detect\\n> whether the buffer is aligned on both 64- and 32-bit platforms, with\\n> an optimized path for each. At least 64-bit doesn't care about\\n> alignment, and 32-bit doesn't warrant anything fancier than pure C.\\n> Simultaneously, the aarch64 equivalent doesn't seem to take care about\\n> alignment. (I think Nathan mentioned he didn't see a difference during\\n> testing, but I wonder how universal that is).\\n\\n0002 makes these changes for pg_popcount_sse42() and\\npg_popcount_masked_sse42().  It does seem strange to prefer a loop over\\npg_number_of_ones instead of using POPCNTQ when unaligned, but perhaps it's\\nworth testing.  I do recall the alignment stuff in the AVX-512 code showing\\nbenefits in tests because it avoids double-load overhead, so I think we\\nshould keep that for now.\\n\\n> 3) There is repeated code for the <8 bytes case, and the tail of the\\n> \\"optimized\\" functions. I'm also not sure why the small case is inlined\\n> everywhere.\\n\\nThis is intended to help avoid function call and SIMD instruction overhead\\nwhen it doesn't make sense to take it.  I recall this showing a rather big\\ndifference in benchmarks when we were working on the AVX-512 versions.\\nRegarding the duplicated code, sure, we could add some static inline\\nfunctions or something.  I think the only reason I haven't done so is\\nbecause it's ~2 lines of code.\\n\\n-- \\nnathan\\n","threadId":"19be51d175b3789d","snippet":"On Thu, Jan 22, 2026 at 04:50:26PM +0700, John Naylor wrote: > 1) Nowadays, the only global call sites of the word-sized functions > are select_best_grantor() and in bitmapsets. The latter calls","historyId":"5945","internalDate":"1769104238000","receivedAtUtc":"2026-01-22T17:50:38.000Z","from":"Nathan Bossart <nathandbossart@gmail.com>"}]	Nathan Bossart responds to John Naylor's proposals for refactoring PostgreSQL's architecture-specific popcount code. He agrees that bitmapset functions like select_best_grantor() should use pg_popcount() instead of word-sized functions, though notes potential performance trade-offs for bms_member_index(). For x86 optimizations, Nathan's patch 0002 removes alignment detection complexity from SSE4.2 variants but suggests keeping AVX-512 alignment optimizations due to proven benefits. He explains that inlined small-case handling avoids function call overhead and showed significant benchmark improvements during AVX-512 development. Nathan acknowledges code duplication could be reduced with static inline functions but considers the current ~2-line duplications minimal. The discussion focuses on balancing code simplification with performance optimization across different CPU architectures.\n\nNathan Bossart回应John Naylor关于重构PostgreSQL架构特定popcount代码的提案。他同意bitmapset函数如select_best_grantor()应使用pg_popcount()而非字长函数，但指出bms_member_index()可能存在性能权衡。对于x86优化，Nathan的补丁0002从SSE4.2变体中移除了对齐检测复杂性，但建议保留AVX-512对齐优化，因为已证明有益。他解释内联小情况处理避免了函数调用开销，在AVX-512开发期间基准测试显示显著改进。Nathan承认代码重复可通过静态内联函数减少，但认为当前约2行的重复很少。讨论重点是在不同CPU架构上平衡代码简化与性能优化。	2026-01-22 17:50:38+00	\N
12	19be6f25752a8025	Speed up COPY FROM text/CSV parsing using SIMD	["andrew@dunslane.net","byavuz81@gmail.com","ma_kazar@esi.dz","manni.wood@enterprisedb.com","markwkm@gmail.com","nathandbossart@gmail.com","neil.conway@gmail.com","shinya11.kato@gmail.com"]	[{"id":"19be6f25752a8025","messageId":"<CA+K2RumUD+aJ3vuD+05aDWj6geek5DCPYD5peXrRU41QjtORFA@mail.gmail.com>","subject":"Re: Speed up COPY FROM text/CSV parsing using SIMD","body":"Hello,\\n\\nOn Tue, Jan 20, 2026 at 9:49 PM Manni Wood <manni.wood@enterprisedb.com>\\nwrote:\\n\\n> Hello, all I have more benchmarks.\\n>\\n> These benchmarks are from a Raspberry Pi 5 that I bought. It has an Arm\\n> Cortex A76 processor.\\n>\\n> (I was so impressed with the stability of the results I got on my\\n> standalone Intel tower PC that I figured I needed a standalone Arm-based\\n> machine that was not a laptop and not a VM at a cloud service provider. The\\n> run-to-run results were indeed more stable, just like with my standalone\\n> tower PC.)\\n>\\n> COPY FROM\\n>\\n> master: (852558b9)\\n>\\n> text, no special: 9111\\n> text, 1/3 special: 10302\\n> csv, no special: 11147\\n> csv, 1/3 special: 13375\\n>\\n> v3\\n>\\n> text, no special: 7351 (19.3% speedup)\\n> text, 1/3 special: 10397 (0.9% regression)\\n> csv, no special: 7272 (34.7% speedup)\\n> csv, 1/3 special: 13472 (0.7% regression)\\n>\\n> v4.2\\n>\\n> text, no special: 7300 (19.6% speedup)\\n> text, 1/3 special: 10537 (2.3% regression)\\n> csv, no special: 7260 (34.8% speedup)\\n> csv, 1/3 special: 13881 (3.8% regression)\\n>\\n> COPY TO\\n>\\n> master: (852558b9)\\n>\\n> text, no special: 2446\\n> text, 1/3 special: 6988\\n> csv, no special: 2822\\n> csv, 1/3 special: 6967\\n>\\n> v4 (copy to)\\n>\\n> text, no special: 1533 (37.3% speedup)\\n> text, 1/3 special: 5949 (14.8% speedup)\\n> csv, no special: 1560 (44.7% speedup)\\n> csv, 1/3 special: 6006 (13.8% speedup)\\n>\\n> I find these results particularly exciting because with the COPY FROM v3\\n> patch, the worst-case scenarios are just under 1% regression. The v4 COPY\\n> TO patch is a win across the board.\\n>\\n> Note that I ran these benchmarks with everything in RAM disk and using the\\n> cpupower instructions that Nazir suggested.\\n>\\n> So on Arm, the v3 COPY FROM patch is almost all upside, and the v4 COPY TO\\n> patch is all upside. The same is almost true for Intel, but the CSV COPY\\n> FROM regression, even from the V3 COPY FROM patch, is about 5%. The v4.2\\n> COPY FROM patch always performs worse than the v3 COPY FROM patch in\\n> worst-case scenarios.\\n>\\n> Does it seem reasonable to stop performance testing the v4.2 COPY FROM\\n> patch? Have we collected enough benchmark data to be confident that the v3\\n> COPY FROM patch is the one we should be moving forward with?\\n>\\nFor the case of v4.2 using the 1/3 specials benchmark, it will always take\\nthe decision to not use SIMD after sampling and that 3%-4% regression is\\nthe combination of the small overhead of counting special characters and\\n2-4 branches and its effect on the general layout, branch prediction,\\npipeline ..etc, while i don't think it's more complex than v3 but this is\\nthe only thing i can think of.\\nAnd since it assumes uniformity of special characters between lines so yes\\nIMHO v3 is generally better.\\n\\nRegards,\\nAyoub\\n","threadId":"19be6f25752a8025","snippet":"Hello, On Tue, Jan 20, 2026 at 9:49 PM Manni Wood <manni.wood@enterprisedb.com> wrote: Hello, all I have more benchmarks. These benchmarks are from a Raspberry Pi 5 that I bought. It has an Arm","historyId":"5965","internalDate":"1769106176000","receivedAtUtc":"2026-01-22T18:22:56.000Z","from":"KAZAR Ayoub <ma_kazar@esi.dz>"},{"id":"19be732495d2f63d","messageId":"<CA+K2Rumkq2biMOaS3XD_x2M6vwy+yPpraeo3oMvarjVw5OJfiw@mail.gmail.com>","subject":"Re: Speed up COPY FROM text/CSV parsing using SIMD","body":"On Wed, Jan 21, 2026 at 9:50 PM Neil Conway <neil.conway@gmail.com> wrote:\\n\\n> A few suggestions:\\n>\\n> * I'm curious if we'll see better performance on large inputs if we flush\\n> to `line_buf` periodically (e.g., at least every few thousand bytes or so).\\n> Otherwise we might see poor data cache behavior if large inputs with no\\n> control characters get evicted before we've copied them over. See the\\n> approach taken in escape_json_with_len() in utils/adt/json.c\\n>\\nHello Neil, thanks for the suggestions!\\nThis might be true as the json code considers it, i'll take a look later.\\n\\n>\\n> * Did you compare the approach taken in the patch with a simpler approach\\n> that just does\\n>\\n> if (!(vector8_has(chunk, '\\\\\\\\') ||\\n>       vector8_has(chunk, '\\\\r') ||\\n>       vector8_has(chunk, '\\\\n') /* and so on, accounting for CSV / escapec\\n> / quotec stuff */))\\n> {\\n>     /* skip chunk */\\n> }\\n>\\n> That's roughly what we do elsewhere (e.g., escape_json_with_len). It has\\n> the advantage of being more readable, along with potentially having fewer\\n> data dependencies.\\n>\\nThis is true and also similar to the concerns of the very first patches\\nwhere i tried to just replace the special chars detection by something less\\ndependent but I missed vector8_has.\\nI have tried this now and here are my thoughts and results:\\n\\nv5: the simplest of all, we take a chunk, detect any special character, if\\nit's clean then skip it all, otherwise fallback to scalar WITHOUT advancing\\nto the first special char found, this is mentioned just for reference and\\ncomparison.\\nNumbers compared to master:\\ntext, no special: +16.8%\\ntext, 1/3 special: -21.3%\\ncsv, no special: +29.5%\\ncsv, 1/3 special: -33.5%\\n\\nv5.1: Take a chunk, if its clean of specials, skip it, if not process the\\nwhole chunk byte-by-byte, retry the same thing for next chunk if it's fully\\nskippable and so on...\\nNumbers:\\ntext, no special: +16.5%\\ntext, 1/3 special: -20.1% (weird) ; but overall the idea is clear maybe.\\ncsv, no special: +29.4%\\ncsv, 1/3 special: -4.4%\\n\\nFor files of 1/3 specials it's almost always terrible to consider simd\\nbecause it will always fall back to scalar without even advancing to the\\nfirst special character, even for something less than 1/3 i think it would\\nbe same case, i attached an extremely simple analysis on probability of\\nhaving a 16 byte clean chunk depending on data we have.\\n\\nAttached also is an overall comparison graph between master, v3, v5.1 (with\\npatch)\\n\\n\\nRegards,\\nAyoub\\n","threadId":"19be6f25752a8025","snippet":"On Wed, Jan 21, 2026 at 9:50 PM Neil Conway <neil.conway@gmail.com> wrote: A few suggestions: * I'm curious if we'll see better performance on large inputs if we flush to `line_buf`","historyId":"8720","internalDate":"1769110363000","receivedAtUtc":"2026-01-22T19:32:43.000Z","from":"KAZAR Ayoub <ma_kazar@esi.dz>"}]	The discussion focuses on optimizing PostgreSQL's COPY FROM text/CSV parsing using SIMD instructions. Manni Wood shared benchmarks from a Raspberry Pi 5 showing v3 COPY FROM patch achieves 19-35% speedup for files without special characters, with minimal regression (under 1%) for files with special characters, while v4.2 performs worse in regression cases. Ayoub explains that v4.2's 3-4% regression stems from sampling overhead and branch prediction effects when detecting special characters. Neil Conway suggested a simpler approach using vector8_has() similar to JSON escaping code, but Ayoub's testing revealed this method causes significant regressions (20-33%) for files with special characters. The consensus appears to favor the v3 COPY FROM patch for moving forward due to its superior performance characteristics.\n\n讨论集中在使用SIMD指令优化PostgreSQL的COPY FROM文本/CSV解析。Manni Wood分享了来自树莓派5的基准测试结果，显示v3 COPY FROM补丁对于没有特殊字符的文件实现了19-35%的加速，对于含有特殊字符的文件回归最小（不到1%），而v4.2在回归情况下表现更差。Ayoub解释v4.2的3-4%回归源于采样开销和检测特殊字符时的分支预测效应。Neil Conway建议使用类似JSON转义代码的vector8_has()的更简单方法，但Ayoub的测试显示这种方法对含有特殊字符的文件造成显著回归（20-33%）。共识倾向于推进v3 COPY FROM补丁，因为它具有优越的性能特性。	2026-01-22 19:32:43+00	\N
12	19be73a001df8030	[BUG] [PATCH] Allow physical replication slots to recover from archive after invalidation	["amit.kapila16@gmail.com","houzj.fnst@fujitsu.com","joao@foltrandba.com"]	[{"id":"19be73a001df8030","messageId":"<CAF8B20Dr28H3pdH472SHSYHdkaOX12BsvBe7D06ssMKmwvqCxQ@mail.gmail.com>","subject":"Re: [BUG] [PATCH] Allow physical replication slots to recover from archive after invalidation","body":"Hi Amit!\\n\\nUnless we have hot_standby_feedback = on, xmin would be null on the\\nphysical replication slot.\\n\\nBut, even if using that parameter, as long as we know that the standby\\nalready has caught up by using the archived wals then the xmin\\nwouldn't matter, since we don't need those rows to be visible anymore.\\n\\nI've attached a simple patch and test here that revalidates the slot\\nafter it is lost. It is still missing any filtering besides checking\\nif the slot is physical or logical, but we can add filters for\\nspecific invalidations.\\n\\nLet me know what you think.\\n\\nRegards,\\nJoão Foltran\\n\\nOn Wed, Jan 14, 2026 at 8:21 AM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n>\\n> On Tue, Jan 6, 2026 at 3:26 AM Joao Foltran <joao@foltrandba.com> wrote:\\n> >\\n> > > The slots could be invalidated due to other reasons like\\n> > > RS_INVAL_IDLE_TIMEOUT as well.\\n> >\\n> > We could just filter which invalidation reasons could be \\"revalidated\\"\\n> > for only reasons that can be resolved this way.\\n> >\\n>\\n> Can we make the slot valid even the required WAL is made available\\n> afterwards? What about the removed rows due to the slot's xmin?\\n>\\n> --\\n> With Regards,\\n> Amit Kapila.\\n","threadId":"19be73a001df8030","snippet":"Hi Amit! Unless we have hot_standby_feedback = on, xmin would be null on the physical replication slot. But, even if using that parameter, as long as we know that the standby already has caught up by","historyId":"8724","internalDate":"1769110873000","receivedAtUtc":"2026-01-22T19:41:13.000Z","from":"Joao Foltran <joao@foltrandba.com>"}]	Joao Foltran proposes allowing physical replication slots to recover from archive after invalidation. He addresses Amit Kapila's concerns about xmin handling, noting that physical slots typically have null xmin unless hot_standby_feedback is enabled. Even when enabled, xmin becomes irrelevant once the standby catches up using archived WALs since those rows no longer need visibility protection. Foltran has attached a patch and test that revalidates lost slots, currently filtering only between physical and logical slots but acknowledging the need for more specific invalidation reason filtering. The discussion continues around whether slots can be made valid when required WAL becomes available later and handling removed rows due to slot xmin values.\n\nJoão Foltran 提议允许物理复制槽在失效后从归档中恢复。他回应了 Amit Kapila 关于 xmin 处理的担忧，指出除非启用 hot_standby_feedback，否则物理槽通常具有空的 xmin。即使启用该参数，一旦备库使用归档 WAL 追上后，xmin 就变得无关紧要，因为这些行不再需要可见性保护。Foltran 已附上一个补丁和测试来重新验证丢失的槽位，目前仅在物理槽和逻辑槽之间进行过滤，但承认需要针对特定失效原因进行更精确的过滤。讨论继续围绕是否可以在所需 WAL 后续可用时使槽位生效，以及如何处理由于槽位 xmin 值而被移除的行。	2026-01-22 19:41:13+00	\N
12	19be78bcc7d6e205	Extensible storage manager API - SMGR hook Redux	["andreas@proxel.se","andres@anarazel.de","boekewurm+postgres@gmail.com","hlinnaka@iki.fi","nitinjadhavpostgres@gmail.com","tristan@neon.tech","vignesh21@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be78bcc7d6e205","messageId":"<CAN4CZFNe1GSAuqWi62UOrpt+M7-Auwiz5V9iF6VavNT=GuPqyQ@mail.gmail.com>","subject":"Re: Extensible storage manager API - SMGR hook Redux","body":"Hello!\\n\\nI rebased the patch and addressed all comments.\\n\\n> Are we sure we need to force extension authors to implement prefetch?\\n> Also, do we intentionally skip Assert on smgr_registersync and\\n> smgr_init here? I am not questioning smgr_shutdown here, as I can see\\n> it is NULL for md implementation.\\n\\nAdded the new asserts, also for the new startreadv.\\n\\nI don't see a problem with requiring implementing prefetch, the\\nimplementing function can be empty.\\n\\n> 0002:\\n> should we merge this with 0001?\\n\\nDone!\\n\\n> 0004:\\n> It's a bit strange to place fsync_checker under contrib, huh? Like,\\n> you will never use it in production. Maybe src/test/modules is a\\n> better place?\\n\\nI moved it to the test folder. In a later version I'll also modify it\\nto something more suited for actual testing - for now it's just a\\nsimple example use.\\n\\n> 0005:\\n> We are missing rationale for this change in the commit message.\\n\\nI added a more detailed commit message, which hopefully explains why\\nthis change could be useful.\\n","threadId":"19be78bcc7d6e205","snippet":"Hello! I rebased the patch and addressed all comments. > Are we sure we need to force extension authors to implement prefetch? > Also, do we intentionally skip Assert on smgr_registersync and","historyId":"8732","internalDate":"1769116230000","receivedAtUtc":"2026-01-22T21:10:30.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	The patch for extensible storage manager API has been rebased with all reviewer comments addressed. Key changes include adding new assertions for smgr_registersync, smgr_init, and the new startreadv function. The author maintains that requiring extension authors to implement prefetch is reasonable, as empty implementations are acceptable. Patches 0001 and 0002 have been merged as suggested. The fsync_checker module has been relocated from contrib to src/test/modules, as it's intended for testing rather than production use. The author plans to enhance it for actual testing in future versions. Patch 0005 received a more detailed commit message explaining the rationale for the changes. The modifications aim to make the storage manager API more extensible while maintaining compatibility.\n该可扩展存储管理器API补丁已重新基于最新代码，并处理了所有审阅者的意见。主要变更包括为smgr_registersync、smgr_init和新的startreadv函数添加新的断言。作者坚持认为要求扩展开发者实现prefetch是合理的，因为可以接受空实现。按建议将补丁0001和0002合并。fsync_checker模块已从contrib移至src/test/modules，因为它用于测试而非生产环境。作者计划在后续版本中增强其实际测试功能。补丁0005获得了更详细的提交信息，解释了变更的原理。这些修改旨在使存储管理器API更具可扩展性，同时保持兼容性。	2026-01-22 21:10:30+00	\N
12	19be79057d59089e	[PATCH] Align verify_heapam.c error message offset with test expectations	["khoaduynguyen@gmail.com","zengman@halodbtech.com"]	[{"id":"19be79057d59089e","messageId":"<CAKQ9eTHCcn++hVDK6TRFqgSyvRx_EnZS7KjXZV9ERaGnm70jNw@mail.gmail.com>","subject":"Re: [PATCH] Align verify_heapam.c error message offset with test expectations","body":"On Thu, Jan 22, 2026 at 9:44 AM zengman <zengman@halodbtech.com> wrote:\\n\\n> Hi all,\\n>\\n> I think there might be an issue with the error messages in\\n> contrib/amcheck/verify_heapam.c.\\n> The test comment in src/bin/pg_amcheck/t/004_verify_heapam.pl (line 715)\\n> clearly states:\\n> ```\\n> # Tuple at offset 43 is the successor of this one\\n> ```\\n> This indicates that for the test case at offnum == 36, the error message\\n> should report \\"offset 43\\" (the successor), not \\"offset 36\\" (the current\\n> tuple).\\n> However, when I updated the test expectation from \\\\d+ wildcard to the\\n> exact value offset 43, the test fails.\\n>\\n\\nPatch 1:  Updating the wildcard matching from \\"\\\\d+\\" to the exact value \\"43\\"\\nmakes the test more precise and clear. After all, this change led to the\\ndiscovery of the bug you fixed in Patch 2 - the original wildcard masked\\nthe problem.  Since the test data was engineered to be deterministic and\\nthere is precedent for hardcoding test values, I think Patch 1 is a good\\naddition.\\n\\nLines 283-296 implies test data was engineer to be deterministic.\\n# Data for HOT chain validation, so not calling VACUUM FREEZE.\\n$node->safe_psql(\\n'postgres', qq(\\nINSERT INTO public.test (a, b, c)\\nVALUES ( x'DEADF9F9DEADF9F9'::bigint, 'abcdefg',\\ngenerate_series(7,15)); -- offset numbers 28 to 36\\nUPDATE public.test SET c = 'a' WHERE c = '7'; -- offset number 37\\nUPDATE public.test SET c = 'a' WHERE c = '10'; -- offset number 38\\nUPDATE public.test SET c = 'a' WHERE c = '11'; -- offset number 39\\nUPDATE public.test SET c = 'a' WHERE c = '12'; -- offset number 40\\nUPDATE public.test SET c = 'a' WHERE c = '13'; -- offset number 41\\nUPDATE public.test SET c = 'a' WHERE c = '14'; -- offset number 42\\nUPDATE public.test SET c = 'a' WHERE c = '15'; -- offset number 43\\n));\\n\\nI think there are a few other test cases that Patch 2 will affect but the\\ndiff will be masked out by regexp.  It is up to you if you want to follow\\nthrough with the exercise.  At a minimum, I think we should address test\\noffnum == 33 a line 693.\\n\\n\\nThis makes me wonder whether the current code in verify_heapam.c (lines\\n> 777, 793, 799) should be using nextoffnum instead of ctx.offnum.\\n> This would also be consistent with similar error messages at lines 746-747\\n> and 753-754, which use nextoffnum when referring to the produced tuple\\n> location.\\n>\\n\\nGreat catch on Patch 2.  Lines 633-664 show that ctx.offnum is simply an\\niteration of the line pointer in the page and nextoffnum maps to the\\nsuccessor of each iteration's line pointer.\\n\\nGiven that the error message is \\"... was updated to produce a tuple at\\noffset %d ...\\", the successor's offset should be used.  Therefore the\\nchange on lines 777, 793, and 799 from using ctx.offnum to using nextoffnum\\nlooks good.\\n\\nBoth patches look great to me.\\n","threadId":"19be79057d59089e","snippet":"On Thu, Jan 22, 2026 at 9:44 AM zengman <zengman@halodbtech.com> wrote: Hi all, I think there might be an issue with the error messages in contrib/amcheck/verify_heapam.c. The test comment in src","historyId":"8734","internalDate":"1769116532000","receivedAtUtc":"2026-01-22T21:15:32.000Z","from":"Khoa Nguyen <khoaduynguyen@gmail.com>"}]	Khoa Nguyen reviewed a two-patch submission by zengman addressing error message offsets in PostgreSQL's verify_heapam.c. Patch 1 updates test expectations from wildcard matching to exact offset values, making tests more precise and revealing the underlying bug. Patch 2 fixes the actual issue where error messages incorrectly report the current tuple's offset (ctx.offnum) instead of the successor tuple's offset (nextoffnum) at lines 777, 793, and 799. The reviewer confirms both patches are correct, noting that the test data was engineered to be deterministic and that the error message format requires the successor's offset. The reviewer suggests addressing similar issues in other test cases, particularly at line 693 for offnum == 33.\n\nKhoa Nguyen审查了zengman提交的两个补丁，用于解决PostgreSQL的verify_heapam.c中错误消息偏移量问题。补丁1将测试期望从通配符匹配更新为精确的偏移值，使测试更加精确并揭示了潜在的错误。补丁2修复了实际问题，即错误消息在第777、793和799行错误地报告当前元组的偏移量(ctx.offnum)而不是后继元组的偏移量(nextoffnum)。审查者确认两个补丁都是正确的，指出测试数据是经过设计的确定性数据，错误消息格式需要后继者的偏移量。审查者建议处理其他测试案例中的类似问题，特别是第693行的offnum == 33。	2026-01-22 21:15:32+00	\N
12	19be745ea9c1b400	[PATCH] llvmjit: always add the simplifycfg pass	["matheusssilv97@gmail.com","p.psql@pinaraf.info"]	[{"id":"19be745ea9c1b400","messageId":"<DFVDQRXJX7QW.KLYVOJSQW08Y@gmail.com>","subject":"Re: [PATCH] llvmjit: always add the simplifycfg pass","body":"Hi,\\n\\nOn 07/01/26 12:08, Pierre Ducroquet wrote:\\n> Hi\\n> \\n> While reading the code generated by llvmjit, I realized the number of LLVM basic blocks used in tuple deforming was directly visible in the generated assembly code with the following code:\\n> 0x723382b781c1: jmp 0x723382b781c3\\n> 0x723382b781c3: jmp 0x723382b781eb\\n> 0x723382b781c5: mov -0x20(%rsp),%rax\\n> 0x723382b781..: ... .....\\n> 0x723382b781e7: mov %cx,(%rax)\\n> 0x723382b781ea: ret\\n> 0x723382b781eb: jmp 0x723382b781ed\\n> 0x723382b781ed: jmp 0x723382b781ef\\n> 0x723382b781ef: jmp 0x723382b781f1\\n> 0x723382b781f1: jmp 0x723382b781f3\\n> 0x723382b781f3: mov -0x30(%rsp),%rax\\n> 0x723382b781..: ... ......\\n> 0x723382b78208: mov %rcx,(%rax)\\n> 0x723382b7820b: jmp 0x723382b781c5\\n> That's a lot of useless jumps, and LLVM has a specific pass to get rid of these. The attached patch modifies the llvmjit code to always call this pass, even below jit_optimize_above_cost.\\n> \\n> On a basic benchmark (a simple select * from table where f = 42), this optimization saved 7ms of runtime while using only 0.1 ms of extra optimization time.\\n> \\n\\nThe patch needs a rebase due to e5d99b4d9ef.\\n\\nYou've added the \\"simplifycfg\\" only when the \\"jit_optimize_above_cost\\"\\nis not triggered which will use the default<O0> and mem2reg passes, the\\ndefault<O3> pass already include \\"simplifycfg\\"?\\n\\nWith e5d99b4d9ef being committed, should we add \\"simplifycfg\\" when\\nPGJIT_INLINE bit is set since it also use the default<O0> and mem2reg\\npasses?\\n\\n--\\nMatheus Alcantara\\nEDB: https://www.enterprisedb.com\\n\\n\\n","threadId":"19be745ea9c1b400","snippet":"Hi, On 07/01/26 12:08, Pierre Ducroquet wrote: > Hi > > While reading the code generated by llvmjit, I realized the number of LLVM basic blocks used in tuple deforming was directly visible in","historyId":"8728","internalDate":"1769111657000","receivedAtUtc":"2026-01-22T19:54:17.000Z","from":"Matheus Alcantara <matheusssilv97@gmail.com>"},{"id":"19be76449cc253bf","messageId":"<H9LI9Enj4-NPP6t2g1RB9KMGkkBwzWjQwfiSLHLOTnT7YUwVPYSu_pMHwQLwwzGQGp54DQcER-eLngTa1GzVjH5Q0addrvfalukYnszTjMY=@pinaraf.info>","subject":"Re: [PATCH] llvmjit: always add the simplifycfg pass","body":"Le jeudi 22 janvier 2026 à 8:54 PM, Matheus Alcantara <matheusssilv97@gmail.com> a écrit :\\n\\n> Hi,\\n> \\n> On 07/01/26 12:08, Pierre Ducroquet wrote:\\n> \\n> > Hi\\n> > \\n> > While reading the code generated by llvmjit, I realized the number of LLVM basic blocks used in tuple deforming was directly visible in the generated assembly code with the following code:\\n> > 0x723382b781c1: jmp 0x723382b781c3\\n> > 0x723382b781c3: jmp 0x723382b781eb\\n> > 0x723382b781c5: mov -0x20(%rsp),%rax\\n> > 0x723382b781..: ... .....\\n> > 0x723382b781e7: mov %cx,(%rax)\\n> > 0x723382b781ea: ret\\n> > 0x723382b781eb: jmp 0x723382b781ed\\n> > 0x723382b781ed: jmp 0x723382b781ef\\n> > 0x723382b781ef: jmp 0x723382b781f1\\n> > 0x723382b781f1: jmp 0x723382b781f3\\n> > 0x723382b781f3: mov -0x30(%rsp),%rax\\n> > 0x723382b781..: ... ......\\n> > 0x723382b78208: mov %rcx,(%rax)\\n> > 0x723382b7820b: jmp 0x723382b781c5\\n> > That's a lot of useless jumps, and LLVM has a specific pass to get rid of these. The attached patch modifies the llvmjit code to always call this pass, even below jit_optimize_above_cost.\\n> > \\n> > On a basic benchmark (a simple select * from table where f = 42), this optimization saved 7ms of runtime while using only 0.1 ms of extra optimization time.\\n> \\n> \\n> The patch needs a rebase due to e5d99b4d9ef.\\n> \\n> You've added the \\"simplifycfg\\" only when the \\"jit_optimize_above_cost\\"\\n> is not triggered which will use the default<O0> and mem2reg passes, the\\n> \\n> default<O3> pass already include \\"simplifycfg\\"?\\n> \\n> \\n> With e5d99b4d9ef being committed, should we add \\"simplifycfg\\" when\\n> PGJIT_INLINE bit is set since it also use the default<O0> and mem2reg\\n> \\n> passes?\\n\\nHi\\n\\nThank you, here is a rebased version of the patch.\\nTo answer your questions:\\n- O3 already includes simplifycfg, so no need to modify O3\\n- any code generated by our llvmjit provider, esp. tuple deforming, is heavily dependent on simplifycfg, so when O0 is the basis we should always add this pass\\n\\n","threadId":"19be745ea9c1b400","snippet":"Le jeudi 22 janvier 2026 à 8:54 PM, Matheus Alcantara <matheusssilv97@gmail.com> a écrit : > Hi, > > On 07/01/26 12:08, Pierre Ducroquet wrote: > > > Hi > > > >","historyId":"8728","internalDate":"1769113649000","receivedAtUtc":"2026-01-22T20:27:29.000Z","from":"Pierre Ducroquet <p.psql@pinaraf.info>"},{"id":"19be7a752eafa7fb","messageId":"<DFVG0AV650GW.2CNS5CZ4OG788@gmail.com>","subject":"Re: [PATCH] llvmjit: always add the simplifycfg pass","body":"On Thu Jan 22, 2026 at 5:27 PM -03, Pierre Ducroquet wrote:\\n>> The patch needs a rebase due to e5d99b4d9ef.\\n>> \\n>> You've added the \\"simplifycfg\\" only when the \\"jit_optimize_above_cost\\"\\n>> is not triggered which will use the default<O0> and mem2reg passes, the\\n>> \\n>> default<O3> pass already include \\"simplifycfg\\"?\\n>> \\n>> \\n>> With e5d99b4d9ef being committed, should we add \\"simplifycfg\\" when\\n>> PGJIT_INLINE bit is set since it also use the default<O0> and mem2reg\\n>> \\n>> passes?\\n>\\n> Hi\\n>\\n> Thank you, here is a rebased version of the patch.\\n> To answer your questions:\\n> - O3 already includes simplifycfg, so no need to modify O3\\n> - any code generated by our llvmjit provider, esp. tuple deforming, is heavily dependent on simplifycfg, so when O0 is the basis we should always add this pass\\n\\nThanks for confirming.\\n\\nI did some benchmarks on some TPCH queries (1 and 4) and I got these\\nresults. Note that for these tests I set jit_optimize_above_cost=1000000\\nso that it force to use the default<O0> pass with simplifycfg.\\n\\nMaster Q1:\\n    Timing: Generation 1.553 ms (Deform 0.573 ms), Inlining 0.052 ms, Optimization 95.571 ms, Emission 58.941 ms, Total 156.116 ms\\n    Execution Time: 38221.318 ms\\n\\nPatch Q1:\\n    Timing: Generation 1.477 ms (Deform 0.534 ms), Inlining 0.040 ms, Optimization 95.364 ms, Emission 58.046 ms, Total 154.927 ms\\n    Execution Time: 38257.797 ms\\n\\nMaster Q4:\\n    Timing: Generation 0.836 ms (Deform 0.309 ms), Inlining 0.086 ms, Optimization 5.098 ms, Emission 6.963 ms, Total 12.983 ms\\n    Execution Time: 19512.134 ms\\n\\nPatch Q4:\\n    Timing: Generation 0.802 ms (Deform 0.294 ms), Inlining 0.090 ms, Optimization 5.234 ms, Emission 6.521 ms, Total 12.648 ms\\n    Execution Time: 16051.483 ms\\n\\n\\nFor Q4 I see a small increase on Optimization phase but we have a good\\nperformance improvement on execution time. For Q1 the results are almost\\nthe same.\\n\\nI did not find any major regression using simplifycfg pass and I think\\nthat it make sense to enable since it generate better IR code for LLVM\\nto compile without too much costs. +1 for this patch.\\n\\nPerhaps we could merge the comments on if/else block to include the\\nsimplifycfg, what do you think?\\n\\n+       /*\\n+        * Determine the LLVM pass pipeline to use. For OPT3 we use the standard\\n+        * suite. For lower optimization levels, we explicitly include mem2reg to\\n+        * promote stack variables, simplifycfg to clean up the control flow , and\\n+        * optionally the inliner if the flag is set. Note that default<O0> already\\n+        * includes the always-inline pass.\\n+        */\\n        if (context->base.flags & PGJIT_OPT3)\\n                passes = \\"default<O3>\\";\\n        else if (context->base.flags & PGJIT_INLINE)\\n-               /* if doing inlining, but no expensive optimization, add inline pass */\\n                passes = \\"default<O0>,mem2reg,simplifycfg,inline\\";\\n        else\\n-               /* default<O0> includes always-inline pass */\\n                passes = \\"default<O0>,mem2reg,simplifycfg\\";\\n\\n--\\nMatheus Alcantara\\nEDB: https://www.enterprisedb.com\\n\\n\\n\\n","threadId":"19be745ea9c1b400","snippet":"On Thu Jan 22, 2026 at 5:27 PM -03, Pierre Ducroquet wrote: >> The patch needs a rebase due to e5d99b4d9ef. >> >> You've added the \\"simplifycfg\\" only when the \\"","historyId":"8728","internalDate":"1769118046000","receivedAtUtc":"2026-01-22T21:40:46.000Z","from":"Matheus Alcantara <matheusssilv97@gmail.com>"}]	Pierre Ducroquet proposes adding the LLVM simplifycfg pass to PostgreSQL's JIT compilation to eliminate unnecessary jump instructions in generated assembly code. The original patch showed significant performance improvements (7ms runtime savings with only 0.1ms extra optimization cost) by removing redundant basic block jumps in tuple deforming operations. Matheus Alcantara reviewed the patch, noting it needed rebasing due to recent commits and questioning whether simplifycfg should be added when PGJIT_INLINE is set. Pierre provided a rebased version, confirming that O3 optimization already includes simplifycfg, but O0-based compilation heavily depends on it. Matheus conducted TPCH benchmarks showing mixed results - Q4 showed substantial execution time improvement (19.5s to 16.0s) while Q1 remained similar. Both agreed the patch makes sense without major regressions, with Matheus suggesting consolidating comments in the if/else blocks for better code clarity.\n\nPierre Ducroquet 提议在 PostgreSQL 的 JIT 编译中添加 LLVM simplifycfg 优化通道，以消除生成汇编代码中的不必要跳转指令。原始补丁通过移除元组变形操作中的冗余基本块跳转，显示出显著的性能改进（运行时间节省 7ms，仅增加 0.1ms 优化成本）。Matheus Alcantara 审查了补丁，指出由于最近的提交需要重新基线，并质疑是否应在设置 PGJIT_INLINE 时添加 simplifycfg。Pierre 提供了重新基线的版本，确认 O3 优化已包含 simplifycfg，但基于 O0 的编译严重依赖它。Matheus 进行了 TPCH 基准测试，结果不一 - Q4 显示出显著的执行时间改进（从 19.5s 到 16.0s），而 Q1 基本相同。双方都同意该补丁合理且没有重大回归，Matheus 建议整合 if/else 块中的注释以提高代码清晰度。	2026-01-22 21:40:46+00	\N
12	19be6ef376891aa7	Having problems generating a code coverage report	["aleksander@timescale.com","andres@anarazel.de","jian.universality@gmail.com","michael@paquier.xyz","pg@bowt.ie"]	[{"id":"19be7c33a80d89d8","messageId":"<aXKgf6G7Osvta8Js@paquier.xyz>","subject":"Re: Having problems generating a code coverage report","body":"On Thu, Jan 22, 2026 at 01:19:43PM -0500, Andres Freund wrote:\\n> On 2026-01-22 14:35:40 +0900, Michael Paquier wrote:\\n> If I suppress the empty errors & warnings with --ignore-errors empty,empty the\\n> current \\"-d . -d $(srcdir)\\" kinda works.  Unfortunately, in VPATH builds, the\\n> directory structure is quite messed up. It seems to get a bit better if I add\\n> -p $(srcdir) to the genhtml invocation, but a few generated files still show\\n> up bogus.\\n\\nWith a bit more information to skip more error patterns, I actually\\ngot an unpatched HEAD build able to work properly as well, with:\\nignore_errors=inconsistent,gcov,range,empty,usage,usage,empty,empty,path\\n\\nThe VPATH build is indeed looking pretty broken here, with the\\ntop-level including the contents of src/ and /home/, /home/ pointing\\nto contrib/.  I'll live with that, that's so much better than nothing\\nworking locally.  Thanks for all the pointers, Andres.\\n--\\nMichael\\n","threadId":"19be6ef376891aa7","snippet":"On Thu, Jan 22, 2026 at 01:19:43PM -0500, Andres Freund wrote: > On 2026-01-22 14:35:40 +0900, Michael Paquier wrote: > If I suppress the empty errors & warnings with --ignore-errors empty,","historyId":"8718","internalDate":"1769119871000","receivedAtUtc":"2026-01-22T22:11:11.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	Michael Paquier reports progress on generating code coverage reports in PostgreSQL. He found that adding `--ignore-errors` with multiple error patterns (inconsistent, gcov, range, empty, usage, path) to the genhtml invocation allows an unpatched HEAD build to work properly. However, VPATH builds remain problematic with a broken directory structure where the top-level incorrectly includes src/ and /home/ contents, with /home/ pointing to contrib/. Despite these VPATH build issues, Michael considers this a significant improvement over the previous non-functional state and expresses gratitude to Andres for the guidance.\nMichael Paquier报告了在PostgreSQL中生成代码覆盖率报告的进展。他发现在genhtml调用中添加`--ignore-errors`并使用多个错误模式（inconsistent、gcov、range、empty、usage、path）可以让未打补丁的HEAD构建正常工作。然而，VPATH构建仍然存在问题，目录结构被破坏，顶级目录错误地包含src/和/home/内容，/home/指向contrib/。尽管存在这些VPATH构建问题，Michael认为这比之前无法工作的状态有了显著改进，并感谢Andres的指导。	2026-01-22 22:11:11+00	\N
12	19be9aafca8cce45	Some tests for TOAST, STORAGE MAIN/EXTENDED	["michael@paquier.xyz","veldanda.nikhilkumar17@gmail.com"]	[{"id":"19be9aafca8cce45","messageId":"<aXMdX1UTHnzYPkHk@paquier.xyz>","subject":"Some tests for TOAST, STORAGE MAIN/EXTENDED","body":"Hi all,\\n\\nWhile playing with the TOAST code this week, I have managed to break\\nthe handling of inline compressible entries, and noticed that the main\\nregression test suite did not complain following that.\\n\\nBreaking that stuff is my issue, but I would like to add some\\nregression tests to cover all that, giving the attached.  This also\\nincludes tests with EXTENDED in the same area, while on it, with\\nchecks for the TOAST table itself.\\n\\nThoughts or comments?\\n--\\nMichael\\n","threadId":"19be9aafca8cce45","snippet":"Hi all, While playing with the TOAST code this week, I have managed to break the handling of inline compressible entries, and noticed that the main regression test suite did not complain following that","historyId":"12881","internalDate":"1769151839000","receivedAtUtc":"2026-01-23T07:03:59.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be9f5cbdfd3eef","messageId":"<CAFAfj_Hq_rMqUKDyz573gZhjd8bEpBx5j4MLNJvZ9PnouJCxDg@mail.gmail.com>","subject":"Re: Some tests for TOAST, STORAGE MAIN/EXTENDED","body":"Hi Michael,\\n\\nOn Thu, Jan 22, 2026 at 11:04 PM Michael Paquier <michael@paquier.xyz> wrote:\\n> Thoughts or comments?\\n\\nTwo nits on the new toasttest block:\\n\\nThe `SELECT count(*) FROM :reltoastname` assertion is a bit brittle\\nfor `STORAGE EXTENDED`: depending on the toast compression method /\\neffectiveness, the value may end up as >1 chunk, which would flip the\\nexpected count(*) = 1. Prefer SELECT count(DISTINCT chunk_id) FROM\\n:reltoastname (or WHERE chunk_seq = 0) and adjust expected.\\n\\npg_column_compression() expects pglz, but default_toast_compression\\nisn't pinned here. Suggest SET default_toast_compression = 'pglz';\\nnear this block; otherwise this can fail on builds with a different\\ndefault.\\n\\n-- \\nNikhil Veldanda\\n\\n\\n","threadId":"19be9aafca8cce45","snippet":"Hi Michael, On Thu, Jan 22, 2026 at 11:04 PM Michael Paquier <michael@paquier.xyz> wrote: > Thoughts or comments? Two nits on the new toasttest block: The `SELECT count(*) FROM :reltoastname`","historyId":"12881","internalDate":"1769156733000","receivedAtUtc":"2026-01-23T08:25:33.000Z","from":"Nikhil Kumar Veldanda <veldanda.nikhilkumar17@gmail.com>"}]	Michael Paquier proposes adding regression tests for PostgreSQL's TOAST functionality, specifically for STORAGE MAIN/EXTENDED configurations. While working with TOAST code, he broke the handling of inline compressible entries but noticed the main regression test suite didn't detect this failure. His proposed patch includes tests for both MAIN and EXTENDED storage types with checks for the TOAST table itself. Nikhil Veldanda provides feedback on two issues: the `SELECT count(*) FROM :reltoastname` assertion could be brittle for EXTENDED storage due to variable chunk counts, suggesting `SELECT count(DISTINCT chunk_id)` instead, and the `pg_column_compression()` test assumes 'pglz' compression but `default_toast_compression` isn't pinned, recommending an explicit `SET default_toast_compression = 'pglz'` statement.\nMichael Paquier提议为PostgreSQL的TOAST功能添加回归测试，特别是针对STORAGE MAIN/EXTENDED配置。在使用TOAST代码时，他破坏了内联可压缩条目的处理，但注意到主回归测试套件没有检测到这个故障。他提议的补丁包括对MAIN和EXTENDED存储类型的测试，并检查TOAST表本身。Nikhil Veldanda对两个问题提供反馈：对于EXTENDED存储，`SELECT count(*) FROM :reltoastname`断言可能由于可变的块数量而不稳定，建议使用`SELECT count(DISTINCT chunk_id)`；`pg_column_compression()`测试假设使用'pglz'压缩，但`default_toast_compression`未固定，建议显式设置`SET default_toast_compression = 'pglz'`语句。	2026-01-23 08:25:33+00	\N
12	19be8183a7603969	Assert when executing query on partitioned table	["d.koval@postgrespro.ru","koshy44@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19be8183a7603969","messageId":"<3008134.1769125434@sss.pgh.pa.us>","subject":"Re: Assert when executing query on partitioned table","body":"Dmitry Koval <d.koval@postgrespro.ru> writes:\\n> I want to send the patch to Commitfest, so the version changed:\\n> [1] -> [2] (for cfbot).\\n\\nI looked this over and concluded that actually, Joseph Koshakow's\\nproposal upthread is the correct one: just delete the faulty\\nAssert.  If we fall through and let the caller retry, we get\\nexactly the same behavior as in the non-partition-movement case,\\nso I'm prepared to accept that behavior as correct.  Moreover,\\nI guess users think so too, because this code is pretty old yet\\nwe've heard no complaints about the production (no-Asserts)\\nbehavior.  If we started to throw an error where we hadn't\\nbefore, I bet we *would* get complaints.\\n\\nAlso, I realized that we don't really need an injection point\\nto demonstrate the assertion failure: it's sufficient to make\\nthe other session lock the tuple with SELECT FOR UPDATE before\\nwe start the INSERT.  This is good because it's simpler and\\nit lets the test be back-patched all the way.\\n\\nPushed at 4b760a181 et al.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19be8183a7603969","snippet":"Dmitry Koval <d.koval@postgrespro.ru> writes: > I want to send the patch to Commitfest, so the version changed: > [1] -> [2] (for cfbot). I looked this over and concluded that actually,","historyId":"8738","internalDate":"1769125434000","receivedAtUtc":"2026-01-22T23:43:54.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	Tom Lane reviewed a patch addressing an assertion failure when executing queries on partitioned tables. He agreed with Joseph Koshakow's earlier proposal to simply delete the faulty Assert rather than implementing a more complex fix. Lane reasoned that allowing the caller to retry produces the same behavior as non-partition-movement cases, which users apparently find acceptable since no complaints have been received about the production behavior despite the code being old. He noted that introducing error throwing where none existed before would likely generate user complaints. Lane also discovered that the assertion failure can be demonstrated without injection points by having another session lock the tuple with SELECT FOR UPDATE before starting the INSERT, making the test simpler and back-patchable. The fix was committed as 4b760a181.\n\nTom Lane 审查了一个解决分区表查询执行时断言失败的补丁。他同意 Joseph Koshakow 早前提出的建议，即简单删除错误的断言而不是实施更复杂的修复。Lane 认为允许调用者重试会产生与非分区移动情况相同的行为，用户显然认为这是可接受的，因为尽管代码很旧，但没有收到关于生产环境行为的投诉。他指出，在以前没有错误的地方引入错误抛出可能会产生用户投诉。Lane 还发现，无需注入点即可演示断言失败，只需让另一个会话在开始 INSERT 之前使用 SELECT FOR UPDATE 锁定元组，这使测试更简单且可向后移植。修复已作为 4b760a181 提交。	2026-01-22 23:43:54+00	\N
12	19be89dcf6d8511e	UPDATE run check constraints for affected columns only	["jian.universality@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19be89dcf6d8511e","messageId":"<CACJufxFimkvG8B+h1cNB7PoPHQiGVxe9-S=poWbJPtbi58XuOA@mail.gmail.com>","subject":"Re: UPDATE run check constraints for affected columns only","body":"hi.\\n\\ncode has been further simplified and is now more neat.\\nThe test is kind of verbose now.\\n\\n\\n--\\njian\\nhttps://www.enterprisedb.com/\\n","threadId":"19be89dcf6d8511e","snippet":"hi. code has been further simplified and is now more neat. The test is kind of verbose now. -- jian https://www.enterprisedb.com/","historyId":"8744","internalDate":"1769134167000","receivedAtUtc":"2026-01-23T02:09:27.000Z","from":"jian he <jian.universality@gmail.com>"}]	Jian He provided an update on a PostgreSQL patch for optimizing UPDATE operations to run check constraints only for affected columns. The code has been further simplified and made more organized. However, the accompanying test has become more verbose in the process. This appears to be an ongoing development effort to improve UPDATE performance by avoiding unnecessary constraint checks on unchanged columns. No specific technical details about the implementation or further review feedback were provided in this brief update message.\nJian He就一个PostgreSQL补丁提供了更新，该补丁用于优化UPDATE操作，仅对受影响的列运行检查约束。代码已进一步简化并变得更加整洁。然而，伴随的测试变得更加冗长。这似乎是一个持续的开发工作，旨在通过避免对未更改列进行不必要的约束检查来提高UPDATE性能。在这个简短的更新消息中没有提供关于实现的具体技术细节或进一步的审查反馈。	2026-01-23 02:09:27+00	\N
12	19be6ab0ee643388	Patch: dumping tables data in multiple chunks in pg_dump	["ashutosh.bapat.oss@gmail.com","dgrowleyml@gmail.com","hannuk@google.com","nathandbossart@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be6ab0ee643388","messageId":"<CAMT0RQQ8DX+K7OTw3Lg+Yp2ew8TsZduiqtPszfiBixcpxKbz-A@mail.gmail.com>","subject":"Re: Patch: dumping tables data in multiple chunks in pg_dump","body":"Fixing all the warnings\\n\\n\\nOn Wed, Jan 21, 2026 at 2:05 PM Hannu Krosing <hannuk@google.com> wrote:\\n>\\n> Please find the latest patch attached which incorporates the feedback received.\\n>\\n> * changed flag name to --max-table-segment-pages\\n> * added check for amname = \\"heap\\"\\n> * switched to using of\\n> pg_relation_size(c.oid)/current_setting('block_size')::int when\\n> --max-table-segment-pages is set\\n> * added option_parse_uint32(...) to be used for full range of pages numbers\\n> * The COPY SELECTs now use <= , BETWEEN or >= depending on the segment position\\n>\\n> * added documentation\\n>\\n> * TESTS:\\n>   * added simple chunked dump and restore test\\n>   * added a WARNING with count and table data hash to source and\\n> chunked restore database\\n>\\n> I left in the boolean to indicate if this is a full table or chunk\\n> (was named chunking, nor is_segment)\\n>\\n> An a lternative would be to use an expression like (td->startPage != 0\\n> || td->endPage != InvalidBlockNumber) whenever td->is_segment is\\n> needed\\n>\\n> If you insist on not having a separate structure member we could turn\\n> this into something like this\\n>\\n> #define is_segment(td) ((td->startPage != 0 || td->endPage !=\\n> InvalidBlockNumber))\\n>\\n> and then use is_segment(td) instead of td->is_segment where needed.\\n","threadId":"19be6ab0ee643388","snippet":"Fixing all the warnings On Wed, Jan 21, 2026 at 2:05 PM Hannu Krosing <hannuk@google.com> wrote: > > Please find the latest patch attached which incorporates the feedback received. >","historyId":"4697","internalDate":"1769101504000","receivedAtUtc":"2026-01-22T17:05:04.000Z","from":"Hannu Krosing <hannuk@google.com>"},{"id":"19be8a3180fc0318","messageId":"<CAApHDvo29-vQz=xV6+x5hU--NZ9qGPXsCNBuOAf88pAHjTpvvQ@mail.gmail.com>","subject":"Re: Patch: dumping tables data in multiple chunks in pg_dump","body":"On Fri, 23 Jan 2026 at 06:05, Hannu Krosing <hannuk@google.com> wrote:\\n>\\n> Fixing all the warnings\\n\\nI think overall this needs significantly more care and precision than\\nwhat you've given it so far. For example, you have:\\n\\n+    if(dopt->max_table_segment_pages != InvalidBlockNumber)\\n+        appendPQExpBufferStr(query,\\n\\"pg_relation_size(c.oid)/current_setting('block_size')::int AS\\nrelpages, \\");\\n+    else\\n+        appendPQExpBufferStr(query, \\"c.relpages, \\");\\n\\nNote that pg_class.relpages is \\"int\\". Later the code in master does:\\n\\ntblinfo[i].relpages = atoi(PQgetvalue(res, i, i_relpages));\\n\\nIf you look in vacuum.c, you'll see \\"pgcform->relpages = (int32)\\nnum_pages;\\" that the value stored in relpages will be negative when\\nthe table is >= 16TB (assuming 8k pages). Your pg_relation_size\\nexpression is not going to produce an INT. It'll produce a BIGINT, per\\n\\"select pg_typeof(pg_relation_size('pg_class') /\\ncurrent_setting('block_size')::int);\\". So the atoi() can receive a\\nstring of digits representing an integer larger than INT_MAX in this\\ncase. Looking at [1], I see:\\n\\n\\"7.22.1 Numeric conversion functions 1 The functions atof, atoi, atol,\\nand atoll need not affect the value of the integer expression errno on\\nan error. If the value of the result cannot be represented, *the\\nbehavior is undefined.*\\"\\n\\nAnd testing locally, I see that my Microsoft compiler will just return\\nINT_MAX on overflow, whereas I see gcc does nothing to prevent\\noverflows and just continues to multiply by 10 regardless of what\\noverflows occur, which I think would just make the code work by\\naccident.\\n\\nAside from that, nothing in the documentation mentions that this is\\nfor \\"heap\\" tables only. That should be mentioned as it'll just result\\nin people posting questions about why it's not working for some other\\ntable access method. There's also not much care for white space.\\nYou've introduced a bunch of whitespace changes unrelated to code\\nchanges you've made, plus there's not much regard for following\\nproject standard. For example, you commonly do \\"if(\\" and don't\\nconsistently follow the bracing rules, e.g:\\n\\n+ for(chkptr = optarg; *chkptr != '\\\\0'; chkptr++)\\n+     if(*chkptr == '-')\\n\\nThings like the following help convey the level of care that's gone into this:\\n\\n+/*\\n+ * option_parse_int\\n+ *\\n+ * Parse integer value for an option.  If the parsing is successful, returns\\n+ * true and stores the result in *result if that's given; if parsing fails,\\n+ * returns false.\\n+ */\\n+bool\\n+option_parse_uint32(const char *optarg, const char *optname,\\n\\ni.e zero effort gone in to modify the comments after pasting them from\\noption_parse_int().\\n\\nAnother example:\\n\\n+ pg_log_error(\\"%s musst be in range %lu..%lu\\",\\n\\nAlso, I have no comprehension of why you'd use uint64 for the valid\\nrange when the function is for processing uint32 types in:\\n\\n+bool\\n+option_parse_uint32(const char *optarg, const char *optname,\\n+ uint64 min_range, uint64 max_range,\\n+ uint32 *result)\\n\\nIn its current state, it's quite hard to take this patch seriously.\\nPlease spend longer self-reviewing it before posting. You could\\ntemporarily hard-code something for testing which makes at least 1\\ntable appear to be larger than 16TB and ensure your code works. What\\nyou have is visually broken and depends on whatever the atoi\\nimplementation opts to do in the overflow case. These are all things\\ndiligent commiters will be testing and it's sad to see how little\\neffort you're putting into this. How do you expect this community to\\nscale with this quality level of patch submissions? You've been around\\nlong enough and should know and do better.  Are you just expecting the\\ncommitter to fix these things for you? That work does not get done via\\nmagic wand. Being on v10 already, I'd have expected the patch to be\\nfar beyond proof of concept grade. If you're withholding investing\\ntime on this until you see more community buy-in, then I'd suggest you\\nwrite that and withhold further revisions until you're happy with the\\nlevel of buy-in.\\n\\nI'm also still not liking your de-normalised TableInfo representation\\nfor \\"is_segment\\". IMO, InvalidBlockNumber should be used to represent\\nopen bounded ranges, and if there's no chunking, then startPage and\\nendPage will both be InvalidBlockNumber. IMO, what you have now\\nneedlessly allows invalid states where is_segment == true and\\nstartPage, endPage are not set correctly. If you want to keep the code\\nsimple, hide the complexity in a macro or an inline function. There's\\njust no performance reason to materialise the more complex condition\\ninto a dedicated boolean flag.\\n\\nIf the quality level of this has not improved significantly by v11,\\ncount me out.\\n\\nDavid\\n\\n[1] https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1548.pdf\\n\\n\\n","threadId":"19be6ab0ee643388","snippet":"On Fri, 23 Jan 2026 at 06:05, Hannu Krosing <hannuk@google.com> wrote: > > Fixing all the warnings I think overall this needs significantly more care and precision than what you've","historyId":"8092","internalDate":"1769134537000","receivedAtUtc":"2026-01-23T02:15:37.000Z","from":"David Rowley <dgrowleyml@gmail.com>"}]	A patch for pg_dump to dump table data in multiple chunks is being reviewed, now at version 10. The patch adds a --max-table-segment-pages flag to split large heap tables during dumps. Recent changes include renaming the flag, adding heap table checks, using pg_relation_size for page calculations, and including documentation and tests. However, reviewer David Rowley has provided harsh feedback, citing multiple serious issues: potential integer overflow problems with tables >= 16TB due to mixing INT and BIGINT types, poor code quality with inconsistent formatting and style violations, inadequate documentation mentioning heap-only limitation, copy-paste errors in comments, and unnecessary boolean flags in data structures. The reviewer demands significant quality improvements before version 11 or threatens to withdraw from the review process.\n针对pg_dump中按多个块转储表数据的补丁正在进行审查，目前已到第10版。该补丁添加了--max-table-segment-pages标志来在转储期间分割大型堆表。最近的更改包括重命名标志、添加堆表检查、使用pg_relation_size进行页面计算，以及包含文档和测试。然而，审查员David Rowley提供了严厉的反馈，指出多个严重问题：由于混合使用INT和BIGINT类型导致表>=16TB时的潜在整数溢出问题、代码质量差且格式和样式不一致、文档不足未提及仅限堆表的限制、注释中的复制粘贴错误，以及数据结构中不必要的布尔标志。审查员要求在第11版之前显著提高质量，否则威胁退出审查过程。	2026-01-23 02:15:37+00	\N
12	19be802be712bae9	Refactor recovery conflict signaling a little	["hlinnaka@iki.fi","li.evan.chao@gmail.com"]	[{"id":"19be802be712bae9","messageId":"<4cc13ba1-4248-4884-b6ba-4805349e7f39@iki.fi>","subject":"Refactor recovery conflict signaling a little","body":"I had a look at recovery conflict signaling and a few things caught my eye. No functional changes, but some cleanups and readability improvements:\\n\\nPatch 0001: Remove useless errdetail_abort()\\n--------------------------------------------\\n\\nThe function is supposed to add DETAIL to errors when you are in an aborted transaction, if the transaction was aborted by a recovery conflict, like this:\\n\\nERROR:  current transaction is aborted, commands ignored until end of transaction block\\"\\nDETAIL:  Abort reason: recovery conflict\\n\\nBut I don't see how to reach that. If a transaction is aborted by recovery conflict, you get a different error like this:\\n\\nERROR:  canceling statement due to conflict with recovery\\nDETAIL:  User was holding a relation lock for too long.\\n\\nThe transaction abort clears the 'recoveryConflictPending' flag, so even if that happens in a transaction block, you don't get that \\"DETAIL: Abort reason: recovery conflict\\" in the subsequent errors.\\n\\nerrdetail_abort() was introduced in commit a8ce974cdd. I suppose it was needed back then, but the signal handling has changed a lot since. Looking at that commit now, though, I don't really understand how it was reachable even back then. (Except with a race with an unrelated transaction abort, see commit message)\\n\\nHas anyone seen the \\"DETAIL:  Abort reason: recovery conflict\\" in recent years, or ever? If not, let's rip it out.\\n\\n\\n0002: Don't hint that you can reconnect when the database is dropped\\n--------------------------------------------------------------------\\n\\nIf you're connected to a database is being dropped, during recovery, you get an error like this:\\n\\nFATAL:  terminating connection due to conflict with recovery\\nDETAIL:  User was connected to a database that must be dropped.\\nHINT:  In a moment you should be able to reconnect to the database and repeat your command.\\n\\nThe hint seems misleading. The database is being dropped, you most likely can *not* reconnect to it. Let's remove it.\\n\\n\\n0003-0004:  Separate RecoveryConflictReasons from procsignals\\n-------------------------------------------------------------\\n\\nWe're currently using different PROCSIG_* flags to indicate different kinds of recovery conflicts. We're also abusing the same flags in functions like LogRecoveryConflict, which isn't related to inter-process signaling. It seems better to have a separate enum for the recovery conflict reasons. With this patch, there's just a single PROCSIG_RECOVERY_CONFLICT to wake up a process on a recovery conflict, and the reason is communicated by setting a flag in a bitmask in PGPROC.\\n\\nI was inspired to do this in preparation of my project to replaces latches with \\"interrupts\\". By having just a single PROCSIG flag, we reduce the need for \\"interrupt bits\\" with that project. But it seems nicer on its own merits too.\\n\\n\\n0005: Refactor ProcessRecoveryConflictInterrupt for readability\\n---------------------------------------------------------------\\n\\nThe function had a switch-statement with fallthrough through all the cases. It took me a while to understand how it works. Once I finally understood it, I refactored it to not rely on the fallthrough. I hope this makes it easier for others too.\\n\\n- Heikki\\n","threadId":"19be802be712bae9","snippet":"I had a look at recovery conflict signaling and a few things caught my eye. No functional changes, but some cleanups and readability improvements: Patch 0001: Remove useless errdetail_abort() ---------","historyId":"8736","internalDate":"1769124020000","receivedAtUtc":"2026-01-22T23:20:20.000Z","from":"Heikki Linnakangas <hlinnaka@iki.fi>"},{"id":"19be8bb4f5354dc2","messageId":"<EA619211-93E3-40BF-8EC0-AED29B87AC33@gmail.com>","subject":"Re: Refactor recovery conflict signaling a little","body":"\\n\\n> On Jan 23, 2026, at 07:20, Heikki Linnakangas <hlinnaka@iki.fi> wrote:\\n> \\n> I had a look at recovery conflict signaling and a few things caught my eye. No functional changes, but some cleanups and readability improvements:\\n> \\n> Patch 0001: Remove useless errdetail_abort()\\n> --------------------------------------------\\n> \\n> The function is supposed to add DETAIL to errors when you are in an aborted transaction, if the transaction was aborted by a recovery conflict, like this:\\n> \\n> ERROR:  current transaction is aborted, commands ignored until end of transaction block\\"\\n> DETAIL:  Abort reason: recovery conflict\\n> \\n> But I don't see how to reach that. If a transaction is aborted by recovery conflict, you get a different error like this:\\n> \\n> ERROR:  canceling statement due to conflict with recovery\\n> DETAIL:  User was holding a relation lock for too long.\\n> \\n> The transaction abort clears the 'recoveryConflictPending' flag, so even if that happens in a transaction block, you don't get that \\"DETAIL: Abort reason: recovery conflict\\" in the subsequent errors.\\n> \\n> errdetail_abort() was introduced in commit a8ce974cdd. I suppose it was needed back then, but the signal handling has changed a lot since. Looking at that commit now, though, I don't really understand how it was reachable even back then. (Except with a race with an unrelated transaction abort, see commit message)\\n> \\n> Has anyone seen the \\"DETAIL:  Abort reason: recovery conflict\\" in recent years, or ever? If not, let's rip it out.\\n> \\n\\nI did a Google search and couldn't find any post reporting the message, which seems to prove that message can be removed.\\n\\n> \\n> 0002: Don't hint that you can reconnect when the database is dropped\\n> --------------------------------------------------------------------\\n> \\n> If you're connected to a database is being dropped, during recovery, you get an error like this:\\n> \\n> FATAL:  terminating connection due to conflict with recovery\\n> DETAIL:  User was connected to a database that must be dropped.\\n> HINT:  In a moment you should be able to reconnect to the database and repeat your command.\\n> \\n> The hint seems misleading. The database is being dropped, you most likely can *not* reconnect to it. Let's remove it.\\n> \\n\\nI like this change. Not only removing the misleading error message, the code is also clearer now.\\n\\n> \\n> 0003-0004:  Separate RecoveryConflictReasons from procsignals\\n> -------------------------------------------------------------\\n> \\n> We're currently using different PROCSIG_* flags to indicate different kinds of recovery conflicts. We're also abusing the same flags in functions like LogRecoveryConflict, which isn't related to inter-process signaling. It seems better to have a separate enum for the recovery conflict reasons. With this patch, there's just a single PROCSIG_RECOVERY_CONFLICT to wake up a process on a recovery conflict, and the reason is communicated by setting a flag in a bitmask in PGPROC.\\n> \\n> I was inspired to do this in preparation of my project to replaces latches with \\"interrupts\\". By having just a single PROCSIG flag, we reduce the need for \\"interrupt bits\\" with that project. But it seems nicer on its own merits too.\\n> \\n> \\n> 0005: Refactor ProcessRecoveryConflictInterrupt for readability\\n> ---------------------------------------------------------------\\n> \\n> The function had a switch-statement with fallthrough through all the cases. It took me a while to understand how it works. Once I finally understood it, I refactored it to not rely on the fallthrough. I hope this makes it easier for others too.\\n> \\n> - Heikki\\n> <0001-Remove-useless-errdetail_abort.patch><0002-Don-t-hint-that-you-can-reconnect-when-the-database-.patch><0003-Use-ProcNumber-rather-than-pid-in-ReplicationSlot.patch><0004-Separate-RecoveryConflictReasons-from-procsignals.patch><0005-Refactor-ProcessRecoveryConflictInterrupt-for-readab.patch>\\n\\nA few comments on 003-0005:\\n\\n1 - 0003\\n```\\n ReplicationSlotAcquire(const char *name, bool nowait, bool error_if_invalid)\\n {\\n \\tReplicationSlot *s;\\n-\\tint\\t\\t\\tactive_pid;\\n+\\tProcNumber\\tactive_proc;\\n+\\tpid_t\\t\\tactive_pid;\\n```\\n\\nActive_pid is only used inside the \\"if (active_proc != MyProcNumber)" clause, so it can be only defined within the "if" clause.\\n\\n\\n2 - 0003\\n```\\n \\t\\t\\t\\tif (MyBackendType == B_STARTUP)\\n-\\t\\t\\t\\t\\t(void) SendProcSignal(active_pid,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  PROCSIG_RECOVERY_CONFLICT_LOGICALSLOT,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  INVALID_PROC_NUMBER);\\n+\\t\\t\\t\\t\\tSendProcSignal(active_pid,\\n+\\t\\t\\t\\t\\t\\t\\t\\t   PROCSIG_RECOVERY_CONFLICT_LOGICALSLOT,\\n+\\t\\t\\t\\t\\t\\t\\t\\t   active_proc);\\n```\\n\\nHere active_proc!=INVALID_PROC_NUMBER, so this changes the original logic without an explanation. Is the change intentional?\\n\\n3 - 0004\\n```\\n+\\t * This is a bitmask of RecoveryConflictReasons\\n+\\t */\\n+\\tpg_atomic_uint32 pendingRecoveryConflicts;\\n```\\n\\nI just feel this comment is a little bit confusing because RecoveryConflictReasons is an enum. Maybe we can say something like: This is a bitmask; each bit corresponds to one RecoveryConflictReason enum value.\\n\\n4 - 0004\\n```\\n-\\t\\t\\t\\t(void) SendProcSignal(pid, sigmode, vxid.procNumber);\\n+\\t\\t\\t\\t(void) SendProcSignal(pid, PROCSIG_RECOVERY_CONFLICT, vxid.procNumber);\\n```\\n\\nNit: Here (void) is retained for SendProcSignal, but in the place of commit 2 for 0003, (void) is deleted when calling SendProcSignal, is there any reason for retaining this one and deleting that one?\\n\\n5 - 0004\\n```\\n+\\t * doesn't check for deadlock direcly, because we want to kill one of the\\n```\\n\\nTypo: direcly -> directly\\n\\n6 - 0005\\n```\\ndiff --git a/src/backend/tcop/postgres.c b/src/backend/tcop/postgres.c\\nindex a2fa98ee971..bbf2254ca67 100644\\n--- a/src/backend/tcop/postgres.c\\n+++ b/src/backend/tcop/postgres.c\\n@@ -179,11 +179,15 @@ static bool IsTransactionExitStmt(Node *parsetree);\\n static bool IsTransactionExitStmtList(List *pstmts);\\n static bool IsTransactionStmtList(List *pstmts);\\n static void drop_unnamed_stmt(void);\\n+static void ProcessRecoveryConflictInterrupts(void);\\n+static void ProcessRecoveryConflictInterrupt(RecoveryConflictReason reason);\\n+static void report_recovery_conflict(RecoveryConflictReason reason);\\n static void log_disconnections(int code, Datum arg);\\n static void enable_statement_timeout(void);\\n static void disable_statement_timeout(void);\\n \\n \\n+\\n /* ----------------------------------------------------------------\\n```\\n\\nNit: No need to add this empty line.\\n\\n7 - 0005\\n```\\n+static void\\n+report_recovery_conflict(RecoveryConflictReason reason)\\n+{\\n+\\tbool\\t\\tfatal;\\n \\n+\\tif (RECOVERY_CONFLICT_DATABASE)\\n+\\t{\\n```\\n\\nI believe this should be if (reason == RECOVERY_CONFLICT_DATABASE).\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be802be712bae9","snippet":"> On Jan 23, 2026, at 07:20, Heikki Linnakangas <hlinnaka@iki.fi> wrote: > > I had a look at recovery conflict signaling and a few things caught my eye. No functional changes, but some","historyId":"8736","internalDate":"1769136100000","receivedAtUtc":"2026-01-23T02:41:40.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	Heikki Linnakangas proposes a series of patches to refactor PostgreSQL's recovery conflict signaling for improved readability without functional changes. The patches include: (1) removing the unused errdetail_abort() function that was supposed to add recovery conflict details to aborted transactions but appears unreachable in current code, (2) removing misleading reconnection hints when databases are being dropped during recovery, (3-4) separating recovery conflict reasons from process signals by introducing a dedicated enum and using a single PROCSIG_RECOVERY_CONFLICT flag with reasons communicated via PGPROC bitmask, and (5) refactoring ProcessRecoveryConflictInterrupt to eliminate confusing switch-statement fallthrough logic. Chao Li provides detailed technical review feedback, confirming the first two changes while identifying several issues in patches 3-5, including variable scoping suggestions, logic changes that need explanation, comment clarity improvements, inconsistent void casting, a typo, and a missing comparison operator in the final patch.\n\nHeikki Linnakangas提出一系列补丁来重构PostgreSQL的恢复冲突信号处理，以提高可读性而不改变功能。补丁包括：(1) 移除未使用的errdetail_abort()函数，该函数本应为中止事务添加恢复冲突详细信息但在当前代码中似乎无法访问，(2) 移除在恢复期间删除数据库时的误导性重连提示，(3-4) 通过引入专用枚举将恢复冲突原因与进程信号分离，使用单个PROCSIG_RECOVERY_CONFLICT标志，原因通过PGPROC位掩码通信，(5) 重构ProcessRecoveryConflictInterrupt以消除令人困惑的switch语句穿透逻辑。Chao Li提供详细技术审查反馈，确认前两个更改，同时识别补丁3-5中的几个问题，包括变量作用域建议、需要解释的逻辑更改、注释清晰度改进、不一致的void强制转换、拼写错误以及最终补丁中缺少比较运算符。	2026-01-23 02:41:40+00	\N
12	19be8d7e8b61b753	Fix a typo in comment	["dingyi_yale@163.com","michael@paquier.xyz"]	[{"id":"19be8d7e8b61b753","messageId":"<5cfb747.2f21.19be8d77431.Coremail.dingyi_yale@163.com>","subject":"Fix a typo in comment","body":"Hi Hackers,\\n\\n\\nRecently, I found a comment error in multixact.c. To address this, I've prepared a relevant patch.\\n\\n\\nFor the details,please see the attached patch file.\\n\\n\\nLooking forward to your feedback.\\n\\n\\nBest regards,\\n--\\nYi Ding\\n\\n","threadId":"19be8d7e8b61b753","snippet":"Hi Hackers, Recently, I found a comment error in multixact.c. To address this, I've prepared a relevant patch. For the details,please see the attached patch file. Looking forward to your feedback.","historyId":"8748","internalDate":"1769137992000","receivedAtUtc":"2026-01-23T03:13:12.000Z","from":"Yi Ding <dingyi_yale@163.com>"},{"id":"19be91cdf4d420fe","messageId":"<aXL4_Zx7zWGuvktz@paquier.xyz>","subject":"Re: Fix a typo in comment","body":"On Fri, Jan 23, 2026 at 11:13:12AM +0800, Yi Ding wrote:\\n> Recently, I found a comment error in multixact.c. To address this,\\n> I've prepared a relevant patch.\\n> \\n> For the details,please see the attached patch file.\\n\\nThanks for the report, picked up for later.\\n--\\nMichael\\n","threadId":"19be8d7e8b61b753","snippet":"On Fri, Jan 23, 2026 at 11:13:12AM +0800, Yi Ding wrote: > Recently, I found a comment error in multixact.c. To address this, > I've prepared a relevant patch. > > For the details,","historyId":"8748","internalDate":"1769142525000","receivedAtUtc":"2026-01-23T04:28:45.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	Yi Ding reported finding a comment error in multixact.c and submitted a patch to fix the typo. The patch details were provided in an attached file. Michael Paquier acknowledged the report and confirmed he picked it up for later review. This is a straightforward documentation fix with no complex technical discussion or controversy. The issue appears resolved with maintainer acceptance, though the actual patch implementation is pending.\nYi Ding报告在multixact.c中发现注释错误，并提交了修复该拼写错误的补丁。补丁详情在附件中提供。Michael Paquier确认收到报告并表示已接受，将稍后审查。这是一个直接的文档修复，没有复杂的技术讨论或争议。问题似乎已通过维护者接受得到解决，但实际补丁实施仍在等待中。	2026-01-23 04:28:45+00	\N
12	19be57f2bef34a1b	Assert the timestamp is available for ORIGN_DIFFERS conflicts	["amit.kapila16@gmail.com","kuroda.hayato@fujitsu.com","li.evan.chao@gmail.com","shveta.malik@gmail.com"]	[{"id":"19be57f2bef34a1b","messageId":"<CAJpy0uCLKRqi0vOJAEGKoOzj6WR32Dxi4mvewjE4_2SE3uEOug@mail.gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"On Wed, Jan 21, 2026 at 12:40 PM Hayato Kuroda (Fujitsu)\\n<kuroda.hayato@fujitsu.com> wrote:\\n>\\n> Dear Shveta,\\n>\\n> Thanks for ideas, I prefer first one. Also, pgindent told me that Line blank\\n> should be before the code comment. PSA the new version.\\n>\\n\\nThe patch LGTM.\\n\\nthanks\\nShveta\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"On Wed, Jan 21, 2026 at 12:40 PM Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > Dear Shveta, > > Thanks for ideas, I prefer first one. Also, pgindent told me that Line","historyId":"5951","internalDate":"1769081851000","receivedAtUtc":"2026-01-22T11:37:31.000Z","from":"shveta malik <shveta.malik@gmail.com>"},{"id":"19be5caa28727e61","messageId":"<60B254A7-A181-4983-A617-6B86E850F052@gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"\\n\\n> On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> \\n> Dear Shveta,\\n> \\n> Thanks for ideas, I prefer first one. Also, pgindent told me that Line blank\\n> should be before the code comment. PSA the new version.\\n> \\n> Best regards,\\n> Hayato Kuroda\\n> FUJITSU LIMITED\\n>> Shveta\\n> <v2-0001-Add-Assert-for-UPDATE-DELETE-_ORIGIN_DIFFERS.patch>\\n\\nHi Hayato-san,\\n\\nThanks for the patch. Though the change is simple, I see some problems:\\n\\n```\\n+\\t\\t\\t/*\\n+\\t\\t\\t * We reach this point only if track_commit_timestamp is enabled.\\n+\\t\\t\\t * Therefore, localts must contain a valid timestamp.\\n+\\t\\t\\t */\\n+\\t\\t\\tAssert(localts);\\n```\\n\\n1. The same code appears twice, so kinda redundant.\\n2. The comment is unclear. It asserts localts, but the comment talks about GUC track_commit_timestamp.\\n3. Assert(localts) technically works, because C treat un-zero integer as true, but as we are check localts is valid, it's better to be explicit as Assert(localts != 0).\\n\\nSo, I would suggest add the assert in the very beginning of the function as:\\n```\\n/*\\n * UPDATE_ORIGIN_DIFFERS and DELETE_ORIGIN_DIFFERS conflicts are only\\n * reported when track_commit_timestamp is enabled, and a valid local\\n * commit timestamp is available for the conflicting row.\\n */\\nAssert(type != CT_UPDATE_ORIGIN_DIFFERS && type != CT_DELETE_ORIGIN_DIFFERS || localts != 0);\\n\\n```\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"> On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > Dear Shveta, > > Thanks for ideas, I prefer first one. Also, pgindent told me that Line","historyId":"5951","internalDate":"1769086771000","receivedAtUtc":"2026-01-22T12:59:31.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be8cb67e7e4cf0","messageId":"<CAA4eK1K_g7bi+6=rut3CFV0rSyBPoFVbZ1k8zeLNRE5SFnmtuA@mail.gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"On Thu, Jan 22, 2026 at 6:30 PM Chao Li <li.evan.chao@gmail.com> wrote:\\n>\\n> > On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> >\\n> > Dear Shveta,\\n> >\\n> > Thanks for ideas, I prefer first one. Also, pgindent told me that Line blank\\n> > should be before the code comment. PSA the new version.\\n> >\\n> > Best regards,\\n> > Hayato Kuroda\\n> > FUJITSU LIMITED\\n> >> Shveta\\n> > <v2-0001-Add-Assert-for-UPDATE-DELETE-_ORIGIN_DIFFERS.patch>\\n>\\n> Hi Hayato-san,\\n>\\n> Thanks for the patch. Though the change is simple, I see some problems:\\n>\\n> ```\\n> +                       /*\\n> +                        * We reach this point only if track_commit_timestamp is enabled.\\n> +                        * Therefore, localts must contain a valid timestamp.\\n> +                        */\\n> +                       Assert(localts);\\n> ```\\n>\\n> 1. The same code appears twice, so kinda redundant.\\n> 2. The comment is unclear. It asserts localts, but the comment talks about GUC track_commit_timestamp.\\n> 3. Assert(localts) technically works, because C treat un-zero integer as true, but as we are check localts is valid, it's better to be explicit as Assert(localts != 0).\\n>\\n> So, I would suggest add the assert in the very beginning of the function as:\\n> ```\\n> /*\\n>  * UPDATE_ORIGIN_DIFFERS and DELETE_ORIGIN_DIFFERS conflicts are only\\n>  * reported when track_commit_timestamp is enabled, and a valid local\\n>  * commit timestamp is available for the conflicting row.\\n>  */\\n> Assert(type != CT_UPDATE_ORIGIN_DIFFERS && type != CT_DELETE_ORIGIN_DIFFERS || localts != 0);\\n>\\n\\nWe can follow your suggestion to reduce minor code duplicacy but OTOH\\nit leads to type specific checks (Assert in this case) which can make\\ncode difficult to follow if we continue such a practice. But your idea\\nto have a bit more explicit assert like Assert(localts != 0) sounds\\nokay to me.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"On Thu, Jan 22, 2026 at 6:30 PM Chao Li <li.evan.chao@gmail.com> wrote: > > > On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > >","historyId":"8712","internalDate":"1769137180000","receivedAtUtc":"2026-01-23T02:59:40.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>"},{"id":"19be9207a168ce05","messageId":"<TY7PR01MB145546B9A4725551D8D662669F594A@TY7PR01MB14554.jpnprd01.prod.outlook.com>","subject":"RE: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"Dear Amit, Chao,\\n\\nThanks for giving comments. But I do not want to move the Assert() atop\\nswitch-case statements; the function would be dirty for other cases.\\nAttached patch updates condition and comments based on your suggestions.\\n\\nBest regards,\\nHayato Kuroda\\nFUJITSU LIMITED\\n\\n","threadId":"19be57f2bef34a1b","snippet":"Dear Amit, Chao, Thanks for giving comments. But I do not want to move the Assert() atop switch-case statements; the function would be dirty for other cases. Attached patch updates condition and","historyId":"8712","internalDate":"1769142758000","receivedAtUtc":"2026-01-23T04:32:38.000Z","from":"\\"Hayato Kuroda (Fujitsu)\\" <kuroda.hayato@fujitsu.com>"},{"id":"19be9324dfa77273","messageId":"<5901BDE1-4726-4823-B69E-3111AE368C60@gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"\\n\\n> On Jan 23, 2026, at 12:32, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> \\n> Dear Amit, Chao,\\n> \\n> Thanks for giving comments. But I do not want to move the Assert() atop\\n> switch-case statements; the function would be dirty for other cases.\\n> Attached patch updates condition and comments based on your suggestions.\\n> \\n> Best regards,\\n> Hayato Kuroda\\n> FUJITSU LIMITED\\n> \\n> <v3-0001-Add-Assert-for-UPDATE-DELETE-_ORIGIN_DIFFERS.patch>\\n\\nThanks for updating the patch. V3 looks good to me.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"> On Jan 23, 2026, at 12:32, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > Dear Amit, Chao, > > Thanks for giving comments. But I do not want to move the Assert()","historyId":"8712","internalDate":"1769143895000","receivedAtUtc":"2026-01-23T04:51:35.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	The discussion centers on a PostgreSQL patch that adds assertions to verify that local timestamps are available for ORIGIN_DIFFERS conflicts. Shveta initially approved Hayato Kuroda's v2 patch after formatting improvements. However, Chao Li identified three issues: code duplication, unclear comments, and non-explicit assertion conditions. He suggested consolidating the assertions at the function's beginning with more explicit conditions. Amit Kapila acknowledged the suggestion to use `Assert(localts != 0)` for clarity but expressed concerns about type-specific checks making code harder to follow. Kuroda disagreed with moving assertions to the top, preferring to keep them within relevant switch-case branches to avoid cluttering other cases. He submitted v3 addressing the comment clarity and assertion explicitness while maintaining the current structure. Chao Li approved v3, indicating the patch is ready for further review.\n\n该讨论围绕一个PostgreSQL补丁展开，该补丁添加断言来验证ORIGIN_DIFFERS冲突的本地时间戳可用性。Shveta最初在格式改进后批准了Hayato Kuroda的v2补丁。然而，Chao Li发现了三个问题：代码重复、注释不清晰和非显式断言条件。他建议在函数开头合并断言并使用更显式的条件。Amit Kapila认可使用`Assert(localts != 0)`提高清晰度的建议，但担心类型特定检查会使代码难以理解。Kuroda不同意将断言移至顶部，更倾向于将其保留在相关的switch-case分支内以避免干扰其他情况。他提交了v3版本，解决了注释清晰度和断言显式性问题，同时保持当前结构。Chao Li批准了v3版本，表明补丁已准备好进行进一步审核。	2026-01-23 04:51:35+00	\N
12	19be8ba53541a4cd	DOCS - "\\d mytable" also shows any publications that publish mytable	["li.evan.chao@gmail.com","masao.fujii@gmail.com","smithpb2250@gmail.com"]	[{"id":"19be8ba53541a4cd","messageId":"<CAHGQGwFhkhdK79fTeYEnxxfgmzjjshfXuBBnfwoD7GneEdBokQ@mail.gmail.com>","subject":"Re: DOCS - \\"\\\\d mytable\\" also shows any publications that publish mytable","body":"On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote:\\n> > Regarding whole patch, I'm not clear about whether this patch is worthwhile\\n> > if it only adds phrasing like \\"such as\\" or \\"for example\\". That said, if some\\n> > users currently interpret the list as exhaustive, this change could help\\n> > clarify the intent...\\n> >\\n>\\n> Yes. The patch is not doing much now, but OTOH the reason for this\\n> patch adding the \\"missing\\" publication entry in the first place was\\n> precisely because I thought the docs page was was documenting\\n> exhaustive lists; so there might be some merit to clear up that\\n> illusion.\\n\\nOK, let's commit the patch as a documentation improvement to\\nreduce user confusion.\\n\\n> PSA v4.\\n\\nThanks for updating the patch! I've applied a few small tweaks and\\nattached an updated version.\\n\\n+        Associated objects, such as indexes, constraints, rules, publications,\\n+        triggers, and so on, are also shown. For foreign tables, the\\n\\nI removed \\"and so on\\" because using both \\"such as\\" and \\"and so on\\"\\nin the same sentence felt redundant.\\n\\n+        more information is displayed, such as: any comments associated with\\n\\nI removed \\"such as\\" and instead added \\"for example\\" before \\"any comments\\",\\nwhich felt more natural here at least for me.\\n\\n-         identity</link> setting and the\\n+         identity</link> settings and the\\n\\nI'm not sure this change is necessary, so I restored the original wording.\\n\\nI also updated the commit message.\\n\\nRegards,\\n\\n-- \\nFujii Masao\\n","threadId":"19be8ba53541a4cd","snippet":"On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote: > > Regarding whole patch, I'm not clear about whether this patch is worthwhile > > if it only adds","historyId":"8746","internalDate":"1769136058000","receivedAtUtc":"2026-01-23T02:40:58.000Z","from":"Fujii Masao <masao.fujii@gmail.com>"},{"id":"19be8c1bf9900460","messageId":"<21B1E0AE-665B-4BEA-9894-65632F36FA06@gmail.com>","subject":"Re: DOCS - \\"\\\\d mytable\\" also shows any publications that publish mytable","body":"\\n\\n> On Jan 23, 2026, at 10:40, Fujii Masao <masao.fujii@gmail.com> wrote:\\n> \\n> On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote:\\n>>> Regarding whole patch, I'm not clear about whether this patch is worthwhile\\n>>> if it only adds phrasing like \\"such as\\" or \\"for example\\". That said, if some\\n>>> users currently interpret the list as exhaustive, this change could help\\n>>> clarify the intent...\\n>>> \\n>> \\n>> Yes. The patch is not doing much now, but OTOH the reason for this\\n>> patch adding the \\"missing\\" publication entry in the first place was\\n>> precisely because I thought the docs page was was documenting\\n>> exhaustive lists; so there might be some merit to clear up that\\n>> illusion.\\n> \\n> OK, let's commit the patch as a documentation improvement to\\n> reduce user confusion.\\n> \\n>> PSA v4.\\n> \\n> Thanks for updating the patch! I've applied a few small tweaks and\\n> attached an updated version.\\n> \\n> +        Associated objects, such as indexes, constraints, rules, publications,\\n> +        triggers, and so on, are also shown. For foreign tables, the\\n> \\n> I removed \\"and so on\\" because using both \\"such as\\" and \\"and so on\\"\\n> in the same sentence felt redundant.\\n> \\n> +        more information is displayed, such as: any comments associated with\\n> \\n> I removed \\"such as\\" and instead added \\"for example\\" before \\"any comments\\",\\n> which felt more natural here at least for me.\\n> \\n> -         identity</link> setting and the\\n> +         identity</link> settings and the\\n> \\n> I'm not sure this change is necessary, so I restored the original wording.\\n> \\n> I also updated the commit message.\\n> \\n> Regards,\\n> \\n> -- \\n> Fujii Masao\\n> <v5-0001-doc-Clarify-that-d-and-d-output-lists-are-illustr.patch>\\n\\n```\\n+        Associated objects, such as indexes, constraints, rules,triggers,\\n```\\n\\nA while-space is missed before "triggers". I tried to render the page, on the rendered html page, the white-space is also missed.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be8ba53541a4cd","snippet":"> On Jan 23, 2026, at 10:40, Fujii Masao <masao.fujii@gmail.com> wrote: > > On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote: >>> Regarding whole","historyId":"8746","internalDate":"1769136524000","receivedAtUtc":"2026-01-23T02:48:44.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be96709d5e0640","messageId":"<CAHut+PuYw21ipjrNEj2PFDCRxVKQpbCabNOT8N4BkoVMbKBzuQ@mail.gmail.com>","subject":"Re: DOCS - \\"\\\\d mytable\\" also shows any publications that publish mytable","body":"v5 LGTM, except for the missing space that Chao has already reported.\\n\\n======\\nKind Regards,\\nPeter Smith.\\nFujitsu Australia\\n\\n\\n","threadId":"19be8ba53541a4cd","snippet":"v5 LGTM, except for the missing space that Chao has already reported. ====== Kind Regards, Peter Smith. Fujitsu Australia","historyId":"12876","internalDate":"1769147366000","receivedAtUtc":"2026-01-23T05:49:26.000Z","from":"Peter Smith <smithpb2250@gmail.com>"}]	Fujii Masao has committed a documentation patch to clarify that PostgreSQL's `\\d` command output lists are illustrative rather than exhaustive. The patch adds phrases like "such as" and "for example" to make clear that associated objects (indexes, constraints, rules, publications, triggers) shown with table descriptions are examples, not complete lists. Peter Smith originally proposed the patch after initially believing the documentation implied exhaustive listings. Fujii made several refinements to avoid redundant phrasing, removing "and so on" when "such as" was already present, and replacing some instances of "such as" with "for example" for better readability. Chao Li identified a missing whitespace before "triggers" in the final version, and Peter Smith confirmed the patch looks good aside from this formatting issue.\nFujii Masao已提交文档补丁，明确PostgreSQL的`\\d`命令输出列表是示例性的而非详尽的。补丁添加了"such as"和"for example"等短语，明确表明与表描述一起显示的关联对象（索引、约束、规则、发布、触发器）是示例而非完整列表。Peter Smith最初提出该补丁，因为他之前认为文档暗示了详尽列表。Fujii进行了几项改进以避免冗余措辞，在已有"such as"时删除"and so on"，并将某些"such as"替换为"for example"以提高可读性。Chao Li发现最终版本中"triggers"前缺少空格，Peter Smith确认补丁看起来不错，除了这个格式问题。	2026-01-23 05:49:26+00	\N
12	19be981582954d3e	Limit memory usage by postgres_fdw batches	["a.pyhalov@postgrespro.ru","tomas@vondra.me"]	[{"id":"19be981582954d3e","messageId":"<e39d964cb5ed91ede13a87109376a463@postgrespro.ru>","subject":"Re: Limit memory usage by postgres_fdw batches","body":"Alexander Pyhalov писал(а) 2026-01-13 13:44:\\n> For now I start thinking we need some form of FETCH, which stops > fetching data based on batch size...\\n\\nHi.\\n\\nTo limit memory consumption, we actually have to retreive less data. And we can do it only on the side of the foreign server. I've rewritten the third patch. We introduce a new parameter - cursor_fetch_limit, which is set by postgres_fdw. When it is set, fetching limited count of records from the cursor is also limited by memory consumed by the records. Of course, record size is some estimation (for example, we don't know what out function will do).\\n\\nThis works as expected - in my tests with tables of large records, backends, executing selects, were always restricted by about 2 GB of RAM overall (without patch memory consumption easily grows up to 8 GB). However, now when we got less tuples from executor, than expected, we should recheck, if these are all tuples we can get. I've introduced es_eof EState field to signal that there's no more tuples. Don't know if it's the best way.\\n\\n-- \\nBest regards,\\nAlexander Pyhalov,\\nPostgres Professional","threadId":"19be981582954d3e","snippet":"Alexander Pyhalov писал(а) 2026-01-13 13:44: > For now I start thinking we need some form of FETCH, which stops > fetching data based on batch size... Hi. To limit memory consumption, we actually","historyId":"12877","internalDate":"1769149109000","receivedAtUtc":"2026-01-23T06:18:29.000Z","from":"Alexander Pyhalov <a.pyhalov@postgrespro.ru>"}]	Alexander Pyhalov proposes a solution to limit memory usage in postgres_fdw batches by introducing a new parameter called cursor_fetch_limit. This parameter restricts data fetching on the foreign server side based on both record count and estimated memory consumption. In testing with large record tables, this approach successfully limited backend memory usage to approximately 2GB instead of the previous 8GB without the patch. However, the implementation requires additional logic to handle cases where fewer tuples are retrieved than expected, introducing an es_eof EState field to signal when no more tuples are available. Pyhalov acknowledges uncertainty about whether this approach represents the optimal solution for the memory limitation problem.\n\nAlexander Pyhalov 提出了一个解决方案来限制 postgres_fdw 批处理中的内存使用，通过引入名为 cursor_fetch_limit 的新参数。该参数基于记录数量和估计内存消耗在外部服务器端限制数据获取。在使用大记录表的测试中，该方法成功地将后端内存使用限制在约 2GB，而不是未打补丁时的 8GB。然而，该实现需要额外的逻辑来处理检索到的元组少于预期的情况，引入了 es_eof EState 字段来表示没有更多元组可用。Pyhalov 承认对于这种方法是否代表内存限制问题的最佳解决方案存在不确定性。	2026-01-23 06:18:29+00	\N
12	19be99a6948cab2b	Extended Statistics set/restore/clear functions.	["corey.huinker@gmail.com","li.evan.chao@gmail.com","michael@paquier.xyz","tndrwang@gmail.com"]	[{"id":"19be99a6948cab2b","messageId":"<CADkLM=c3JivzHNXLt-X_JicYknRYwLTiOCHOPiKagm2_vdrFUg@mail.gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","body":">\\n> How about the multirange range case in extended_statistics_update()\\n> for the mcv/expression path?\\n>\\n\\nAdded.\\n\\n\\n> import_expressions() also complains about a statatt_set_slot() with\\n> histograms.\\n>\\n\\nUnsure what you mean here.\\n\\n\\n> These ones are less consistent in style, the error hints should be the\\n> errmsg, and there are some s/statitisics/statistics/.  The errhint\\n> should be a full sentence, so I guess that you mean to switch both\\n> fields in such cases.\\n>\\n\\nThe 0003 patch of this set addresses this.\\n\\n\\n> s/the the/the/, I think this one's mine.  :D\\n>\\n\\n0002\\n\\n\\n>\\n> While the documentation shows one example with n_distinct,\\n> dependencies and exprs, I'd guess that we should push forward with\\n> something similar regarding most_common_val, most_common_val_nulls,\\n> most_common_freqs, most_common_base_freqs.  It looks particularly\\n> important to expand this part, the relationship they have between each\\n> pther, their expected input format (?), and what they map to in the\\n> catalogs.  If one is specified, all four of them are required, for\\n> example, but that's not the only thing I imagine should keep a track\\n> of.  This data is more complex than the single stats fields.\\n>\\n\\nI think some of this may have been addressed in this patchset.\\n\\nI've left these patches un-squashed to help differentiate what changes\\naddress which problems. They'll likely be re-squashed once those issues are\\naddressed.\\n\\nThe most interesting here is the change I did to statatt_get_type() to get\\nit to work for MCV/expression multiranges. Mostly, the problem arose from\\nthe fact that MCVlist will have multirange as a part of the exported tuple\\ntext array, so there is a legit need to parse the input of a multirange's\\ntext reprepresentation, whereas with attribute stats we only ever need to\\nparse the input of the multirange's element, a plain old range. The fix, as\\nyou may see highlights how statatt_get_type() is doing two things\\n(resolving typ* info for an attribute or expression, and fetching the\\nbasetype and basetype's ltopr and eqopr) and maybe the basetype/operator\\nstuff should be moved to its own function.\\n\\nAnother possible solution is to change the two refactor the\\nexamine_attribute() functions (one in analyze.c, one in extended_stats.c)\\nunifying them where possible, and allowing the unified function to still\\ngenerate a VacAttrStats even if the attstattarget is 0. That's a heavier\\nlift, and I left things as they are now to demonstrate the issue at hand.\\n\\nRebased as well.\\n","threadId":"19be99a6948cab2b","snippet":"How about the multirange range case in extended_statistics_update() for the mcv/expression path? Added. import_expressions() also complains about a statatt_set_slot() with histograms. Unsure what you","historyId":"12878","internalDate":"1769150738000","receivedAtUtc":"2026-01-23T06:45:38.000Z","from":"Corey Huinker <corey.huinker@gmail.com>"}]	The discussion centers on improvements to Extended Statistics set/restore/clear functions in PostgreSQL. The main focus is addressing issues with multirange handling in extended_statistics_update() for the mcv/expression path, which has been added. There's uncertainty about import_expressions() complaints regarding statatt_set_slot() with histograms. Style inconsistencies in error messages are being addressed in patch 0003, including typo fixes. Documentation needs expansion for most_common_val fields and their relationships. The key technical challenge involves statatt_get_type() function handling multirange text representations differently for MCVlist versus attribute stats. A proposed solution suggests refactoring examine_attribute() functions to unify them while allowing VacAttrStats generation even with zero attstattarget. The patches remain un-squashed for clarity.\n\n关于PostgreSQL扩展统计集合/恢复/清除函数的改进讨论。主要焦点是解决extended_statistics_update()中mcv/表达式路径的多范围处理问题，该问题已得到解决。对于import_expressions()关于带直方图的statatt_set_slot()的投诉存在不确定性。错误消息的样式不一致问题正在0003补丁中解决，包括拼写错误修复。文档需要扩展most_common_val字段及其关系的说明。关键技术挑战涉及statatt_get_type()函数对MCVlist与属性统计的多范围文本表示的不同处理。提议的解决方案建议重构examine_attribute()函数以统一它们，同时允许即使在零attstattarget下也能生成VacAttrStats。补丁保持未压缩状态以保持清晰度。	2026-01-23 06:45:38+00	\N
12	19beb9adc5e1e332	display hot standby state in psql prompt	["andreas@proxel.se","htamfids@gmail.com","jim.jones@uni-muenster.de","li.evan.chao@gmail.com","masao.fujii@gmail.com","nathandbossart@gmail.com","srinath2133@gmail.com"]	[{"id":"19beb9adc5e1e332","messageId":"<d81c08f6-1a4f-48ee-b1ff-e78b145c9e12@uni-muenster.de>","subject":"Re: display hot standby state in psql prompt","body":"Hi Fujii\\n\\nOn 12/11/2025 04:48, Fujii Masao wrote:\\n> I'm fine with the initial proposal. I think showing whether the connected\\n> server is a primary or standby in the prompt would be helpful when managing\\n> multiple servers. OTOH, I'm not sure how useful it would be to display\\n> whether the current transaction is read-only.\\n> \\n> That said, this is just my view, so I'd like to hear what others think.\\n\\nSince we haven't heard any objections from the other reviewers, do you\\nthink we should switch back to the initial \\"primary\\" or \\"standby\\" proposal?\\n\\nBest, Jim\\n\\n\\n","threadId":"19beb9adc5e1e332","snippet":"Hi Fujii On 12/11/2025 04:48, Fujii Masao wrote: > I'm fine with the initial proposal. I think showing whether the connected > server is a primary or standby in the prompt would be helpful","historyId":"12896","internalDate":"1769184341000","receivedAtUtc":"2026-01-23T16:05:41.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"}]	The discussion centers on a proposal to display hot standby state information in the psql prompt to help administrators manage multiple PostgreSQL servers. Fujii Masao supports the initial proposal to show "primary" or "standby" status in the prompt, finding it helpful for server management, but questions the utility of displaying read-only transaction status. Jim Jones responds by noting the lack of objections from other reviewers and asks whether they should revert to the original "primary" or "standby" proposal. The thread appears to be seeking consensus on the final implementation approach, with the simpler primary/standby indicator gaining favor over more complex transaction state information.\n讨论围绕在psql提示符中显示热备状态信息的提案展开，以帮助管理员管理多个PostgreSQL服务器。Fujii Masao支持在提示符中显示"主服务器"或"备服务器"状态的初始提案，认为这对服务器管理很有帮助，但质疑显示只读事务状态的实用性。Jim Jones回应说其他审查者没有提出反对意见，并询问是否应该回到原来的"主服务器"或"备服务器"提案。该讨论似乎在寻求对最终实现方法的共识，较简单的主/备指示器比复杂的事务状态信息更受青睐。	2026-01-23 16:05:41+00	\N
12	19be76a420b81e68	pg_upgrade: optimize replication slot caught-up check	["li.evan.chao@gmail.com","sawada.mshk@gmail.com","shveta.malik@gmail.com"]	[{"id":"19be76a420b81e68","messageId":"<CAD21AoBQ7aRwfiizn4FFm9d9Lf9uEmn7-66L4eKsCAd17Gy=7g@mail.gmail.com>","subject":"Re: pg_upgrade: optimize replication slot caught-up check","body":"On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 5:19 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> >\\n> > On Mon, Jan 19, 2026 at 10:38 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> > >\\n> > > On Wed, Jan 14, 2026 at 11:24 PM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> > > >\\n> > > > I've attached the updated patch.\\n> > > >\\n> > >\\n> > > Thank You for the patch. I like the idea of optimization. Few initial comments:\\n> >\\n> > Thank you for reviewing the patch!\\n> >\\n> > >\\n> > > 1)\\n> > > + * The query returns the slot names and their caught-up status in\\n> > > + * the same order as the results collected by\\n> > > + * get_old_cluster_logical_slot_infos(). If this query is changed,\\n> > >\\n> > > I could not find the function get_old_cluster_logical_slot_infos(), do\\n> > > you mean get_old_cluster_logical_slot_infos_query()?\\n> >\\n> > It seems an oversight in commit 6d3d2e8e541f0. I think it should be\\n> > get_db_rel_and_slot_infos().\\n> >\\n> > >\\n> > > 2)\\n> > > \\"  WHERE database = current_database() AND \\"\\n> > > \\"    slot_type = 'logical' AND \\"\\n> > >\\n> > > Is there a reason why database = current_database() is placed before\\n> > > slot_type = 'logical'? I am not sure how the PostgreSQL optimizer and\\n> > > executor will order these predicates, but from the first look,\\n> > > slot_type = 'logical' appears cheaper and could be placed first,\\n> > > consistent with the ordering used at other places.\\n> >\\n> > Changed.\\n> >\\n> > >\\n> > > 3)\\n> > > Shouldn't we add a sanity check inside\\n> > > get_old_cluster_logical_slot_infos_query() to ensure that when\\n> > > skip_caught_up_check is true, we are on PostgreSQL 18 or lower? This\\n> > > would make the function safer for future use if it's called elsewhere.\\n> > > I understand the caller already performs a similar check, but I think\\n> > > it's more appropriate here since we call\\n> > > binary_upgrade_logical_slot_has_caught_up() from inside, which doesn't\\n> > > even exist on newer versions.\\n> >\\n> > What kind of sanity check did you mean? We can have a check with\\n> > pg_fatal() but it seems almost the same to me even if pg_upgrade fails\\n> > with an error due to missing\\n> > binary_upgrade_logical_slot_has_caught_up().\\n>\\n> I was referring to a development-level sanity check, something like:\\n>\\n> /* skip_caught_up_check is required iff PG19 or newer */\\n> Assert((GET_MAJOR_VERSION(cluster->major_version) >= 1900) ==\\n>    skip_caught_up_check);\\n>\\n> But performing this check requires access to the cluster version (or\\n> cluster information), which this function currently does not have.\\n> Given that, do you think it would make sense to pass the cluster as an\\n> argument to this function in order to perform the sanity check here?\\n\\nHmm, I think it's better not to have the same check in multiple\\nplaces, but it might make sense to have\\nget_old_cluster_logical_slot_infos_query() decide whether to use the\\nfast method. I've updated the patch accordingly, please review it.\\n\\n>\\n> > >\\n> > > 4)\\n> > > +# Check the file content. While both test_slot1 and test_slot2 should\\n> > > be reporting\\n> > > +# that they have unconsumed WAL records, test_slot3 should not be reported as\\n> > > +# it has caught up.\\n> > >\\n> > > Can you please elaborate the reason behind test_slot3 not being\\n> > > reported? Also mention in the comment if possible.\\n> >\\n> > We advance test_slot3 to the current WAL LSN before executing\\n> > pg_upgrade, so the test_slot3 should have consumed all pending WALs.\\n> > Please refer to the following changes:\\n>\\n> I understand the test, and the comments are clear to me. I also\\n> understand that only test_slot3 is expected to be in the caught-up\\n> state. My questions were specifically about the following points:\\n> 1)  Why do we expect 'slot3 caught-up' not to be mentioned in the LOG?\\n> Is it simply because there is no corresponding logging in the code, or\\n> is this behavior related to some aspect of your fix that I may have\\n> missed?\\n>\\n> 2) In general, we do not validate the absence of LOG messages in\\n> tests. Why is this considered a special case where such a check is\\n> appropriate?\\n\\nWhat LOG do you refer to? In these tests, we check the\\ninvalid_logical_slots.txt file where pg_upgrade reports only invalid\\nslots (in terms of pg_upgrade). For test_slot3, it should not be\\nmentioned in that file as it has caught up. Given that the file has\\nonly invalid slots, checking the absence of test_slot3 in the file\\nmakes sense to me.\\n\\n\\nRegards,\\n\\n--\\nMasahiko Sawada\\nAmazon Web Services: https://aws.amazon.com\\n","threadId":"19be76a420b81e68","snippet":"On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote: > > On Thu, Jan 22, 2026 at 5:19 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote: > > > > On","historyId":"8730","internalDate":"1769114008000","receivedAtUtc":"2026-01-22T20:33:28.000Z","from":"Masahiko Sawada <sawada.mshk@gmail.com>"},{"id":"19be86d26e5beafb","messageId":"<B098C626-EE7D-4E98-8685-FBB7980C795E@gmail.com>","subject":"Re: pg_upgrade: optimize replication slot caught-up check","body":"\\n\\n> On Jan 23, 2026, at 04:33, Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> \\n> On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote:\\n>> \\n>> On Thu, Jan 22, 2026 at 5:19 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n>>> \\n>>> On Mon, Jan 19, 2026 at 10:38 PM shveta malik <shveta.malik@gmail.com> wrote:\\n>>>> \\n>>>> On Wed, Jan 14, 2026 at 11:24 PM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n>>>>> \\n>>>>> I've attached the updated patch.\\n>>>>> \\n>>>> \\n>>>> Thank You for the patch. I like the idea of optimization. Few initial comments:\\n>>> \\n>>> Thank you for reviewing the patch!\\n>>> \\n>>>> \\n>>>> 1)\\n>>>> + * The query returns the slot names and their caught-up status in\\n>>>> + * the same order as the results collected by\\n>>>> + * get_old_cluster_logical_slot_infos(). If this query is changed,\\n>>>> \\n>>>> I could not find the function get_old_cluster_logical_slot_infos(), do\\n>>>> you mean get_old_cluster_logical_slot_infos_query()?\\n>>> \\n>>> It seems an oversight in commit 6d3d2e8e541f0. I think it should be\\n>>> get_db_rel_and_slot_infos().\\n>>> \\n>>>> \\n>>>> 2)\\n>>>> \\"  WHERE database = current_database() AND \\"\\n>>>> \\"    slot_type = 'logical' AND \\"\\n>>>> \\n>>>> Is there a reason why database = current_database() is placed before\\n>>>> slot_type = 'logical'? I am not sure how the PostgreSQL optimizer and\\n>>>> executor will order these predicates, but from the first look,\\n>>>> slot_type = 'logical' appears cheaper and could be placed first,\\n>>>> consistent with the ordering used at other places.\\n>>> \\n>>> Changed.\\n>>> \\n>>>> \\n>>>> 3)\\n>>>> Shouldn't we add a sanity check inside\\n>>>> get_old_cluster_logical_slot_infos_query() to ensure that when\\n>>>> skip_caught_up_check is true, we are on PostgreSQL 18 or lower? This\\n>>>> would make the function safer for future use if it's called elsewhere.\\n>>>> I understand the caller already performs a similar check, but I think\\n>>>> it's more appropriate here since we call\\n>>>> binary_upgrade_logical_slot_has_caught_up() from inside, which doesn't\\n>>>> even exist on newer versions.\\n>>> \\n>>> What kind of sanity check did you mean? We can have a check with\\n>>> pg_fatal() but it seems almost the same to me even if pg_upgrade fails\\n>>> with an error due to missing\\n>>> binary_upgrade_logical_slot_has_caught_up().\\n>> \\n>> I was referring to a development-level sanity check, something like:\\n>> \\n>> /* skip_caught_up_check is required iff PG19 or newer */\\n>> Assert((GET_MAJOR_VERSION(cluster->major_version) >= 1900) ==\\n>>   skip_caught_up_check);\\n>> \\n>> But performing this check requires access to the cluster version (or\\n>> cluster information), which this function currently does not have.\\n>> Given that, do you think it would make sense to pass the cluster as an\\n>> argument to this function in order to perform the sanity check here?\\n> \\n> Hmm, I think it's better not to have the same check in multiple\\n> places, but it might make sense to have\\n> get_old_cluster_logical_slot_infos_query() decide whether to use the\\n> fast method. I've updated the patch accordingly, please review it.\\n> \\n>> \\n>>>> \\n>>>> 4)\\n>>>> +# Check the file content. While both test_slot1 and test_slot2 should\\n>>>> be reporting\\n>>>> +# that they have unconsumed WAL records, test_slot3 should not be reported as\\n>>>> +# it has caught up.\\n>>>> \\n>>>> Can you please elaborate the reason behind test_slot3 not being\\n>>>> reported? Also mention in the comment if possible.\\n>>> \\n>>> We advance test_slot3 to the current WAL LSN before executing\\n>>> pg_upgrade, so the test_slot3 should have consumed all pending WALs.\\n>>> Please refer to the following changes:\\n>> \\n>> I understand the test, and the comments are clear to me. I also\\n>> understand that only test_slot3 is expected to be in the caught-up\\n>> state. My questions were specifically about the following points:\\n>> 1)  Why do we expect 'slot3 caught-up' not to be mentioned in the LOG?\\n>> Is it simply because there is no corresponding logging in the code, or\\n>> is this behavior related to some aspect of your fix that I may have\\n>> missed?\\n>> \\n>> 2) In general, we do not validate the absence of LOG messages in\\n>> tests. Why is this considered a special case where such a check is\\n>> appropriate?\\n> \\n> What LOG do you refer to? In these tests, we check the\\n> invalid_logical_slots.txt file where pg_upgrade reports only invalid\\n> slots (in terms of pg_upgrade). For test_slot3, it should not be\\n> mentioned in that file as it has caught up. Given that the file has\\n> only invalid slots, checking the absence of test_slot3 in the file\\n> makes sense to me.\\n> \\n> \\n> Regards,\\n> \\n> --\\n> Masahiko Sawada\\n> Amazon Web Services: https://aws.amazon.com\\n> <v7-0001-pg_upgrade-Optimize-replication-slot-caught-up-ch.patch>\\n\\nI just went through v7, and overall looks good to me.\\n\\nOnly nitpick is:\\n```\\n+ *\\n+ * use_fast_caught_up_check is set to true on return if available in the given\\n+ * cluster.\\n```\\n\\nStrictly speaking, use_fast_caught_up_check is a pointer, it cannot be set, it is *use_fast_caught_up_check that is set to true. So, please add a star sign in front of use_fast_caught_up_check.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be76a420b81e68","snippet":"> On Jan 23, 2026, at 04:33, Masahiko Sawada <sawada.mshk@gmail.com> wrote: > > On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote: >> >> On","historyId":"8730","internalDate":"1769130977000","receivedAtUtc":"2026-01-23T01:16:17.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be9a9fb4ead83a","messageId":"<CAJpy0uAf-S-MWsnTk17VY8AkpbBGSpjxKeZNGCh_dCRLJJW4-Q@mail.gmail.com>","subject":"Re: pg_upgrade: optimize replication slot caught-up check","body":"On Fri, Jan 23, 2026 at 2:04 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n>\\n> On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> >\\n> > On Thu, Jan 22, 2026 at 5:19 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> > >\\n> > > On Mon, Jan 19, 2026 at 10:38 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> > > >\\n> > > > On Wed, Jan 14, 2026 at 11:24 PM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> > > > >\\n> > > > > I've attached the updated patch.\\n> > > > >\\n> > > >\\n> > > > Thank You for the patch. I like the idea of optimization. Few initial comments:\\n> > >\\n> > > Thank you for reviewing the patch!\\n> > >\\n> > > >\\n> > > > 1)\\n> > > > + * The query returns the slot names and their caught-up status in\\n> > > > + * the same order as the results collected by\\n> > > > + * get_old_cluster_logical_slot_infos(). If this query is changed,\\n> > > >\\n> > > > I could not find the function get_old_cluster_logical_slot_infos(), do\\n> > > > you mean get_old_cluster_logical_slot_infos_query()?\\n> > >\\n> > > It seems an oversight in commit 6d3d2e8e541f0. I think it should be\\n> > > get_db_rel_and_slot_infos().\\n> > >\\n> > > >\\n> > > > 2)\\n> > > > \\"  WHERE database = current_database() AND \\"\\n> > > > \\"    slot_type = 'logical' AND \\"\\n> > > >\\n> > > > Is there a reason why database = current_database() is placed before\\n> > > > slot_type = 'logical'? I am not sure how the PostgreSQL optimizer and\\n> > > > executor will order these predicates, but from the first look,\\n> > > > slot_type = 'logical' appears cheaper and could be placed first,\\n> > > > consistent with the ordering used at other places.\\n> > >\\n> > > Changed.\\n> > >\\n> > > >\\n> > > > 3)\\n> > > > Shouldn't we add a sanity check inside\\n> > > > get_old_cluster_logical_slot_infos_query() to ensure that when\\n> > > > skip_caught_up_check is true, we are on PostgreSQL 18 or lower? This\\n> > > > would make the function safer for future use if it's called elsewhere.\\n> > > > I understand the caller already performs a similar check, but I think\\n> > > > it's more appropriate here since we call\\n> > > > binary_upgrade_logical_slot_has_caught_up() from inside, which doesn't\\n> > > > even exist on newer versions.\\n> > >\\n> > > What kind of sanity check did you mean? We can have a check with\\n> > > pg_fatal() but it seems almost the same to me even if pg_upgrade fails\\n> > > with an error due to missing\\n> > > binary_upgrade_logical_slot_has_caught_up().\\n> >\\n> > I was referring to a development-level sanity check, something like:\\n> >\\n> > /* skip_caught_up_check is required iff PG19 or newer */\\n> > Assert((GET_MAJOR_VERSION(cluster->major_version) >= 1900) ==\\n> >    skip_caught_up_check);\\n> >\\n> > But performing this check requires access to the cluster version (or\\n> > cluster information), which this function currently does not have.\\n> > Given that, do you think it would make sense to pass the cluster as an\\n> > argument to this function in order to perform the sanity check here?\\n>\\n> Hmm, I think it's better not to have the same check in multiple\\n> places, but it might make sense to have\\n> get_old_cluster_logical_slot_infos_query() decide whether to use the\\n> fast method. I've updated the patch accordingly, please review it.\\n>\\n\\nOkay, looks good. Just one minor thing:\\n\\n+ * Note that binary_upgrade_logical_slot_has_caught_up() is available only\\n+ * PG18 or older. For PG19 or newer *use_fast_caught_up_check should be\\n+ * set true, and use binary_upgrade_check_logical_slot_pending_wal()\\n+ * instead in the separate query (see slot_caught_up_info_query).\\n\\nShall we tweak it slightly:\\n\\n * Note that binary_upgrade_logical_slot_has_caught_up() is available\\n * only in PG18 and earlier. For PG19 and later, set *use_fast_caught_up_check\\n * to true and use binary_upgrade_check_logical_slot_pending_wal() instead,\\n * in a separate query (see slot_caught_up_info_query in\\nget_db_rel_and_slot_infos()).\\n\\n\\n> >\\n> > > >\\n> > > > 4)\\n> > > > +# Check the file content. While both test_slot1 and test_slot2 should\\n> > > > be reporting\\n> > > > +# that they have unconsumed WAL records, test_slot3 should not be reported as\\n> > > > +# it has caught up.\\n> > > >\\n> > > > Can you please elaborate the reason behind test_slot3 not being\\n> > > > reported? Also mention in the comment if possible.\\n> > >\\n> > > We advance test_slot3 to the current WAL LSN before executing\\n> > > pg_upgrade, so the test_slot3 should have consumed all pending WALs.\\n> > > Please refer to the following changes:\\n> >\\n> > I understand the test, and the comments are clear to me. I also\\n> > understand that only test_slot3 is expected to be in the caught-up\\n> > state. My questions were specifically about the following points:\\n> > 1)  Why do we expect 'slot3 caught-up' not to be mentioned in the LOG?\\n> > Is it simply because there is no corresponding logging in the code, or\\n> > is this behavior related to some aspect of your fix that I may have\\n> > missed?\\n> >\\n> > 2) In general, we do not validate the absence of LOG messages in\\n> > tests. Why is this considered a special case where such a check is\\n> > appropriate?\\n>\\n> What LOG do you refer to? In these tests, we check the\\n> invalid_logical_slots.txt file where pg_upgrade reports only invalid\\n> slots (in terms of pg_upgrade). For test_slot3, it should not be\\n> mentioned in that file as it has caught up. Given that the file has\\n> only invalid slots, checking the absence of test_slot3 in the file\\n> makes sense to me.\\n>\\n\\nOkay, I get the intent now. Thanks!\\n\\nOther than the comment suggestion above, the patch LGTM.\\n\\nthanks\\nShveta\\n\\n\\n","threadId":"19be76a420b81e68","snippet":"On Fri, Jan 23, 2026 at 2:04 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote: > > On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote: > > > > On","historyId":"12873","internalDate":"1769151767000","receivedAtUtc":"2026-01-23T07:02:47.000Z","from":"shveta malik <shveta.malik@gmail.com>"}]	Masahiko Sawada has proposed an optimization for pg_upgrade's replication slot caught-up check. The patch introduces a faster method using binary_upgrade_check_logical_slot_pending_wal() for PostgreSQL 19+ instead of the slower binary_upgrade_logical_slot_has_caught_up() function used in PG18 and earlier. Shveta Malik provided detailed feedback on function naming, predicate ordering, version checks, and test validation. She suggested adding sanity checks and clarifying comments about test behavior. Chao Li reviewed the latest version (v7) and found it mostly good, noting only a minor documentation issue about pointer notation. Shveta confirmed the approach looks good after Sawada's updates, suggesting one small comment improvement. The optimization aims to reduce upgrade time by efficiently checking slot status in bulk rather than individually.\n\nMasahiko Sawada 提出了对 pg_upgrade 复制槽追赶检查的优化方案。该补丁为 PostgreSQL 19+ 版本引入了更快的方法，使用 binary_upgrade_check_logical_slot_pending_wal() 函数替代 PG18 及更早版本中较慢的 binary_upgrade_logical_slot_has_caught_up() 函数。Shveta Malik 对函数命名、谓词排序、版本检查和测试验证提供了详细反馈，建议添加健全性检查并澄清测试行为的注释。Chao Li 审查了最新版本（v7）并认为总体良好，仅指出了关于指针表示法的小文档问题。在 Sawada 更新后，Shveta 确认该方法看起来不错，建议进行一个小的注释改进。该优化旨在通过批量而非逐个检查槽状态来减少升级时间。	2026-01-23 07:02:47+00	\N
12	19be4f0789a66a7c	tablecmds: reject CLUSTER ON for partitioned tables earlier	["li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be80caa92d2341","messageId":"<07773235-2E94-478F-BEF6-38C73B0553B8@gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"\\n\\n> On Jan 22, 2026, at 17:01, Chao Li <li.evan.chao@gmail.com> wrote:\\n> \\n> \\n> \\n>> On Jan 21, 2026, at 11:55, Chao Li <li.evan.chao@gmail.com> wrote:\\n>> \\n>> Hi Hacker,\\n>> \\n>> I noticed this while working other patches related to "ALTER TABLE".\\n>> \\n>> "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for partitioned tables, but currently ATPrepCmd() allows them through and they only fail later at execution time.\\n>> \\n>> This patch rejects these commands earlier by using the existing ATSimplePermissions() infrastructure in ATPrepCmd(), matching the handling of other unsupported ALTER TABLE actions on partitioned tables (such as SET LOGGED / SET UNLOGGED). This makes the behavior more consistent and simplifies the code path.\\n>> \\n>> As a result, the error reported for partitioned tables changes:\\n>> \\n>> Before the patch:\\n>> ```\\n>> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n>> ERROR:  cannot mark index clustered in partitioned table\\n>> ```\\n>> \\n>> With the patch:\\n>> ```\\n>> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n>> ERROR:  ALTER action CLUSTER ON cannot be performed on relation \\"p_test\\"\\n>> DETAIL:  This operation is not supported for partitioned tables.\\n>> ```\\n>> \\n>> Best regards,\\n>> --\\n>> Chao Li (Evan)\\n>> HighGo Software Co., Ltd.\\n>> https://www.highgo.com/\\n>> \\n>> \\n>> \\n>> \\n>> <v1-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch>\\n> \\n> \\n> \\n> Applying the same change to INHERIT/NO INHeRIT in v2-0002. Other than that, fixing 2 more things for INHERIT/NO INHERIT:\\n> \\n> * The header comment of ATPrepAddInherit() was a copy-paste mistake, it described something totally unrelated.\\n> * NO INHERIT didn't call ATPrepAddInherit() to check early, so it had to go deeper and run unnecessary checks.\\n> \\n> Basically, 0001 and 0002 do the same thing on two sub-commands. If accepted, they can be squashed.\\n> \\n> Best regards,\\n> --\\n> Chao Li (Evan)\\n> HighGo Software Co., Ltd.\\n> https://www.highgo.com/\\n> \\n> <v2-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch><v2-0002-tablecmds-reject-INHERIT-NO-INHERIT-for-partition.patch>\\n\\nPFA v3:\\n\\n0001 is the same as v2. In 0002:\\n\\n* Restored the header comment of ATPrepAddInherit, because I realized the should belong to ATExecAddInherit.\\n* Renamed ATPrepAddInherit to ATPrepChangeInherit.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n","threadId":"19be4f0789a66a7c","snippet":"> On Jan 22, 2026, at 17:01, Chao Li <li.evan.chao@gmail.com> wrote: > > > >> On Jan 21, 2026, at 11:55, Chao Li <li.evan.chao@gmail.com> wrote: >> >> Hi","historyId":"8704","internalDate":"1769124655000","receivedAtUtc":"2026-01-22T23:30:55.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be859463d03e42","messageId":"<EA6CB317-60C2-4BA9-8E02-DBCAD384F107@gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"\\n\\n> On Jan 23, 2026, at 07:30, Chao Li <li.evan.chao@gmail.com> wrote:\\n> \\n> \\n> \\n>> On Jan 22, 2026, at 17:01, Chao Li <li.evan.chao@gmail.com> wrote:\\n>> \\n>> \\n>> \\n>>> On Jan 21, 2026, at 11:55, Chao Li <li.evan.chao@gmail.com> wrote:\\n>>> \\n>>> Hi Hacker,\\n>>> \\n>>> I noticed this while working other patches related to "ALTER TABLE".\\n>>> \\n>>> "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for partitioned tables, but currently ATPrepCmd() allows them through and they only fail later at execution time.\\n>>> \\n>>> This patch rejects these commands earlier by using the existing ATSimplePermissions() infrastructure in ATPrepCmd(), matching the handling of other unsupported ALTER TABLE actions on partitioned tables (such as SET LOGGED / SET UNLOGGED). This makes the behavior more consistent and simplifies the code path.\\n>>> \\n>>> As a result, the error reported for partitioned tables changes:\\n>>> \\n>>> Before the patch:\\n>>> ```\\n>>> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n>>> ERROR:  cannot mark index clustered in partitioned table\\n>>> ```\\n>>> \\n>>> With the patch:\\n>>> ```\\n>>> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n>>> ERROR:  ALTER action CLUSTER ON cannot be performed on relation \\"p_test\\"\\n>>> DETAIL:  This operation is not supported for partitioned tables.\\n>>> ```\\n>>> \\n>>> Best regards,\\n>>> --\\n>>> Chao Li (Evan)\\n>>> HighGo Software Co., Ltd.\\n>>> https://www.highgo.com/\\n>>> \\n>>> \\n>>> \\n>>> \\n>>> <v1-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch>\\n>> \\n>> \\n>> \\n>> Applying the same change to INHERIT/NO INHeRIT in v2-0002. Other than that, fixing 2 more things for INHERIT/NO INHERIT:\\n>> \\n>> * The header comment of ATPrepAddInherit() was a copy-paste mistake, it described something totally unrelated.\\n>> * NO INHERIT didn't call ATPrepAddInherit() to check early, so it had to go deeper and run unnecessary checks.\\n>> \\n>> Basically, 0001 and 0002 do the same thing on two sub-commands. If accepted, they can be squashed.\\n>> \\n>> Best regards,\\n>> --\\n>> Chao Li (Evan)\\n>> HighGo Software Co., Ltd.\\n>> https://www.highgo.com/\\n>> \\n>> <v2-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch><v2-0002-tablecmds-reject-INHERIT-NO-INHERIT-for-partition.patch>\\n> \\n> PFA v3:\\n> \\n> 0001 is the same as v2. In 0002:\\n> \\n> * Restored the header comment of ATPrepAddInherit, because I realized the should belong to ATExecAddInherit.\\n> * Renamed ATPrepAddInherit to ATPrepChangeInherit.\\n> \\n> Best regards,\\n> --\\n> Chao Li (Evan)\\n> HighGo Software Co., Ltd.\\n> https://www.highgo.com/\\n> \\n> \\n> \\n> \\n> <v3-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch><v3-0002-tablecmds-reject-INHERIT-NO-INHERIT-for-partition.patch>\\n\\nPlease ignore v3 that was badly generated.\\n\\nPFA v4:\\n\\n> 0001 is the same as v2. In 0002:\\n> \\n> * Restored the header comment of ATPrepAddInherit, because I realized the should belong to ATExecAddInherit.\\n> * Renamed ATPrepAddInherit to ATPrepChangeInherit.\\n\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n","threadId":"19be4f0789a66a7c","snippet":"> On Jan 23, 2026, at 07:30, Chao Li <li.evan.chao@gmail.com> wrote: > > > >> On Jan 22, 2026, at 17:01, Chao Li <li.evan.chao@gmail.com> wrote: >> >> >>","historyId":"8704","internalDate":"1769129673000","receivedAtUtc":"2026-01-23T00:54:33.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be9cedd50133b5","messageId":"<CAN4CZFMUJWM0veLK93Ew8mYaL5pcU6G550STh6AZ-_LWV2zS+w@mail.gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"Hello!\\n\\nA simple patch and generally looks good, I only have a few observations.\\n\\n> "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for\\n> partitioned tables, but currently ATPrepCmd() allows them through and they\\n> only fail later at execution time.\\n\\nLooking at the ALTER TABLE documentation, for other options there is a\\nmention like \\"This form is not currently supported on partitioned\\ntables.\\" / \\"This form is not supported for partitioned tables.\\"\\n\\nI don't see this mentioned for CLUSTER or INHERIT. Maybe it would be\\nbetter to also mention this in the documentation?\\n\\nAlso, there seems to be no test for partitioned NO INHERIT, since the\\npatch changes it, it could also add a test case to verify the\\nbehavior.\\n\\nrg \\"INHERIT\\" | grep \\"cannot be performed\\"\\nsrc/test/regress/expected/alter_table.out:ERROR:  ALTER action INHERIT\\ncannot be performed on relation \\"partitioned\\"\\n\\nrg \\"NO INHERIT\\" | grep \\"cannot be performed\\"\\n# no result\\n\\ntablecmds.c:5202\\n  case AT_DropInherit: /* NO INHERIT */\\n  ATSimplePermissions(cmd->subtype, rel,\\n- ATT_TABLE | ATT_PARTITIONED_TABLE | ATT_FOREIGN_TABLE);\\n+ ATT_TABLE | ATT_FOREIGN_TABLE);\\n  /* This command never recurses */\\n+ ATPrepChangeInherit(rel);\\n  /* No command-specific prep needed */\\n\\nThat last comment seems to be a leftover, it's no longer true with this change.\\n\\ntablecmds.c:17289 trailing whitespace (in the empty line)\\n /*\\n+ * ALTER TABLE INHERIT\\n+ *\\n+ * Add a parent to the child's parents. This verifies that all the columns and\\n+ * check constraints of the parent appear in the child and that they have the\\n+ * same data types and expressions.\\n+ *\\n  * Return the address of the new parent relation.\\n  */\\n\\ntablecmds.c:17860 - this check in ATExecDropInherit is now redundant,\\nsince we already have it in ATPrepChangeInherit\\n\\n> Before the patch:\\n> ```\\n> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n> ERROR: cannot mark index clustered in partitioned table\\n\\nCan we still reach the original error in mark_index_clustered somehow?\\nI don't see any examples in the test suite, or execution paths when I\\nhave looked at the code, and it can be confusing to see a different\\nerror code/message there.\\n\\n\\n","threadId":"19be4f0789a66a7c","snippet":"Hello! A simple patch and generally looks good, I only have a few observations. > "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for > partitioned tables, but","historyId":"12863","internalDate":"1769154187000","receivedAtUtc":"2026-01-23T07:43:07.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"},{"id":"19be9d8794eb777b","messageId":"<B9E960BD-9E45-46E7-951E-D11841D43431@gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"\\n\\n> On Jan 23, 2026, at 15:43, Zsolt Parragi <zsolt.parragi@percona.com> wrote:\\n> \\n> Hello!\\n> \\n> A simple patch and generally looks good, I only have a few observations.\\n> \\n>> "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for\\n>> partitioned tables, but currently ATPrepCmd() allows them through and they\\n>> only fail later at execution time.\\n> \\n> Looking at the ALTER TABLE documentation, for other options there is a\\n> mention like \\"This form is not currently supported on partitioned\\n> tables.\\" / \\"This form is not supported for partitioned tables.\\"\\n> \\n> I don't see this mentioned for CLUSTER or INHERIT. Maybe it would be\\n> better to also mention this in the documentation?\\n> \\n\\nHi Zsolt,\\n\\nThank you very much for your review.\\n\\nI have the other patch for the documentation update, see [1], that is an overall clarification for alter table behaviors against partition tables. Actually, I just found this issue while working on that patch.\\n\\nI will handle rest of your comments soon.\\n\\n[1] https://www.postgresql.org/message-id/CAEoWx2%3DmYhCfsnHaN96Qqwq5b0GVS2YgO3zpVqPPRd_iO52wRw%40mail.gmail.com\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be4f0789a66a7c","snippet":"> On Jan 23, 2026, at 15:43, Zsolt Parragi <zsolt.parragi@percona.com> wrote: > > Hello! > > A simple patch and generally looks good, I only have a few observations. > >>","historyId":"12863","internalDate":"1769154786000","receivedAtUtc":"2026-01-23T07:53:06.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	Chao Li (Evan) proposes a patch to reject ALTER TABLE CLUSTER ON and SET WITHOUT CLUSTER commands for partitioned tables earlier in the command preparation phase rather than at execution time. The patch uses the existing ATSimplePermissions() infrastructure in ATPrepCmd() to make error handling consistent with other unsupported ALTER TABLE actions on partitioned tables. This changes the error message from "cannot mark index clustered in partitioned table" to a more standardized format. The patch evolved through multiple versions, with v2 adding similar treatment for INHERIT/NO INHERIT commands, fixing header comments, and ensuring NO INHERIT calls proper validation. Zsolt Parragi reviews the patch positively but suggests adding documentation mentions for unsupported operations, adding test cases for partitioned NO INHERIT, fixing trailing whitespace, removing redundant checks, and addressing leftover comments. Chao acknowledges the feedback and mentions working on related documentation updates in another patch.\n\n李超（Evan）提出一个补丁，将ALTER TABLE CLUSTER ON和SET WITHOUT CLUSTER命令对分区表的拒绝从执行时提前到命令准备阶段。该补丁使用ATPrepCmd()中现有的ATSimplePermissions()基础设施，使错误处理与分区表上其他不支持的ALTER TABLE操作保持一致。这将错误消息从"cannot mark index clustered in partitioned table"改为更标准化的格式。补丁经历多个版本演进，v2版本添加了对INHERIT/NO INHERIT命令的类似处理，修复了标题注释，并确保NO INHERIT调用适当的验证。Zsolt Parragi积极评价该补丁，但建议为不支持的操作添加文档说明，为分区NO INHERIT添加测试用例，修复尾随空白符，移除冗余检查，并处理遗留注释。李超确认了反馈意见，并提到正在另一个补丁中处理相关文档更新。	2026-01-23 07:53:06+00	\N
12	19be543e22dcee9b	Race conditions in logical decoding	["ah@cybertec.at","alvherre@kurilemu.de","andres@anarazel.de","mihailnikalayeu@gmail.com"]	[{"id":"19be543e22dcee9b","messageId":"<124728.1769077978@localhost>","subject":"Re: Race conditions in logical decoding","body":"Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote:\\n\\n> Hello, Andres.\\n> \\n> On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <andres@anarazel.de> wrote:\\n> > I don't think that's enough - during non-timetravel visibility semantics, you\\n> > can only look at the clog if the transaction isn't marked as in-progress in\\n> > the procarray.  ISTM that we need to do that here too?\\n> \\n> Do you mean replace\\n> > if (unlikely(!TransactionIdDidCommit(builder->committed.xip[i])))\\n> to\\n> > if (unlikely(TransactionIdIsInProgress(builder->committed.xip[i]) || !TransactionIdDidCommit(builder->committed.xip[i])))\\n\\nThis way the synchronous replication gets stuck, as it did when I tried to use\\nXactLockTableWait(): subscriber cannot confirm replication of certain LSN\\nbecause publisher is not able to even finalize the commit (due to the waiting\\nfor the subscriber's confirmation), and therefore publisher it's not able to\\ndecode the data and send it to the subscriber.\\n\\n-- \\nAntonin Houska\\nWeb: https://www.cybertec-postgresql.com\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote: > Hello, Andres. > > On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <andres@anarazel.de> wrote: > > I don't think","historyId":"5948","internalDate":"1769077978000","receivedAtUtc":"2026-01-22T10:32:58.000Z","from":"Antonin Houska <ah@cybertec.at>"},{"id":"19be7126d277a089","messageId":"<202601221804.nbrvjquik7qp@alvherre.pgsql>","subject":"Re: Race conditions in logical decoding","body":"On 2026-Jan-22, Antonin Houska wrote:\\n\\n> Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote:\\n> \\n> > Hello, Andres.\\n> > \\n> > On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <andres@anarazel.de> wrote:\\n> > > I don't think that's enough - during non-timetravel visibility semantics, you\\n> > > can only look at the clog if the transaction isn't marked as in-progress in\\n> > > the procarray.  ISTM that we need to do that here too?\\n> > \\n> > Do you mean replace\\n> > > if (unlikely(!TransactionIdDidCommit(builder->committed.xip[i])))\\n> > to\\n> > > if (unlikely(TransactionIdIsInProgress(builder->committed.xip[i]) || !TransactionIdDidCommit(builder->committed.xip[i])))\\n> \\n> This way the synchronous replication gets stuck, as it did when I tried to use\\n> XactLockTableWait(): subscriber cannot confirm replication of certain LSN\\n> because publisher is not able to even finalize the commit (due to the waiting\\n> for the subscriber's confirmation), and therefore publisher it's not able to\\n> decode the data and send it to the subscriber.\\n\\nThe layering here is wild, but if I understand it correctly, these XIDs\\nare all added to an array by SnapBuildAddCommittedTxn(), which in turn\\nis only called by SnapBuildCommitTxn(), which is only called by\\nDecodeCommit(), which is only called by xact_decode() when it sees a\\nXLOG_XACT_COMMIT or XLOG_XACT_COMMIT_PREPARED record by reading WAL.\\n\\nCrucially, RecordTransactionCommit() writes the WAL first, then marks\\neverything as committed in CLOG, and finally does the waiting for\\nthe synchronous replica to ACK the commit if necessary.  However, the\\ntransaction is only removed from procarray after RecordTransactionCommit\\nhas returned.\\n\\nThis means that DecodeCommit() could add a transaction to the\\nSnapBuilder (that needs to be waited for) while that transaction is\\nstill shown as running in ProcArray.  This sounds problematic in itself,\\nso I'm wondering whether we should do anything (namely, wait) on\\nDecodeCommit() instead of hacking SnapBuildBuildSnapshot() to patch it\\nup by waiting after the fact.\\n\\n-- \\nÁlvaro Herrera         PostgreSQL Developer  —  https://www.EnterpriseDB.com/\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"On 2026-Jan-22, Antonin Houska wrote: > Mihail Nikalayeu <mihailnikalayeu@gmail.com> wrote: > > > Hello, Andres. > > > > On Tue, Jan 20, 2026 at 6:50 PM Andres Freund <","historyId":"5948","internalDate":"1769108285000","receivedAtUtc":"2026-01-22T18:58:05.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"},{"id":"19be7423da693c46","messageId":"<202601221939.rs5bossvsnfb@alvherre.pgsql>","subject":"Re: Race conditions in logical decoding","body":"On 2026-Jan-22, Álvaro Herrera wrote:\\n\\n> On 2026-Jan-22, Antonin Houska wrote:\\n\\n> > > Do you mean replace\\n> > > > if (unlikely(!TransactionIdDidCommit(builder->committed.xip[i])))\\n> > > to\\n> > > > if (unlikely(TransactionIdIsInProgress(builder->committed.xip[i]) || !TransactionIdDidCommit(builder->committed.xip[i])))\\n> > \\n> > This way the synchronous replication gets stuck, as it did when I tried to use\\n> > XactLockTableWait(): subscriber cannot confirm replication of certain LSN\\n> > because publisher is not able to even finalize the commit (due to the waiting\\n> > for the subscriber's confirmation), and therefore publisher it's not able to\\n> > decode the data and send it to the subscriber.\\n\\nBTW, the reason XactLockTableWait and TransactionIdIsInProgress() cause\\na deadlock in the same way, is that they are using essentially the same\\nmechanism.  The former uses the Lock object on the transaction, which is\\nreleased (by the ResourceOwnerRelease(RESOURCE_RELEASE_LOCKS) call in\\nCommitTransaction) after RecordTransactionCommit() has returned -- that\\nis, after the wait on a synchronous replica has happened.\\n\\nXactLockTableWait does an _additional_ test for\\nTransactionIdIsInProgress, but that should be pretty much innocuous at\\nthat point.\\n\\n\\nOne thing that I just realized I don't know, is what exactly are the two\\npieces that are deadlocking.  I mean, one is this side that's decoding\\ncommit.  But how/why is that other side, the one trying to mark the\\ntransaction as committed, waiting on the commit decoding?  Maybe there's\\nsomething that we need to do to _that_ side to prevent the blockage, so\\nthat we can use TransactionIdIsInProgress() here.\\n\\n-- \\nÁlvaro Herrera         PostgreSQL Developer  —  https://www.EnterpriseDB.com/\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"On 2026-Jan-22, Álvaro Herrera wrote: > On 2026-Jan-22, Antonin Houska wrote: > > > Do you mean replace > > > > if (unlikely(!TransactionIdDidCommit(builder->committed.xip[i]","historyId":"8710","internalDate":"1769111422000","receivedAtUtc":"2026-01-22T19:50:22.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"},{"id":"19be74a7e014e5b1","messageId":"<202601221950.c5lwdnye3idv@alvherre.pgsql>","subject":"Re: Race conditions in logical decoding","body":"On 2026-Jan-20, Antonin Houska wrote:\\n\\n> Antonin Houska <ah@cybertec.at> wrote:\\n> \\n> > I'm not sure yet how to fix the problem. I tried to call XactLockTableWait()\\n> > from SnapBuildAddCommittedTxn() (like it happens in SnapBuildWaitSnapshot()),\\n> > but it made at least one regression test (subscription/t/010_truncate.pl)\\n> > stuck - probably a deadlock. I can spend more time on it, but maybe someone\\n> > can come up with a good idea sooner than me.\\n> \\n> Attached here is what I consider a possible fix - simply wait for the CLOG\\n> update before building a new snapshot.\\n> \\n> Unfortunately I have no idea right now how to test it using the isolation\\n> tester. With the fix, the additional waiting makes the current test\\n> block. (And if a step is added that unblock the session, it will not reliably\\n> catch failure to wait.)\\n> \\n> -- \\n> Antonin Houska\\n> Web: https://www.cybertec-postgresql.com\\n> \\n\\n> @@ -400,6 +400,47 @@ SnapBuildBuildSnapshot(SnapBuild *builder)\\n>  \\tsnapshot->xmin = builder->xmin;\\n>  \\tsnapshot->xmax = builder->xmax;\\n>  \\n> +\\t/*\\n> +\\t * Although it's very unlikely, it's possible that a commit WAL record was\\n> +\\t * decoded but CLOG is not aware of the commit yet. Should the CLOG update\\n> +\\t * be delayed even more, visibility checks that use this snapshot could\\n> +\\t * work incorrectly. Therefore we check the CLOG status here.\\n> +\\t */\\n> +\\twhile (true)\\n> +\\t{\\n> +\\t\\tbool\\tfound = false;\\n> +\\n> +\\t\\tfor (int i = 0; i < builder->committed.xcnt; i++)\\n> +\\t\\t{\\n> +\\t\\t\\t/*\\n> +\\t\\t\\t * XXX Is it worth remembering the XIDs that appear to be\\n> +\\t\\t\\t * committed per CLOG and skipping them in the next iteration of\\n> +\\t\\t\\t * the outer loop? Not sure it's worth the effort - a single\\n> +\\t\\t\\t * iteration is enough in most cases.\\n> +\\t\\t\\t */\\n> +\\t\\t\\tif (unlikely(!TransactionIdDidCommit(builder->committed.xip[i])))\\n> +\\t\\t\\t{\\n> +\\t\\t\\t\\tfound = true;\\n> +\\n> +\\t\\t\\t\\t/*\\n> +\\t\\t\\t\\t * Wait a bit before going to the next iteration of the outer\\n> +\\t\\t\\t\\t * loop. The race conditions we address here is pretty rare,\\n> +\\t\\t\\t\\t * so we shouldn't need to wait too long.\\n> +\\t\\t\\t\\t */\\n> +\\t\\t\\t\\t(void) WaitLatch(MyLatch,\\n> +\\t\\t\\t\\t\\t\\t\\t\\t WL_LATCH_SET | WL_TIMEOUT | WL_EXIT_ON_PM_DEATH,\\n> +\\t\\t\\t\\t\\t\\t\\t\\t 10L,\\n> +\\t\\t\\t\\t\\t\\t\\t\\t WAIT_EVENT_SNAPBUILD_CLOG);\\n> +\\t\\t\\t\\tResetLatch(MyLatch);\\n> +\\n> +\\t\\t\\t\\tbreak;\\n> +\\t\\t\\t}\\n> +\\t\\t}\\n> +\\n> +\\t\\tif (!found)\\n> +\\t\\t\\tbreak;\\n> +\\t}\\n\\nI think this algorithm is strange -- if you do have to wait more than\\nonce for one transaction, it would lead to doing the\\nTransactionIdDidCommit again times for _all_ transactions by starting\\nthe inner loop from scratch, which sounds really wasteful.  Why not nest\\nthe for() loops the other way around?  Something like this perhaps,\\n\\n    for (int i = 0; i < builder->committed.xcnt; i++)\\n    {\\n        for (;;)\\n        {\\n            if (TransactionIdDidCommit(builder->committed.xip[i]))\\n                break;\\n            else\\n            {\\n                (void) WaitLatch(MyLatch,\\n                                 WL_LATCH_SET, WL_TIMEOUT, WL_EXIT_ON_PM_DEATH,\\n                                 10L,\\n                                 WAIT_EVENT_SNAPBUILD_CLOG);\\n                ResetLatch(MyLatch);\\n            }\\n            CHECK_FOR_INTERRUPTS();\\n        }\\n    }\\n\\nThis way you wait repeatedly for one transaction until it is marked\\ncommitted; and once it does, you don't test it again.\\n\\nI also wondered if it would make sense to get rid of the memcpy, given\\nthat we're doing so much work per xid anyway it won't make any visible\\ndifference (I believe), and do the copy per XID there, like\\n\\n            if (TransactionIdDidCommit(builder->committed.xip[i]))\\n\\t    {\\n\\t        snapshot->xip[i] = builder->committed.xip[i];\\n                break;\\n\\t    }\\n            else\\n            ...\\n\\n\\n-- \\nÁlvaro Herrera         PostgreSQL Developer  —  https://www.EnterpriseDB.com/\\n\\"Sallah, I said NO camels! That's FIVE camels; can't you count?\\"\\n(Indiana Jones)\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"On 2026-Jan-20, Antonin Houska wrote: > Antonin Houska <ah@cybertec.at> wrote: > > > I'm not sure yet how to fix the problem. I tried to call XactLockTableWait() > > from","historyId":"8710","internalDate":"1769111961000","receivedAtUtc":"2026-01-22T19:59:21.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"},{"id":"19be98f086a58ea0","messageId":"<3805.1769150012@localhost>","subject":"Re: Race conditions in logical decoding","body":"Álvaro Herrera <alvherre@kurilemu.de> wrote:\\n\\n> I think this algorithm is strange -- if you do have to wait more than\\n> once for one transaction, it would lead to doing the\\n> TransactionIdDidCommit again times for _all_ transactions by starting\\n> the inner loop from scratch, which sounds really wasteful.  Why not nest\\n> the for() loops the other way around?\\n\\nI'm quite sure I wanted to iterate through committed.xnt in the outer loop,\\nbut probably got distracted by something else and messed things up.\\n\\n> Something like this perhaps,\\n> \\n>     for (int i = 0; i < builder->committed.xcnt; i++)\\n>     {\\n>         for (;;)\\n>         {\\n>             if (TransactionIdDidCommit(builder->committed.xip[i]))\\n>                 break;\\n>             else\\n>             {\\n>                 (void) WaitLatch(MyLatch,\\n>                                  WL_LATCH_SET, WL_TIMEOUT, WL_EXIT_ON_PM_DEATH,\\n>                                  10L,\\n>                                  WAIT_EVENT_SNAPBUILD_CLOG);\\n>                 ResetLatch(MyLatch);\\n>             }\\n>             CHECK_FOR_INTERRUPTS();\\n>         }\\n>     }\\n> \\n> This way you wait repeatedly for one transaction until it is marked\\n> committed; and once it does, you don't test it again.\\n\\nSure, that's much beter. Thanks.\\n\\n-- \\nAntonin Houska\\nWeb: https://www.cybertec-postgresql.com\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"Álvaro Herrera <alvherre@kurilemu.de> wrote: > I think this algorithm is strange -- if you do have to wait more than > once for one transaction, it would lead to doing the >","historyId":"12866","internalDate":"1769150012000","receivedAtUtc":"2026-01-23T06:33:32.000Z","from":"Antonin Houska <ah@cybertec.at>"},{"id":"19be9e03a86c208a","messageId":"<5698.1769155332@localhost>","subject":"Re: Race conditions in logical decoding","body":"Andres Freund <andres@anarazel.de> wrote:\\n\\n> > Attached here is what I consider a possible fix - simply wait for the CLOG\\n> > update before building a new snapshot.\\n> \\n> I don't think that's enough - during non-timetravel visibility semantics, you\\n> can only look at the clog if the transaction isn't marked as in-progress in\\n> the procarray.  ISTM that we need to do that here too?\\n\\nI understand that CLOG must be up-to-date by the time the snapshot is used for\\nvisibility checks, but I think that - from the snapshot user POV - what\\nmatters is \\"snapshot->xip vs CLOG\\" rather than \\"procarray vs CLOG\\".\\n\\nFor procarray-based snapshots, this consistency is ensured by 1) not removing\\nthe XID from procarray until the status is set in CLOG and 2) getting the list\\nof running transactions from procarray. Thus if an MVCC snapshot does not have\\nparticular XID in its \\"xip\\" array, it implies that it's no longer in procarray\\nand therefore it's been marked in CLOG.\\n\\nAs for logical decoding based snapshots (whether HISTORIC_MVCC or those\\nconverted eventually to regular MVCC), we currently do not check if CLOG is\\nconsistent with the transaction list in snapshot->xip. What I proposed is that\\nwe enforce this consistency by checking CLOG (and possibly waiting) before we\\nfinalize the snapshot. Thus the snapshot user can safely assume that the\\nsnapshot->xip array is consistent with CLOG, as if the snapshot was based on\\nprocarray.\\n\\nOr is there another issue with the CLOG itself? I thought about wraparound\\n(i.e. getting the XID status from a CLOG slot which is still being used by old\\ntransactions) but I wouldn't expect that (AFAICS, CLOG truncation takes place\\nduring XID freezing). Concurrent access to the slot should neither be a\\nproblem since only a single byte (which is atomic) needs to be fetched during\\nthe XID status check.\\n\\nAnother hypothetical problem that occurs to me is memory access ordering,\\ni.e. one backend creates and exports the snapshot and another one imports it\\nbefore it can see the CLOG update. It's hard to imagine though.\\n\\nOr are there other concerns?\\n\\n-- \\nAntonin Houska\\nWeb: https://www.cybertec-postgresql.com\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"Andres Freund <andres@anarazel.de> wrote: > > Attached here is what I consider a possible fix - simply wait for the CLOG > > update before building a new snapshot. > > I don","historyId":"12866","internalDate":"1769155332000","receivedAtUtc":"2026-01-23T08:02:12.000Z","from":"Antonin Houska <ah@cybertec.at>"}]	PostgreSQL developers are discussing race conditions in logical decoding where commit WAL records are decoded before CLOG (commit log) is updated, potentially causing incorrect visibility checks. Antonin Houska proposed a fix that waits for CLOG updates before building snapshots, using a polling mechanism with WaitLatch(). However, this approach causes deadlocks in synchronous replication scenarios where the publisher waits for subscriber confirmation while the subscriber cannot proceed without the commit being finalized. Álvaro Herrera analyzed the transaction commit sequence and suggested the deadlock occurs because transactions remain in procarray during synchronous replica waiting. He recommended algorithm improvements, restructuring nested loops to wait per transaction rather than restarting checks for all transactions. The discussion centers on finding an approach that ensures CLOG consistency without creating circular dependencies in synchronous replication.\n\nPostgreSQL开发者正在讨论逻辑解码中的竞态条件问题，即在CLOG（提交日志）更新之前就解码了提交WAL记录，可能导致错误的可见性检查。Antonin Houska提出了一个修复方案，在构建快照前等待CLOG更新，使用WaitLatch()的轮询机制。然而，这种方法在同步复制场景中会导致死锁，发布者等待订阅者确认而订阅者无法在提交完成前继续处理。Álvaro Herrera分析了事务提交序列，建议死锁发生是因为事务在等待同步副本期间仍保留在procarray中。他建议改进算法，重构嵌套循环以按事务等待而不是重新检查所有事务。讨论的核心是找到既能确保CLOG一致性又不会在同步复制中产生循环依赖的方法。	2026-01-23 08:02:12+00	\N
12	19be9e661ca52f1f	Remove redundant initialization of smgr pointer for relcache	["mrdrivingduck@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be9e661ca52f1f","messageId":"<CAN4CZFP4zaFWXx2cP=X=6+VoDnoJ8Dh9cTpT4SjGdAAp=Ui2AQ@mail.gmail.com>","subject":"Re: Remove redundant initialization of smgr pointer for relcache","body":"Hello!\\n\\nThis is a simple change, and should work correctly.\\n\\nHowever, I think I would do more, as this part of the code is just confusing.\\n\\n* AllocateRelationDesc only has one caller\\n* Its description comment only mentions some things it does, not all\\nof them. The call site explains it differently, but also not\\ncompletely.\\n\\nI would at least also modify the comments so that they are only at one\\nplace and explain the function correctly. But maybe it would be even\\nbetter to remove this function completely or to modify it so it's\\nusable at multiple places?\\n\\n\\n","threadId":"19be9e661ca52f1f","snippet":"Hello! This is a simple change, and should work correctly. However, I think I would do more, as this part of the code is just confusing. * AllocateRelationDesc only has one caller * Its description","historyId":"12882","internalDate":"1769155727000","receivedAtUtc":"2026-01-23T08:08:47.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	The discussion focuses on removing redundant initialization of the smgr pointer in relcache code. While the proposed change is technically sound and should work correctly, concerns are raised about broader code clarity issues. The AllocateRelationDesc function has only one caller, and its documentation is incomplete and inconsistent between the function comment and call site. The reviewer suggests improving comments for better documentation or potentially removing the function entirely to make it more generally usable. The change itself is simple, but the surrounding code structure could benefit from refactoring for better maintainability and clarity.\n\n讨论的重点是移除relcache代码中smgr指针的冗余初始化。虽然提议的更改在技术上是正确的并且应该能正常工作，但提出了关于更广泛代码清晰度问题的担忧。AllocateRelationDesc函数只有一个调用者，其文档不完整且在函数注释和调用点之间不一致。审查者建议改进注释以获得更好的文档，或者可能完全移除该函数以使其更通用。更改本身很简单，但周围的代码结构可以通过重构来提高可维护性和清晰度。	2026-01-23 08:08:47+00	\N
12	19be740d3737841d	warning: dereferencing type-punned pointer	["andres@anarazel.de","ishii@postgresql.org","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19be740d3737841d","messageId":"<ujkndaqmyvahxm6ob3jnljqu5ihtfzm64ndewpra3t3dpgvsoj@e2jrtgjnkn7x>","subject":"Re: warning: dereferencing type-punned pointer","body":"Hi,\\n\\nOn 2025-12-01 17:08:15 +0100, Peter Eisentraut wrote:\\n> My conclusion is that casting Node * to a different pointer-to-struct is\\n> always an aliasing violation.  The reason why the compiler only warns in a\\n> few cases is probably that those are fully within the same translation unit,\\n> while most other ones are across file boundaries that the compiler cannot\\n> analyze reliably.  If you dial up the warning verbosity with\\n> -Wstrict-aliasing=1/2 (lower = more warnings but less reliable), you get\\n> more warnings about this.\\n> \\n> Unlike what PostgreSQL code appears to assume, there is no rule in C (or\\n> C++) that overlaying similar structs is a valid aliasing.  So this was never\\n> correct, but compilers have only gotten more aggressive about this over\\n> time.\\n\\nIt's not clear to me that this is true.\\n\\nC23's §6.7.3.2 contains (and earlier versions have similar language:\\n\\n  A pointer to a structure object, suitably converted, points to its initial\\n  member (or if that member is a bit-field, then to the unit in which it\\n  resides),\\n\\nWhich afaict means that it'd be legal to cast an ErrorSaveContext * to a\\nNodeTag*.  Of course, IsA(), via nodeTag(), doesn't actually cast to NodeTag *,\\nbut to Node *.\\n\\nHowever, you qualified your answer with \\"to a different pointer-to-struct\\",\\nbut afaict the rules would be the same if the \\"initial member\\" of two\\ndifferent structs were a struct.\\n\\n\\nThere's also C23's §6.5 7):\\n  An object shall have its stored value accessed only by an lvalue expression that has one of\\n  the following types:\\n  ...\\n  — an aggregate or union type that includes one of the aforementioned types among its\\n  members (including, recursively, a member of a subaggregate or contained union), or\\n\\nwhich afaict means that if we *can* cast between different equivalent structs,\\nas long as they have the same initial sequence?\\n\\n\\nThe purpose of the aliasing rules is to allow for type based alias analysis,\\nto figure out things like whether two pointers could potentially point to the\\nsame memory.  For that aggregate types don't really matter, it's just scalars\\n(and I guess bitfields, however you classify them) that do. And thus whether\\nyou have overlayed structs with the same types doesn't really matter either [1].\\n\\n\\n\\nThe language around this is near impenetrable though, and hasn't improved\\nmeaningfully since at least C99, so it's really hard to say.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n[1] There are some nasty cases where not being careful could lead to alignment\\n    problems, but I don't think that's typically a problem in postgres.\\n\\n\\n","threadId":"19be740d3737841d","snippet":"Hi, On 2025-12-01 17:08:15 +0100, Peter Eisentraut wrote: > My conclusion is that casting Node * to a different pointer-to-struct is > always an aliasing violation. The reason why the compiler","historyId":"8726","internalDate":"1769111197000","receivedAtUtc":"2026-01-22T19:46:37.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19be9f10d50bf30c","messageId":"<581db49e-2a12-4f89-8c3e-334ba5889ff7@eisentraut.org>","subject":"Re: warning: dereferencing type-punned pointer","body":"On 22.01.26 20:46, Andres Freund wrote:\\n> However, you qualified your answer with \\"to a different pointer-to-struct\\",\\n> but afaict the rules would be the same if the \\"initial member\\" of two\\n> different structs were a struct.\\n> > > There's also C23's §6.5 7):\\n>    An object shall have its stored value accessed only by an lvalue expression that has one of\\n>    the following types:\\n>    ...\\n>    — an aggregate or union type that includes one of the aforementioned types among its\\n>    members (including, recursively, a member of a subaggregate or contained union), or\\n> > which afaict means that if we *can* cast between different equivalent structs,\\n> as long as they have the same initial sequence?\\n\\nI think what this means is that if you have\\n\\ntypedef struct Append\\n{\\n    Plan        plan;\\n    ...\\n}\\n\\nand you have an object of type Plan, then you can access that object via a pointer of type Append.\\n\\nNow that I see this again, this is the opposite the direction of what we would need (have object of type Append, access via pointer to Plan, or pointer to Node).  Also note that it doesn't require that member to be the first member.  So this consideration seems to be unrelated to what we are looking for.\\n\\n\\n\\n","threadId":"19be740d3737841d","snippet":"On 22.01.26 20:46, Andres Freund wrote: > However, you qualified your answer with \\"to a different pointer-to-struct\\", > but afaict the rules would be the same if the \\"initial","historyId":"12872","internalDate":"1769156429000","receivedAtUtc":"2026-01-23T08:20:29.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	Peter Eisentraut initially concluded that casting Node * to different pointer-to-struct types in PostgreSQL always violates C aliasing rules, explaining that compiler warnings appear mainly within translation units rather than across file boundaries. Andres Freund challenges this interpretation, citing C23 specifications about structure pointer conversions and initial member access rules. He argues that casting between structs with equivalent initial sequences may be legal under certain conditions, referencing aggregate type aliasing rules. Peter responds by clarifying that the cited C23 rule about aggregate types works in the opposite direction from what PostgreSQL needs - allowing access to Plan objects via Append pointers, not Append objects via Plan pointers. The discussion reveals uncertainty about C standard interpretations regarding struct casting and aliasing violations in PostgreSQL's Node system.\nPeter Eisentraut最初认为在PostgreSQL中将Node *转换为不同的结构体指针类型总是违反C别名规则，解释编译器警告主要出现在翻译单元内而非跨文件边界。Andres Freund质疑这一解释，引用C23规范中关于结构体指针转换和初始成员访问规则的条款。他认为在某些条件下，具有等价初始序列的结构体之间的转换可能是合法的，并引用聚合类型别名规则。Peter回应澄清，所引用的C23规则关于聚合类型的工作方向与PostgreSQL需要的相反——允许通过Append指针访问Plan对象，而不是通过Plan指针访问Append对象。讨论揭示了对PostgreSQL节点系统中结构体转换和别名违规的C标准解释存在不确定性。	2026-01-23 08:20:29+00	\N
12	19be9fc3e3e03f83	Hackorum - a new mailing list frontend	["kai.wagner@percona.com","zsolt.parragi@percona.com"]	[{"id":"19be9fc3e3e03f83","messageId":"<CAG0qCNhxpzE4hHozO2fgQ13oeqkWgkAGv4kUfnqxbPRxke-1PA@mail.gmail.com>","subject":"Re: Hackorum - a new mailing list frontend","body":"I've reworked the mobile view, so it should now be way easier to use\\non smaller screens.\\n\\nPlease let me know how it looks and behaves, and if anyone is missing\\nanything, I'd be happy to help.\\n\\nKai\\n\\nOn Sat, Jan 17, 2026 at 10:28 PM Zsolt Parragi\\n<zsolt.parragi@percona.com> wrote:\\n>\\n> Hello!\\n>\\n> Thank you for all the feedback so far!\\n>\\n>\\n>\\n> David Geier <geidav.pg@gmail.com> wrote:\\n>\\n> > - Threads with more than a couple of messages take a very long time to load\\n>\\n> While the performance stabilized after the initial issues, generally\\n> the speed of hackorum should be a lot faster now after a few\\n> performance fixes, both for the index and the topic views.\\n>\\n> > - I find it difficult to match the thread outline to the actual message. Making a visual connection between the thread outline and the currently viewed message would be helpful.\\n>\\n> Done! To be honest, I'm not entirely happy with the topic\\n> view/outline, but I also don't know how to make it significantly\\n> better.\\n>\\n> For now:\\n>\\n> * message headers include the same colors as the outline view\\n> * the currently visible message is highlighted in the outline\\n>\\n> I hope this helps match the two together.\\n>\\n> If you have any other ideas, please share, maybe we can make it even better.\\n>\\n>\\n>\\n> Marcos Pegoraro <marcos@f10.com.br> wrote:\\n>\\n> > Maybe an option to show in descending order and show only the first 10 or 20 messages\\n> > Sometimes there are hundreds of messages on that thread, so this way would be faster and would show the current status of it and not how it started.\\n>\\n> We had multiple listing options in an earlier version, but it can be\\n> confusing - the outline and the actual messages would go in a\\n> different order.\\n>\\n> But the idea about \\"showing the current status\\" sounds interesting,\\n> I'm playing with the idea of some automatic grouping based on date\\n> period (months/years) and automatically collapsing older entries\\n> (especially if all read already) could work.\\n>\\n>\\n>\\n> Nico Williams <nico@cryptonector.com> wrote:\\n>\\n> > This one feature in particular is very nice.  I wonder if you can make it so you can subscribe in the sense of being an approved sender but not in the sense of getting copies sent.\\n>\\n> I don't understand this question, subscribe where? If you mean to the\\n> mailing list, you can turn off receiving messages in the settings, and\\n> you can still continue sending emails. That's how I've been using the\\n> list since I started using hackorum. If I want to reply to a new\\n> thread where I don't have a local email yet, I'm using the \\"resend\\n> email\\" (paper plane icon) in hackorum to get an email, and then I can\\n> reply as normally from my email client.\\n>\\n> > A read-only IMAP/JMAP server might also be nice, especially if it could mark messages as read/replied-to/marked like this.  But yeah, the web interface is not limited by IMAP/JMAP and can do so much more.\\n>\\n> IMAP/JMAP are also much more complex than just marking messages read,\\n> I'm not sure how well that would work out. For now, we have the CSV\\n> import option, and I plan to release a downloadable script in the near\\n> future that generates CSVs using IMAP for initial status import.\\n>\\n>\\n>\\n> Other than the performance fix and outline change I mentioned above,\\n> hackorum now also has a button to download the latest patchset as a\\n> single tar.gz file for every topic.\\n>\\n> There is also a downloadable script that helps with adding it to a\\n> local git checkout automatically, works with all attachments, doesn't\\n> require a commitfest entry. It's available and documented at:\\n> https://hackorum.dev/help/hackorum-patch\\n>\\n>\\n\\n\\n","threadId":"19be9fc3e3e03f83","snippet":"I've reworked the mobile view, so it should now be way easier to use on smaller screens. Please let me know how it looks and behaves, and if anyone is missing anything, I'd be happy to help.","historyId":"12883","internalDate":"1769157158000","receivedAtUtc":"2026-01-23T08:32:38.000Z","from":"Kai Wagner <kai.wagner@percona.com>"}]	Kai Wagner announced improvements to Hackorum, a PostgreSQL mailing list frontend, focusing on mobile view enhancements for better usability on smaller screens. The discussion addresses previous feedback including performance issues with thread loading, which have been resolved through optimization fixes. Visual improvements were made to connect thread outlines with messages using color coding and highlighting of currently visible messages. The team considered but decided against multiple listing options due to potential confusion between outline and message ordering. New features include automatic patchset download as tar.gz files and a downloadable script for local git integration. Questions remain about subscription options for approved senders and potential IMAP/JMAP server implementation, though the latter is considered complex for current implementation.\n\nKai Wagner宣布了对PostgreSQL邮件列表前端Hackorum的改进，重点是移动端视图优化以提升小屏幕设备的可用性。讨论回应了之前的反馈，包括线程加载性能问题，这些问题已通过优化修复得到解决。通过颜色编码和高亮显示当前可见消息，改善了线程大纲与消息之间的视觉连接。团队考虑但决定不采用多种列表选项，因为可能导致大纲和消息排序之间的混乱。新功能包括自动下载补丁集为tar.gz文件，以及用于本地git集成的可下载脚本。关于已批准发送者的订阅选项和潜在的IMAP/JMAP服务器实现仍存在疑问，但后者被认为对当前实现过于复杂。	2026-01-23 08:32:38+00	\N
12	19be4bfe79e845a8	Add WALRCV_CONNECTING state to walreceiver	["li.evan.chao@gmail.com","michael@paquier.xyz","noah@leadboat.com","rahilasyed90@gmail.com","xunengzhou@gmail.com"]	[{"id":"19be7eab871adb80","messageId":"<aXKqm-mDNlAD_DT0@paquier.xyz>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote:\\n>> Before this patch, this is no state change here, thus rest logic\\n>> can handle STOPPING. After this patch, if the race occurs, in dev\\n>> mode, the Assert is fired; in production mode, STOPPING is overwritten\\n>> by STREAMING, which is wrong.\\n>>\\n>> So, instead of Assert(), I think we should check if current state\\n>> is CONNECTING, if not, it should not proceed.\\n> \\n> It makes sense to me. Please check the updated patch.\\n\\n+            if (state != WALRCV_CONNECTING)\\n+            {\\n+                if (state == WALRCV_STOPPING)\\n+                    proc_exit(0);\\n+                elog(FATAL, \\"unexpected walreceiver state\\");\\n+            }\\n\\nSorry, but this addition does not make sense to me.  Before this\\npatch, if the startup process decides to mark a WAL receiver as\\nstopping after it has been started in WalReceiverMain(), then we would\\nrun at least one loop until we reach WalRcvWaitForStartPosition(),\\nwhich is the path where the WAL receiver exits.  Aka, I don't think we\\nshould increase the number of paths where we decide if a WAL receiver\\nshould fast-exit or not (I'd rather try to reduce them, but I don't\\nthink we can do that currently based on the ping-pong game between the\\nstartup process and WAL receiver process).  Saying that, you are right\\nabout the fact that the assertion is wrong, and that we should not\\nupgrade the status to STREAMING if the WAL receiver is not CONNECTING.\\n\\nSo it seems to me that this code should remain as simple as followed,\\ndocumenting that we switch to STREAMING when the first connection has\\nbeen established after the WAL receiver has started, or when the WAL\\nreceiver is switched after WalRcvWaitForStartPosition() once\\nstartstreaming() has acknowledged that streaming is happening (I would\\nadd a comment saying that):\\nif (state == WALRCV_CONNECTING)\\n   walrcv->walRcvState = WALRCV_STREAMING;\\n--\\nMichael\\n","threadId":"19be4bfe79e845a8","snippet":"On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote: >> Before this patch, this is no state change here, thus rest logic >> can handle STOPPING. After this patch, if the race occurs","historyId":"8702","internalDate":"1769122459000","receivedAtUtc":"2026-01-22T22:54:19.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be7f7b52ed8fc6","messageId":"<CA52AB8E-2985-4003-8BAC-56C9EE2B52E4@gmail.com>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"\\n\\n> On Jan 23, 2026, at 06:54, Michael Paquier <michael@paquier.xyz> wrote:\\n> \\n> On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote:\\n>>> Before this patch, this is no state change here, thus rest logic\\n>>> can handle STOPPING. After this patch, if the race occurs, in dev\\n>>> mode, the Assert is fired; in production mode, STOPPING is overwritten\\n>>> by STREAMING, which is wrong.\\n>>> \\n>>> So, instead of Assert(), I think we should check if current state\\n>>> is CONNECTING, if not, it should not proceed.\\n>> \\n>> It makes sense to me. Please check the updated patch.\\n> \\n> +            if (state != WALRCV_CONNECTING)\\n> +            {\\n> +                if (state == WALRCV_STOPPING)\\n> +                    proc_exit(0);\\n> +                elog(FATAL, \\"unexpected walreceiver state\\");\\n> +            }\\n> \\n> Sorry, but this addition does not make sense to me.  Before this\\n> patch, if the startup process decides to mark a WAL receiver as\\n> stopping after it has been started in WalReceiverMain(), then we would\\n> run at least one loop until we reach WalRcvWaitForStartPosition(),\\n> which is the path where the WAL receiver exits.  Aka, I don't think we\\n> should increase the number of paths where we decide if a WAL receiver\\n> should fast-exit or not (I'd rather try to reduce them, but I don't\\n> think we can do that currently based on the ping-pong game between the\\n> startup process and WAL receiver process).  Saying that, you are right\\n> about the fact that the assertion is wrong, and that we should not\\n> upgrade the status to STREAMING if the WAL receiver is not CONNECTING.\\n> \\n> So it seems to me that this code should remain as simple as followed,\\n> documenting that we switch to STREAMING when the first connection has\\n> been established after the WAL receiver has started, or when the WAL\\n> receiver is switched after WalRcvWaitForStartPosition() once\\n> startstreaming() has acknowledged that streaming is happening (I would\\n> add a comment saying that):\\n> if (state == WALRCV_CONNECTING)\\n>   walrcv->walRcvState = WALRCV_STREAMING;\\n> --\\n> Michael\\n\\n+1. \\n\\nIf current state is not CONNECTING, then leave it as is, which will then follow the original logic. Unless we find some issue in future, I think we can take this approach for now.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be4bfe79e845a8","snippet":"> On Jan 23, 2026, at 06:54, Michael Paquier <michael@paquier.xyz> wrote: > > On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote: >>> Before this patch, this is no","historyId":"8702","internalDate":"1769123282000","receivedAtUtc":"2026-01-22T23:08:02.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be909b2bf50fd5","messageId":"<CABPTF7VQ5tGOSG5TS-Cg+Fb8gLCGFzxJ_eX4qg+WZ3ZPt=FtwQ@mail.gmail.com>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"Hi,\\n\\nOn Fri, Jan 23, 2026 at 6:54 AM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote:\\n> >> Before this patch, this is no state change here, thus rest logic\\n> >> can handle STOPPING. After this patch, if the race occurs, in dev\\n> >> mode, the Assert is fired; in production mode, STOPPING is overwritten\\n> >> by STREAMING, which is wrong.\\n> >>\\n> >> So, instead of Assert(), I think we should check if current state\\n> >> is CONNECTING, if not, it should not proceed.\\n> >\\n> > It makes sense to me. Please check the updated patch.\\n>\\n> +            if (state != WALRCV_CONNECTING)\\n> +            {\\n> +                if (state == WALRCV_STOPPING)\\n> +                    proc_exit(0);\\n> +                elog(FATAL, \\"unexpected walreceiver state\\");\\n> +            }\\n>\\n> Sorry, but this addition does not make sense to me.  Before this\\n> patch, if the startup process decides to mark a WAL receiver as\\n> stopping after it has been started in WalReceiverMain(), then we would\\n> run at least one loop until we reach WalRcvWaitForStartPosition(),\\n> which is the path where the WAL receiver exits.  Aka, I don't think we\\n> should increase the number of paths where we decide if a WAL receiver\\n> should fast-exit or not (I'd rather try to reduce them, but I don't\\n> think we can do that currently based on the ping-pong game between the\\n> startup process and WAL receiver process).  Saying that, you are right\\n> about the fact that the assertion is wrong, and that we should not\\n> upgrade the status to STREAMING if the WAL receiver is not CONNECTING.\\n>\\n> So it seems to me that this code should remain as simple as followed,\\n> documenting that we switch to STREAMING when the first connection has\\n> been established after the WAL receiver has started, or when the WAL\\n> receiver is switched after WalRcvWaitForStartPosition() once\\n> startstreaming() has acknowledged that streaming is happening (I would\\n> add a comment saying that):\\n> if (state == WALRCV_CONNECTING)\\n>    walrcv->walRcvState = WALRCV_STREAMING;\\n> --\\n> Michael\\n\\nThanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and\\nkept the change minimal: only switch to STREAMING if the state is\\nstill CONNECTING, otherwise leave it unchanged.\\n\\n-- \\nBest,\\nXuneng\\n","threadId":"19be4bfe79e845a8","snippet":"Hi, On Fri, Jan 23, 2026 at 6:54 AM Michael Paquier <michael@paquier.xyz> wrote: > > On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote: > >> Before this patch, this is no","historyId":"8702","internalDate":"1769141256000","receivedAtUtc":"2026-01-23T04:07:36.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>"},{"id":"19be955eb092dc5d","messageId":"<aXMHlwhEURdLB9-d@paquier.xyz>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote:\\n> Thanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and\\n> kept the change minimal: only switch to STREAMING if the state is\\n> still CONNECTING, otherwise leave it unchanged.\\n\\nThanks for the newer version of the patch.  I have been playing with\\nit today, even before you have sent this v7, with a set of injection\\npoints to make the WAL receiver wait at some of its steps, then\\ndouble-checked that the startup process was able to control the WAL\\nreceiver as it should, flipping primary_conninfo with reloads.  AFAIK\\nas I can see, that felt OK, so applied as a36164e7465f.\\n--\\nMichael\\n","threadId":"19be4bfe79e845a8","snippet":"On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote: > Thanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and > kept the change minimal: only switch to STREAMING if the","historyId":"12861","internalDate":"1769146263000","receivedAtUtc":"2026-01-23T05:31:03.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19bea0a13c3de89e","messageId":"<CABPTF7WQbywas2Fog8NP79xzLKSc8dvgVjSJfe_iPdmFRMy6pA@mail.gmail.com>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"Hi,\\n\\nOn Fri, Jan 23, 2026 at 1:31 PM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote:\\n> > Thanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and\\n> > kept the change minimal: only switch to STREAMING if the state is\\n> > still CONNECTING, otherwise leave it unchanged.\\n>\\n> Thanks for the newer version of the patch.  I have been playing with\\n> it today, even before you have sent this v7, with a set of injection\\n> points to make the WAL receiver wait at some of its steps, then\\n> double-checked that the startup process was able to control the WAL\\n> receiver as it should, flipping primary_conninfo with reloads.  AFAIK\\n> as I can see, that felt OK, so applied as a36164e7465f.\\n> --\\n> Michael\\n\\nThanks for checking and applying it. I'm playing with exposing\\nXLogRecoveryCtlData metrics at the SQL level, following your input.\\nI'll post the patches and possibly start a new thread for discussion.\\n\\n-- \\nBest,\\nXuneng\\n\\n\\n","threadId":"19be4bfe79e845a8","snippet":"Hi, On Fri, Jan 23, 2026 at 1:31 PM Michael Paquier <michael@paquier.xyz> wrote: > > On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote: > > Thanks Michael — agreed. Patch v7","historyId":"12861","internalDate":"1769158063000","receivedAtUtc":"2026-01-23T08:47:43.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>"}]	The discussion centers on a patch adding a WALRCV_CONNECTING state to PostgreSQL's WAL receiver. Michael Paquier reviews Xuneng Zhou's implementation, pointing out that the proposed assertion and fast-exit logic for handling race conditions is problematic. He argues against increasing exit paths between the startup process and WAL receiver process, suggesting instead a simpler approach: only transition to STREAMING state when the current state is CONNECTING, otherwise leave it unchanged. Both Chao Li and Xuneng Zhou agree with this feedback. Xuneng provides patch v7 implementing the minimal change as suggested. Michael tests the patch with injection points to verify WAL receiver control behavior and applies it as commit a36164e7465f. Xuneng concludes by mentioning plans to work on exposing XLogRecoveryCtlData metrics at SQL level.\n\n讨论围绕为PostgreSQL的WAL接收器添加WALRCV_CONNECTING状态的补丁展开。Michael Paquier审查了Xuneng Zhou的实现，指出提议的断言和快速退出逻辑处理竞态条件是有问题的。他反对增加启动进程和WAL接收器进程之间的退出路径，建议采用更简单的方法：仅在当前状态为CONNECTING时才转换到STREAMING状态，否则保持不变。Chao Li和Xuneng Zhou都同意这一反馈。Xuneng提供了按建议实现最小更改的补丁v7。Michael使用注入点测试补丁以验证WAL接收器控制行为，并将其应用为提交a36164e7465f。Xuneng最后提到计划在SQL级别公开XLogRecoveryCtlData指标。	2026-01-23 08:47:43+00	\N
12	19be897af3bbca01	Newly created replication slot may be invalidated by checkpoint	["aekorotkov@gmail.com","amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","houzj.fnst@fujitsu.com","kuroda.hayato@fujitsu.com","mengjuan.cmj@alibaba-inc.com","michael@paquier.xyz","sawada.mshk@gmail.com","tomas@vondra.me","v.davydov@postgrespro.ru","vignesh21@gmail.com"]	[{"id":"19be897af3bbca01","messageId":"<TY4PR01MB169074400DA851B425BA5D4219494A@TY4PR01MB16907.jpnprd01.prod.outlook.com>","subject":"RE: Newly created replication slot may be invalidated by checkpoint","body":"On Thursday, January 22, 2026 2:54 PM Kuroda, Hayato/黒田 隼人 <kuroda.hayato@fujitsu.com> wrote:\\n> \\n> Thanks for updating the patch. Further comments.\\n\\nThanks for the comments.\\n\\n> \\n> 01.\\n> ```\\n> +#include \\"access/xlog.h\\"\\n> ```\\n> \\n> I could build without the inclusion because \\"replication/logical.h\\" already\\n> includes it. Can we remove or we should retain?\\n\\nRemoved.\\n\\n> \\n> 02.\\n> Should we increase checkpoint_timeout for stabilizing tests?\\n\\nI think we don't need this as concurrent checkpoint won't\\ncause the slot to be invalidated.\\n\\n> \\n> 03.\\n> To confirm, you've removed the logic that checks the oldest segment and try\\n> reserving, but it can be removed same as ReplicationSlotReserveWal(), right?\\n\\nIf you meant we can remove the retry logic similar to what 3510ebe did, the\\nunderstanding is correct.\\n\\n> XLogGetOldestSegno() is also not needed anymore because race can't happen\\n> if standby have never discarded.\\n\\nYes\\n\\n> \\n> 04.\\n> ```\\n> $primary->psql('postgres',\\n> \\tq{SELECT pg_create_logical_replication_slot('failover_slot',\\n> 'test_decoding', false, false, true);\\n> \\t SELECT pg_create_physical_replication_slot('phys_slot');}\\n> );\\n> ...\\n> $primary->psql('postgres', \\"CHECKPOINT\\"); ```\\n> \\n> I found two lines use `psql()`, but should be `safe_psql()`.\\n\\nChanged.\\n\\n> \\n> 05.\\n> Per my tests, the issue exists till PG17 and your patch can be backpatched till\\n> it, right?\\n\\nThis patch cannot be applied cleanly on backbranches, I can prepare patches for\\nthose once the main patch is stable.\\n\\nBest Regards,\\nHou zj\\n","threadId":"19be897af3bbca01","snippet":"On Thursday, January 22, 2026 2:54 PM Kuroda, Hayato/黒田 隼人 <kuroda.hayato@fujitsu.com> wrote: > > Thanks for updating the patch. Further comments. Thanks for the comments. > > 01.","historyId":"8742","internalDate":"1769133796000","receivedAtUtc":"2026-01-23T02:03:16.000Z","from":"\\"Zhijie Hou (Fujitsu)\\" <houzj.fnst@fujitsu.com>"},{"id":"19bea1b30f5e683b","messageId":"<CAA4eK1+T8a7JysOcM6PL1ycfQ6yXvJdDkzrkGOBZGj=fo7S7Lw@mail.gmail.com>","subject":"Re: Newly created replication slot may be invalidated by checkpoint","body":"On Fri, Jan 23, 2026 at 7:33 AM Zhijie Hou (Fujitsu)\\n<houzj.fnst@fujitsu.com> wrote:\\n>\\n> This patch cannot be applied cleanly on backbranches, I can prepare patches for\\n> those once the main patch is stable.\\n>\\n\\nSome comments:\\n1.\\n+ /*\\n+ * Determine the minimum non-removable LSN by comparing the redo pointer\\n+ * with the minimum slot LSN.\\n+ */\\n+ min_safe_lsn = GetRedoRecPtr();\\n+ slot_min_lsn = XLogGetReplicationSlotMinimumLSN();\\n\\nCan we expand these comments a bit to state why we need both\\nRedoRecPtr and slot's minimum LSN?\\n\\n2.\\n+# Verify that while syncing a slot to the standby server, if the WAL before the\\n+# remote restart_lsn is at risk of being removed by a checkpoint, the slot\\n+# cannot be synced. Otherwise, even if the slot syncing succeeds, it may be\\n+# immediately invalidated by the checkpoint.\\n+my $primary = $node;\\n\\nThis comment atop the testcase is not very clear. Because, it is\\ntesting that the slot is synced and is not invalidated. How about:\\n\\"Verify that the synchronized slots won't be invalidated immediately\\nafter synchronization in the presence of a concurrent checkpoint.\\"?\\n\\n3.\\n+# Increase the log_min_messages setting to DEBUG2 on both the standby and\\n+# primary to debug test failures, if any.\\n+my $connstr_1 = $primary->connstr;\\n\\nDo we need this DEBUG2? I don't think we should add too many DEBUG2\\ntests as it increases Log volume.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n","threadId":"19be897af3bbca01","snippet":"On Fri, Jan 23, 2026 at 7:33 AM Zhijie Hou (Fujitsu) <houzj.fnst@fujitsu.com> wrote: > > This patch cannot be applied cleanly on backbranches, I can prepare patches for > those once the","historyId":"12875","internalDate":"1769159185000","receivedAtUtc":"2026-01-23T09:06:25.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>"}]	The discussion focuses on a patch addressing replication slot invalidation during checkpoint operations. Hou Zhijie responds to code review comments from Kuroda Hayato, making several adjustments: removing unnecessary header inclusion, confirming that checkpoint_timeout changes aren't needed since concurrent checkpoints won't invalidate slots, and switching from psql() to safe_psql() in tests. The patch removes retry logic similar to commit 3510ebe and eliminates XLogGetOldestSegno() calls since race conditions are prevented. Amit Kapila provides additional feedback requesting expanded comments explaining why both RedoRecPtr and slot minimum LSN are needed, clearer test case documentation, and questioning the necessity of DEBUG2 logging. The issue affects PostgreSQL versions back to PG17, with backpatches planned once the main patch stabilizes.\n\n该讨论专注于解决检查点操作期间复制槽失效问题的补丁。侯志杰回应了黑田隼人的代码审查意见，进行了几项调整：删除不必要的头文件包含，确认不需要更改checkpoint_timeout因为并发检查点不会使槽失效，并在测试中将psql()改为safe_psql()。该补丁删除了类似于提交3510ebe的重试逻辑，并消除了XLogGetOldestSegno()调用，因为可以防止竞态条件。Amit Kapila提供了额外反馈，要求扩展注释说明为什么需要RedoRecPtr和槽最小LSN，澄清测试用例文档，并质疑DEBUG2日志的必要性。该问题影响PostgreSQL版本直至PG17，一旦主补丁稳定将计划向后移植。	2026-01-23 09:06:25+00	\N
12	19bea3ae7835bc64	[PATCH] Avoid potential NULL dereference in LIKE/ILIKE with C locale	["gorcom2012@gmail.com"]	[{"id":"19bea3ae7835bc64","messageId":"<CABg3sZo30PKF-AYZ_eih=5snxqp73bVOGX7O_hBMqoFhcOWbjQ@mail.gmail.com>","subject":"[PATCH] Avoid potential NULL dereference in LIKE/ILIKE with C locale","body":"Hi hackers,\\n\\nWhile reviewing the MatchText function in backend/utils/adt/like_match.c, I\\nnoticed a potential NULL pointer dereference when using LIKE or ILIKE with\\nthe C locale.\\n\\nThe issue arises because the locale argument (of type pg_locale_t, which is\\na pointer) can be NULL when the C collation is in use. However, the GETCHAR\\nmacro unconditionally passes this locale to MATCH_LOWER, which - depending\\non its definition - may attempt to dereference it (e.g., to access\\nlocale->provider or other fields).\\n\\nThis can lead to a crash in builds or configurations where MATCH_LOWER is\\nnot safe to call with a NULL locale.\\n\\nThe proposed patch adds an explicit check for locale == NULL in the GETCHAR\\nmacro and falls back to pg_ascii_tolower() in that case, which is both safe\\nand correct for the C locale (since no locale-specific case folding is\\nneeded).\\n\\nThe change aligns with existing patterns in the codebase (e.g., in text_cmp\\nand other collation-aware functions) where NULL locale is treated as\\nequivalent to C/POSIX behavior.\\n\\nBest regards, Eugeny Goryachev.\\n\\nPatch:\\nSubject: [PATCH] Avoid potential NULL dereference in LIKE/ILIKE with C\\nlocale\\n\\n---\\n src/backend/utils/adt/like_match.c | 3 ++-\\n 1 file changed, 2 insertions(+), 1 deletion(-)\\n\\ndiff --git a/src/backend/utils/adt/like_match.c\\nb/src/backend/utils/adt/like_match.c\\nindex 892f8a745ea..884edc7ff42 100644\\n--- a/src/backend/utils/adt/like_match.c\\n+++ b/src/backend/utils/adt/like_match.c\\n@@ -71,7 +71,8 @@\\n  */\\n\\n #ifdef MATCH_LOWER\\n-#define GETCHAR(t, locale) MATCH_LOWER(t, locale)\\n+#define GETCHAR(t, locale) \\\\\\n+ ((locale) == 0 ? pg_ascii_tolower((unsigned char)(t)) : MATCH_LOWER(t,\\nlocale))\\n #else\\n #define GETCHAR(t, locale) (t)\\n #endif\\n--\\n2.42.4\\n","threadId":"19bea3ae7835bc64","snippet":"Hi hackers, While reviewing the MatchText function in backend/utils/adt/like_match.c , I noticed a potential NULL pointer dereference when using LIKE or ILIKE with the C locale. The issue arises","historyId":"12884","internalDate":"1769161263000","receivedAtUtc":"2026-01-23T09:41:03.000Z","from":"Eugeny Goryachev <gorcom2012@gmail.com>"}]	Eugeny Goryachev identified a potential NULL pointer dereference in PostgreSQL's LIKE/ILIKE operations when using the C locale. The issue occurs in the MatchText function in like_match.c, where the GETCHAR macro unconditionally passes a locale pointer to MATCH_LOWER, but this pointer can be NULL for C collation. This could cause crashes in configurations where MATCH_LOWER attempts to dereference the NULL locale pointer. The proposed patch adds an explicit NULL check in the GETCHAR macro, falling back to pg_ascii_tolower() for NULL locales, which is safe and appropriate for C locale behavior. This approach aligns with existing patterns in other PostgreSQL collation-aware functions that treat NULL locale as equivalent to C/POSIX behavior.\nEugeny Goryachev发现了PostgreSQL在使用C语言环境时LIKE/ILIKE操作中潜在的NULL指针解引用问题。该问题出现在like_match.c文件的MatchText函数中，GETCHAR宏无条件地将语言环境指针传递给MATCH_LOWER，但对于C排序规则，该指针可能为NULL。这可能在MATCH_LOWER尝试解引用NULL语言环境指针的配置中导致崩溃。提议的补丁在GETCHAR宏中添加了显式的NULL检查，对于NULL语言环境回退到pg_ascii_tolower()函数，这对于C语言环境行为是安全且合适的。这种方法与PostgreSQL中其他排序规则感知函数的现有模式一致，将NULL语言环境视为等同于C/POSIX行为。	2026-01-23 09:41:03+00	\N
12	19be72cf98864068	ALTER TABLE: warn when actions do not recurse to partitions	["david.g.johnston@gmail.com","htamfids@gmail.com","jim.jones@uni-muenster.de","li.evan.chao@gmail.com"]	[{"id":"19be72cf98864068","messageId":"<fb70022a-5403-4e16-9efc-28b041f35d9a@uni-muenster.de>","subject":"Re: ALTER TABLE: warn when actions do not recurse to partitions","body":"Hi Chao\\n\\nOn 22/01/2026 06:45, Chao Li wrote:\\n> evantest=# alter table p_test replica identity full, alter column\\n> username set (n_distinct = 0.1);\\n> NOTICE:  ALTER action REPLICA IDENTITY on relation \\"p_test\\" does not\\n> affect present partitions\\n> HINT:  partitions may be modified individually, or specify ONLY to\\n> suppress this message\\n> NOTICE:  ALTER action ALTER COLUMN ... SET on relation \\"p_test\\" does not\\n> affect present partitions\\n> HINT:  partitions may be modified individually, or specify ONLY to\\n> suppress this message\\n> ALTER TABLE\\n\\n\\nOne could argue that encapsulating all conditions in\\nEmitPartitionNoRecurseNotice(), meaning it is called all the time, is\\nslightly inefficient, but the impact is really negligible in this case -\\nand it is how it is done in similar functions in tablecmds.c :) The code\\nLGTM.\\n\\nOne small thing:\\n\\nerrhint is supposed to be capitalised - see Error Message Style Guide[1]\\n\\n\\"Detail and hint messages: Use complete sentences, and end each with a\\nperiod. Capitalize the first word of sentences. Put two spaces after the\\nperiod if another sentence follows (for English text; might be\\ninappropriate in other languages).\\"\\n\\nereport(NOTICE,\\n\\terrmsg(\\"ALTER action %s on relation \\\\\\"%s\\\\\\" does not affect present\\npartitions\\",\\n\\t\\t   action_str,\\n\\t\\t   RelationGetRelationName(rel)),\\n\\terrhint(\\"partitions may be modified individually, or specify ONLY to\\nsuppress this message\\"));\\n\\nWhat about this?\\n\\nHINT: To update partitions, apply the command to each one individually,\\nor specify ONLY to suppress this message.\\n\\nI'll test the newly covered subcomands tomorrow.\\n\\nBest, Jim\\n\\n1 - https://www.postgresql.org/docs/current/error-style-guide.html\\n\\n\\n","threadId":"19be72cf98864068","snippet":"Hi Chao On 22/01/2026 06:45, Chao Li wrote: > evantest=# alter table p_test replica identity full, alter column > username set (n_distinct = 0.1); > NOTICE: ALTER action REPLICA IDENTITY on","historyId":"6221","internalDate":"1769110031000","receivedAtUtc":"2026-01-22T19:27:11.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"},{"id":"19be831e29cb001a","messageId":"<8ECD9403-F0BB-4971-94CF-2709EEB4E3B9@gmail.com>","subject":"Re: ALTER TABLE: warn when actions do not recurse to partitions","body":"\\n\\n> On Jan 23, 2026, at 03:27, Jim Jones <jim.jones@uni-muenster.de> wrote:\\n> \\n> Hi Chao\\n> \\n> On 22/01/2026 06:45, Chao Li wrote:\\n>> evantest=# alter table p_test replica identity full, alter column\\n>> username set (n_distinct = 0.1);\\n>> NOTICE:  ALTER action REPLICA IDENTITY on relation \\"p_test\\" does not\\n>> affect present partitions\\n>> HINT:  partitions may be modified individually, or specify ONLY to\\n>> suppress this message\\n>> NOTICE:  ALTER action ALTER COLUMN ... SET on relation \\"p_test\\" does not\\n>> affect present partitions\\n>> HINT:  partitions may be modified individually, or specify ONLY to\\n>> suppress this message\\n>> ALTER TABLE\\n> \\n> \\n> One could argue that encapsulating all conditions in\\n> EmitPartitionNoRecurseNotice(), meaning it is called all the time, is\\n> slightly inefficient, but the impact is really negligible in this case -\\n> and it is how it is done in similar functions in tablecmds.c :) The code\\n> LGTM.\\n\\nHi Jim, thanks a lot for the review.\\n\\n> \\n> One small thing:\\n> \\n> errhint is supposed to be capitalised - see Error Message Style Guide[1]\\n\\nThanks for the info, I wasn't aware of that. When I wrote the code, I searched "errhint" over the source tree, and didn't find a standard to follow.\\n\\n> \\n> \\"Detail and hint messages: Use complete sentences, and end each with a\\n> period. Capitalize the first word of sentences. Put two spaces after the\\n> period if another sentence follows (for English text; might be\\n> inappropriate in other languages).\\"\\n> \\n> ereport(NOTICE,\\n> errmsg(\\"ALTER action %s on relation \\\\\\"%s\\\\\\" does not affect present\\n> partitions\\",\\n>   action_str,\\n>   RelationGetRelationName(rel)),\\n> errhint(\\"partitions may be modified individually, or specify ONLY to\\n> suppress this message\\"));\\n> \\n> What about this?\\n> \\n> HINT: To update partitions, apply the command to each one individually,\\n> or specify ONLY to suppress this message.\\n\\nLooks good. I will integrate your edit to the next version.\\n\\n> \\n> I'll test the newly covered subcomands tomorrow.\\n\\nThanks again for testing. I will wait to see the test results and address all issues together in next version.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be72cf98864068","snippet":"> On Jan 23, 2026, at 03:27, Jim Jones <jim.jones@uni-muenster.de> wrote: > > Hi Chao > > On 22/01/2026 06:45, Chao Li wrote: >> evantest=# alter table p_test replica","historyId":"8722","internalDate":"1769127095000","receivedAtUtc":"2026-01-23T00:11:35.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19bea4a13acdcbb4","messageId":"<f4f70647-8738-48b3-abbd-5b52cde97374@uni-muenster.de>","subject":"Re: ALTER TABLE: warn when actions do not recurse to partitions","body":"\\n\\nOn 23/01/2026 01:11, Chao Li wrote:\\n> I will wait to see the test results and address all issues together in next version.\\n\\nWhile testing some edge cases I found out that the NOTICE is being\\nemitted too early in the code path, e.g.\\n\\npostgres=# ALTER TABLE m ALTER COLUMN b SET COMPRESSION pglz;\\nNOTICE:  ALTER action ALTER COLUMN ... SET COMPRESSION on relation \\"m\\"\\ndoes not affect present partitions\\nHINT:  partitions may be modified individually, or specify ONLY to\\nsuppress this message\\nERROR:  column data type integer does not support compression\\n\\nI'd argue that emitting only the ERROR message in this case would be the\\nright approach. What about moving the EmitPartitionNoRecurseNotice()\\ncall to ATExecCmd, right **after** the changes were successfully\\nexecuted? For instance, in the case I mentioned above, you could explore:\\n\\n@@ -5446,6 +5475,8 @@ ATExecCmd(List **wqueue, AlteredTableInfo *tab,\\n                case AT_SetCompression: /* ALTER COLUMN SET COMPRESSION */\\n                        address = ATExecSetCompression(rel, cmd->name,\\ncmd->def,\\n\\n          lockmode);\\n+                       /* Emit notice after validation passes */\\n+                       EmitPartitionNoRecurseNotice(cmd->subtype, rel,\\ncmd->recurse, false);\\n                        break;\\n\\nNot sure if cmd->recurse is propagated in this code path. If not, you\\nmight need to do it manually, e.g.\\n\\n@@ -4936,6 +4937,14 @@ ATPrepCmd(List **wqueue, Relation rel,\\nAlterTableCmd *cmd,\\n         */\\n        cmd = copyObject(cmd);\\n\\n+       if (recurse)\\n+               cmd->recurse = true;\\n+\\n\\nI'm not saying it should be exactly this way, but it sounds more\\nreasonable to me to emit the NOTICE only if we know that the command is\\ngoing to be successfully executed (or was successfully executed).\\n\\nThis patch touches a lot of regression tests, but mostly to add the\\nkeyword ONLY to the ALTER TABLE statements, to avoid the NOTICE message,\\nso that's ok.\\n\\nThanks!\\n\\nBest, Jim\\n\\n\\n","threadId":"19be72cf98864068","snippet":"On 23/01/2026 01:11, Chao Li wrote: > I will wait to see the test results and address all issues together in next version. While testing some edge cases I found out that the NOTICE is being emitted","historyId":"12871","internalDate":"1769162268000","receivedAtUtc":"2026-01-23T09:57:48.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"}]	The discussion focuses on a PostgreSQL patch that adds warning notices when ALTER TABLE actions don't recurse to partitions. Jim Jones reviews Chao Li's code implementation, finding it generally acceptable but suggesting improvements. Key feedback includes fixing the errhint message capitalization per PostgreSQL's Error Message Style Guide, with Jim proposing a clearer hint: "To update partitions, apply the command to each one individually, or specify ONLY to suppress this message." A critical issue emerges during testing where the NOTICE is emitted before command validation, causing confusing output when commands fail (e.g., showing partition warnings before compression errors). Jim suggests moving the EmitPartitionNoRecurseNotice() call to ATExecCmd after successful execution rather than during preparation. The patch affects many regression tests, primarily adding ONLY keywords to suppress notices. Chao acknowledges the feedback and plans to integrate suggestions in the next version.\n该讨论围绕一个PostgreSQL补丁展开，该补丁在ALTER TABLE操作不递归到分区时添加警告通知。Jim Jones审查了Chao Li的代码实现，认为总体可接受但建议改进。关键反馈包括根据PostgreSQL错误消息风格指南修正errhint消息大小写，Jim提出了更清晰的提示："要更新分区，请对每个分区单独应用命令，或指定ONLY来抑制此消息。"测试中出现一个关键问题，即在命令验证前就发出NOTICE，导致命令失败时输出混乱（如在压缩错误前显示分区警告）。Jim建议将EmitPartitionNoRecurseNotice()调用移至ATExecCmd中成功执行后，而非准备阶段。该补丁影响许多回归测试，主要是添加ONLY关键字来抑制通知。Chao确认了反馈并计划在下一版本中整合建议。	2026-01-23 09:57:48+00	\N
12	19be6bab3032bd29	Remove PG_MMAP_FLAGS	["ashutosh.bapat.oss@gmail.com","michael@paquier.xyz","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19be6bab3032bd29","messageId":"<CAExHW5vTWABxuM5fbQcFkGuTLwaxuZDEE2vtx2WuMUWk6JnF4g@mail.gmail.com>","subject":"Remove PG_MMAP_FLAGS","body":"Hi,\\nOver [1] Peter mentioned that PG_MMAP_FLAGS is not used for\\nportability even though it's placed in portability/mem.h. That might\\nhave been the intention when it was added in\\nb0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67. But history does not show it\\nbeing used that way at any point in time. Per suggestion removing that\\nmacro and instead using the flags directly in CreateAnonymousSegment()\\nwhich is the only place where it's used.\\n\\nPFA patch for the same.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be6bab3032bd29","snippet":"Hi, Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for portability even though it's placed in portability/mem.h. That might have been the intention when it was added in","historyId":"5964","internalDate":"1769102528000","receivedAtUtc":"2026-01-22T17:22:08.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19be723d4b961c2d","messageId":"<2772065.1769109428@sss.pgh.pa.us>","subject":"Re: Remove PG_MMAP_FLAGS","body":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes:\\n> Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for\\n> portability even though it's placed in portability/mem.h. That might\\n> have been the intention when it was added in\\n> b0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67. But history does not show it\\n> being used that way at any point in time. Per suggestion removing that\\n> macro and instead using the flags directly in CreateAnonymousSegment()\\n> which is the only place where it's used.\\n\\nI think you attached the wrong patch?  This one doesn't touch\\nPG_MMAP_FLAGS.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19be6bab3032bd29","snippet":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes: > Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for > portability even though it's placed in portability/mem.h. That","historyId":"5964","internalDate":"1769109428000","receivedAtUtc":"2026-01-22T19:17:08.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19be8051e10c434e","messageId":"<aXKxX-tFjYJgyo_M@paquier.xyz>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Thu, Jan 22, 2026 at 02:17:08PM -0500, Tom Lane wrote:\\n> Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes:\\n>> Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for\\n>> portability even though it's placed in portability/mem.h. That might\\n>> have been the intention when it was added in\\n>> b0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67. But history does not show it\\n>> being used that way at any point in time. Per suggestion removing that\\n>> macro and instead using the flags directly in CreateAnonymousSegment()\\n>> which is the only place where it's used.\\n> \\n> I think you attached the wrong patch?  This one doesn't touch\\n> PG_MMAP_FLAGS.\\n\\nPG_MMAP_FLAGS is still used in two places in sysv_shmem.c, where I\\nguess the intention of Robert back in b0fc0df9364d was to not\\ncopy-paste the same flag values multiple times.  I can still get the\\nintention even today, so, if we were to do something, why don't you\\njust make PG_MMAP_FLAGS local to sysv_shmem.c and call it a day?\\n\\nHonestly, I don't think that we should change this code at all: I also \\nlike the current idea of PG_MMAP_FLAGS being defined in the same place\\nwhere we check for HASSEMAPHORE and ANONYMOUS, so it comes down to\\nthis being a matter of taste.\\n--\\nMichael\\n","threadId":"19be6bab3032bd29","snippet":"On Thu, Jan 22, 2026 at 02:17:08PM -0500, Tom Lane wrote: > Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes: >> Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for >>","historyId":"8716","internalDate":"1769124191000","receivedAtUtc":"2026-01-22T23:23:11.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be8b43b82e94ad","messageId":"<CAExHW5ugLWtxiLZbAg0vBZac=Aix6J7Xt7DB7Reb8od-+vwkxQ@mail.gmail.com>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 4:53 AM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 02:17:08PM -0500, Tom Lane wrote:\\n> > Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes:\\n> >> Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for\\n> >> portability even though it's placed in portability/mem.h. That might\\n> >> have been the intention when it was added in\\n> >> b0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67. But history does not show it\\n> >> being used that way at any point in time. Per suggestion removing that\\n> >> macro and instead using the flags directly in CreateAnonymousSegment()\\n> >> which is the only place where it's used.\\n> >\\n> > I think you attached the wrong patch?  This one doesn't touch\\n> > PG_MMAP_FLAGS.\\n\\nI didn't do a good job writing that email: attached wrong patch and\\nalso didn't provide the required reference. Sorry for that. Corrected\\nin this email.\\n\\n>\\n> PG_MMAP_FLAGS is still used in two places in sysv_shmem.c, where I\\n> guess the intention of Robert back in b0fc0df9364d was to not\\n> copy-paste the same flag values multiple times.  I can still get the\\n> intention even today, so, if we were to do something, why don't you\\n> just make PG_MMAP_FLAGS local to sysv_shmem.c and call it a day?\\n>\\n> Honestly, I don't think that we should change this code at all: I also\\n> like the current idea of PG_MMAP_FLAGS being defined in the same place\\n> where we check for HASSEMAPHORE and ANONYMOUS, so it comes down to\\n> this being a matter of taste.\\n\\nAs Peter mentioned in the shared buffers resizing thread [1] it's\\nplacement and name in mem.h led us to think that it affects all mmap\\ncalls or that all mmap calls should use those flags. Neither of which\\nis true. We have different mmap calls using different set of flags.\\nAttached patch proposes changes similar (not exact) as you suggest\\nabove. Please take a look.\\n\\n[1] https://www.postgresql.org/message-id/12add41a-7625-4639-a394-a5563e349322@eisentraut.org\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 4:53 AM Michael Paquier <michael@paquier.xyz> wrote: > > On Thu, Jan 22, 2026 at 02:17:08PM -0500, Tom Lane wrote: > > Ashutosh Bapat <ashutosh.bapat.oss@","historyId":"8716","internalDate":"1769135658000","receivedAtUtc":"2026-01-23T02:34:18.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19be929c270c15ed","messageId":"<aXL8TKH2dvt7EgLO@paquier.xyz>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote:\\n> As Peter mentioned in the shared buffers resizing thread [1] it's\\n> placement and name in mem.h led us to think that it affects all mmap\\n> calls or that all mmap calls should use those flags. Neither of which\\n> is true. We have different mmap calls using different set of flags.\\n> Attached patch proposes changes similar (not exact) as you suggest\\n> above. Please take a look.\\n> \\n> [1] https://www.postgresql.org/message-id/12add41a-7625-4639-a394-a5563e349322@eisentraut.org\\n\\nOkay, point taken.  I can live with your patch suggestion based on\\nwhat you have attached.\\n--\\nMichael\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote: > As Peter mentioned in the shared buffers resizing thread [1] it's > placement and name in mem.h led us to think that it","historyId":"8716","internalDate":"1769143372000","receivedAtUtc":"2026-01-23T04:42:52.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19bea4f7f8cf29db","messageId":"<CAExHW5uN1T2LRf7WypNT8ZyJ0yY_pp4Zo4uNH7m_Pxr1AuW0nQ@mail.gmail.com>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 10:12 AM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote:\\n> > As Peter mentioned in the shared buffers resizing thread [1] it's\\n> > placement and name in mem.h led us to think that it affects all mmap\\n> > calls or that all mmap calls should use those flags. Neither of which\\n> > is true. We have different mmap calls using different set of flags.\\n> > Attached patch proposes changes similar (not exact) as you suggest\\n> > above. Please take a look.\\n> >\\n> > [1] https://www.postgresql.org/message-id/12add41a-7625-4639-a394-a5563e349322@eisentraut.org\\n>\\n> Okay, point taken.  I can live with your patch suggestion based on\\n> what you have attached.\\n\\nThanks.\\n\\nI revised the patch a bit. The macro had parenthesis around the macro\\ndefinition which are not required in the assignment. Removed them.\\nAlso revised the commit message a bit.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 10:12 AM Michael Paquier <michael@paquier.xyz> wrote: > > On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote: > > As Peter mentioned in the shared","historyId":"12870","internalDate":"1769162613000","receivedAtUtc":"2026-01-23T10:03:33.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"}]	Ashutosh Bapat proposed removing the PG_MMAP_FLAGS macro from portability/mem.h, citing Peter's observation that despite its placement in a portability header, it's only used in sysv_shmem.c and doesn't serve the intended portability purpose. Tom Lane initially noted that Ashutosh attached the wrong patch. Michael Paquier suggested making PG_MMAP_FLAGS local to sysv_shmem.c instead of complete removal, arguing the current approach avoids code duplication. However, Ashutosh clarified that the macro's placement and name misleadingly suggests it affects all mmap calls, when different mmap operations actually use different flag sets. Michael accepted this reasoning and agreed with Ashutosh's revised patch proposal. Ashutosh then provided an updated patch removing unnecessary parentheses from the macro definition and revising the commit message.\nAshutosh Bapat提议从portability/mem.h中移除PG_MMAP_FLAGS宏，引用Peter的观察，尽管该宏放置在可移植性头文件中，但实际只在sysv_shmem.c中使用，并未实现预期的可移植性目的。Tom Lane最初指出Ashutosh附加了错误的补丁。Michael Paquier建议将PG_MMAP_FLAGS设为sysv_shmem.c的本地宏而非完全移除，认为当前方法避免了代码重复。然而，Ashutosh澄清说该宏的位置和名称误导性地暗示它影响所有mmap调用，而实际上不同的mmap操作使用不同的标志集。Michael接受了这一理由并同意Ashutosh的修订补丁建议。Ashutosh随后提供了更新的补丁，移除了宏定义中不必要的括号并修订了提交消息。	2026-01-23 10:03:33+00	\N
12	19bea52b86e5169b	docs: clarify ALTER TABLE behavior on partitioned tables	["amit.kapila16@gmail.com","david.g.johnston@gmail.com","li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bea52b86e5169b","messageId":"<CAN4CZFNoLSUcVKcOOJgOtTkDuOseCL5j9MQr3tGjb3btD=jHNQ@mail.gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","body":"Hello\\n\\nReally good changes!\\n\\n+ When applied to a partitioned table, the constraint is altered on the\\n+ partitioned table definition is implicitly applied to all partitions.\\n\\nan \\"and\\" is missing here (definition and is)\\n\\n+      When applied to a partitioned table, partition columns constraints\\n+      are implicitly renamed and specifying <literal>ONLY</literal>\\nis not allowed.\\n+     </para>\\n\\n\\"partition columns constraints\\" - that seems like a strange/unclear\\nwording to me. maybe \\", the partition's column constraints are ... \\" ?\\n\\n\\n+     <para>\\n+      When applied to a partitioned table <literal>ONLY</literal> is implicit,\\n+      these forms must be applied separately to the partitioned table and/or to\\n+      individual partitions.\\n+     </para>\\n\\n\\"When applied to a partitioned table, <literal>ONLY</literal> is\\nimplicit and ...\\"  (at multiple places, this is an example)\\n\\n-   <para>\\n-    A recursive <literal>DROP COLUMN</literal> operation will remove a\\n-    descendant table's column only if the descendant does not inherit\\n-    that column from any other parents and never had an independent\\n-    definition of the column.  A nonrecursive <literal>DROP\\n-    COLUMN</literal> (i.e., <command>ALTER TABLE ONLY ... DROP\\n-    COLUMN</command>) never removes any descendant columns, but\\n-    instead marks them as independently defined rather than inherited.\\n-    A nonrecursive <literal>DROP COLUMN</literal> command will fail for a\\n-    partitioned table, because all partitions of a table must have the same\\n-    columns as the partitioning root.\\n-   </para>\\n\\n\\n\\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\nnever removes any descendant columns, but instead marks them as\\nindependently defined rather than inherited.\\"\\n\\nThis part is now undocumented, it was only mentioned in this paragraph.\\n\\n> C2 - Sub-commands where using them with a partitioned table will automatically propagate to child partitions; ONLY prevents propagation; new partitions inherit the parent's new setting; and child partitions can be set to different values than the parent.\\n\\nThe documentation of this group is inconsistent.\\n\\nDROP CONSTRAINT mentions that individual partitions can be dropped separately:\\n\\n+      When applied to a partitioned table, the constraint is dropped from\\n+      all existing partitions unless <literal>ONLY</literal> is specified.\\n+      Individual partitions may drop constraints independently of the\\n+      partitioned table.\\n\\nBut most of the sub commands in the C2 group leave the last sentence\\nout, and also the C7 (ADD table_constraint)\\n\\nAlso, isn't DROP CONSTRAINT on a partition limited to constraints\\ndefined on that partition? So it would be better to say \\"may drop\\nconstraints defined directly on that individual partition\\nindependently\\".\\n\\n  CREATE TABLE parent (id int, val int) PARTITION BY RANGE (id);\\n  ALTER TABLE parent ADD CONSTRAINT val_positive CHECK (val > 0);\\n  CREATE TABLE child PARTITION OF parent FOR VALUES FROM (1) TO (100);\\n  ALTER TABLE child DROP CONSTRAINT val_positive;\\n  -- ERROR: cannot drop inherited constraint \\"val_positive\\" of relation \\"child\\"\\n\\n+      When a new partition is created, it generally inherits the current\\n+      definition-level properties of the parent partitioned table.\\n\\nMaybe something like the following?\\n\\nWhen a new partition is created, it generally inherits structural\\nproperties of the parent partitioned table, such as column\\ndefinitions, constraints, and storage settings.\\n\\nTo be more explicit about what's inherited, and not only focus on\\nwhat's not. (The commit message also says that the change describes\\nboth what's inherited and what's not inherited)\\n\\n\\n","threadId":"19bea52b86e5169b","snippet":"Hello Really good changes! + When applied to a partitioned table, the constraint is altered on the + partitioned table definition is implicitly applied to all partitions. an \\"and\\" is missing","historyId":"12885","internalDate":"1769162823000","receivedAtUtc":"2026-01-23T10:07:03.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	A PostgreSQL documentation patch aims to clarify ALTER TABLE behavior on partitioned tables. The reviewer provides detailed feedback on the proposed changes, identifying several grammatical and clarity issues. Key concerns include missing words ("and" in constraint alteration description), unclear wording for "partition columns constraints," and inconsistent documentation across different sub-commands. The reviewer notes that some existing documentation was removed without replacement, specifically about nonrecursive DROP COLUMN behavior. They highlight inconsistencies in how different constraint operations are documented, particularly regarding whether individual partitions can independently modify constraints. The reviewer suggests more explicit language about what properties new partitions inherit from their parent tables, recommending clearer descriptions of structural properties like column definitions, constraints, and storage settings.\n\n一个PostgreSQL文档补丁旨在澄清分区表上的ALTER TABLE行为。审阅者对提议的更改提供了详细反馈，识别出几个语法和清晰度问题。主要关注点包括缺少词语（约束更改描述中缺少"and"）、"partition columns constraints"措辞不清楚，以及不同子命令间文档不一致。审阅者指出某些现有文档被删除而没有替换，特别是关于非递归DROP COLUMN行为的内容。他们强调了不同约束操作文档记录方式的不一致性，特别是关于各个分区是否可以独立修改约束。审阅者建议对新分区从父表继承的属性使用更明确的语言，推荐对列定义、约束和存储设置等结构属性进行更清晰的描述。	2026-01-23 10:07:03+00	\N
12	19bea5d6a1b05fd5	Reduce build times of pg_trgm GIN indexes	["boekewurm+postgres@gmail.com","geidav.pg@gmail.com","hlinnaka@iki.fi"]	[{"id":"19bea5d6a1b05fd5","messageId":"<ef8782c9-68b7-4915-9f79-497765a8e205@gmail.com>","subject":"Re: Reduce build times of pg_trgm GIN indexes","body":"Hi Matthias,\\n\\nOn 21.01.2026 21:50, Matthias van de Meent wrote:\\n> On Wed, 21 Jan 2026 at 16:45, David Geier <geidav.pg@gmail.com> wrote:\\n>>\\n>> How do we usually go about such backwards-compatibility breaking\\n>> changes?\\n> \\n> When it concerns a bug, we mention the change in the release notes\\n> with a warning to reindex affected indexes to be sure no known\\n> corruption remains. See e.g. the final entry in the PG18 release\\n> notes' migration section here:\\n> https://www.postgresql.org/docs/18/release-18.html#RELEASE-18-MIGRATION.\\n> \\n>> Could we have pg_upgrade reindex all GIN indexes? Would that be\\n>> acceptable?\\n> \\n> No. We'd handle this like any other collation/opclass fixes; we ask\\n> users to reindex their indexes in their own time after they've\\n> upgraded their cluster. Note that in this case it concerns an issue\\n> with just one GIN opclass, not all GIN indexes; so even if we were to\\n> address this in pg_upgrade it wouldn't be a correct choice to reindex\\n> every GIN index, as only a subset of those would be affected by this\\n> issue.\\n> \\n> Generally speaking, pg_upgrade doesn't concern itself with the\\n> validity of the data structures that are described by the catalogs\\n> that it upgrades, it only concerns itself with that it correctly\\n> transcribes the catalogs from one version to another, and that the\\n> data files of the old cluster are transfered correctly without\\n> changes.\\n\\nThanks for the clarifications and the link to the release notes. That's\\nvery helpful. Then I know how to move on and will update the patch\\naccordingly.\\n\\n--\\nDavid Geier\\n\\n\\n","threadId":"19bea5d6a1b05fd5","snippet":"Hi Matthias, On 21.01.2026 21:50, Matthias van de Meent wrote: > On Wed, 21 Jan 2026 at 16:45, David Geier <geidav.pg@gmail.com> wrote: >> >> How do we usually go about such","historyId":"12886","internalDate":"1769163536000","receivedAtUtc":"2026-01-23T10:18:56.000Z","from":"David Geier <geidav.pg@gmail.com>"}]	David Geier seeks guidance on handling backwards-compatibility breaking changes for a pg_trgm GIN index optimization patch. Matthias van de Meent explains PostgreSQL's standard approach: when fixing bugs that affect index correctness, changes are documented in release notes with warnings for users to reindex affected indexes post-upgrade. He clarifies that pg_upgrade doesn't automatically reindex structures, as it only transfers catalogs and data files without validating data structure validity. Since only specific GIN opclasses would be affected (not all GIN indexes), automatic reindexing during upgrade would be inappropriate. David acknowledges the guidance and commits to updating his patch accordingly.\n\nDavid Geier就pg_trgm GIN索引优化补丁的向后兼容性破坏变更寻求指导。Matthias van de Meent解释了PostgreSQL的标准做法：修复影响索引正确性的错误时，变更会记录在发行说明中，并警告用户在升级后重建受影响的索引。他澄清pg_upgrade不会自动重建索引结构，因为它只负责传输目录和数据文件而不验证数据结构有效性。由于只有特定的GIN操作符类会受影响（而非所有GIN索引），升级期间自动重建索引是不合适的。David确认了指导意见并承诺相应更新补丁。	2026-01-23 10:18:56+00	\N
12	19bea617c6c8099e	Time to drop RADIUS support?	["thomas.munro@gmail.com"]	[{"id":"19bea617c6c8099e","messageId":"<CA+hUKG+SH309V8KECU5=xuLP9Dks0v9f9UVS2W74fPAE5O21dg@mail.gmail.com>","subject":"Time to drop RADIUS support?","body":"Hi,\\n\\nA bit over a year ago, I wrote about a RADIUS vulnerability and a\\nrecommended mitigation[1].  I was grateful for the reviews, but I lost\\nsteam on those patches because:\\n\\n1.  Our implementation seems to have accidental (?) resilience because\\nit has a short hard-coded timeout.  The RADIUS/UDP Considered\\nHarmful[0] people used 47 servers to get \\"2% of the successful runs to\\nfinish before 240s and 16% before 300s\\", but we time out after 3\\nseconds.  Assuming perfect scaling, maybe they could use 4700 servers\\nto get a 16% chance of success in 3s... or maybe I have the maths\\nwrong but it's fairly extreme anyway...\\n\\n2.  It seems increasingly likely that there are no users, since\\nRADIUS/UDP without the mitigation spews warnings from FreeRADIUS, and\\nMicrosoft RADIUS's 2024 update (KB5040456) recommended requiring it\\n(though you didn't have to accept IIUC).  I'm pretty sure we'd have\\nheard about it from users if there were any.\\n\\n3.  That mitigation would help, but in the end it's still leaky\\nobfuscation of credentials + MD5-based technology that is being\\nformally deprecated with a mandated replacement[2], and de facto has\\nbeen for a long time.\\n\\nThe real recommendation of the paper was \\"don't use RADIUS/UDP at\\nall\\", and I don't want to expend energy writing a RADIUS/TLS client\\nfor a hypothetical user, so I think we should just delete it all, and\\nstick a deprecation notice in the release branch documentation, as\\nattached.  That'd also mean our Windows select() and non-thread-safe\\nUDP kludges can be VACUUMed.\\n\\nAFAICS you can already do RADIUS better with PAM using a module\\nmaintained by the FreeRADIUS project (see below for quick and dirty\\ndemo).  That way it's not our problem, follows the standards etc.  The\\nonly issue I can think of with that is that Windows and OpenBSD\\nprobably don't have PAM. But then, recall that we are talking about\\napproximately zero users so I think we can still hit 100% of them this\\nway?\\n\\n\\n\\n=== Example of RADIUS via PAM ===\\n\\nTell PAM how to authenticate for service postgresql in /etc/pam.d/postgresql:\\n#%PAM-1.0\\nauth required pam_radius.so require_message_authenticator\\naccount required pam_permit.so\\n\\nTell pam_radius.so how to talk to RADIUS server in /etc/radius.conf:\\n# Server[:port] SharedSecret Timeout Retries\\n127.0.0.1 shared_secret 3 3\\n\\nTell PostgreSQL to use PAM service postgresql in pg_hba.conf:\\nhost all all 127.0.0.1/32 pam pamservice=postgresql\\n\\n=== Setting up a test server to try it out ===\\n\\nTell FreeRADIUS how to be a RADIUS server in /tmp/radiusd/radiusd.conf:\\n/tmp/radiusd/radiusd.conf\\nclient default {\\n  ipaddr = \\"127.0.0.1\\"\\n  secret = \\"shared_secret\\"\\n}\\nmodules {\\n  files {\\n    filename = \\"/tmp/radiusd/users.txt\\"\\n  }\\n  pap {\\n  }\\n}\\nserver default {\\n  listen {\\n    type   = \\"auth\\"\\n    ipv4addr = \\"127.0.0.1\\"\\n    port = \\"1812\\"\\n  }\\n  authenticate {\\n    Auth-Type PAP {\\n      pap\\n    }\\n  }\\n  authorize {\\n    files\\n    pap\\n  }\\n}\\nlog {\\n  destination = \\"files\\"\\n  localstatedir = \\"/tmp/radiusd\\"\\n  logdir = \\"/tmp/radiusd\\"\\n  file = \\"/tmp/radiusd/radiusd.log\\"\\n}\\npidfile = \\"/tmp/radiusd/radiusd.pid\\"\\n\\nTell FreeRADIUS the passwords in /tmp/radiusd/users.txt:\\ntestuser Cleartext-Password := \\"xxx\\"\\n\\nThen run it in the foreground with \\"radiusd -d /tmp/radiusd -f\\".  If\\nyou leave out \\"require_message_authenticator\\" from\\n/etc/pam.d/postgresql then you'll get log messages just like when\\nPostgreSQL speaks RADIUS natively:\\n\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\nBlastRADIUS check: Received packet without Message-Authenticator.\\nSetting \\"require_message_authenticator = false\\" for client default\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\nUPGRADE THE CLIENT AS YOUR NETWORK IS VULNERABLE TO THE BLASTRADIUS ATTACK.\\nOnce the client is upgraded, set \\"require_message_authenticator =\\ntrue\\" for  client default\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\\nBoth client and server should ideally be set to require\\nMessage-Authenticator.  Presumably with more coffee and man pages you\\ncould also configure it to use RADIUS/TLS instead of RADIUS/UDP, etc.\\n\\n[0] https://www.usenix.org/conference/usenixsecurity24/presentation/goldberg\\n[1] https://www.postgresql.org/message-id/flat/CA%2BhUKGLRSPTOC_ygx4_sJjWeKOkOpWGCBCJiRq8cPNuMisuzgw%40mail.gmail.com\\n[2] https://datatracker.ietf.org/doc/draft-ietf-radext-deprecating-radius/\\n","threadId":"19bea617c6c8099e","snippet":"Hi, A bit over a year ago, I wrote about a RADIUS vulnerability and a recommended mitigation[1]. I was grateful for the reviews, but I lost steam on those patches because: 1. Our implementation seems","historyId":"12887","internalDate":"1769163765000","receivedAtUtc":"2026-01-23T10:22:45.000Z","from":"Thomas Munro <thomas.munro@gmail.com>"}]	Thomas Munro proposes removing PostgreSQL's RADIUS authentication support due to security vulnerabilities and apparent lack of users. He notes that PostgreSQL's implementation may have accidental resilience through short timeouts, but the underlying RADIUS/UDP protocol has fundamental security issues highlighted in recent research. The RADIUS vulnerability mitigation he previously worked on lost momentum because: the protocol uses deprecated MD5-based technology, major RADIUS servers now issue warnings without mitigations, and no users have complained about compatibility issues. Munro suggests users can achieve better RADIUS authentication through PAM modules maintained by the FreeRADIUS project, which would handle standards compliance externally. He provides detailed configuration examples for RADIUS via PAM and proposes adding deprecation notices while removing the native RADIUS code and associated Windows/UDP workarounds.\nThomas Munro提议移除PostgreSQL的RADIUS认证支持，原因是存在安全漏洞且似乎缺乏用户。他指出PostgreSQL的实现可能通过短超时意外获得了弹性，但底层的RADIUS/UDP协议存在最近研究突出的根本性安全问题。他之前致力于的RADIUS漏洞缓解工作失去动力，因为：该协议使用已弃用的基于MD5的技术，主要RADIUS服务器现在在没有缓解措施时发出警告，且没有用户抱怨兼容性问题。Munro建议用户可以通过FreeRADIUS项目维护的PAM模块实现更好的RADIUS认证，这将在外部处理标准合规性。他提供了通过PAM进行RADIUS配置的详细示例，并提议在移除原生RADIUS代码和相关Windows/UDP变通方法的同时添加弃用通知。	2026-01-23 10:22:45+00	\N
12	19bea7defb8a17b6	Proposal: Conflict log history table for Logical Replication	["amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","sawada.mshk@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19bea7defb8a17b6","messageId":"<CAFiTN-t_4XvofM3an-WmykqnPE+9wf9U+o2M7p1CWd9eXkN88Q@mail.gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","body":"On Tue, Jan 20, 2026 at 6:48 PM vignesh C <vignesh21@gmail.com> wrote:\\n>\\n> On Mon, 19 Jan 2026 at 10:57, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n> >\\n> > On Mon, Jan 19, 2026 at 9:42 AM Peter Smith <smithpb2250@gmail.com> wrote:\\n> > >\\n> > > Some review comments for v22-0003.\\n> > >\\n> > > ======\\n> > >\\n> > > 1.\\n> > > It looks like none of my previous v20-0003 review comments [1] have\\n> > > been addressed. Maybe accidentally overlooked?\\n> > >\\n> > > ======\\n> > >\\n> > > 2.\\n> > > +         <caution>\\n> > > +          <para>\\n> > > +           The internal conflict logging table is strictly tied to\\n> > > the lifecycle of the\\n> > > +           subscription or the\\n> > > <literal>conflict_log_destination</literal> setting. If\\n> > > +           the subscription is dropped, or if the destination is changed to\\n> > > +           <literal>log</literal>, the table and all its recorded\\n> > > conflict data are\\n> > > +           <emphasis>permanently deleted</emphasis>. To perform a\\n> > > post-mortem analysis\\n> > > +           after removing a subscription, users must manually back up\\n> > > or rename the\\n> > > +           conflict table before the deletion occurs.\\n> > > +          </para>\\n> > > +         </caution>\\n> > >\\n> > > 2a.\\n> > > Let's consistently call this the \\"Conflict log table\\", same as\\n> > > everywhere else, not \\"logging table\\".\\n> > >\\n> > > ~\\n> > >\\n> > > 2b.\\n> > > This is only a caution for the CLT, so I felt it's better to put this\\n> > > in the scope of the 'table' param value.\\n> > >\\n> > > ~~~\\n> > >\\n> > > 3.\\n> > > +             analysis of conflicts. This table is automatically\\n> > > dropped when the\\n> > > +             subscription is removed.\\n> > >\\n> > > If you move the <caution> to this scope, as suggested above in #2b,\\n> > > then you can remove the sentence \\"This table is automatically dropped\\n> > > when the subscription is removed\\", because that is duplicate\\n> > > information you already wrote in the caution.\\n> >\\n> > The attached patch fixes above comments and other comments reported in\\n> > v22-0001 and v22-0002\\n>\\n> The tests are failing randomly at the following places\\n> +# Wait for the conflict to be logged in the CLT\\n> +my $log_check = $node_subscriber->poll_query_until(\\n> +    'postgres',\\n> +    \\"SELECT count(*) > 0 FROM $clt;\\"\\n> +);\\n> +\\n> +my $conflict_check = $node_subscriber->safe_psql('postgres',\\n> +    \\"SELECT count(*) FROM $clt WHERE conflict_type =\\n> 'multiple_unique_conflicts';\\");\\n> +is($conflict_check, 1, 'Verified multiple_unique_conflicts logged\\n> into conflict log table');\\n>\\n>\\n> +# Wait for the conflict to be logged in the CLT\\n> +$log_check = $node_subscriber->poll_query_until(\\n> +    'postgres',\\n> +    \\"SELECT count(*) > 0 FROM $clt;\\"\\n> +);\\n> +\\n> +$conflict_check = $node_subscriber->safe_psql('postgres',\\n> +    \\"SELECT count(*) FROM $clt WHERE conflict_type =\\n> 'multiple_unique_conflicts';\\");\\n> +is($conflict_check, 1, 'Verified multiple_unique_conflicts logged\\n> into conflict log table');\\n>\\n>\\n> In both places it fails because the number of conflict records\\n> inserted can be more than 1 like below:\\n> [18:35:58.342](1.786s) not ok 1 - Verified multiple_unique_conflicts\\n> logged into conflict log table\\n> [18:35:58.346](0.004s)\\n> [18:35:58.347](0.002s) #   Failed test 'Verified\\n> multiple_unique_conflicts logged into conflict log table'\\n> #   at t/035_conflicts.pl line 104.\\n> [18:35:58.348](0.000s) #          got: '2'\\n> #     expected: '1'\\n>\\n> How about we check that the record count >= 1 and check for 't'.\\n\\nYeah that makes sense, fixed that and also fixed Shveta's comments,\\nnow only doc changes suggestions from Peter are pending.\\n\\n\\n-- \\nRegards,\\nDilip Kumar\\nGoogle\\n","threadId":"19bea7defb8a17b6","snippet":"On Tue, Jan 20, 2026 at 6:48 PM vignesh C <vignesh21@gmail.com> wrote: > > On Mon, 19 Jan 2026 at 10:57, Dilip Kumar <dilipbalaut@gmail.com> wrote: > > > > On Mon, Jan 19,","historyId":"12888","internalDate":"1769165645000","receivedAtUtc":"2026-01-23T10:54:05.000Z","from":"Dilip Kumar <dilipbalaut@gmail.com>"}]	The discussion focuses on a PostgreSQL patch proposal for implementing a conflict log history table for logical replication. Dilip Kumar has addressed review comments from Peter Smith regarding documentation improvements, specifically fixing terminology to consistently use "Conflict log table" and reorganizing caution text placement. Vignesh C reported test failures where conflict record counts exceeded expected values, suggesting the tests should check for counts >= 1 rather than exact matches. Dilip confirmed fixing the test issues and addressing Shveta's comments, noting that only Peter's documentation suggestions remain pending. The patch appears to be in active development with ongoing code reviews and test refinements.\n该讨论集中在PostgreSQL逻辑复制冲突日志历史表的补丁提案上。Dilip Kumar已经处理了Peter Smith关于文档改进的审查意见，具体包括修正术语以统一使用"Conflict log table"并重新组织警告文本的位置。Vignesh C报告了测试失败问题，其中冲突记录数超出预期值，建议测试应检查计数>=1而不是精确匹配。Dilip确认已修复测试问题并处理了Shveta的意见，指出只剩下Peter的文档建议待处理。该补丁似乎正在积极开发中，持续进行代码审查和测试改进。	2026-01-23 10:54:05+00	\N
12	19bea86b1ad24288	Fix gistkillitems & add regression test to microvacuum	["reshkekirill@gmail.com","x4mmm@yandex-team.ru"]	[{"id":"19bea86b1ad24288","messageId":"<CALdSSPiGnqgvpfQDCydBf-=0hzyUs6Y0o0xNvd53BbcMWTVO=w@mail.gmail.com>","subject":"Re: Fix gistkillitems & add regression test to microvacuum","body":"On Tue, 20 Jan 2026 at 15:30, Andrey Borodin <x4mmm@yandex-team.ru> wrote:\\n>\\n>\\n>\\n> > On 15 Jan 2026, at 22:59, Kirill Reshke <reshkekirill@gmail.com> wrote:\\n> >\\n> > PFA v2 which leaves the test in-place.\\n> >\\n> > Also commit message improvements.\\n>\\n> Yeah, killtuples for GiST root page is broken. Your patch is fixing it.\\n> I don't think we should backpatch this, the bug is harmless, but for master the patch LGTM.\\n\\nThank you\\n\\n> It would be good to assign so->curBlkno and so->curBlkno together. But gistScanPage() is the only place with access to the block number.\\n\\nSorry, didnt get this take.\\n\\n> +# Test gist, but with fewer rows - that killitems used to be buggy.\\n>\\n> Probably, in this comment we can explicitly say that killitems was buggy, but now is fixed.\\n>\\n\\nHmm, what would be a good wording here?\\n\\n\\n-- \\nBest regards,\\nKirill Reshke\\n\\n\\n","threadId":"19bea86b1ad24288","snippet":"On Tue, 20 Jan 2026 at 15:30, Andrey Borodin <x4mmm@yandex-team.ru> wrote: > > > > > On 15 Jan 2026, at 22:59, Kirill Reshke <reshkekirill@gmail.com> wrote: > > >","historyId":"12889","internalDate":"1769166230000","receivedAtUtc":"2026-01-23T11:03:50.000Z","from":"Kirill Reshke <reshkekirill@gmail.com>"}]	Kirill Reshke submitted a v2 patch to fix a bug in GiST's killtuples functionality for root pages and add a regression test. Andrey Borodin reviewed the patch and confirmed that killtuples for GiST root pages is indeed broken, with the patch providing the correct fix. Borodin recommended against backpatching since the bug is harmless, but approved the patch for master. The discussion included minor suggestions about variable assignment in gistScanPage() and improving the test comment to explicitly mention the bug fix. Reshke requested clarification on the optimal wording for the test comment. The patch appears ready for integration with positive review feedback.\n\nKirill Reshke 提交了 v2 补丁，修复 GiST 根页面 killtuples 功能的错误并添加回归测试。Andrey Borodin 审查了补丁，确认 GiST 根页面的 killtuples 确实存在问题，补丁提供了正确的修复。Borodin 建议不要向后移植，因为该错误无害，但批准了主分支的补丁。讨论包括关于 gistScanPage() 中变量赋值的小建议以及改进测试注释以明确提及错误修复。Reshke 询问测试注释的最佳措辞。补丁在获得积极审查反馈后似乎已准备好集成。	2026-01-23 11:03:50+00	\N
12	19beab27f07b7cd3	Deadlock detector fails to activate on a hot standby replica	["v.davydov@postgrespro.ru"]	[{"id":"19beab27f07b7cd3","messageId":"<b178ea8d-9ed9-48b3-b4f7-5cfc3ff6ee44@postgrespro.ru>","subject":"Re: Deadlock detector fails to activate on a hot standby replica","body":"Dear Hackers,\\n\\nI would like to propose a patch that fixes the problem, which has the roots in\\nthe possibility of spontaneous SIGALRM signals when waiting for some timeouts.\\nThe idea of the patch - ignore spontaneous SIGALRM signals and continue waiting\\nfor expected timeouts or buffer unpinning by the conflicting backend. This\\npatch is not a final version. I plan to add a tap-test for this case.\\n\\nI'm in doubt to put the calls of some page buffer specific functions into\\nResolveRecoveryConflictWithBufferPin (standby.c), but otherwise we have to\\ndo more changes in LockBufferForCleanup and ResolveRecoveryConflictWithBufferPin.\\n\\nI also think, we have to add some description of the found problem in timeout.c,\\nbecause the implemented optimization of setitimer calls leads to some not\\nevident consequences. The optimization seems to be implemented in the commit:\\n09cf1d52267644cdbdb734294012cf1228745aaa\\n\\nWith best regards,\\nVitaly","threadId":"19beab27f07b7cd3","snippet":"Dear Hackers, I would like to propose a patch that fixes the problem, which has the roots in the possibility of spontaneous SIGALRM signals when waiting for some timeouts. The idea of the patch -","historyId":"12890","internalDate":"1769169109000","receivedAtUtc":"2026-01-23T11:51:49.000Z","from":"Vitaly Davydov <v.davydov@postgrespro.ru>"}]	Vitaly Davydov proposes a patch to fix a deadlock detector issue on hot standby replicas. The problem stems from spontaneous SIGALRM signals that occur while waiting for timeouts, preventing proper deadlock detection. His solution involves ignoring these spurious signals and continuing to wait for expected timeouts or buffer unpinning by conflicting backends. The patch is not finalized as he plans to add TAP tests. He expresses concerns about placing buffer-specific function calls in ResolveRecoveryConflictWithBufferPin but notes that alternative approaches would require more extensive changes. Davydov also suggests adding documentation about the timeout optimization introduced in commit 09cf1d52267644cdbdb734294012cf1228745aaa, as it creates non-obvious consequences for signal handling behavior.\nVitaly Davydov提出了一个补丁来修复热备副本上死锁检测器的问题。该问题源于在等待超时时出现的自发SIGALRM信号，这些信号阻止了正确的死锁检测。他的解决方案是忽略这些虚假信号，继续等待预期的超时或冲突后端的缓冲区解锁。补丁尚未完成，因为他计划添加TAP测试。他对在ResolveRecoveryConflictWithBufferPin中放置缓冲区特定函数调用表示担忧，但指出替代方法需要更广泛的更改。Davydov还建议为提交09cf1d52267644cdbdb734294012cf1228745aaa中引入的超时优化添加文档，因为它对信号处理行为产生了不明显的后果。	2026-01-23 11:51:49+00	\N
12	19be9aa372b5fabc	Checkpointer write combining	["andres@anarazel.de","byavuz81@gmail.com","li.evan.chao@gmail.com","melanieplageman@gmail.com","soumyamurali.work@gmail.com"]	[{"id":"19be9aa372b5fabc","messageId":"<CAMtXxw-2xFGrFzQ7O_9_a0zSJytkh6v-se5JvroCCQXtXUt=VA@mail.gmail.com>","subject":"Re: Checkpointer write combining","body":"Hi all,\\n\\nThank you all for the patches.\\nI am keeping this as a single patch because the refactoring, batching\\nbehavior and instrumentation are tightly coupled and all serve one\\npurpose to reduce checkpoint writeback overhead while making the\\neffect observable. Due to version and context differences, the patches\\ndid not apply cleanly in my development environment. Instead, I\\nstudied the patches and went through the logic in detail and then\\nimplemented the same ideas directly in my current tree adapting them\\nwherever needed. The implementation was then validated with\\ninstrumentation and measurements.\\n\\nBefore batching:\\n2026-01-22 17:27:26.969 IST [148738] LOG:  checkpoint complete: wrote\\n15419 buffers (94.1%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\nremoved, 25 recycled; write=0.325 s, sync=0.284 s, total=0.754 s; sync\\nfiles=30, longest=0.227 s, average=0.010 s; distance=407573 kB,\\nestimate=407573 kB; lsn=0/1A5B8E30, redo lsn=0/1A5B8DD8\\n\\nAfter batching:\\n2026-01-22 17:31:36.165 IST [148738] LOG:  checkpoint complete: wrote\\n13537 buffers (82.6%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\nremoved, 25 recycled; write=0.260 s, sync=0.211 s, total=0.625 s; sync\\nfiles=3, longest=0.205 s, average=0.070 s; distance=404310 kB,\\nestimate=407247 kB; lsn=0/3308E738, redo lsn=0/3308E6E0\\n\\nDebug instrumentation with (batch size = 16) confirms the batching\\nbehavior itself,\\nbuffers_written = 6196\\nwriteback_calls = 389\\nOn average: I am getting 15.9 i.e approx 16 buffers per writeback\\nThis shows that writebacks are issued per batch rather than per\\nbuffer, while WAL ordering and durability semantics remain unchanged.\\nThe change remains localized to BufferSync() and is intended to be a\\nconservative and measurable improvement to checkpoint I/O behavior. I\\nam attaching the patches herewith for review.\\nI am happy to adjust the approach if there are concerns or\\nsuggestions. Looking forward to more feedback.\\n\\nRegards,\\nSoumya\\n","threadId":"19be9aa372b5fabc","snippet":"Hi all, Thank you all for the patches. I am keeping this as a single patch because the refactoring, batching behavior and instrumentation are tightly coupled and all serve one purpose to reduce","historyId":"12880","internalDate":"1769151820000","receivedAtUtc":"2026-01-23T07:03:40.000Z","from":"Soumya S Murali <soumyamurali.work@gmail.com>"},{"id":"19beac9b17fb9c86","messageId":"<CAMtXxw9cqxgNH6=8NDAA2o11GoF=4P4JO=7-FCkhr=vJCmQiJA@mail.gmail.com>","subject":"Re: Checkpointer write combining","body":"Hi all,\\n\\n\\n> Thank you all for the patches.\\n> I am keeping this as a single patch because the refactoring, batching\\n> behavior and instrumentation are tightly coupled and all serve one\\n> purpose to reduce checkpoint writeback overhead while making the\\n> effect observable. Due to version and context differences, the patches\\n> did not apply cleanly in my development environment. Instead, I\\n> studied the patches and went through the logic in detail and then\\n> implemented the same ideas directly in my current tree adapting them\\n> wherever needed. The implementation was then validated with\\n> instrumentation and measurements.\\n>\\n> Before batching:\\n> 2026-01-22 17:27:26.969 IST [148738] LOG:  checkpoint complete: wrote\\n> 15419 buffers (94.1%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\n> removed, 25 recycled; write=0.325 s, sync=0.284 s, total=0.754 s; sync\\n> files=30, longest=0.227 s, average=0.010 s; distance=407573 kB,\\n> estimate=407573 kB; lsn=0/1A5B8E30, redo lsn=0/1A5B8DD8\\n>\\n> After batching:\\n> 2026-01-22 17:31:36.165 IST [148738] LOG:  checkpoint complete: wrote\\n> 13537 buffers (82.6%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\n> removed, 25 recycled; write=0.260 s, sync=0.211 s, total=0.625 s; sync\\n> files=3, longest=0.205 s, average=0.070 s; distance=404310 kB,\\n> estimate=407247 kB; lsn=0/3308E738, redo lsn=0/3308E6E0\\n>\\n> Debug instrumentation with (batch size = 16) confirms the batching\\n> behavior itself,\\n> buffers_written = 6196\\n> writeback_calls = 389\\n> On average: I am getting 15.9 i.e approx 16 buffers per writeback\\n> This shows that writebacks are issued per batch rather than per\\n> buffer, while WAL ordering and durability semantics remain unchanged.\\n> The change remains localized to BufferSync() and is intended to be a\\n> conservative and measurable improvement to checkpoint I/O behavior. I\\n> am attaching the patches herewith for review.\\n> I am happy to adjust the approach if there are concerns or\\n> suggestions. Looking forward to more feedback.\\n>\\n\\nWith reference to my previous patch related to the batching behavior,\\nI evaluated batch sizes 8, 16, and 32 under identical workloads. I am\\nattaching the log for 8, 16 and 32. All conclusions are based on\\nactual checkpoint logs and DEBUG BufferSync statistics:\\n\\nBatch size = 8\\nLOG: checkpoint complete: wrote 12622 buffers (77.0%); write=0.113 s,\\nsync=0.195 s, total=0.485 s; sync files=37\\nDEBUG:  checkpoint BufferSync stats: buffers_written=9923, writeback_calls=1242\\nAvg: 7.989 approx 8 buffers per writeback.\\n\\nBatch size = 16\\nLOG: checkpoint complete: wrote 13537 buffers (82.6%); write=0.260 s,\\nsync=0.211 s, total=0.625 s; sync files=3\\nDEBUG:  checkpoint BufferSync stats: buffers_written=6196, writeback_calls=389\\nAvg: 15.9 approx 16 buffers per writeback.\\n\\nBatch size = 32\\nLOG: checkpoint complete: wrote 12914 buffers (78.8%); write=0.116 s,\\nsync=0.136 s, total=0.442 s; sync files=5\\nDEBUG:  checkpoint BufferSync stats: buffers_written=12914, writeback_calls=1616\\nAvg: 7.99 approx 8 buffers per writeback.\\n\\nBatch 16 significantly reduces sync fan-out (as low as 3 files per\\ncheckpoint), but this comes at the cost of longer individual sync\\noperations, resulting in higher total checkpoint time (≈0.625 s).\\nBatch 32 provides a better balance, maintaining low sync fragmentation\\nwhile avoiding long sync stalls, yielding the lowest overall\\ncheckpoint time (≈0.442 s). I am attaching the patch with batch size\\nfixed as 32 for now for further review.\\nPlease let me know if further workloads or instrumentation would be useful.\\n\\nRegards\\nSoumya\\n","threadId":"19be9aa372b5fabc","snippet":"Hi all, > Thank you all for the patches. > I am keeping this as a single patch because the refactoring, batching > behavior and instrumentation are tightly coupled and all serve one >","historyId":"12880","internalDate":"1769170658000","receivedAtUtc":"2026-01-23T12:17:38.000Z","from":"Soumya S Murali <soumyamurali.work@gmail.com>"}]	Soumya S Murali implemented checkpointer write combining patches to reduce checkpoint writeback overhead by batching buffer writes instead of issuing writebacks per buffer. The implementation combines refactoring, batching behavior, and instrumentation in a single patch targeting BufferSync(). Performance testing shows significant improvements: batching reduced checkpoint time from 0.754s to 0.625s and decreased sync files from 30 to 3. Additional testing compared batch sizes 8, 16, and 32, with batch size 32 providing the best balance - achieving lowest total checkpoint time (0.442s) while maintaining low sync fragmentation. Debug instrumentation confirms proper batching behavior with approximately 16 buffers per writeback call, while preserving WAL ordering and durability semantics. The author seeks feedback on the conservative approach.\n\nSoumya S Murali 实现了检查点写入合并补丁，通过批处理缓冲区写入而非按缓冲区发出写回来减少检查点写回开销。该实现将重构、批处理行为和监控在单个补丁中结合，针对 BufferSync()。性能测试显示显著改进：批处理将检查点时间从 0.754 秒减少到 0.625 秒，同步文件数从 30 减少到 3。额外测试比较了批处理大小 8、16 和 32，批处理大小 32 提供最佳平衡 - 实现最低总检查点时间（0.442 秒）同时保持低同步碎片化。调试监控确认了正确的批处理行为，每次写回调用约处理 16 个缓冲区，同时保持 WAL 排序和持久性语义。作者寻求对保守方法的反馈。	2026-01-23 12:17:38+00	\N
12	19bead36276a5204	pg_waldump: support decoding of WAL inside tarfile	["jakub.wartak@enterprisedb.com","li.evan.chao@gmail.com","robertmhaas@gmail.com","sulamul@gmail.com"]	[{"id":"19bead36276a5204","messageId":"<CAAJ_b95FOeW38gw-3BLmpdnTWHFimopTvf=eTObYUbTOC0x8qg@mail.gmail.com>","subject":"Re: pg_waldump: support decoding of WAL inside tarfile","body":"On Mon, Jan 19, 2026 at 7:01 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n>\\n> > But, I am thinking that instead of setting privateInfo->cur_wal to\\n> > NULL, we could simply discard the buffer data at that place and let\\n> > memcpy in astreamer_content copy if it would be that much of an issue.\\n>\\n> I don't think doing unnecessary copying is the right way forward. The\\n> copying itself could be expensive, but I am a little concerned about\\n> the memory utilization of this code. Suppose the user has increased\\n> the WAL segment size to 1GB or even higher. It seems like we could\\n> buffer a whole segment or maybe even more in some scenarios. If we\\n> avoid copying data we don't need, then we also avoid buffering it in\\n> memory.\\n>\\n> In terms of the separation of concerns, we could view setting\\n> privateInfo->cur_wal = NULL as a form of signaling, a way for this\\n> code to tell the astreamer that it doesn't need the data buffering.\\n> However, I think it might be better to make the signaling more\\n> explicit. Instead of having the caller directly set the buffer to\\n> NULL, or directly trim data out of the buffer, maybe it should set\\n> some value in privateInfo that tells the astreamer what to do. For\\n> instance, suppose it sets the oldest LSN that it might still care\\n> about in privateInfo, and then the astreamer is free to do skip\\n> copying of any data prior to that LSN, and discard any that it already\\n> has. Especially if properly commented, I think this might be more\\n> clear than what you have now. I am not 100% sure that's the right\\n> idea, though. I just think right now it's a bit murky who does what\\n> and why the division of responsibilities is what it is.\\n>\\n\\nThe current implementation of astreamer_waldump_content() does not\\nhave sufficient information to skip WAL segments during the initial\\nhash entry preparation and data-copying phase. Because the filtration\\nparameters -- which determine if a segment should be skipped -- depend\\non the WAL segment size, we must first read a WAL page through the\\nstreamer to calculate that size, which is done in\\ninit_archive_reader(). Therefore, the responsibility of the archive\\nstreamer is strictly to copy the WAL segment data to the buffer.\\n\\nThe skipping decision is handled inside get_archive_wal_entry(), which\\nsets privateInfo->cur_wal to NULL. In the next version, I am planning\\nto add a separate routine (with better commenting) that, along with\\nsetting the pointer to NULL, releases that hash entry to avoid\\nunnecessary memory usage.\\n\\nAnother option I previously considered was adding the filtration logic\\ninside the archive streamer itself. However, since the very first read\\nis required to calculate the WAL segment size, the filter check cannot\\nbe performed immediately. However, we could send a signal to the\\narchive streamer via privateInfo (e.g., a read_any_wal or\\nskip_wal_check boolean flag) to disable the filtration check until the\\nsize is calculated. But that approach isn't very elegant; if the first\\nWAL page we read belongs to a segment we actually want to skip, we\\nwould still have to run the filter check and handle the skip/removal\\nlogic outside of the streamer (i.e., inside init_archive_reader()).\\nThis would result in performing the same filtration check in two\\ndifferent places.\\n\\nTherefore, I believe performing the filtration check through\\nget_archive_wal_entry() and then calling a routine to clear\\nprivateInfo->cur_wal and the hash entry is the better approach, IMO.\\nAdditionally, once we consume a WAL file and move to the next one, the\\nhash entry and buffer for that WAL can be released to prevent\\nunnecessary memory consumption by calling the same routine that I am\\nplanning to add.\\n\\n> > > +       if (strstr(member->pathname, \\"PaxHeaders.\\"))\\n> > > +               return false;\\n> > >\\n> > > There is no way that a filename containing the string \\"PaxHeaders.\\"\\n> > > could ever pass the IsXLogFileName test just above. We shouldn't need\\n> > > this.\\n> > >\\n> >\\n> > This checks the directory name (e.g.,\\n> > x_dir/y_dir/PaxHeaders.NNNN/wal_file_name). The name of that metadata\\n> > file is exactly the same as the WAL file name, which is why\\n> > IsXLogFileName() doesn't help here.\\n>\\n> I think this code should only be considering files in the toplevel\\n> directory, and skipping over any directories it finds. I absolutely\\n> promise I am not going to commit anything that is specifically looking\\n> for PaxHeaders. Nothing we've ever done with tar files up to now has\\n> required that, and I don't think this should, either.\\n\\nOk, fair enough, my intention was to allow decoding of valid WAL data\\nfrom any directory in the tar archive, but I will go ahead and add\\nthat restriction as suggested.\\n\\nRegards,\\nAmul\\n\\n\\n","threadId":"19bead36276a5204","snippet":"On Mon, Jan 19, 2026 at 7:01 PM Robert Haas <robertmhaas@gmail.com> wrote: > > > But, I am thinking that instead of setting privateInfo->cur_wal to > > NULL, we could simply","historyId":"12893","internalDate":"1769171231000","receivedAtUtc":"2026-01-23T12:27:11.000Z","from":"Amul Sul <sulamul@gmail.com>"}]	The discussion centers on implementing WAL decoding support inside tar files for pg_waldump. Robert Haas raises concerns about memory efficiency when buffering large WAL segments (potentially 1GB+) and suggests making the signaling between components more explicit rather than directly setting privateInfo->cur_wal to NULL. Amul Sul defends the current approach, explaining that the archive streamer lacks sufficient information for early filtering decisions since WAL segment size must be determined first through init_archive_reader(). He proposes adding a separate routine to handle memory cleanup when releasing hash entries. Regarding PaxHeaders filtering, Haas objects to hardcoded string matching and insists the code should only process top-level directory files, skipping subdirectories entirely. Sul agrees to implement this restriction, abandoning the goal of decoding WAL data from any directory within the tar archive.\n\n讨论围绕为pg_waldump实现tar文件内WAL解码支持展开。Robert Haas担心缓冲大型WAL段（可能1GB+）的内存效率问题，建议让组件间的信号传递更明确，而非直接设置privateInfo->cur_wal为NULL。Amul Sul为当前方法辩护，解释archive streamer缺乏早期过滤决策的充分信息，因为必须先通过init_archive_reader()确定WAL段大小。他提议添加单独的例程来处理释放哈希条目时的内存清理。关于PaxHeaders过滤，Haas反对硬编码字符串匹配，坚持代码应只处理顶级目录文件，完全跳过子目录。Sul同意实现此限制，放弃从tar归档任何目录解码WAL数据的目标。	2026-01-23 12:27:11+00	\N
12	19beac6f0651a93f	Is abort() still needed in WalSndShutdown()?	["hlinnaka@iki.fi","masao.fujii@gmail.com"]	[{"id":"19beac6f0651a93f","messageId":"<CAHGQGwHPX1yoixq+YB5rF4zL90TMmSEa3FpHURtqW3Jc5+=oSA@mail.gmail.com>","subject":"Is abort() still needed in WalSndShutdown()?","body":"Hi,\\n\\nWhile reviewing the patch [1], I found that WalSndShutdown() calls abort()\\nwith the comment \\"keep the compiler quiet\\" just after proc_exit(0).\\n\\n        static void\\n        WalSndShutdown(void)\\n        {\\n        /*\\n        * Reset whereToSendOutput to prevent ereport from attempting to send any\\n        * more messages to the standby.\\n        */\\n        if (whereToSendOutput == DestRemote)\\n        whereToSendOutput = DestNone;\\n\\n        proc_exit(0);\\n        abort(); /* keep the compiler quiet */\\n        }\\n\\nThis may have been necessary in the past, but is it still required?\\nOther functions, such as CheckpointerMain(), simply call proc_exit(0)\\nwithout an abort(), which doesn't seem to cause compiler warnings.\\nThat made me wonder whether the abort() in WalSndShutdown() is\\nstill needed, or which compiler would actually warn if WalSndLoop()\\ndoes not end with an abort().\\n\\nThoughts?\\n\\n[1] https://postgr.es/m/d062db6a-8040-41eb-b3c9-32c3af30ef2b@postgrespro.ru\\n\\n-- \\nFujii Masao\\n\\n\\n","threadId":"19beac6f0651a93f","snippet":"Hi, While reviewing the patch [1], I found that WalSndShutdown() calls abort() with the comment \\"keep the compiler quiet\\" just after proc_exit(0). static void WalSndShutdown(void) { /* *","historyId":"12891","internalDate":"1769170438000","receivedAtUtc":"2026-01-23T12:13:58.000Z","from":"Fujii Masao <masao.fujii@gmail.com>"},{"id":"19bead5a9c7ccb09","messageId":"<796c4d50-b92b-46a7-8c07-60acb3a9b75d@iki.fi>","subject":"Re: Is abort() still needed in WalSndShutdown()?","body":"On 23/01/2026 14:13, Fujii Masao wrote:\\n> Hi,\\n> > While reviewing the patch [1], I found that WalSndShutdown() calls abort()\\n> with the comment \\"keep the compiler quiet\\" just after proc_exit(0).\\n> >          static void\\n>          WalSndShutdown(void)\\n>          {\\n>          /*\\n>          * Reset whereToSendOutput to prevent ereport from attempting to send any\\n>          * more messages to the standby.\\n>          */\\n>          if (whereToSendOutput == DestRemote)\\n>          whereToSendOutput = DestNone;\\n> >          proc_exit(0);\\n>          abort(); /* keep the compiler quiet */\\n>          }\\n> > This may have been necessary in the past, but is it still required?\\n> Other functions, such as CheckpointerMain(), simply call proc_exit(0)\\n> without an abort(), which doesn't seem to cause compiler warnings.\\n> That made me wonder whether the abort() in WalSndShutdown() is\\n> still needed, or which compiler would actually warn if WalSndLoop()\\n> does not end with an abort().\\n\\nSeems useless to me. Looking at the git history, long time ago the proc_exit(0) call was in a function that returned \\"int\\", and I can see how the compiler would complain about that if it didn't know that the function doesn't return. But WalSendShutdown() returns void these days, so you should not get a compiler warning, whether or not the compiler understands that proc_exit(0) doesn't return.\\n\\n- Heikki\\n\\n\\n\\n","threadId":"19beac6f0651a93f","snippet":"On 23/01/2026 14:13, Fujii Masao wrote: > Hi, > > While reviewing the patch [1], I found that WalSndShutdown() calls abort() > with the comment \\"keep the compiler quiet\\" just","historyId":"12891","internalDate":"1769171415000","receivedAtUtc":"2026-01-23T12:30:15.000Z","from":"Heikki Linnakangas <hlinnaka@iki.fi>"}]	Fujii Masao questions whether the abort() call in WalSndShutdown() is still necessary, noting it exists with a "keep the compiler quiet" comment after proc_exit(0). He observes that other functions like CheckpointerMain() use only proc_exit(0) without compiler warnings, making him wonder if the abort() is obsolete or which compilers would actually require it. Heikki Linnakangas responds that the abort() appears useless in the current code. He explains that historically, when proc_exit(0) was in a function returning "int", compilers might have complained without understanding that proc_exit() doesn't return. However, since WalSndShutdown() now returns void, no compiler warning should occur regardless of whether the compiler recognizes proc_exit(0) as non-returning.\n\nFujii Masao质疑WalSndShutdown()中的abort()调用是否仍然必要，注意到它在proc_exit(0)之后存在，带有"keep the compiler quiet"注释。他观察到其他函数如CheckpointerMain()只使用proc_exit(0)而没有编译器警告，这让他怀疑abort()是否已过时，或者哪些编译器实际上需要它。Heikki Linnakangas回应说abort()在当前代码中似乎是无用的。他解释说历史上当proc_exit(0)在返回"int"的函数中时，如果编译器不理解proc_exit()不返回，可能会产生警告。然而，由于WalSndShutdown()现在返回void，无论编译器是否识别proc_exit(0)为不返回，都不应该出现编译器警告。	2026-01-23 12:30:15+00	\N
12	19be597e72b87c37	Skipping schema changes in publication	["1518981153@qq.com","amit.kapila16@gmail.com","barwick@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","houzj.fnst@fujitsu.com","shlok.kyal.oss@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19be597e72b87c37","messageId":"<CANhcyEWTxqsrZsaqHwHO_eGD5=mrT=+RLGkCJ4cRvfua_fSdRQ@mail.gmail.com>","subject":"Re: Skipping schema changes in publication","body":"On Wed, 21 Jan 2026 at 17:11, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n>\\n> On Wed, Jan 21, 2026 at 4:57 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> >\\n> > On Wed, Jan 21, 2026 at 11:35 AM Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n> > >\\n> > > Thanks for explaining this, overall I like the Approach 1, and I also\\n> > > see the problem when publish via root is given in that case COPY FROM\\n> > > is executed on the root and it would be hard to exclude specific\\n> > > partitions.  What is the behavior when root of partition tree is added\\n> > > but publish via root is not true, it doesn't add any relation to\\n> > > publication rel or how does it manage to not copy data from\\n> > > partitions?\\n> > >\\n> >\\n> > So, I believe you are asking about the behavior of COPY on HEAD for\\n> > the following case:\\n> >\\n> > CREATE PUBLICATION pub1 FOR TABLE tab_root WITH\\n> > (publish_via_partition_root = false);\\n> >\\n> > In this scenario, pg_publication_rel contains an entry for tab_root,\\n> > while pg_publication_tables contains all leaf partitions (because\\n> > publish_via_partition_root = false). Consequently,\\n> > pg_subscription_rel, which is derived from pg_publication_tables, also\\n> > contains all corresponding leaf partitions.  As a result, on HEAD, a\\n> > separate tablesync worker is launched for each leaf partition, and\\n> > each leaf partition is copied independently.\\n> >\\n> > ~~\\n> >\\n> > Now, in Approach 4, when publish_via_partition_root is set to false,\\n> > we propose avoiding the inclusion of leaf partitions in\\n> > pg_publication_tables if their parent appears in the EXCEPT list.\\n> > Given the table hierarchy described in Approach1_challenges:\\n> >\\n> > tab_root\\n> > ├── tab_part_1\\n> > │   ├── tab_part_1_1\\n> > │   │   ├── tab_part_1_1_1\\n> > │   │   │   └── tab_part_1_1_1_1\\n> > │   │   └── tab_part_1_1_2\\n> > │   └── tab_part_1_2\\n> > │       ├── tab_part_1_2_1\\n> > │       └── tab_part_1_2_2\\n> > └── tab_part_2\\n> >\\n> > If tab_part_1_1 is specified in the EXCEPT list, then\\n> > pg_publication_tables will include only those leaf partitions that are\\n> > not in the partition-chain of tab_part_1_1. As a result, both\\n> > pg_publication_tables and pg_subscription_rel (which is built from\\n> > pg_publication_tables via fetch_relation_list) will contain:\\n> >\\n> > tab_part_1_2_1\\n> > tab_part_1_2_2\\n> > tab_part_2\\n> >\\n> > With this setup, any INSERT into tab_part_1 or tab_root that routes\\n> > rows to tab_part_1_1_1_1 or tab_part_1_1_2 will not be replicated.\\n> > However, rows routed to any of the three leaf partitions listed above\\n> > will be replicated.\\n> >\\n> > I hope it answers your query. If we have to go by Approach1, then do\\n> > you see any simpler way to overcome the challenges we mention for\\n> > publish_via_partition_root=true case. Or any other approach\\n> > altogether?\\n>\\n> Thanks for the explanation, that clears it up. I agree that Approach 3\\n> is the right path forward. And it makes sense to extend this with\\n> Approach 4. Logically, I think it's reasonable to say that if a user\\n> chooses to partition via the root, they are treating the entire\\n> partition tree as a single entity. Therefore, it makes sense to\\n> disallow the exclusion of individual child partitions in that context.\\n>\\nHi,\\n\\nI have prepared a patch for Approach-3. We are also checking the\\nfeasibility of other approaches.\\n\\nThanks,\\nShlok Kyal\\n","threadId":"19be597e72b87c37","snippet":"On Wed, 21 Jan 2026 at 17:11, Dilip Kumar <dilipbalaut@gmail.com> wrote: > > On Wed, Jan 21, 2026 at 4:57 PM shveta malik <shveta.malik@gmail.com> wrote: > > > > On Wed,","historyId":"5953","internalDate":"1769083465000","receivedAtUtc":"2026-01-22T12:04:25.000Z","from":"Shlok Kyal <shlok.kyal.oss@gmail.com>"},{"id":"19be96181f22b678","messageId":"<CAHut+PtKD6zoACwW61MuNBo8iqT8dc6Es4Rwqi5u7jCuEtW=Dw@mail.gmail.com>","subject":"Re: Skipping schema changes in publication","body":"Hi Shlok.\\n\\nSome review comments for v36-0001.\\n\\n======\\n1.\\nIt seems that most of my v35 public/internal review comments from\\naround 8/JAN have not been addressed in v36.\\n\\n======\\ndoc/src/sgml/ref/create_publication.sgml\\n\\nEXCEPT TABLE\\n\\n2.\\n+     <para>\\n+      For partitioned tables, only the root partitioned table may be specified\\n+      in <literal>EXCEPT TABLE</literal>. Doing so excludes the root table and\\n+      all of its partitions from replication, regardless of the value of\\n+      <literal>publish_via_partition_root</literal>. The optional\\n+      <literal>*</literal> has no effect for partitioned tables.\\n+     </para>\\n\\n2a.\\nAFAIK, the 'publish_via_partition_root' value has nothing to do with\\nEXCEPT(partition) in this patch, but why was it really necessary to\\nactually say that?\\n\\n~\\n\\n2b.\\nShould this be saying that \\"ONLY\\" also does not mean anything when a\\npartitioned table is specified?\\n\\n======\\nsrc/backend/catalog/pg_publication.c\\n\\npublication_add_relation:\\n\\n3.\\n+ /*\\n+ * Handle the case where a partition is excluded by EXCEPT TABLE\\n+ */\\n+ if (pub->alltables && pri->except && targetrel->rd_rel->relispartition)\\n+ ereport(ERROR,\\n+ (errmsg(\\"partition \\\\\\"%s\\\\\\" cannot be excluded using EXCEPT TABLE\\",\\n+ RelationGetRelationName(targetrel))));\\n\\nShould we have a hintmsg here to ask/tell the user that they might\\nneed to try EXCEPT the partitioned root instead?\\n\\n======\\nsrc/backend/commands/tablecmds.c\\n\\nATExecAttachPartition:\\n\\n4.\\n+ /* Check if the partiton is part of EXCEPT list of any publication */\\n+ GetRelationPublications(RelationGetRelid(attachrel), NULL, &except_pubids);\\n+ if (except_pubids != NIL)\\n+ ereport(ERROR,\\n+ (errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE),\\n+ errmsg(\\"cannot attach relation \\\\\\"%s\\\\\\" as partition because it is\\npart of EXCEPT list in publication\\",\\n+ RelationGetRelationName(attachrel))));\\n\\nMaybe reword the message\\n\\nSUGGESTION\\n... because it is named in a publication EXCEPT TABLE list\\n\\n======\\nsrc/backend/utils/cache/relcache.c\\n\\nRelationBuildPublicationDesc:\\n\\n5.\\n+ /*\\n+ * Only the topmost ancestor of a partitioned table can be specified\\n+ * in EXCEPT TABLES clause of a FOR ALL TABLES publication. So fetch\\n+ * the publications excluding the topmost ancestor only.\\n+ */\\n+ GetRelationPublications(llast_oid(ancestors), NULL, &exceptpuboids);\\n+\\n\\nI found that \\"So fetch...\\" sentence to be quite ambiguous.\\n\\nSUGGESTION\\n... , so we only need to check the topmost ancestor.\\n\\n======\\n.../t/037_rep_changes_except_table.pl\\n\\n6.\\n+ ALTER TABLE sch1.t1 ATTACH PARTITION sch1.part2 FOR VALUES FROM\\n(101) TO (200);\\n\\nWas there any reason to do this ALTER?\\nAFAIK, you could've said both PARTITION BY and PARTITION OF in the\\noriginal CREATE TABLE.\\n\\n~~~\\n\\n7.\\n+# Partititions cannot be excluded using EXCEPT TABLE\\n\\n7a.\\ntypo: /Partititions/Partitions/\\n\\n~\\n\\n7b.\\nTBH, I don't know if it was necessary to repeat these partition tests\\nall the time with/without publish_via_partition_root set, but if you\\nstill think it is needed, then the comment should say that all\\ncombinations are tested to demonstrate that the parameter has no\\neffect.\\n\\nMeanwhile, the same goes for all the other tests too ... Given that\\n'publish_via_partition_root' has no impact on EXCEPT TABLE, then why\\ndo we need so many combinations of tests to show that it has no\\neffect? IOW, many other parameters also have nothing to do with EXCEPT\\nTABLE, but we don't test those.\\n\\n~~~\\n\\n8.\\n+# Cannot attach partition that is part of EXCEPT list in publication\\n\\nSUGGESTION\\nCannot attach a partition  that is named in the EXCEPT list of any publication\\n\\n======\\nKind Regards,\\nPeter Smith.\\nFujitsu Australia\\n\\n\\n","threadId":"19be597e72b87c37","snippet":"Hi Shlok. Some review comments for v36-0001. ====== 1. It seems that most of my v35 public/internal review comments from around 8/JAN have not been addressed in v36. ====== doc/src/sgml/ref/","historyId":"12867","internalDate":"1769147001000","receivedAtUtc":"2026-01-23T05:43:21.000Z","from":"Peter Smith <smithpb2250@gmail.com>"},{"id":"19beafb3b3fb39e1","messageId":"<CALDaNm2x3fR+AEji0ZruTdss-4WDatraXKs1QA44eVnsBmbUiA@mail.gmail.com>","subject":"Re: Skipping schema changes in publication","body":"On Wed, 21 Jan 2026 at 11:35, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n>\\n> On Mon, Jan 19, 2026 at 3:08 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> >\\n> > Approaches for Supporting EXCEPT in Partitioned Tables\\n> > ------------------------------------------------------------------------\\n> >\\n> > In an offline discussion with Peter Smith, Amit, and Shlok, we\\n> > identified several approaches for supporting EXCEPT with partitioned\\n> > tables and their partitions. I'd like to hear others' opinions on\\n> > these approaches.\\n> >\\n> > Consider the following partition hierarchy:\\n> > tab_root\\n> >   ├─ tab_part_1\\n> >   │   ├─ tab_part_1_p1\\n> >   │   └─ tab_part_1_p2\\n> >   └─ tab_part_2\\n> >       ├─ tab_part_2_p1\\n> >       └─ tab_part_2_p2\\n> >\\n> >\\n> > Approach 1:\\n> > ---------------------------------\\n> > If we exclude a table, then the data in that table and all of its\\n> > partitions (i.e., the entire subtree under that table) should not be\\n> > replicated.\\n> >\\n> > For example EXCEPT (tab_part_1) skips replication of tab_part_1 and\\n> > all of its partitions.\\n> >\\n> > This behaviour remains the same with or without\\n> > publish_via_partition_root. The publish_via_partition_root flag only\\n> > affects publish_via_relid, i.e., the relation through which data is\\n> > published.\\n> >\\n> > This approach involves certain implementation challenges. For brevity,\\n> > these are documented in the attached 'Approach1_challenges' document.\\n> >\\n> > Approach 2:\\n> > ---------------------------------------------------\\n> > Assign meaning to ONLY and '*' for partition tables in the EXCEPT\\n> > list. In HEAD, ONLY and '*' do not have any meaning for partitioned\\n> > tables or partitions, and these keywords are currently ignored.\\n> >\\n> > Examples:\\n> > 1. EXCEPT (ONLY tab_part_1) skips replication of only the table\\n> > tab_part_1. Changes for tab_root, tab_part_1_p1, and tab_part_1_p2 are\\n> > still replicated.\\n> >\\n> > ii. EXCEPT (tab_part_1*) skips replication of tables tab_part_1,\\n> > tab_part_1_p1, and tab_part_1_p2\\n> >\\n> > The challenges described in Approach 1, particularly around tablesync\\n> > handling and COPY behaviour, would still need to be addressed under\\n> > this approach as well. ONLY or '*' with partitioned tables is not\\n> > supported in HEAD, supporting it specifically for ALL TABLES EXCEPT\\n> > may introduce additional confusion for users.\\n> >\\n> > Approach 3:\\n> > ----------------\\n> > Do not allow partitions to be specified in the EXCEPT clause.\\n> >\\n> > Only EXCEPT (tab_root) is supported, which excludes tab_root and all\\n> > of its partitions. Specifying EXCEPT (tab_part_1) or EXCEPT\\n> > (tab_part_1_p1) will result in an error.\\n> >\\n> > ~~\\n> >\\n> > While Approach 1 and Approach 2 offer more flexibility to the user\\n> > compared to Approach 3, they also introduce additional design\\n> > complexity which does not seem simpler to address.\\n>\\n> Thanks for explaining this, overall I like the Approach 1, and I also\\n> see the problem when publish via root is given in that case COPY FROM\\n> is executed on the root and it would be hard to exclude specific\\n> partitions.\\n\\nRegarding the above issue which is also mentioned in\\nApproach1_challenges at [1]:\\nWhen a publication is created with publish_via_partition_root = true\\nand a specific partition(tab_part_1_1) is excluded, the expected\\nbehavior is that changes from non-excluded partitions (for example,\\ntab_part_2 and tab_part_1_2 and their descendants) are replicated,\\nwhile changes from the excluded partition (tab_part_1_1 and its\\nsubtree) are not.\\ntab_root\\n├── tab_part_1\\n│   ├── tab_part_1_1        (except)\\n│   │   ├── tab_part_1_1_1\\n│   │   │   └── tab_part_1_1_1_1\\n│   │   └── tab_part_1_1_2\\n│   └── tab_part_1_2\\n│       ├── tab_part_1_2_1\\n│       └── tab_part_1_2_2\\n└── tab_part_2\\n\\nIn this situation, replication cannot be performed purely via the\\npartition root (tab_root), because doing so would implicitly include\\ndata from the excluded child partitions.\\n\\nTo address this, the publication creation should explicitly record the\\nexcluded partition(tab_part_1_1) in pg_publication_rel with an\\nexcluded = true flag. The publish_via_partition_root setting remains\\nstored at the publication level, as it is today. With\\npublish_via_partition_root = true, the publisher–subscriber mapping is\\nnot partition-to-partition. Instead, all eligible data is mapped to\\nthe subscriber's partition root. Therefore,\\npg_get_publication_tables() should return only the top-level root\\ntable (tab_root) to the subscriber for table synchronization. During\\ninitial table sync, when the tablesync worker prepares the COPY\\ncommand, it can query the publisher to determine the effective set of\\ntables that belong to the publication after applying the exclusion\\nrules. Based on this resolved table list, the tablesync worker can\\nconstruct a COPY query that unions data only from the non-excluded\\npartitions, for example:\\nCOPY (\\n    SELECT * FROM tab_part_1_2_1\\n    UNION ALL\\n    SELECT * FROM tab_part_1_2_2\\n    UNION ALL\\n    SELECT * FROM tab_part_2\\n)\\n\\nThis ensures that only non-excluded data is copied and applied to\\ntab_root on the subscriber, while preserving the semantics of\\npublish_via_partition_root = true.\\nThoughts?\\n\\n[1] - https://www.postgresql.org/message-id/CAJpy0uD81HRrMYr7S-6AV4W2PtbGKM-nf2D89zsoMHJ9jZssUg%40mail.gmail.com\\n\\nRegards,\\nVignesh\\n\\n\\n","threadId":"19be597e72b87c37","snippet":"On Wed, 21 Jan 2026 at 11:35, Dilip Kumar <dilipbalaut@gmail.com> wrote: > > On Mon, Jan 19, 2026 at 3:08 PM shveta malik <shveta.malik@gmail.com> wrote: > > > >","historyId":"12867","internalDate":"1769173869000","receivedAtUtc":"2026-01-23T13:11:09.000Z","from":"vignesh C <vignesh21@gmail.com>"}]	The discussion centers on implementing EXCEPT TABLE functionality for PostgreSQL publications, specifically addressing challenges with partitioned tables. Three main approaches are being evaluated: Approach 1 allows excluding any partition which excludes the entire subtree but faces implementation complexity with publish_via_partition_root=true; Approach 2 introduces ONLY and '*' keywords for granular control but adds user confusion; Approach 3 restricts EXCEPT to only root partitioned tables, avoiding complexity but reducing flexibility. The team has prepared a patch for Approach 3, with Dilip Kumar supporting this direction. Peter Smith provided detailed code review feedback on v36, noting unaddressed comments and suggesting documentation improvements. Vignesh proposed a solution for Approach 1's tablesync challenges using UNION queries for non-excluded partitions during COPY operations. The discussion involves technical considerations around pg_publication_rel, pg_publication_tables, and replication behavior consistency.\n\n讨论围绕在PostgreSQL发布中实现EXCEPT TABLE功能，特别是解决分区表的挑战。正在评估三种主要方法：方法1允许排除任何分区并排除整个子树，但在publish_via_partition_root=true时面临实现复杂性；方法2引入ONLY和'*'关键字进行精细控制，但增加了用户困惑；方法3将EXCEPT限制为仅根分区表，避免了复杂性但减少了灵活性。团队已为方法3准备了补丁，Dilip Kumar支持这个方向。Peter Smith对v36提供了详细的代码审查反馈，指出未解决的评论并建议文档改进。Vignesh为方法1的表同步挑战提出了解决方案，在COPY操作期间对非排除分区使用UNION查询。讨论涉及pg_publication_rel、pg_publication_tables和复制行为一致性的技术考虑。	2026-01-23 13:11:09+00	\N
12	19be99f7f3572d65	Non-text mode for pg_dumpall	["jian.universality@gmail.com","mahi6run@gmail.com","tushar.ahuja@enterprisedb.com","vaibhav.dalvi@enterprisedb.com"]	[{"id":"19be99f7f3572d65","messageId":"<CAC6VRoZbP=-=a+a78RoWcs2L4=4VEDZqJMg+7SyUAcSHATyDAQ@mail.gmail.com>","subject":"Re: Non-text mode for pg_dumpall","body":"On Sat, Jan 17, 2026 at 1:39 AM Mahendra Singh Thalor <mahi6run@gmail.com>\\nwrote:\\n\\n> Thanks Tushar for the testing.\\n>\\n> On Wed, 7 Jan 2026 at 13:53, tushar <tushar.ahuja@enterprisedb.com> wrote:\\n> >\\n> >\\n> >\\n> > On Tue, Jan 6, 2026 at 11:56 AM Mahendra Singh Thalor <\\n> mahi6run@gmail.com> wrote:\\n> >>\\n> >>\\n> >>\\n> >>\\n> >> We have another thread for this. We have patches also. Last year, we\\n> >> planned to block these databases at creation time.\\n> >>\\n> >> >\\n> >> > It's probably harmless, we connect to the databases further down to\\n> do actual work. But it's also not nice. The toc.glo seems to have a bunch\\n> of extraneous entries of type COMMENT and CONNECT. Why is that? As far as\\n> poible this should have output pretty much  identical to a plain pg_dumpall.\\n> >> >\\n> >> >\\n> >> > cheer\\n> >> >\\n> >> >\\n> >> > andrew\\n> >>\\n>\\n> Thanks Andrew for the feedback.\\n>\\n> In the attached patch, I fixed some comments. In the next version, I\\n> will try to make it much identical to a plain pg_dumpall.\\n>\\n> >> If we don't dump those comments in non-text format, then the output of\\n> >> \\"pg_restore -f filename dump_non_text\\" will not be the same as the\\n> >> plain dump of pg_dumpall.\\n> >>\\n> >> Here, I am attaching an updated patch for the review and testing.\\n> >>\\n> >\\n> > Hi Mahendra,\\n> >\\n> > I found a scenario  in which the table is not restored if\\n> --transaction-size switch is used  at the time of pg_restore operation\\n> >\\n> > Please refer this scenario:\\n> > Case A --pg_restore operation with \\"--transaction-size\\" against the\\n> dump (taken using pg_dump) -\\n> > create a table ( create table t(n int); )\\n> > perform pg_dump ( ./pg_dump -Ft postgres -f xyz.tar)\\n> > create a database (create database test;)\\n> > perform pg_restore using switch \\"--transaction-size\\" ( ./pg_restore\\n> --transaction-size=1 -d test xyz.tar)\\n> > table is restored into test database\\n> >\\n> > Case B --pg_restore operation with \\"--transaction-size\\" against the\\n> dump (taken using pg_dumpall) -\\n> > create a table ( create table t(n int); )\\n> > perform pg_dumpall ( ./pg_dumpall -Ft -f abc.tar)\\n> > create a new cluster, start the server against a different port\\n> > perform pg_restore using switch \\"--transaction-size\\" (./pg_restore -Ft\\n> --transaction-size=10 -d postgres abc.tar -p 9000 -C)\\n> > table is not restored\\n> >\\n> > if i remove --transaction-size switch then this works.\\n> >\\n> > regards,\\n> >\\n>\\n> Fixed.\\n>\\n> On Mon, 12 Jan 2026 at 13:39, tushar <tushar.ahuja@enterprisedb.com>\\n> wrote:\\n> >\\n> >\\n> >\\n> > On Tue, Jan 6, 2026 at 11:56 AM Mahendra Singh Thalor <\\n> mahi6run@gmail.com> wrote:\\n> >>\\n> >>\\n> >> Here, I am attaching an updated patch for the review and testing.\\n> >>\\n> >> Note: some of the review comments are still not fixed. I am working on\\n> >> those and will post an updated patch.\\n> >>\\n> > Hi Mahendra,\\n> > Please refer this scenario - if we are using with \\"--jobs\\" switch then\\n> getting an error at the time of restore\\n> >\\n> > Create a table (  create table t(n int); insert into t values (1);  )\\n> > Perform pg_dumpall ( ./pg_dumpall -Fd -f abc1.dr )\\n> > Create a new cluster, start the server against a different port\\n> > Perform pg_restore using switch \\"--jobs 4 \\" (./pg_restore -j 4 -d\\n> postgres abc1.dr/  -p 9000 -C )\\n> >\\n> > \\"\\n> > [edb@1a1c15437e7c bin]$ ./pg_restore -j 4 -d postgres abc1.dr/  -p 9000\\n> -C\\n> > pg_restore: error: could not execute query: ERROR:  role \\"edb\\" already\\n> exists\\n> > Command was: CREATE ROLE edb;\\n> > ALTER ROLE edb WITH SUPERUSER INHERIT CREATEROLE CREATEDB LOGIN\\n> REPLICATION BYPASSRLS;\\n> >\\n> >\\n> > pg_restore: error: could not execute query: ERROR:  syntax error at or\\n> near \\"\\\\\\"\\n> > LINE 1: \\\\connect template1\\n> >         ^\\n> > Command was: \\\\connect template1\\n> >\\n> >\\n> >\\n> > pg_restore: error: could not execute query: ERROR:  syntax error at or\\n> near \\"\\\\\\"\\n> > LINE 1: \\\\connect postgres\\n> >         ^\\n> > Command was: \\\\connect postgres\\n> >\\n> >\\n> >\\n> > pg_restore: warning: errors ignored on restore: 3\\n> > [edb@1a1c15437e7c bin]$\\n> > \\"\\n> >\\n> > regards,\\n>\\n> Fixed this syntax error but user error is still there for parallel\\n> mode(for non-parallel, fixed). This will be fixed in the next version.\\n>\\n> Here, I am attaching an updated patch for the review and testing.\\n>\\n>\\nThanks Mahendra, a minor  observation -  The pg_restore output shows a\\ndouble slash in the map.dat path (e.g., abc.tar//map.dat).\\nWhile it doesn't break the restore, we may want to clean up the path\\njoining logic.\\n\\n[edb@1a1c15437e7c bin]$ ./pg_restore -Ft -C abc.tar/ -d postgres -p 9011\\n -U  ed -v\\npg_restore: found database \\"template1\\n\\" (OID: 1) in file \\"abc.tar//map.dat\\"\\npg_restore: found database \\"postgres\\n\\" (OID: 5) in file \\"abc.tar//map.dat\\"\\n\\nregards,\\n","threadId":"19be99f7f3572d65","snippet":"On Sat, Jan 17, 2026 at 1:39 AM Mahendra Singh Thalor <mahi6run@gmail.com> wrote: Thanks Tushar for the testing. On Wed, 7 Jan 2026 at 13:53, tushar <tushar.ahuja@enterprisedb.com> wrote:","historyId":"12879","internalDate":"1769151077000","receivedAtUtc":"2026-01-23T06:51:17.000Z","from":"tushar <tushar.ahuja@enterprisedb.com>"},{"id":"19beb12cb27fa5c4","messageId":"<CAC6VRoY-1WC_O5UDwKzNc18LXLwjuTFb+qMNY3gaF3cCov6M6g@mail.gmail.com>","subject":"Re: Non-text mode for pg_dumpall","body":"On Fri, Jan 23, 2026 at 12:21 PM tushar <tushar.ahuja@enterprisedb.com>\\nwrote:\\n\\n>\\n> Thanks Mahendra, a minor  observation -  The pg_restore output shows a\\n> double slash in the map.dat path (e.g., abc.tar//map.dat).\\n> While it doesn't break the restore, we may want to clean up the path\\n> joining logic.\\n>\\n> [edb@1a1c15437e7c bin]$ ./pg_restore -Ft -C abc.tar/ -d postgres -p 9011\\n>  -U  ed -v\\n> pg_restore: found database \\"template1\\n> \\" (OID: 1) in file \\"abc.tar//map.dat\\"\\n> pg_restore: found database \\"postgres\\n> \\" (OID: 5) in file \\"abc.tar//map.dat\\"\\n>\\n>\\n>\\nPlease refer to this scenario where - Objects  created under template1 and\\nthe postgres database by a specific user are failing during a cross-cluster\\nrestore.\\nWhen restoring to a new cluster as a different superuser, pg_restore throws\\nthe error: ERROR: role \\"edb\\" does not exist.\\nIt appears the restore is attempting to preserve the original ownership of\\ntemplate1 objects even when the target environment lacks those specific\\nroles.\\n\\n*Steps to reproduce:*\\ninitdb ( ./initdb -U edb -D data) , start the server , connect to postgres\\nand  template1 database one by one and  create\\nthis table ( create table test(n int); )\\nperform pg_dumpall operation ( ./pg_dumpall -Ft -f abc.tar)\\ninitdb (./initdb -U xyz) , start the server , create a database ( create\\ndatabase abc;)\\nperform pg_restore operation ( ./pg_restore -Ft -C abc.tar/ -d postgres -p\\n9033 -U xyz)\\n--getting an error,  table 'test' will be created on 'template1' database\\nbut failed to create on an another database ( in this case - 'abc' database)\\n\\nregards,\\n","threadId":"19be99f7f3572d65","snippet":"On Fri, Jan 23, 2026 at 12:21 PM tushar <tushar.ahuja@enterprisedb.com> wrote: Thanks Mahendra, a minor observation - The pg_restore output shows a double slash in the map.dat path (eg, abc.tar//","historyId":"12879","internalDate":"1769175407000","receivedAtUtc":"2026-01-23T13:36:47.000Z","from":"tushar <tushar.ahuja@enterprisedb.com>"}]	The discussion centers on implementing non-text mode support for pg_dumpall, allowing it to produce binary/custom format dumps like pg_dump. Tushar is testing Mahendra's patches and reporting several issues. Key problems identified include: tables not being restored when using --transaction-size option with pg_restore, syntax errors with \\connect commands when using --jobs parallel mode, and a minor double slash issue in map.dat file paths. Additionally, cross-cluster restores fail when the target environment lacks the original roles, with pg_restore attempting to preserve original ownership of template1 objects. Mahendra has fixed some issues including the syntax errors for non-parallel mode, but parallel mode user errors and cross-cluster role ownership problems remain unresolved and require further work in upcoming patch versions.\n讨论集中在为pg_dumpall实现非文本模式支持，使其能够像pg_dump一样生成二进制/自定义格式转储。Tushar正在测试Mahendra的补丁并报告了几个问题。识别出的关键问题包括：使用pg_restore的--transaction-size选项时表未能恢复，使用--jobs并行模式时\\connect命令出现语法错误，以及map.dat文件路径中的轻微双斜杠问题。此外，当目标环境缺少原始角色时跨集群恢复失败，pg_restore尝试保留template1对象的原始所有权。Mahendra已修复了一些问题，包括非并行模式的语法错误，但并行模式用户错误和跨集群角色所有权问题仍未解决，需要在即将发布的补丁版本中进一步处理。	2026-01-23 13:36:47+00	\N
12	19beb15ac21a714b	Optimize IS DISTINCT FROM with non-nullable inputs	["guofenglinux@gmail.com"]	[{"id":"19beb15ac21a714b","messageId":"<CAMbWs49BMAOWvkdSHxpUDnniqJcEcGq3_8dd_5wTR4xrQY8urA@mail.gmail.com>","subject":"Optimize IS DISTINCT FROM with non-nullable inputs","body":"Unlike ordinary comparison operators, the IS [NOT] DISTINCT FROM\\npredicate treats NULL as a normal data value rather than \\"unknown\\".\\nFor non-null inputs, its semantics are identical to standard\\noperators: IS DISTINCT FROM is equivalent to <>, and IS NOT DISTINCT\\nFROM is equivalent to =.\\n\\nCurrently, the planner simplifies DistinctExpr only if all inputs are\\nconstants.  I'm thinking that maybe we can optimize cases where inputs\\nare non-constant but proven to be non-nullable, by converting \\"x IS\\nDISTINCT FROM y\\" to \\"x <> y\\".  This representation exposes the\\ncomparison to the planner as a standard operator.  If the clause is\\nnegated (e.g. IS NOT DISTINCT FROM), the resulting \\"=\\" operator can\\nallow the planner to use index scans, merge joins, hash joins, and\\nEC-based qual deductions.\\n\\nAttached is a draft patch for this optimization.\\n\\nI'm kind of concerned about whether there are edge cases where this\\ntransformation is not safe, specifically regarding \\"rowtype\\" inputs.\\nAny feedback would be appreciated.\\n\\n- Richard\\n","threadId":"19beb15ac21a714b","snippet":"Unlike ordinary comparison operators, the IS [NOT] DISTINCT FROM predicate treats NULL as a normal data value rather than \\"unknown\\". For non-null inputs, its semantics are identical to","historyId":"12894","internalDate":"1769175601000","receivedAtUtc":"2026-01-23T13:40:01.000Z","from":"Richard Guo <guofenglinux@gmail.com>"}]	Richard Guo proposes optimizing PostgreSQL's IS DISTINCT FROM predicate when inputs are proven non-nullable. Currently, the planner only simplifies DistinctExpr with constant inputs. The proposed optimization would convert "x IS DISTINCT FROM y" to "x <> y" and "IS NOT DISTINCT FROM" to "=" when inputs are non-nullable, since their semantics are identical for non-null values. This transformation would expose comparisons as standard operators, enabling the planner to utilize index scans, merge joins, hash joins, and equivalence class-based deductions. A draft patch is provided, though concerns remain about potential edge cases with rowtype inputs requiring further evaluation.\n\nRichard Guo 提议优化 PostgreSQL 的 IS DISTINCT FROM 谓词，当输入被证明为非空时。目前，规划器仅在输入为常量时简化 DistinctExpr。提议的优化将在输入非空时将"x IS DISTINCT FROM y"转换为"x <> y"，将"IS NOT DISTINCT FROM"转换为"="，因为对于非空值它们的语义相同。此转换将比较操作暴露为标准操作符，使规划器能够利用索引扫描、归并连接、哈希连接和等价类推导。提供了草稿补丁，但对于 rowtype 输入的潜在边界情况仍有担忧，需要进一步评估。	2026-01-23 13:40:01+00	\N
12	19be4e79751331f7	Use correct collation in pg_trgm	["geidav.pg@gmail.com","hlinnaka@iki.fi","reshkekirill@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19beb684a47b67d5","messageId":"<1981b5f0-7d06-4911-a231-23bbb6bf504c@gmail.com>","subject":"Re: Use correct collation in pg_trgm","body":"Hi!\\n\\nThanks for reviewing.\\n\\nOn 22.01.2026 07:32, Zsolt Parragi wrote:\\n> Hello!\\n> \\n> The patch is simple and it does what it says it does, I verified the\\n> difference in behavior with/without it.\\n\\nWhile reading through [1] I realized that the word boundary detection\\nalso uses the wrong collation. Patch 0002 fixes that.\\n\\n> I think the test case included in the email should be part of the\\n> patch, maybe as a new file contrib/pg_trgm/sql/pg_trgm_collation.sql?\\n> It also needs a proper commit message, and seems like the affected\\n> indexes will need a REINDEX after this fix.\\n\\n- I've added tests to 0001 and 0002 based on what each commit fixes.\\n- I've improved the commit messages.\\n\\nLooking at [2], it seems like we don't include release note changes in\\nbug fix commits but rather collect them retroactively before cutting the\\nrelease.\\n\\n[1]\\nhttps://www.postgresql.org/message-id/f30299bf-ad8e-4125-bf80-e0a8663991b6%40eisentraut.org\\n\\n[2]\\nhttps://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=fb1a18810f0\\n\\n--\\nDavid Geier","threadId":"19be4e79751331f7","snippet":"Hi! Thanks for reviewing. On 22.01.2026 07:32, Zsolt Parragi wrote: > Hello! > > The patch is simple and it does what it says it does, I verified the > difference in behavior with/without","historyId":"12862","internalDate":"1769181022000","receivedAtUtc":"2026-01-23T15:10:22.000Z","from":"David Geier <geidav.pg@gmail.com>"}]	David Geier responded to patch review feedback for fixing collation issues in pg_trgm. The original patch addressed incorrect collation usage, which reviewer Zsolt Parragi verified works as intended. Geier expanded the fix by adding a second patch (0002) that corrects word boundary detection collation after discovering this additional issue while reviewing related discussions. He incorporated the suggested test case into both patches as new test files, improved commit messages, and noted that affected indexes will require REINDEX after the fix. Geier clarified that release notes are typically added retroactively before releases rather than included in individual bug fix commits, referencing PostgreSQL development practices.\n\nDavid Geier回应了修复pg_trgm中排序规则问题的补丁审查反馈。原始补丁解决了不正确的排序规则使用，审查者Zsolt Parragi验证了其按预期工作。Geier在审查相关讨论时发现了额外问题，扩展了修复范围，添加了第二个补丁(0002)来纠正单词边界检测排序规则。他将建议的测试用例纳入两个补丁作为新测试文件，改进了提交消息，并指出受影响的索引在修复后需要重建索引。Geier澄清发布说明通常在发布前追溯添加，而不是包含在单个错误修复提交中，并引用了PostgreSQL开发实践。	2026-01-23 15:10:22+00	\N
12	19beb80a82747bcf	Auto-tune shared_buffers to use available huge pages	["anthonin.bonnefoy@datadoghq.com"]	[{"id":"19beb80a82747bcf","messageId":"<CAO6_Xqq6w5hTY_W+gJWp29t15NRtNLSTzD6khDC=Xy2P0BWPTQ@mail.gmail.com>","subject":"Auto-tune shared_buffers to use available huge pages","body":"Hi,\\n\\nUnder a normal environment, the instance's number of huge pages can be\\nadjusted to the size reported by shared_memory_size_in_huge_pages,\\nthen Postgres can be started and the requested shared memory fit in\\nthe available huge pages.\\n\\nA similar approach is harder to implement with environments like\\nkubernetes. If I want to modify the huge pages on a pod, I need to:\\n- Modify the host's huge pages\\n- Restart the host's kubelet so it detects the new amount of huge pages\\n- Modify the pod's huge page request\\n\\nMost of those steps are far from practical. An alternative would be to\\nhave a fixed number of huge pages (like 25% of the node's memory), and\\nto adjust the configuration, like the amount of shared_buffers.\\nHowever, adjusting the configuration to fit in a fixed amount of\\nmemory is tricky:\\n- shared_buffers is used to auto-tune multiple parameters so there's\\nno easy formula to get the correct amount. The only way I've found is\\nto basically increase shared_buffers until\\nshared_memory_size_in_huge_pages matches the desired amount of huge\\npages\\n- changing other parameters like max_connections mean shared_buffers\\nhas to be adjusted again\\n\\nTo help with that, the attached patch provides a new option,\\nhuge_pages_autotune_buffers, to automatically use leftover huge pages\\nas shared_buffers. This requires some changes in the auto-tune logic:\\n- Subsystems that are using shared_buffers for auto-tuning will rely\\non the configured shared_buffers, not the auto-tuned shared_buffers\\nand they should save the auto-tuned value in a GUC. This will be done\\nin dedicated auto-tune functions.\\n- Once the auto-tune functions are called, modifying NBuffers won't\\nchange the requested memory except for the shared buffer pool in\\nBufferManagerShmemSize\\n- We can get the leftover memory (free huge pages - requested memory),\\nand estimate how much shared_buffers we can add\\n- Increasing shared_buffers will also increase the freelist hashmap,\\nso the auto-tuned shared_buffers needs to be reduced\\n\\nThe patch is split in the following sub-patches:\\n\\n0001: Extract the current auto-tune logic in dedicated functions,\\nmaking the behaviour more consistent across subsystems.\\n\\n0002: The checkpointer auto-tunes the request size using NBuffers, but\\ndoesn't save the result in a GUC. This adds a new\\ncheckpoint_request_size GUC with the same auto-tune logic.\\n\\n0003: Extract HugePages_Free value when /proc/meminfo is parsed in\\nGetHugePageSize.\\n\\n0004: Pass NBuffers as parameters to StrategyShmemSize. This is\\nnecessary to get how much memory will be used by the freelist using\\n'StrategyShmemSize(candidate_nbuffers) - StrategyShmemSize(NBuffers)'.\\n\\n0005: Add BufferManagerAutotune to auto-tune the amount of shared_buffers.\\n\\nRegards,\\nAnthonin Bonnefoy\\n","threadId":"19beb80a82747bcf","snippet":"Hi, Under a normal environment, the instance's number of huge pages can be adjusted to the size reported by shared_memory_size_in_huge_pages, then Postgres can be started and the requested shared","historyId":"12895","internalDate":"1769182611000","receivedAtUtc":"2026-01-23T15:36:51.000Z","from":"Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com>"}]	Anthonin Bonnefoy proposes a new feature to automatically tune shared_buffers to utilize available huge pages in PostgreSQL. The current approach requires manually adjusting huge pages to match shared_memory_size_in_huge_pages, which is impractical in Kubernetes environments where modifying huge pages requires host changes and kubelet restarts. The proposed solution introduces a huge_pages_autotune_buffers option that automatically uses leftover huge pages as shared_buffers. The patch includes five sub-patches: extracting auto-tune logic into dedicated functions, adding a checkpoint_request_size GUC, extracting HugePages_Free values from /proc/meminfo, modifying StrategyShmemSize to accept NBuffers parameters, and implementing BufferManagerAutotune for automatic shared_buffers tuning. This would enable fixed huge page allocations while automatically adjusting PostgreSQL configuration.\n\nAnthonin Bonnefoy提出了一个新功能，用于自动调整shared_buffers以利用PostgreSQL中的可用巨页。当前方法需要手动调整巨页以匹配shared_memory_size_in_huge_pages，这在Kubernetes环境中不切实际，因为修改巨页需要更改主机并重启kubelet。提议的解决方案引入了huge_pages_autotune_buffers选项，自动使用剩余的巨页作为shared_buffers。补丁包括五个子补丁：将自动调整逻辑提取到专用函数中，添加checkpoint_request_size GUC，从/proc/meminfo提取HugePages_Free值，修改StrategyShmemSize以接受NBuffers参数，以及实现BufferManagerAutotune用于自动shared_buffers调整。这将允许固定巨页分配，同时自动调整PostgreSQL配置。	2026-01-23 15:36:51+00	\N
12	19beacbb6938d144	WIP - xmlvalidate implementation from TODO list	["jim.jones@uni-muenster.de","maguetamarcos@gmail.com","reshkekirill@gmail.com","x4mmm@yandex-team.ru"]	[{"id":"19beacbb6938d144","messageId":"<08052569-9384-41b5-bcb7-33929fcc6c71@uni-muenster.de>","subject":"Re: WIP - xmlvalidate implementation from TODO list","body":"\\n\\nOn 21/01/2026 21:44, Marcos Magueta wrote:\\n>> Any particular reason for that? If not, take a look at other options,\\n> e.g. a_expr\\n> No particular reason apart from it being simpler since I didn't need to\\n> invoke an execution at the cmd. Changed it now.\\n> \\n>> Why did you choose text over xml for schemadata?\\n> My original thought was that XML schemas require additional validation\\n> in contrast to normal XML, but it being additive, we would have\\n> redundant checks. But in reconsideration, perhaps keeping the field with\\n> an XML type is more intuitive for anyone introspecting over the catalog.\\n> Also applied the change on the latest version of the patch.\\n\\nData type for schemadata in pg_xmlschema is now xml.\\n\\npostgres=# \\\\d pg_xmlschema\\n               Table \\"pg_catalog.pg_xmlschema\\"\\n     Column      |   Type    | Collation | Nullable | Default\\n-----------------+-----------+-----------+----------+---------\\n oid             | oid       |           | not null |\\n schemaname      | name      |           | not null |\\n schemanamespace | oid       |           | not null |\\n schemaowner     | oid       |           | not null |\\n schemadata      | xml       |           | not null |\\n schemaacl       | aclitem[] |           |          |\\nIndexes:\\n    \\"pg_xmlschema_oid_index\\" PRIMARY KEY, btree (oid)\\n    \\"pg_xmlschema_name_nsp_index\\" UNIQUE CONSTRAINT, btree (schemaname,\\nschemanamespace)\\n\\nI agree it's more intuitive this way. It also facilitates function calls\\nthat require the parameter to be xml, e.g. xmlserialize\\n\\npostgres=# CREATE XMLSCHEMA x AS\\n '<xs:schema xmlns:xs=\\"http://www.w3.org/2001/XMLSchema\\"><xs:element\\nname=\\"duplicate\\" type=\\"xs:string\\"/></xs:schema>';\\nCREATE XMLSCHEMA\\n\\npostgres=# SELECT xmlserialize(DOCUMENT schemadata AS text INDENT) FROM\\npg_xmlschema;\\n                      xmlserialize\\n---------------------------------------------------------\\n <xs:schema xmlns:xs=\\"http://www.w3.org/2001/XMLSchema\\">+\\n   <xs:element name=\\"duplicate\\" type=\\"xs:string\\"/>      +\\n </xs:schema>\\n(1 row)\\n\\n\\n> I noticed DefineXmlSchema() calls IsThereXmlSchemaInNamespace() right\\n> after XmlSchemaCreate() returns a valid OID. Since XmlSchemaCreate()\\n> already inserted the tuple into the catalog (via CatalogTupleInsert at\\n> pg_xmlschema.c:166), wouldn't SearchSysCacheExists2() find it and always\\n> throw \\"already exists\\"? We all tested the original code and it worked\\n> fine, so I'm missing something about syscache visibility or timing; that\\n> was an early function I did to check for duplicates that ended up in the\\n> wrong place. I removed the call (and function) as I judged it to be\\n> redundant (the duplicate check already happens inside\\n> XmlSchemaCreate()), but is there something subtle about intra-command\\n> visibility I'm not understanding? If anyone knows, please let me know.\\n\\nI couldn't find any IsThereXmlSchemaInNamespace call in DefineXmlSchema\\nin the current version, so I cannot say much here. But I agree that the\\na further check is not necessary, since XmlSchemaCreate is already doing it.\\n\\n> Also, I added tab completion on psql and fixed pg_dump.\\n\\nNice. pg_dump now exports CREATE XMLSCHEMA statements.\\n\\nTab completion for CREATE, ALTER, and DROP XMLSCHEMA now also works.\\n\\nA few other comments\\n\\n== patch version ==\\n\\nYou forgot to include the version to the patch name.\\n\\nFor instance, instead of\\n0001-Add-CREATE-ALTER-DROP-XMLSCHEMA-DDL-commands.patch the file could\\nbe named v3-0001-Add-CREATE-ALTER-DROP-XMLSCHEMA-DDL-commands.patch\\n\\n== IS_XMLVALIDATE dependency ==\\n\\nThe patches 0001, 0002, and 0003 depend on IS_XMLVALIDATE, which is only\\nintroduced in 0004, so they cannot be compiled and tested independently.\\n\\n== permissions ==\\n\\nIn the tests I see you added a few GRANTs to set the visibility of\\ncertain xmlschemas:\\n\\nGRANT USAGE ON XMLSCHEMA permission_test_schema TO regress_xmlschema_user2\\n\\nI could not find anything regarding this in the docs. If we are to\\nsupport it, shouldn't we add it to grant.sgml?\\n\\nAs I mentioned upthread, I believe that schema registration and usage\\nshould be privilege-controlled, for example via dedicated roles\\n\\nGRANT pg_read_xmlschemas TO u;\\nGRANT pg_write_xmlschemas TO u;\\n\\nWhat do you think?\\n\\nBut being able to grant or revoke access to a certain xmlschema also has\\nits appeal :)\\n\\nBest, Jim\\n\\n\\n\\n","threadId":"19beacbb6938d144","snippet":"On 21/01/2026 21:44, Marcos Magueta wrote: >> Any particular reason for that? If not, take a look at other options, > eg a_expr > No particular reason apart from it being simpler since I","historyId":"12892","internalDate":"1769170765000","receivedAtUtc":"2026-01-23T12:19:25.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"},{"id":"19beb86bd5471dc7","messageId":"<cfd2c12a-41fb-4a8b-9b14-390e53f4c898@uni-muenster.de>","subject":"Re: WIP - xmlvalidate implementation from TODO list","body":"\\n\\nOn 23/01/2026 13:19, Jim Jones wrote:\\n> On 21/01/2026 21:44, Marcos Magueta wrote:\\n>>> Any particular reason for that? If not, take a look at other options,\\n>> e.g. a_expr\\n>> No particular reason apart from it being simpler since I didn't need to\\n>> invoke an execution at the cmd. Changed it now.\\n\\nOn second thought, is there any scenario where we'll need a_expr for \\"y\\"\\nat all in \\"CREATE XMLSCHEMA x AS y\\"? Isn't it always going to be a\\nstring? I see now that my example in the previous post was somewhat\\nmisleading (sorry for the noise).\\n\\nBest, Jim\\n\\n\\n","threadId":"19beacbb6938d144","snippet":"On 23/01/2026 13:19, Jim Jones wrote: > On 21/01/2026 21:44, Marcos Magueta wrote: >>> Any particular reason for that? If not, take a look at other options, >> eg a_expr >> No","historyId":"12892","internalDate":"1769183020000","receivedAtUtc":"2026-01-23T15:43:40.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"}]	The discussion focuses on implementing XML schema validation functionality in PostgreSQL. Jim Jones reviews changes made by Marcos Magueta to the XML schema implementation. Key updates include changing the schemadata field type from text to xml in pg_xmlschema catalog for better intuitiveness and functionality. The implementation now supports xmlserialize operations on schema data. A redundant duplicate check function was removed from DefineXmlSchema since XmlSchemaCreate already handles this validation. Additional improvements include psql tab completion and pg_dump support for CREATE XMLSCHEMA statements. Outstanding issues include missing patch versioning, dependency problems where patches 0001-0003 depend on IS_XMLVALIDATE only introduced in 0004, and questions about permission handling. Jim suggests using dedicated roles like pg_read_xmlschemas and pg_write_xmlschemas for privilege control, though individual schema-level permissions also have merit. A final clarification is requested about whether a_expr is necessary for the schema definition syntax.\n讨论重点是在PostgreSQL中实现XML模式验证功能。Jim Jones审查了Marcos Magueta对XML模式实现的修改。主要更新包括将pg_xmlschema目录中的schemadata字段类型从text改为xml，以提供更好的直观性和功能性。实现现在支持对模式数据进行xmlserialize操作。从DefineXmlSchema中删除了冗余的重复检查函数，因为XmlSchemaCreate已经处理了此验证。额外改进包括psql制表符补全和pg_dump对CREATE XMLSCHEMA语句的支持。未解决的问题包括缺少补丁版本控制、依赖问题（补丁0001-0003依赖于仅在0004中引入的IS_XMLVALIDATE）以及权限处理问题。Jim建议使用专用角色如pg_read_xmlschemas和pg_write_xmlschemas进行权限控制，尽管单独的模式级权限也有其价值。最后请求澄清模式定义语法是否需要a_expr。	2026-01-23 15:43:40+00	\N
12	19be67781ef21b94	AIX support	["peter@eisentraut.org","sriram.rk@in.ibm.com"]	[{"id":"19be67781ef21b94","messageId":"<SJ4PPFB81778326E995FAD5945ECF752FA1DB96A@SJ4PPFB81778326.namprd15.prod.outlook.com>","subject":"RE: AIX support","body":"Hi Peter,\\nThanks for looking into this and providing your feedback.\\n\\n> I took this idea of disabling static libraries in meson and made it a\\n> separate patch; see [0].  It looks like this patch is getting close to\\n> consensus, so we could commit it soon.  Then you could rebase your patch\\n> over it, which would make it quite a bit simpler.\\n\\n\\nThat's a great idea and will definitely help simplify the overall changes.\\n\\nOnce that patch is committed, I'll rebase my changes accordingly to align with the new approach.\\n\\n> I think in general, the meson changes are ok.  But I needed some\\n> changes, for example, your patch contains\\n\\nThanks for reviewing the changes.\\n\\n\\n> but the method .disabled() doesn't exist, it should be .found().  So I'm\\n> wondering how this patch was tested.\\n\\nYou're correct — the method .disabled() doesn't exist; it should be .found(). We initially tried to follow the same approach used for other dependencies (like docs, docs_pdf, gssapi), and didn't encounter any errors during testing.\\n\\nIn Meson, the option() class implements disabled(), but the disabler() object does not. When we ran a sample test, we observed that Meson's behaviour on AIX/Linux seems to ignore any unknown methods. As a result, the .disabled() conditional check was silently skipped, which explains why it didn't fail during our tests.\\n\\n\\n> Another patch of interest to you could be [1], which moves the\\n> MAXIMUM_ALIGNOF computation into c.h.  This should also simplify your\\n> patch.  But that patch has not received any discussion so far.\\nThis is a better approach. This would simplify the changes in both configure and meson.build.\\n\\n\\n> It's ok to split changes into multiple patches, and then recommend which parts you want\\n> reviewed first.  But we need to see at least a rough outline of the\\n> complete plan before spending significant effort on reviewing the pieces.\\nSure. We are working on the changes. I'll submit the full patch accordingly.\\n\\n\\nThanks again for your guidance and support!\\n\\n\\n\\nWarm regards,\\n\\nSriram.\\n\\n\\n","threadId":"19be67781ef21b94","snippet":"Hi Peter, Thanks for looking into this and providing your feedback. > I took this idea of disabling static libraries in meson and made it a > separate patch; see [0]. It looks like this patch is","historyId":"5961","internalDate":"1769098116000","receivedAtUtc":"2026-01-22T16:08:36.000Z","from":"Srirama Kucherlapati <sriram.rk@in.ibm.com>"},{"id":"19beba0a8a39c464","messageId":"<SJ4PPFB81778326EC35CBFA16B5449CFA97DB94A@SJ4PPFB81778326.namprd15.prod.outlook.com>","subject":"RE: AIX support","body":"Hi Peter,\\n\\n> It's ok to split changes into multiple patches, and then recommend which parts you want\\n> reviewed first.  But we need to see at least a rough outline of the\\n> complete plan before spending significant effort on reviewing the pieces.\\nPlease find attached patches.\\n    Meson changes    - 0001-Support-for-AIX-pg19-meson.2.diff\\n    Complete changes - 0001-Support-for-AIX.pg19.v11.patch\\n\\nWe have updated couple of changes in the full patch wrt to your previous\\ncomments as well. Also, we are working to get the stats for the s_lock.h wrt\\nTAS. Will submit in a different thread.\\n\\nKindly request you to review the meson related changes.\\n\\n\\nWarm regards,\\n\\nSriram.\\n\\n\\n\\n\\n\\n\\n","threadId":"19be67781ef21b94","snippet":"Hi Peter, > It's ok to split changes into multiple patches, and then recommend which parts you want > reviewed first. But we need to see at least a rough outline of the > complete plan","historyId":"12868","internalDate":"1769184685000","receivedAtUtc":"2026-01-23T16:11:25.000Z","from":"Srirama Kucherlapati <sriram.rk@in.ibm.com>"}]	Sriram is working on adding AIX support to PostgreSQL and responding to Peter's feedback on the patch submission. Peter suggested separating the meson static library disabling into a standalone patch that's nearing consensus, which would simplify Sriram's AIX changes when rebased. Peter identified a bug where `.disabled()` method was used instead of `.found()` in the meson configuration. Sriram acknowledged this error, explaining they followed patterns from other dependencies and that Meson silently ignored the unknown method during testing on AIX/Linux. Peter also referenced another relevant patch for MAXIMUM_ALIGNOF computation that could further simplify the changes. Sriram provided updated patches including both meson-specific changes and complete AIX support modifications, and committed to submitting a comprehensive plan before requesting detailed reviews.\n\nSriram正在为PostgreSQL添加AIX支持，并回应Peter对补丁提交的反馈。Peter建议将meson静态库禁用功能分离为一个独立补丁，该补丁即将达成共识，这将简化Sriram在变基时的AIX更改。Peter发现了一个错误，即在meson配置中使用了`.disabled()`方法而不是`.found()`。Sriram承认了这个错误，解释说他们遵循了其他依赖项的模式，而Meson在AIX/Linux测试期间静默忽略了未知方法。Peter还引用了另一个关于MAXIMUM_ALIGNOF计算的相关补丁，可以进一步简化更改。Sriram提供了更新的补丁，包括meson特定的更改和完整的AIX支持修改，并承诺在请求详细审查之前提交一个全面的计划。	2026-01-23 16:11:25+00	\N
12	19be86e8f63a302d	More speedups for tuple deformation	["andres@anarazel.de","dgrowleyml@gmail.com","li.evan.chao@gmail.com"]	[{"id":"19be86e8f63a302d","messageId":"<pmik622adey6fnddivkt4uvkulvnc6rasmq3tcbrzeglx4hsn7@f3x6e2eph3w5>","subject":"Re: More speedups for tuple deformation","body":"Hi,\\n\\nI haven't yet looked at the new version of the patch, but I ran your benchmark\\nfrom upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results\\nseem stable enough anyway) on two intel machines, as you mentioned that you\\nsaw a lot variation in Azure.\\n\\nFor both I disabled turbo boost, cpu idling and pinned the backend to a single\\nCPU core.\\n\\nThere's a bit of noise on \\"awork3\\" (basically an editor and an idle browser\\nwindow), but everything is pinned to the other socket. \\"awork4\\" is entirely\\nidle.\\n\\n\\nLooks like overall the results are quite impressive!  Some of the extra_cols=0\\nruns saphire rapids are a bit slower, but the losses are much smaller than the\\ngains in other cases.\\n\\n\\nI think it'd be good to add a few test cases of \\"incremental deforming\\" to the\\nbenchmark. E.g. a qual that accesses column 10, but projection then deforms up\\nto 20.  I'm a bit worried that e.g. the repeated first_null_attr()\\ncomputations could cause regressions.\\n\\n\\nGreetings,\\n\\nAndres Freund\\n","threadId":"19be86e8f63a302d","snippet":"Hi, I haven't yet looked at the new version of the patch, but I ran your benchmark from upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results seem stable enough anyway) on two","historyId":"8740","internalDate":"1769131101000","receivedAtUtc":"2026-01-23T01:18:21.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19be954d8c090dc0","messageId":"<82AD055C-3280-4DFB-ADA8-A7A4DE3844A5@gmail.com>","subject":"Re: More speedups for tuple deformation","body":"\\n\\n> On Jan 23, 2026, at 09:18, Andres Freund <andres@anarazel.de> wrote:\\n> \\n> Hi,\\n> \\n> I haven't yet looked at the new version of the patch, but I ran your benchmark\\n> from upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results\\n> seem stable enough anyway) on two intel machines, as you mentioned that you\\n> saw a lot variation in Azure.\\n> \\n> For both I disabled turbo boost, cpu idling and pinned the backend to a single\\n> CPU core.\\n> \\n> There's a bit of noise on \\"awork3\\" (basically an editor and an idle browser\\n> window), but everything is pinned to the other socket. \\"awork4\\" is entirely\\n> idle.\\n> \\n> \\n> Looks like overall the results are quite impressive!  Some of the extra_cols=0\\n> runs saphire rapids are a bit slower, but the losses are much smaller than the\\n> gains in other cases.\\n> \\n> \\n> I think it'd be good to add a few test cases of \\"incremental deforming\\" to the\\n> benchmark. E.g. a qual that accesses column 10, but projection then deforms up\\n> to 20.  I'm a bit worried that e.g. the repeated first_null_attr()\\n> computations could cause regressions.\\n> \\n> \\n> Greetings,\\n> \\n> Andres Freund\\n> <deform_bench.csv>\\n\\nToday I ran the benchmark on my MacBook M4 against 3 versions (all without assert and with -O2):\\n\\n1) Master (f9a468c664a)\\n2) Master + v4\\n3) Master + v4 + My tweak (first_null_attr immediately returns 0 when natts == 0)\\n\\nOverall, v4 shows significant improvements across most configuration combinations. In the best case, v4 is about 43% faster than master.\\n\\nThe tweak version is only slightly faster than v4. In the best case, the tweak achieves an additional ~3.5% improvement over v4.\\n\\nNote that the MacBook is my working laptop. I didn't actively work on it while the tests were running, but it was still not fully idle, as some other applications (Email, VScode, etc.) were running in the background. That said, I suppose this is still fair for the three rounds of test runs.\\n\\nSee the attached Excel sheet for details.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n","threadId":"19be86e8f63a302d","snippet":"> On Jan 23, 2026, at 09:18, Andres Freund <andres@anarazel.de> wrote: > > Hi, > > I haven't yet looked at the new version of the patch, but I ran your benchmark > from","historyId":"12874","internalDate":"1769146162000","receivedAtUtc":"2026-01-23T05:29:22.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19bebb44f89e0b11","messageId":"<rvlc7pb6zn4kydqovcqh72lf2qfcgs3qkj2seq7tcpvxyqwtqt@nrvv6lpehwwa>","subject":"Re: More speedups for tuple deformation","body":"Hi,\\n\\nOn 2026-01-22 20:18:21 -0500, Andres Freund wrote:\\n> I haven't yet looked at the new version of the patch, but I ran your benchmark\\n> from upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results\\n> seem stable enough anyway) on two intel machines, as you mentioned that you\\n> saw a lot variation in Azure.\\n>\\n> For both I disabled turbo boost, cpu idling and pinned the backend to a single\\n> CPU core.\\n>\\n> There's a bit of noise on \\"awork3\\" (basically an editor and an idle browser\\n> window), but everything is pinned to the other socket. \\"awork4\\" is entirely\\n> idle.\\n>\\n>\\n> Looks like overall the results are quite impressive!  Some of the extra_cols=0\\n> runs saphire rapids are a bit slower, but the losses are much smaller than the\\n> gains in other cases.\\n>\\n>\\n> I think it'd be good to add a few test cases of \\"incremental deforming\\" to the\\n> benchmark. E.g. a qual that accesses column 10, but projection then deforms up\\n> to 20.  I'm a bit worried that e.g. the repeated first_null_attr()\\n> computations could cause regressions.\\n\\nThe overhead of the aggregation etc makes it harder to see efficiency changes\\nin deformation speed:\\n\\nI think it'd be worth replacing the SUM(a) with WHERE a < 0 (filtering all\\nrows), to reduce the cost of the executor dispatch.\\n\\nHere's a profile of the SUM(a):\\n\\n-   99.90%     0.00%  postgres         postgres           [.] standard_ExecutorRun\\n   - standard_ExecutorRun\\n      - 96.83% ExecAgg\\n         - 49.86% ExecInterpExpr\\n            - 28.30% slot_getsomeattrs_int\\n                 tts_buffer_heap_getsomeattrs\\n              0.67% tts_buffer_heap_getsomeattrs\\n            + 0.02% asm_sysvec_apic_timer_interrupt\\n         - 37.44% fetch_input_tuple\\n            - 31.42% ExecSeqScan\\n               + 20.58% heap_getnextslot\\n                 3.58% MemoryContextReset\\n                 0.52% heapgettup_pagemode\\n                 0.32% ExecStoreBufferHeapTuple\\n              0.99% heap_getnextslot\\n              0.79% MemoryContextReset\\n           2.81% int4_sum\\n           1.39% MemoryContextReset\\n\\nWhich takes ~93ms on average for the first generated bench.sql\\n\\n\\n-   99.88%     0.00%  postgres  postgres           [.] standard_ExecutorRun\\n   - standard_ExecutorRun\\n      - 95.78% ExecSeqScanWithQual\\n         - 57.65% ExecInterpExpr\\n            - 29.08% slot_getsomeattrs_int\\n                 tts_buffer_heap_getsomeattrs\\n              0.49% tts_buffer_heap_getsomeattrs\\n         - 25.40% heap_getnextslot\\n            + 15.00% heapgettup_pagemode\\n            + 4.71% ExecStoreBufferHeapTuple\\n              0.05% UnlockBuffer\\n           1.80% MemoryContextReset\\n           0.77% int4lt\\n           0.52% heapgettup_pagemode\\n           0.47% ExecStoreBufferHeapTuple\\n           0.37% slot_getsomeattrs_int\\n        2.11% heap_getnextslot\\n        1.49% ExecInterpExpr\\n        0.50% MemoryContextReset\\n\\nSame data, but with a WHERE a < 0, takes on average ~74m.\\n\\n\\nI wonder if it's worth writing a C helper to test deformation in a bit more\\ntargeted way.\\n\\n\\nLooking at the profile of ExecSeqScanWithQual() made me a bit sad, turns out\\nthat some of the generated code isn't great :(. I'll start a separate thread\\nabout that.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19be86e8f63a302d","snippet":"Hi, On 2026-01-22 20:18:21 -0500, Andres Freund wrote: > I haven't yet looked at the new version of the patch, but I ran your benchmark > from upthread (fwiw, I removed the sleep 10 to reduce","historyId":"12874","internalDate":"1769186006000","receivedAtUtc":"2026-01-23T16:33:26.000Z","from":"Andres Freund <andres@anarazel.de>"}]	This discussion focuses on performance improvements for tuple deformation in PostgreSQL. Andres Freund tested a benchmark on Intel machines with controlled conditions (disabled turbo boost, CPU pinning) and found impressive overall results, though some configurations showed minor slowdowns. Chao Li tested version 4 of the patch on a MacBook M4, achieving up to 43% performance gains over master, with an additional small optimization providing ~3.5% further improvement. Andres suggests adding incremental deforming test cases to address potential regressions from repeated first_null_attr() computations. He also recommends modifying the benchmark to use filtering (WHERE a < 0) instead of aggregation (SUM) to better isolate deformation performance, noting that executor overhead obscures efficiency changes. Profiling shows significant time spent in slot_getsomeattrs_int and suggests a targeted C helper for more focused deformation testing.\n这个讨论专注于PostgreSQL中元组解构性能改进。Andres Freund在受控条件下（禁用睿频，CPU绑定）的Intel机器上测试基准，发现总体结果令人印象深刻，尽管某些配置显示轻微性能下降。Chao Li在MacBook M4上测试补丁第4版，相比主分支实现了高达43%的性能提升，额外的小优化提供了约3.5%的进一步改进。Andres建议添加增量解构测试用例以解决repeated first_null_attr()计算可能导致的性能回退。他还建议修改基准测试使用过滤（WHERE a < 0）而非聚合（SUM）来更好地隔离解构性能，指出执行器开销掩盖了效率变化。性能分析显示大量时间花费在slot_getsomeattrs_int上，建议使用针对性的C辅助程序进行更专注的解构测试。	2026-01-23 16:33:26+00	\N
12	19bebbb1bd6c2d07	Proposal: Adding compression of temporary files	["fjanus@redhat.com","lakshmigcdac@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bebbb1bd6c2d07","messageId":"<CAFjYY+LMTciR=3SLh+8EbAFjumQTrcTKbyU703Srzy3j_yEhSw@mail.gmail.com>","subject":"Re: Proposal: Adding compression of temporary files","body":"Hi all,\\nThanks for the feedback and the provided patch.\\nI've addressed your findings and proposals. Lakshmi's documentation patch\\nwas incorporated.\\n\\n    -Filip-\\n\\n\\nst 21. 1. 2026 v 7:30 odesílatel lakshmi <lakshmigcdac@gmail.com> napsal:\\n\\n> HI all,\\n> While testing the temp file compression patch,noticed that the new\\n> temp_file_compression GUC isn't documented yet.I put together a small docs\\n> patch to add a short description and clarify that the effect of compression\\n> depends on the workload(for example ,hash join spills may not show visible\\n> size reduction due to fixed_size chunks).\\n>\\n> patch is attached.Happy to adjust the wording if needed.\\n> thanks,\\n> lakshmi\\n>\\n> On Tue, Jan 20, 2026 at 4:21 PM lakshmi <lakshmigcdac@gmail.com> wrote:\\n>\\n>> Hi Filip,\\n>>\\n>> I tested both patches on current master using git am -3 .They apply\\n>> cleanly,build fine,and the temp_file _compression GUC works as expected.\\n>> Query results are unchanged.\\n>>\\n>> For hash join spill test,temp files were created as expected,but the\\n>> logged size were same for no,lz4,and pglz,which seems consistent with\\n>> fixed-size fileset chunking.It might be helpful to briefly note this in the\\n>> documentation to avoid confusion.\\n>>\\n>> Thanks for working on this .\\n>> best regards,\\n>> lakshmi\\n>>\\n>> On Tue, Jan 20, 2026 at 4:10 AM Zsolt Parragi <zsolt.parragi@percona.com>\\n>> wrote:\\n>>\\n>>> Hello!\\n>>>\\n>>> I tried to review the code. It compiled, the test suite passed.\\n>>>\\n>>> I noticed two typos:\\n>>>\\n>>> buffile.c:77 - \\"Disaled\\"\\n>>> buffile.c:133 - \\"mathods\\"\\n>>>\\n>>> And a few other small findings:\\n>>>\\n>>> buffile.h:35 and buffile.c:63 - same constants defined first as an\\n>>> Enum and then as #defines - code builds properly without the defines.\\n>>>\\n>>> buffile.c:121 - compress_tempfile is defined, set to false at :167,\\n>>> but never used otherwise\\n>>>\\n>>> guc_tables.c:470 - the comment says that pglz isn't supported yet, but\\n>>> we have a value for it, and I see support for it in the code\\n>>>\\n>>> buffile.c:659: (and at other places) if USE_LZ4 is undefined, the\\n>>> codepath doesn't do anything. I think these ifdefs should follow how\\n>>> other compression code works, such as wal compression where there's an\\n>>> #else path with elog(ERROR, ...)\\n>>> Similarly, maybe there should be an explicit TEMP_NONE_COMPRESSION\\n>>> branch that does nothing, and the default branch should be an error?\\n>>>\\n>>> buffile.c:265: If seek isn't supported/limited, shouldn't there be at\\n>>> least an assertion about it in BufFileSeek? And tell isn't mentioned,\\n>>> but it seems to me that tell also doesn't work properly.\\n>>>\\n>>\\n","threadId":"19bebbb1bd6c2d07","snippet":"Hi all, Thanks for the feedback and the provided patch. I've addressed your findings and proposals. Lakshmi's documentation patch was incorporated. -Filip- st 21. 1. 2026 v 7:30 odesílatel","historyId":"12898","internalDate":"1769186432000","receivedAtUtc":"2026-01-23T16:40:32.000Z","from":"Filip Janus <fjanus@redhat.com>"}]	Filip Janus responded to feedback on his PostgreSQL temporary file compression patch proposal. He incorporated Lakshmi's documentation patch for the new temp_file_compression GUC parameter. Lakshmi had tested the patches successfully and noted that hash join spills showed no visible size reduction due to fixed-size chunking, suggesting documentation should clarify workload-dependent compression effects. Zsolt Parragi provided code review feedback identifying typos, redundant constant definitions, an unused variable, inconsistent comments about pglz support, missing error handling for undefined USE_LZ4, and concerns about seek/tell functionality limitations with compressed temporary files.\nFilip Janus回应了关于PostgreSQL临时文件压缩补丁提案的反馈。他整合了Lakshmi为新的temp_file_compression GUC参数编写的文档补丁。Lakshmi已成功测试补丁并注意到由于固定大小分块，哈希连接溢出没有显示明显的大小减少，建议文档应澄清与工作负载相关的压缩效果。Zsolt Parragi提供了代码审查反馈，指出了拼写错误、冗余常量定义、未使用变量、关于pglz支持的不一致注释、未定义USE_LZ4时缺少错误处理，以及对压缩临时文件seek/tell功能限制的担忧。	2026-01-23 16:40:32+00	\N
12	19be696a3fcf6343	Fix rounding method used to compute huge pages	["anthonin.bonnefoy@datadoghq.com","ashutosh.bapat.oss@gmail.com","michael@paquier.xyz","nathandbossart@gmail.com"]	[{"id":"19be696a3fcf6343","messageId":"<CAO6_Xqq2vZbva0R9eQSY0p2kfksX2aP4r=+Z_q1HBYNU=m8bBg@mail.gmail.com>","subject":"Fix rounding method used to compute huge pages","body":"Hi,\\n\\nWhen computing the dynamic value of shared_memory_size_in_huge_pages,\\n(1+size_b/hp_size) is currently used. This works when size_b is not\\ndivisible by hp_size. However, it will yield an additional huge page\\nwhen size_b is divisible by hp_size.\\n\\nOn CreateAnonymousSegment's side, the allocation size is rounded up to\\nthe next required huge pages when necessary. However, there's no\\noverflow check when doing this round up.\\n\\n0001: This patch replicates CreateAnonymousSegment's rounding method\\nto InitializeShmemGUCs, only rounding up when the value is not\\ndivisible by hp_size.\\n\\n0002: This patch uses add_size in CreateAnonymousSegment when the\\nallocation size is rounded up, to check for possible overflow.\\n\\nRegards,\\nAnthonin Bonnefoy\\n","threadId":"19be696a3fcf6343","snippet":"Hi, When computing the dynamic value of shared_memory_size_in_huge_pages, (1+size_b/hp_size) is currently used. This works when size_b is not divisible by hp_size. However, it will yield an additional","historyId":"5962","internalDate":"1769100164000","receivedAtUtc":"2026-01-22T16:42:44.000Z","from":"Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com>"},{"id":"19be6c2d55989191","messageId":"<CAExHW5tSm7=dH9wnV6McXeqw5C6_Kcv1Oa3QPsroSOpeoLA8xA@mail.gmail.com>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Thu, Jan 22, 2026 at 10:13 PM Anthonin Bonnefoy\\n<anthonin.bonnefoy@datadoghq.com> wrote:\\n>\\n> Hi,\\n>\\n> When computing the dynamic value of shared_memory_size_in_huge_pages,\\n> (1+size_b/hp_size) is currently used. This works when size_b is not\\n> divisible by hp_size. However, it will yield an additional huge page\\n> when size_b is divisible by hp_size.\\n>\\n> On CreateAnonymousSegment's side, the allocation size is rounded up to\\n> the next required huge pages when necessary. However, there's no\\n> overflow check when doing this round up.\\n>\\n> 0001: This patch replicates CreateAnonymousSegment's rounding method\\n> to InitializeShmemGUCs, only rounding up when the value is not\\n> divisible by hp_size.\\n>\\n> 0002: This patch uses add_size in CreateAnonymousSegment when the\\n> allocation size is rounded up, to check for possible overflow.\\n\\nWe have similar incantation in CalculateShmemSize()\\nsize = add_size(size, 8192 - (size % 8192));\\n\\nI think we should just introduce a method ceil_size() and place it\\nnear add_size() and mul_size() and use wherever we are rounding the\\nsizes.\\nSize\\nceil_size(size, base)\\n{\\nreturn add_size(size, base - (size % base))\\n}\\n\\nInitializeShmemGUCs() also has following line, which can can be\\nreplaced with ceil_size(size_b, 1024 * 1024)\\nsize_mb = add_size(size_b, (1024 * 1024) - 1) / (1024 * 1024);\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"On Thu, Jan 22, 2026 at 10:13 PM Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com> wrote: > > Hi, > > When computing the dynamic value of shared_memory_size_in_huge_pages, > (1+","historyId":"5962","internalDate":"1769103061000","receivedAtUtc":"2026-01-22T17:31:01.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19be79825c6720e4","messageId":"<aXKVfaTntXRn1V0m@nathan>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Thu, Jan 22, 2026 at 05:42:44PM +0100, Anthonin Bonnefoy wrote:\\n> When computing the dynamic value of shared_memory_size_in_huge_pages,\\n> (1+size_b/hp_size) is currently used. This works when size_b is not\\n> divisible by hp_size. However, it will yield an additional huge page\\n> when size_b is divisible by hp_size.\\n\\nOops, it looks like this is my fault.  I doubt this causes any practical\\nproblems, but we might as well fix it.\\n\\n+\\t\\tif (size_b % hp_size != 0)\\n+\\t\\t\\tsize_b = add_size(size_b, hp_size - (size_b % hp_size));\\n+\\t\\thp_required = size_b / hp_size;\\n\\nI think we could simplify this a tad:\\n\\n\\thp_required = size_b / hp_size;\\n\\tif (size_b % hp_size != 0)\\n\\t\\thp_required = add_size(hp_required, 1);\\n\\n> 0002: This patch uses add_size in CreateAnonymousSegment when the\\n> allocation size is rounded up, to check for possible overflow.\\n\\nSeems reasonable.\\n\\n-- \\nnathan\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"On Thu, Jan 22, 2026 at 05:42:44PM +0100, Anthonin Bonnefoy wrote: > When computing the dynamic value of shared_memory_size_in_huge_pages, > (1+size_b/hp_size) is currently used. This works when","historyId":"8714","internalDate":"1769117053000","receivedAtUtc":"2026-01-22T21:24:13.000Z","from":"Nathan Bossart <nathandbossart@gmail.com>"},{"id":"19be7f4063db5c26","messageId":"<aXKs_Y4NucBznm0j@paquier.xyz>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Thu, Jan 22, 2026 at 03:24:13PM -0600, Nathan Bossart wrote:\\n> Oops, it looks like this is my fault.  I doubt this causes any practical\\n> problems, but we might as well fix it.\\n\\nAnd it's something I have committed.\\n\\n> +\\t\\tif (size_b % hp_size != 0)\\n> +\\t\\t\\tsize_b = add_size(size_b, hp_size - (size_b % hp_size));\\n> +\\t\\thp_required = size_b / hp_size;\\n> \\n> I think we could simplify this a tad:\\n> \\n> \\thp_required = size_b / hp_size;\\n> \\tif (size_b % hp_size != 0)\\n> \\t\\thp_required = add_size(hp_required, 1);\\n\\nFWIW, we have always been kind of sloppy with slightly overestimating\\nthe shmem size required in the backend code, and here it's just a one.\\nI don't see a strong need for a backpatch here.  Of course, no\\nobjections in adjusting that on HEAD.  Nathan, you are planning to\\ntake care of that as original author?  This should fall under my\\nbucket as original committer, but as you were an author, feel free to\\ntake priority here of course.\\n--\\nMichael\\n","threadId":"19be696a3fcf6343","snippet":"On Thu, Jan 22, 2026 at 03:24:13PM -0600, Nathan Bossart wrote: > Oops, it looks like this is my fault. I doubt this causes any practical > problems, but we might as well fix it. And it's","historyId":"8714","internalDate":"1769123069000","receivedAtUtc":"2026-01-22T23:04:29.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be7f922ba5d2eb","messageId":"<aXKuUOhBzjb6ovtz@nathan>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Fri, Jan 23, 2026 at 08:04:29AM +0900, Michael Paquier wrote:\\n> FWIW, we have always been kind of sloppy with slightly overestimating\\n> the shmem size required in the backend code, and here it's just a one.\\n> I don't see a strong need for a backpatch here.  Of course, no\\n> objections in adjusting that on HEAD.\\n\\nAgreed.\\n\\n> Nathan, you are planning to\\n> take care of that as original author?  This should fall under my\\n> bucket as original committer, but as you were an author, feel free to\\n> take priority here of course.\\n\\nI'll take care of it (likely tomorrow).\\n\\n-- \\nnathan\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"On Fri, Jan 23, 2026 at 08:04:29AM +0900, Michael Paquier wrote: > FWIW, we have always been kind of sloppy with slightly overestimating > the shmem size required in the backend code, and here","historyId":"8714","internalDate":"1769123408000","receivedAtUtc":"2026-01-22T23:10:08.000Z","from":"Nathan Bossart <nathandbossart@gmail.com>"},{"id":"19be7fba2e5319c3","messageId":"<aXKu8XtDhDAvqj5X@paquier.xyz>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Thu, Jan 22, 2026 at 05:10:08PM -0600, Nathan Bossart wrote:\\n> I'll take care of it (likely tomorrow).\\n\\nThanks!\\n--\\nMichael\\n","threadId":"19be696a3fcf6343","snippet":"On Thu, Jan 22, 2026 at 05:10:08PM -0600, Nathan Bossart wrote: > I'll take care of it (likely tomorrow). Thanks! -- Michael","historyId":"8714","internalDate":"1769123569000","receivedAtUtc":"2026-01-22T23:12:49.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be9f26259a1fe7","messageId":"<CAO6_Xqp8NVAeNuDgWaMW_+AKHSQTC4nARbJVW23DkXT6KGh81Q@mail.gmail.com>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Thu, Jan 22, 2026 at 10:24 PM Nathan Bossart\\n<nathandbossart@gmail.com> wrote:\\n> Oops, it looks like this is my fault.  I doubt this causes any practical\\n> problems, but we might as well fix it.\\n\\nYeah, the chance of this being a problem is pretty low.\\n\\n> +               if (size_b % hp_size != 0)\\n> +                       size_b = add_size(size_b, hp_size - (size_b % hp_size));\\n> +               hp_required = size_b / hp_size;\\n>\\n> I think we could simplify this a tad:\\n>\\n>         hp_required = size_b / hp_size;\\n>         if (size_b % hp_size != 0)\\n>                 hp_required = add_size(hp_required, 1);\\n\\nFrom my understanding, 'add_size(hp_required, 1)' will never overflow\\nsince size_b was checked for overflow, and hp_size should always be >1\\n(except if huge pages of 1 byte exist somewhere).\\n\\nFor consistency with CreateAnonymousSegment, using 'add_size(size_b,\\nhp_size - (size_b % hp_size))' will also check that the final\\nrequested allocation doesn't overflow.\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"On Thu, Jan 22, 2026 at 10:24 PM Nathan Bossart <nathandbossart@gmail.com> wrote: > Oops, it looks like this is my fault. I doubt this causes any practical > problems, but we might as well","historyId":"12869","internalDate":"1769156513000","receivedAtUtc":"2026-01-23T08:21:53.000Z","from":"Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com>"},{"id":"19bebc2c33dc3ee4","messageId":"<aXOmjM69GVTbzhGE@nathan>","subject":"Re: Fix rounding method used to compute huge pages","body":"Committed.\\n\\nOn Fri, Jan 23, 2026 at 09:21:53AM +0100, Anthonin Bonnefoy wrote:\\n> From my understanding, 'add_size(hp_required, 1)' will never overflow\\n> since size_b was checked for overflow, and hp_size should always be >1\\n> (except if huge pages of 1 byte exist somewhere).\\n\\nThat's true, but for this sort of thing, I usually prefer to avoid relying\\non those kinds of assumptions to reason about the correctness of the code.\\nThe overflow check costs little, and IIUC this function is run exactly once\\nfor the lifetime of the server.\\n\\n> For consistency with CreateAnonymousSegment, using 'add_size(size_b,\\n> hp_size - (size_b % hp_size))' will also check that the final\\n> requested allocation doesn't overflow.\\n\\n*shrug*  I don't see a strong reason for consistency here.  AFAICT you'd\\nhave to be trying to allocate something like 18 exabytes on most systems\\nfor there to be a problem, at which point there are probably bigger issues\\nto sort out.\\n\\nThanks for the patch!\\n\\n-- \\nnathan\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"Committed. On Fri, Jan 23, 2026 at 09:21:53AM +0100, Anthonin Bonnefoy wrote: > From my understanding, 'add_size(hp_required, 1)' will never overflow > since size_b was checked for","historyId":"12869","internalDate":"1769186956000","receivedAtUtc":"2026-01-23T16:49:16.000Z","from":"Nathan Bossart <nathandbossart@gmail.com>"}]	Anthonin Bonnefoy reported a rounding bug in PostgreSQL's huge page computation where the formula (1+size_b/hp_size) allocates an unnecessary extra huge page when size_b is divisible by hp_size. He proposed two patches: fixing the rounding method in InitializeShmemGUCs to match CreateAnonymousSegment's approach, and adding overflow checks using add_size. Nathan Bossart acknowledged introducing the bug and suggested a simpler implementation using hp_required = add_size(hp_required, 1) when there's a remainder. Ashutosh Bapat recommended creating a generic ceil_size() function for consistent rounding across the codebase. Michael Paquier noted that PostgreSQL has historically overestimated shared memory requirements and saw no need for backpatching this minor issue to stable branches. Nathan committed the fix, choosing his simpler approach over exact consistency with CreateAnonymousSegment, reasoning that overflow protection is unnecessary given the astronomical allocation sizes required to trigger problems.\n\nAnthonin Bonnefoy报告了PostgreSQL巨页计算中的舍入错误，当size_b能被hp_size整除时，公式(1+size_b/hp_size)会分配一个不必要的额外巨页。他提出了两个补丁：修复InitializeShmemGUCs中的舍入方法以匹配CreateAnonymousSegment的方法，并使用add_size添加溢出检查。Nathan Bossart承认引入了这个bug，并建议在有余数时使用hp_required = add_size(hp_required, 1)的更简单实现。Ashutosh Bapat建议创建一个通用的ceil_size()函数以在代码库中保持一致的舍入。Michael Paquier指出PostgreSQL历史上一直高估共享内存需求，认为没必要将这个小问题回溯到稳定分支。Nathan提交了修复，选择了他的简化方法而非与CreateAnonymousSegment保持完全一致，理由是考虑到触发问题需要天文数字级的分配大小，溢出保护是不必要的。	2026-01-23 16:49:16+00	\N
12	19be5345d4172528	Import Statistics in postgres_fdw before resorting to sampling.	["ashutosh.bapat.oss@gmail.com","corey.huinker@gmail.com","etsuro.fujita@gmail.com","jkatz@postgresql.org","michael@paquier.xyz","nathandbossart@gmail.com"]	[{"id":"19be57795c6119b8","messageId":"<CAExHW5uTy=xbdsjKO6kHE3Oc=5O5L_Fy-UPmBGkUW2aQPuiirA@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":"On Thu, Jan 22, 2026 at 3:45 PM Ashutosh Bapat\\n<ashutosh.bapat.oss@gmail.com> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote:\\n> >>\\n> >> Changes in this release, aside from rebasing:\\n> >>\\n> >> - The generic analyze and fdw.h changes are in their own patch (0001) that ignores contrib/postgres_fdw entirely.\\n> >> - The option for remote_analyze has been moved to its own patch (0003).\\n> >> - The errors raised are now warnings, to ensure that we can always fall back to row sampling.\\n> >> - All local attributes with attstatarget > 0 must get matching remote statistics or the import is considered a failure.\\n> >> - The pg_restore_attribute_stats() call has been turned into a prepared statement, for clarity and some minor parsing savings.\\n> >> - The calls to pg_restore_relation_stats() are parameterized, but not prepared as this is rarely called more than once.\\n> >> - postgresStatisticsAreImportable will now disqualify a table if has extended statistics objects, because we can't compute those without a row sample.\\n> >\\n\\nThe patches fail to build the document. Attached diff fixes that.\\n\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be5345d4172528","snippet":"On Thu, Jan 22, 2026 at 3:45 PM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> wrote: > > On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote: > >>","historyId":"5947","internalDate":"1769081352000","receivedAtUtc":"2026-01-22T11:29:12.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19be7cba13ebe755","messageId":"<CADkLM=cibnjxisDXkVUMwTVWBO3Px5a-crcQXweQmVr_PHRCJA@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":"On Thu, Jan 22, 2026 at 5:16 AM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>\\nwrote:\\n\\n> On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com>\\n> wrote:\\n> >>\\n> >> Changes in this release, aside from rebasing:\\n> >>\\n> >> - The generic analyze and fdw.h changes are in their own patch (0001)\\n> that ignores contrib/postgres_fdw entirely.\\n> >> - The option for remote_analyze has been moved to its own patch (0003).\\n> >> - The errors raised are now warnings, to ensure that we can always fall\\n> back to row sampling.\\n> >> - All local attributes with attstatarget > 0 must get matching remote\\n> statistics or the import is considered a failure.\\n> >> - The pg_restore_attribute_stats() call has been turned into a prepared\\n> statement, for clarity and some minor parsing savings.\\n> >> - The calls to pg_restore_relation_stats() are parameterized, but not\\n> prepared as this is rarely called more than once.\\n> >> - postgresStatisticsAreImportable will now disqualify a table if has\\n> extended statistics objects, because we can't compute those without a row\\n> sample.\\n> >\\n>\\n> Thanks Corey for breaking down these patches. It makes reviewing easier.\\n>\\n> analyze_rel() and acquire_inherited_sample_rows() both call\\n> fdwroutine->AnalyzeForeignTable() but only the first one uses the\\n> statistics import facility. Is that intentional? Typical use case of\\n> sharding will create a partitioned table with foreign tables as\\n> partitions. The partitions will be analyzed by the second function.\\n> Thus a big use case of postgres_fdw won't be able to use the import\\n> statistics facility. That seems like a major drawback of this patch.\\n> Thinking more about it, acquire_inherited_sample_rows() accumulates\\n> the sample rows from the child tables and extracts statistics from\\n> those rows and then updates corresponding pg_statistics rows. Doing\\n> that through import statistics seems a bit tricky since we need to be\\n> able to combine statistics from multiple relations. Can we do that?\\n>\\n\\nWe can't synthesize sample rows from imported statistics, no.\\n\\n\\n> There's an advantage if we can combine stats across multiple relations\\n> - we don't have to sample children twice when analyzing the parent\\n> without ONLY. Instead we could produce parent statistics by combining\\n> statistics across children and the parent. To me this looks like\\n> altogether a different beast just like partial aggregates.\\n>\\n\\nI think this patch is only ever going to get us out of 1 of the 2 samples,\\nwhich isn't ideal but it is a savings.\\n\\n\\n>\\n> It will be good to fix this drawback. If not, at least we should\\n> figure out (plan/POC) how to deal with the child tables? We need to at\\n> least document this drawback - the documentation in the current patch\\n> reads as if all foreign tables will use this facility when available.\\n>\\n\\n Yes, we will have to note the limitation. I have made that note, as well\\nas the documentation fix attached.\\n","threadId":"19be5345d4172528","snippet":"On Thu, Jan 22, 2026 at 5:16 AM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> wrote: On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote: >> >> Changes","historyId":"8708","internalDate":"1769120412000","receivedAtUtc":"2026-01-22T22:20:12.000Z","from":"Corey Huinker <corey.huinker@gmail.com>"},{"id":"19beb8698b1cd06d","messageId":"<CAExHW5u6ue1hMqjAubLAbz_ZQqZRdnwJAQtWUw=b+3NXTzYy-A@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":"On Fri, Jan 23, 2026 at 3:50 AM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 5:16 AM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> wrote:\\n>>\\n>> On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>> >>\\n>> >> Changes in this release, aside from rebasing:\\n>> >>\\n>> >> - The generic analyze and fdw.h changes are in their own patch (0001) that ignores contrib/postgres_fdw entirely.\\n>> >> - The option for remote_analyze has been moved to its own patch (0003).\\n>> >> - The errors raised are now warnings, to ensure that we can always fall back to row sampling.\\n>> >> - All local attributes with attstatarget > 0 must get matching remote statistics or the import is considered a failure.\\n>> >> - The pg_restore_attribute_stats() call has been turned into a prepared statement, for clarity and some minor parsing savings.\\n>> >> - The calls to pg_restore_relation_stats() are parameterized, but not prepared as this is rarely called more than once.\\n>> >> - postgresStatisticsAreImportable will now disqualify a table if has extended statistics objects, because we can't compute those without a row sample.\\n>> >\\n>>\\n>> Thanks Corey for breaking down these patches. It makes reviewing easier.\\n>>\\n>> analyze_rel() and acquire_inherited_sample_rows() both call\\n>> fdwroutine->AnalyzeForeignTable() but only the first one uses the\\n>> statistics import facility. Is that intentional? Typical use case of\\n>> sharding will create a partitioned table with foreign tables as\\n>> partitions. The partitions will be analyzed by the second function.\\n>> Thus a big use case of postgres_fdw won't be able to use the import\\n>> statistics facility. That seems like a major drawback of this patch.\\n>> Thinking more about it, acquire_inherited_sample_rows() accumulates\\n>> the sample rows from the child tables and extracts statistics from\\n>> those rows and then updates corresponding pg_statistics rows. Doing\\n>> that through import statistics seems a bit tricky since we need to be\\n>> able to combine statistics from multiple relations. Can we do that?\\n>\\n>\\n> We can't synthesize sample rows from imported statistics, no.\\n>\\n>>\\n>> There's an advantage if we can combine stats across multiple relations\\n>> - we don't have to sample children twice when analyzing the parent\\n>> without ONLY. Instead we could produce parent statistics by combining\\n>> statistics across children and the parent. To me this looks like\\n>> altogether a different beast just like partial aggregates.\\n>\\n>\\n> I think this patch is only ever going to get us out of 1 of the 2 samples, which isn't ideal but it is a savings.\\n>\\n\\nI am not suggesting to synthesize sample rows. Calculate the\\nstatistics of the parent table from that of its children.\\n\\n>>\\n>>\\n>> It will be good to fix this drawback. If not, at least we should\\n>> figure out (plan/POC) how to deal with the child tables? We need to at\\n>> least document this drawback - the documentation in the current patch\\n>> reads as if all foreign tables will use this facility when available.\\n>\\n>\\n>  Yes, we will have to note the limitation. I have made that note, as well as the documentation fix attached.\\n\\nThe note just mentions partition table but the limitation applies to\\nany foreign child table.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n","threadId":"19be5345d4172528","snippet":"On Fri, Jan 23, 2026 at 3:50 AM Corey Huinker <corey.huinker@gmail.com> wrote: > > On Thu, Jan 22, 2026 at 5:16 AM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> wrote: >> >","historyId":"12865","internalDate":"1769182999000","receivedAtUtc":"2026-01-23T15:43:19.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19bebdb17f886a16","messageId":"<CADkLM=f5e+MvnDG_swTiJ=2ha02ksMY7njK7xuK=ktX3-mxUkQ@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":">\\n> >> There's an advantage if we can combine stats across multiple relations\\n> >> - we don't have to sample children twice when analyzing the parent\\n> >> without ONLY. Instead we could produce parent statistics by combining\\n> >> statistics across children and the parent. To me this looks like\\n> >> altogether a different beast just like partial aggregates.\\n> >\\n> >\\n> > I think this patch is only ever going to get us out of 1 of the 2\\n> samples, which isn't ideal but it is a savings.\\n> >\\n>\\n> I am not suggesting to synthesize sample rows. Calculate the\\n> statistics of the parent table from that of its children.\\n>\\n\\nI'm not sure we can actually do that. The functions that compute the\\nstatistics are all based off of row samples, not already computed\\nstatistics. I don't think we can synthesize a rowsample from the imported\\nstatistics, at least not accurately. If I'm misunderstanding what you're\\nsuggesting, please correct me.\\n\\n\\n> The note just mentions partition table but the limitation applies to\\n> any foreign child table.\\n>\\n\\nNoted. Will fix in next revision.\\n","threadId":"19be5345d4172528","snippet":">> There's an advantage if we can combine stats across multiple relations >> - we don't have to sample children twice when analyzing the parent >> without ONLY. Instead we","historyId":"12865","internalDate":"1769188540000","receivedAtUtc":"2026-01-23T17:15:40.000Z","from":"Corey Huinker <corey.huinker@gmail.com>"}]	The discussion focuses on a postgres_fdw patch that imports remote table statistics to avoid expensive row sampling during ANALYZE operations. Corey Huinker's latest patch revision includes several improvements: generic analyze/fdw.h changes separated into their own patch, remote_analyze option isolated, errors converted to warnings for fallback capability, and prepared statements for performance. However, Ashutosh Bapat identifies a significant limitation: the statistics import facility only works with analyze_rel() but not acquire_inherited_sample_rows(), meaning partitioned tables with foreign table partitions cannot benefit from this optimization. Bapat suggests combining statistics across multiple relations instead of synthesizing sample rows, but Huinker notes that existing statistics computation functions are designed for row samples, not pre-computed statistics. Both agree the limitation needs proper documentation, with Bapat clarifying it applies to any foreign child table, not just partitioned ones. The patch also includes documentation fixes for build issues.\n\n讨论聚焦于一个postgres_fdw补丁，该补丁通过导入远程表统计信息来避免ANALYZE操作中昂贵的行采样。Corey Huinker的最新补丁版本包含多项改进：将通用analyze/fdw.h更改分离到独立补丁、隔离remote_analyze选项、将错误转换为警告以支持回退机制，以及使用预编译语句提升性能。然而，Ashutosh Bapat指出了一个重大限制：统计信息导入功能仅适用于analyze_rel()而不适用于acquire_inherited_sample_rows()，这意味着使用外部表作为分区的分区表无法从此优化中受益。Bapat建议组合多个关系的统计信息而非合成采样行，但Huinker指出现有统计计算函数是为行样本而非预计算统计信息设计的。双方都同意需要适当记录此限制，Bapat澄清该限制适用于任何外部子表，而非仅限于分区表。补丁还包含文档构建问题的修复。	2026-01-23 17:15:40+00	\N
12	19bebbb73c919f20	Time to add FIDO2 support?	["joel@compiler.org","zsolt.parragi@percona.com"]	[{"id":"19bebbb73c919f20","messageId":"<b55c256c-1e48-4188-8c7a-629a38d7a021@app.fastmail.com>","subject":"Time to add FIDO2 support?","body":"Hi hackers,\\n\\nWould others be interested in adding support for FIDO2 as a new SASL\\nauthentication mechanism?\\n\\nAs a macOS user, FIDO2 has become very convenient since the release of\\nmacOS Tahoe in September 2025, that added built-in support for Secure\\nEnclave-backed SSH keys [1] [2].  The key pair is generated on the\\nSecurity Enclave and the private key cannot be exported, so even if your\\ncomputer is compromised, you can be quite confident that they at least\\ncouldn't steal your private keys.  When logging in, you have to touch\\nthe TouchID for the Security Enclave to sign the challenge. I really\\nlove how this scores very high on both security and convenience.\\n\\nSo, I think it would be nice if authenticating to PostgreSQL via psql\\ncould be made equally secure and convenient, by simply reusing the same\\nOpenSSH hardware-backed FIDO2 SSH keys, copying the key string from\\n~/.ssh/authorized_keys, and register it with your PostgreSQL role.\\n\\nThis would of course also work with hardware keys, such as Yubikey.\\n\\nExample:\\n\\nALTER ROLE joel ADD CREDENTIAL macos 'sk-ecdsa-sha2-nistp256@openssh.com AAAAInNrLWVjZHNhLXNoYTItbmlzdHAyNTZAb3BlbnNzaC5jb20AAAAIbmlzdHAyNTYAAABBBOG0NTN8AqegdlKrGTuddOFt0G4ANYzwkBtjSS0zCWCB1IuJisW41qBQ/JSGWjJp1B7OXD52AwfyB4sbUs1Kqg0AAAAEc3NoOg==';\\n\\nAdd \\"fido2\\" to pg_hba.conf:\\n\\nhostssl    all             all             0.0.0.0/0               fido2\\nhostssl    all             all             ::/0                    fido2\\n\\nYou would need to load the resident keys from the FIDO2 authenticator,\\nonce per bootup:\\n\\n% ssh-add -K\\nEnter PIN for authenticator:\\nResident identity added: ECDSA-SK SHA256:6/FvVcfzjLTt27bieSk5UpsPFYvGGkL5njORDz1JmM8\\n\\nYou would then specify the sk-provider when connecting via psql:\\n\\n% PGSKPROVIDER=/usr/lib/ssh-keychain.dylib psql\\n\\nThe server sends a random challenge, the user is prompted to touch the\\nTouchID, the client's security key then signs it, and the server\\nverifies the signature.\\n\\nI have some experience of FIDO2/WebAuthn in the application layer,\\nand would be willing to try to draft a patch on this, given there is\\nenough interest in this.\\n\\n/Joel\\n\\n[1] https://gist.github.com/arianvp/5f59f1783e3eaf1a2d4cd8e952bb4acf\\n[2] https://lists.mindrot.org/pipermail/openssh-unix-dev/2024-July/041451.html\\n\\n\\n","threadId":"19bebbb73c919f20","snippet":"Hi hackers, Would others be interested in adding support for FIDO2 as a new SASL authentication mechanism? As a macOS user, FIDO2 has become very convenient since the release of macOS Tahoe in","historyId":"12899","internalDate":"1769186457000","receivedAtUtc":"2026-01-23T16:40:57.000Z","from":"Joel Jacobson <joel@compiler.org>"},{"id":"19bebde48c57b2f6","messageId":"<CAN4CZFNCrY-CrKenU1dVto27XFBE43PuFT8A6rkgxQvWLOPRqA@mail.gmail.com>","subject":"Re: Time to add FIDO2 support?","body":"> Would others be interested in adding support for FIDO2 as a new SASL\\n> authentication mechanism?\\n\\nMe definitely, I was also thinking about the same thing. For context,\\nI did implement fido authentication for Percona Server for MySQL.\\n\\nBut as far as I know, SASL only has drafts[1][2] about fido, not accepted RFCs.\\n\\nThis is also related to why I asked about generic (not oauth related)\\nauthentication plugins on the list a few days ago[3], one of the\\nthings I was thinking about was fido/webauthn.\\n\\n> Add \\"fido2\\" to pg_hba.conf:\\n>\\n> hostssl all all 0.0.0.0/0 fido2\\n> hostssl all all ::/0 fido2\\n\\nIt would be really good to implement MFA properly (allowing users to\\nconfigure password + fido requirement for login), but that would also\\nrequire changes in pg_hba processing.\\n\\n[1] : https://www.ietf.org/archive/id/draft-bucksch-sasl-passkey-00.html\\n[2] : https://www.ietf.org/archive/id/draft-ietf-kitten-scram-2fa-05.html\\n[3] : https://www.postgresql.org/message-id/CAN4CZFN%3D5%3DdWvY%3DYAPeF4PVOMtR5U6jMLc2kCSHdO0EhejPp%2BQ%40mail.gmail.com\\n\\n\\n","threadId":"19bebbb73c919f20","snippet":"> Would others be interested in adding support for FIDO2 as a new SASL > authentication mechanism? Me definitely, I was also thinking about the same thing. For context, I did implement fido","historyId":"12899","internalDate":"1769188751000","receivedAtUtc":"2026-01-23T17:19:11.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	Joel Jacobson proposes adding FIDO2 support as a new SASL authentication mechanism for PostgreSQL. He suggests leveraging macOS Tahoe's built-in Secure Enclave-backed SSH keys, which provide high security by storing private keys in hardware that cannot be exported. The proposal includes reusing existing OpenSSH FIDO2 SSH keys, registering them with PostgreSQL roles via ALTER ROLE commands, and configuring pg_hba.conf with a "fido2" method. Users would load resident keys once per bootup and specify an sk-provider when connecting. Zsolt Parragi expresses strong interest, noting his previous FIDO implementation experience with Percona Server for MySQL. However, he raises concerns about SASL FIDO standards being only drafts, not accepted RFCs, and suggests implementing proper multi-factor authentication (password + FIDO) would require changes to pg_hba processing.\n\nJoel Jacobson提议为PostgreSQL添加FIDO2支持作为新的SASL认证机制。他建议利用macOS Tahoe内置的安全隔区支持的SSH密钥，通过将私钥存储在无法导出的硬件中提供高安全性。该提案包括重用现有的OpenSSH FIDO2 SSH密钥，通过ALTER ROLE命令将其注册到PostgreSQL角色，并在pg_hba.conf中配置"fido2"方法。用户需要在每次启动时加载常驻密钥，连接时指定sk-provider。Zsolt Parragi表示强烈兴趣，提到他之前在Percona Server for MySQL中实现FIDO的经验。然而，他提出SASL FIDO标准仅为草案而非已接受的RFC的担忧，并建议实现适当的多因素认证（密码+FIDO）需要更改pg_hba处理。	2026-01-23 17:19:11+00	\N
12	19bebb16779ae05d	Time to drop RADIUS support?	["alvherre@kurilemu.de","jacob.champion@enterprisedb.com","mbanck@gmx.net","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19bec39e69aa2b93","messageId":"<3112825.1769185807@sss.pgh.pa.us>","subject":"Re: Time to drop RADIUS support?","body":"=?utf-8?Q?=C3=81lvaro?= Herrera <alvherre@kurilemu.de> writes:\\n> Would it work to add a WARNING (or something) to all back branches to\\n> ask users to write here, so that we can confirm in the next few months\\n> whether the protocol is completely unused or not?  If we do find users,\\n> then we could try to think of workarounds[*], but otherwise we'd just\\n> remove it for pg19 (or pg20 at the latest) and not waste any more time\\n> on it.\\n\\nI don't think that'd prove a lot.  Affected users (if any) wouldn't\\nnecessarily be quick to adopt the latest minor releases.  They're\\nprobably not even up-to-date on their RADIUS server, or they'd have\\nnoticed it spewing complaints.\\n\\n> I don't think removing it entirely from all back branches is a good\\n> idea, without first making sure that there are no users.\\n\\nAgreed, we can't pull it from the back branches.  But I'm in favor of\\npulling it from HEAD if we document how to use PAM-based RADIUS\\ninstead.  I agree with Thomas' argument that the cost-benefit ratio\\nof fixing our implementation would be poor.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"On 2026-Jan-23, Michael Banck wrote: > So you are saying we add a deprecation notice in the back branches and > drop it in V19? If this is a severe security issue then maybe we can > just","historyId":"12897","internalDate":"1769179993000","receivedAtUtc":"2026-01-23T14:53:13.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"},{"id":"19bebb16779ae05d","messageId":"<CAOYmi+kwVHbra-80wSC7Rh9OGttdd8QFV+VcBtSNkEkux6XkyQ@mail.gmail.com>","subject":"Re: Time to drop RADIUS support?","body":"On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> > I don't think removing it entirely from all back branches is a good\\n> > idea, without first making sure that there are no users.\\n>\\n> Agreed, we can't pull it from the back branches.  But I'm in favor of\\n> pulling it from HEAD if we document how to use PAM-based RADIUS\\n> instead.  I agree with Thomas' argument that the cost-benefit ratio\\n> of fixing our implementation would be poor.\\n\\n+1.\\n\\nI still think a WARNING in the back branches would be a kindness, to\\nlet people know that they need to move.\\n\\n--Jacob\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"=?utf-8?Q?=C3=81lvaro?= Herrera <alvherre@kurilemu.de> writes: > Would it work to add a WARNING (or something) to all back branches to > ask users to write here, so that we can confirm in","historyId":"12897","internalDate":"1769185807000","receivedAtUtc":"2026-01-23T16:30:07.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bebfb1d2134b77","messageId":"<202601231423.4522ubhwkcwj@alvherre.pgsql>","subject":"Re: Time to drop RADIUS support?","body":"On 2026-Jan-23, Michael Banck wrote:\\n\\n> So you are saying we add a deprecation notice in the back branches and\\n> drop it in V19? If this is a severe security issue then maybe we can\\n> just remove it everywhere (ugh), or if not, I think it probably warrants\\n> at least one release cycle of deprecation. Do we have a formal\\n> deprecation timeline policy nowadays?\\n\\nI don't think we do.\\n\\nWould it work to add a WARNING (or something) to all back branches to\\nask users to write here, so that we can confirm in the next few months\\nwhether the protocol is completely unused or not?  If we do find users,\\nthen we could try to think of workarounds[*], but otherwise we'd just\\nremove it for pg19 (or pg20 at the latest) and not waste any more time\\non it.\\n\\nI don't think removing it entirely from all back branches is a good\\nidea, without first making sure that there are no users.\\n\\n[*] or even just a way to document a migration to PAM-based Radius.\\n\\n-- \\nÁlvaro Herrera               48°01'N 7°57'E  —  https://www.EnterpriseDB.com/\\n\\"I'm impressed how quickly you are fixing this obscure issue. I came from \\nMS SQL and it would be hard for me to put into words how much of a better job\\nyou all are doing on [PostgreSQL].\\"\\n Steve Midgley, http://archives.postgresql.org/pgsql-sql/2008-08/msg00000.php\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > > I don't think removing it entirely from all back branches is a good > > idea, without first making sure","historyId":"12897","internalDate":"1769190640000","receivedAtUtc":"2026-01-23T17:50:40.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"}]	PostgreSQL developers are discussing whether to drop RADIUS authentication support due to security issues. Álvaro Herrera proposes adding a WARNING to back branches to identify active users before removal, suggesting removal in pg19 or pg20 if no users are found. Tom Lane agrees that back branches shouldn't be affected but supports removing RADIUS from HEAD, favoring documentation of PAM-based RADIUS alternatives instead. He argues that fixing the current implementation has a poor cost-benefit ratio. Jacob Champion supports this approach and endorses adding warnings to back branches as a courtesy to help users migrate. The discussion centers on balancing user notification with the technical burden of maintaining problematic code.\n\nPostgreSQL开发者正在讨论是否因安全问题而放弃RADIUS身份验证支持。Álvaro Herrera提议在后续分支中添加警告以识别活跃用户，如果没有发现用户则建议在pg19或pg20版本中移除。Tom Lane同意不应影响后续分支，但支持从HEAD中移除RADIUS，倾向于记录基于PAM的RADIUS替代方案。他认为修复当前实现的成本效益比很差。Jacob Champion支持这种方法，并赞成在后续分支中添加警告以帮助用户迁移。讨论的核心是在用户通知和维护有问题代码的技术负担之间取得平衡。	2026-01-23 17:50:40+00	\N
12	19bec03ddcb80663	Unstable path in index regress test query	["hukutoc@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19bec03ddcb80663","messageId":"<CAN-LCVOgBms6==prC48io0kw_muQfYerEbiYxNivqRCcLgL0qw@mail.gmail.com>","subject":"Unstable path in index regress test query","body":"Hi hackers!\\n\\nWhile doing some tests I've stumbled upon an unstable behavior of the query\\n\\nexplain\\nSELECT unique1 FROM tenk1\\nWHERE unique1 IN (1,42,7)\\nORDER BY unique1;\\n\\nfrom create_index regress test.\\n\\nThis test could randomly return any of 2 paths (below is sequential run,\\nclean latest master install, without server restart or any other queries\\nin-between):\\n\\npostgres=# explain SELECT unique1 FROM tenk1\\n WHERE unique1 IN (1,42,7)\\n ORDER BY unique1;\\n                                     QUERY PLAN\\n-------------------------------------------------------------------------------------\\n Sort  (cost=310.65..311.02 rows=150 width=4)\\n   Sort Key: unique1\\n   ->  Bitmap Heap Scan on tenk1  (cost=14.02..305.23 rows=150 width=4)\\n         Recheck Cond: (unique1 = ANY ('{1,42,7}'::integer[]))\\n         ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..13.98 rows=150\\nwidth=0)\\n               Index Cond: (unique1 = ANY ('{1,42,7}'::integer[]))\\n(6 rows)\\n\\npostgres=# explain SELECT unique1 FROM tenk1\\n WHERE unique1 IN (1,42,7)\\n ORDER BY unique1;\\n                                   QUERY PLAN\\n---------------------------------------------------------------------------------\\n Index Only Scan using tenk1_unique1 on tenk1  (cost=0.29..12.91 rows=3\\nwidth=4)\\n   Index Cond: (unique1 = ANY ('{1,42,7}'::integer[]))\\n(2 rows)\\n\\nThe strange thing is that paths are returned quite randomly, but the first\\nmore often than the second.\\nIs it a bug? Or some feature?\\n\\nYou could check the full log in attach.\\n\\nThanks!\\n\\n--\\nRegards,\\nNikita Malakhov\\nPostgres Professional\\nThe Russian Postgres Company\\nhttps://postgrespro.ru/\\n","threadId":"19bec03ddcb80663","snippet":"Hi hackers! While doing some tests I've stumbled upon an unstable behavior of the query explain SELECT unique1 FROM tenk1 WHERE unique1 IN (1,42,7) ORDER BY unique1; from create_index regress test.","historyId":"12901","internalDate":"1769191211000","receivedAtUtc":"2026-01-23T18:00:11.000Z","from":"Nikita Malakhov <hukutoc@gmail.com>"},{"id":"19bec0de1578734b","messageId":"<3123188.1769191879@sss.pgh.pa.us>","subject":"Re: Unstable path in index regress test query","body":"Nikita Malakhov <hukutoc@gmail.com> writes:\\n> While doing some tests I've stumbled upon an unstable behavior of the query\\n\\n> explain\\n> SELECT unique1 FROM tenk1\\n> WHERE unique1 IN (1,42,7)\\n> ORDER BY unique1;\\n\\n> from create_index regress test.\\n\\nI wouldn't call what you're showing here an instability.\\nYou create and populate the table, but your test script\\nisn't giving autovacuum any time to catch up, so the\\nfirst EXPLAIN is based on default behaviors without stats.\\nThen when you do an ANALYZE, the plan changes because the\\nrowcount estimates change.\\n\\nYou probably should make that a VACUUM ANALYZE, actually,\\nto ensure that the whole table is marked all-visible.\\nThat can affect the estimated cost of an index-only scan too.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bec03ddcb80663","snippet":"Nikita Malakhov <hukutoc@gmail.com> writes: > While doing some tests I've stumbled upon an unstable behavior of the query > explain > SELECT unique1 FROM tenk1 > WHERE unique1 IN","historyId":"12901","internalDate":"1769191879000","receivedAtUtc":"2026-01-23T18:11:19.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bec13d2f23211e","messageId":"<CAN-LCVNt552i1=F7Z8OW1VCYa3NSpymQXXfAKcucHFrkJ_N66g@mail.gmail.com>","subject":"Re: Unstable path in index regress test query","body":"Hi,\\n\\nYes, the VACUUM ANALYZE does it, I forgot that the vacuum\\ncould affect estimations.\\nTom, thank you for the clarification!\\n\\n-- \\nRegards,\\nNikita Malakhov\\nPostgres Professional\\nThe Russian Postgres Company\\nhttps://postgrespro.ru/\\n","threadId":"19bec03ddcb80663","snippet":"Hi, Yes, the VACUUM ANALYZE does it, I forgot that the vacuum could affect estimations. Tom, thank you for the clarification! -- Regards, Nikita Malakhov Postgres Professional The Russian Postgres","historyId":"12901","internalDate":"1769192258000","receivedAtUtc":"2026-01-23T18:17:38.000Z","from":"Nikita Malakhov <hukutoc@gmail.com>"}]	Nikita Malakhov reported observing unstable query plan behavior in a PostgreSQL index regression test. The query "SELECT unique1 FROM tenk1 WHERE unique1 IN (1,42,7) ORDER BY unique1" was randomly switching between two execution plans: a Bitmap Heap Scan with Sort and an Index Only Scan. Tom Lane explained that this is not a bug but expected behavior due to timing issues with autovacuum and statistics collection. The first EXPLAIN runs before autovacuum updates table statistics, using default estimates, while subsequent runs use updated statistics after ANALYZE. Lane recommended using VACUUM ANALYZE to ensure consistent behavior by marking the table as all-visible, which affects index-only scan cost estimates. Malakhov acknowledged the explanation and confirmed that VACUUM ANALYZE resolved the instability.\n\nPostgreSQL黑客Nikita Malakhov报告了在PostgreSQL索引回归测试中观察到的不稳定查询计划行为。查询"SELECT unique1 FROM tenk1 WHERE unique1 IN (1,42,7) ORDER BY unique1"在两个执行计划之间随机切换：带排序的位图堆扫描和仅索引扫描。Tom Lane解释说这不是错误，而是由于自动清理和统计收集时序问题导致的预期行为。第一个EXPLAIN在自动清理更新表统计信息之前运行，使用默认估算，而后续运行则使用ANALYZE后的更新统计信息。Lane建议使用VACUUM ANALYZE来确保一致的行为，通过将表标记为全可见来影响仅索引扫描的成本估算。Malakhov确认了这个解释，并证实VACUUM ANALYZE解决了不稳定性问题。	2026-01-23 18:17:38+00	\N
12	19bec7b069713c1b	ON CONFLICT DO SELECT (take 3)	["andreas@proxel.se","dean.a.rasheed@gmail.com","jian.universality@gmail.com","marko@joh.to","v@viktorh.net"]	[{"id":"19bec7b069713c1b","messageId":"<8b107b01-6e94-4919-a3bf-66af22c17899@Spark>","subject":"Re: ON CONFLICT DO SELECT (take 3)","body":"On 21 Jan 2026 at 21:06 +0100, Viktor Holmberg <v@viktorh.net>, wrote:\\n> > There are some white spaces in v19.\\n> > Sorry, what do you mean \\"white spaces"? Is it a problem?\\n> > it's time to squash the patchset into one, IMHO.\\n> > you can also begin to write the draft commit message, explain what this is all\\n> > about.\\n> > Yes, done.\\n> > ExecOnConflictSelect\\n> > if (lockStrength == LCS_NONE)\\n> > {\\n> > /* Evem if the tuple is deleted, it must still be physically present */\\n> > Assert(table_tuple_fetch_row_version(relation, conflictTid,\\n> > SnapshotAny, existing));\\n> > }\\n> > this is wrong, i think.\\n> > buildtype=release, the Assert macro will always be true,\\n> > the whole Assert may be optimized out,\\n> > and later code would have trouble using (TupleTableSlot *existing).\\n> > Yes, you're right. Nice catch. Fixed.\\n> > updatable_views.sql: I did some ON CONFLICT DO SELECT permissions checks, and\\n> > other tests in it, please check attached.\\n> > Added\\n> >\\n> > -----\\n> > I've updated all the comments you mentioned.\\n> > Thanks for the review Jian, I'm hoping we've caught all the issues now.\\n> > Please find v20 attached.\\nI went through all mentions of ON CONFLICT in the codebase to see there are no more forgotten comments/docs, and found 2 more places to update.\\n","threadId":"19bec7b069713c1b","snippet":"On 21 Jan 2026 at 21:06 +0100, Viktor Holmberg <v@viktorh.net>, wrote: There are some white spaces in v19. Sorry, what do you mean \\"white spaces"? Is it a problem? it's time to squash","historyId":"13081","internalDate":"1769199000000","receivedAtUtc":"2026-01-23T20:10:00.000Z","from":"Viktor Holmberg <v@viktorh.net>"}]	Viktor Holmberg discusses updates to the "ON CONFLICT DO SELECT" PostgreSQL patch in version 20. The patch addresses reviewer feedback from Jian, including fixing whitespace issues, squashing the patchset, and writing a draft commit message. A critical bug was identified and fixed in ExecOnConflictSelect where an Assert macro could be optimized out in release builds, potentially causing issues with the existing tuple slot variable. Permission checks and additional tests were added to updatable_views.sql. Viktor conducted a comprehensive review of all ON CONFLICT mentions in the codebase and discovered two additional places requiring documentation updates. The patch appears to be nearing completion after addressing these latest issues.\n\nViktor Holmberg讨论了"ON CONFLICT DO SELECT" PostgreSQL补丁第20版的更新。该补丁解决了来自Jian的审阅反馈，包括修复空白字符问题、压缩补丁集以及编写草案提交消息。在ExecOnConflictSelect中发现并修复了一个严重bug，其中Assert宏在发布版本中可能被优化掉，可能导致existing元组槽变量出现问题。向updatable_views.sql添加了权限检查和额外测试。Viktor对代码库中所有ON CONFLICT提及进行了全面审查，发现还有两个地方需要更新文档。在解决这些最新问题后，补丁似乎接近完成。	2026-01-23 20:10:00+00	\N
12	19be5000123f9d5e	Optional skipping of unchanged relations during ANALYZE?	["dgrowleyml@gmail.com","ilya.evdokimov@tantorlabs.com","myon@debian.org","rob@xzilla.net","robertmhaas@gmail.com","samimseih@gmail.com","vasukianand0119@gmail.com"]	[{"id":"19be73b80b532027","messageId":"<CAJSLCQ2ZTLng_4vF9O74oxaOg_cAxD6=ixLMoW_+5CxCkNtXrA@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"On Wed, Jan 21, 2026 at 4:44 AM Christoph Berg <myon@debian.org> wrote:\\n>\\n> Re: VASUKI M\\n> >     VACUUM(SMART);\\n>\\n> IMHO it was a historical mistake to combine VACUUM and ANALYZE into a\\n> single command. We should not add any more options on that\\n> combination. If people want to pass options to ANALYZE, they should\\n> call ANALYZE and not VACUUM.\\n>\\n\\nI don't know if I go that far, but if you are saying that you dont\\nthink \\"smart analyze\\" should be an option for vacuum runs, I can get\\nonboard with that. We don't really know what any given vacuum run will\\ndo with regards to the table, but if we are shuffling data / storage\\naround, it probably makes sense to update statistics info along the\\nway.\\n\\nRobert Treat\\nhttps://xzilla.net\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"On Wed, Jan 21, 2026 at 4:44 AM Christoph Berg <myon@debian.org> wrote: > > Re: VASUKI M > > VACUUM(SMART); > > IMHO it was a historical mistake to combine VACUUM and ANALYZE","historyId":"8706","internalDate":"1769110972000","receivedAtUtc":"2026-01-22T19:42:52.000Z","from":"Robert Treat <rob@xzilla.net>"},{"id":"19be75be39f072ab","messageId":"<CAA5RZ0s-akwQTy5bBTVBgSHB9Sy-6jS7eFZXqLcTbvL13pb8eA@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"Hi,\\n\\n> I would appreciate feedback on the overall approach.\\n\\nI did not read through the patch in detail but by looking at the commit\\nmessage:\\n\\n\\"A relation is skipped only if:\\n- it has been analyzed before (manual or auto-analyze), and\\n- n_mod_since_analyze == 0\\n\\nRelations that have never been analyzed are always analyzed normally.\\nThe default ANALYZE behavior is unchanged unless SMART is explicitly\\nspecified.\\n\\"\\n\\nI can't help but think that this SMART option is not as smart as it\\nshould be to actually\\nbe valuable.\\n\\nI agree that we should never skip a table that has never been\\nanalyzed. My concern\\nis that n_mod_since_analyze == 0 is not very useful. What if I modify\\n1 tuple? does\\nthat really justify an ANALYZE to run on the table? Shouldn't the\\ndecision be driven based\\non some threshold calculation; similar to how autoanalyze makes the decision?\\n\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"Hi, > I would appreciate feedback on the overall approach. I did not read through the patch in detail but by looking at the commit message: \\"A relation is skipped only if: - it has been","historyId":"8706","internalDate":"1769113094000","receivedAtUtc":"2026-01-22T20:18:14.000Z","from":"Sami Imseih <samimseih@gmail.com>"},{"id":"19be79631ba382dd","messageId":"<6b5d7f83-7ac8-47b1-ab7f-0040b65ad02a@tantorlabs.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"I spent some more time thinking about this new option.\\n\\nOn 22.01.2026 23:18, Sami Imseih wrote:\\n> I can't help but think that this SMART option is not as smart as it\\n> should be to actually\\n> be valuable.\\n>\\n> I agree that we should never skip a table that has never been\\n> analyzed. My concern\\n> is that n_mod_since_analyze == 0 is not very useful.\\n\\nIMO, for the purpose of ensuring that we never skip relations that have never been analyzed, checking last_analyze / last_autoanalyze being NULL seems sufficient and reliable.\\n\\n\\n> What if I modify\\n> 1 tuple? does\\n> that really justify an ANALYZE to run on the table? Shouldn't the\\n> decision be driven based\\n> on some threshold calculation; similar to how autoanalyze makes the decision?\\n\\nThe primary purpose of ANALYZE is to allow users to explicitly rebuildstatistics when they believe it is necessary. When a user specifiesparticular tables or columns (e.g., ANALYZE table; or ANALYZE table(i, j); ), I would not expect them to use this newoption - in that case, the intent is usually to force statistics to berecollected.\\n\\nHowever, the situation looks different when ANALYZE is run across theentire database (i.e., plain ANALYZE;). In that context, havingan option to skip relations that are known not to have changed sincetheir last analyze seems useful, as it avoids doing work that is clearlyunnecessary. That said, I think we still need to be precise about what exactly \\"relations that have not changed\\" means in this context, in order to understand where statistics would and would not be rebuilt. In particular, relying solely on n_mod_since_analyze == 0 does not seem sufficient, as we have already discussed several cases where ANALYZE may still be required even without direct data modifications (e.g. partitioned tables, inheritance, foreign tables, extended statistics, etc.)\\n\\nAbout thresholds: I'm not convinced they make much sense for manualANALYZE. autovacuum already exists to decide when statistics need tobe refreshed based on thresholds, and if those conditions are met, itwill run automatically. I'm not sure there is much value in duplicatingthat logic for explicit ANALYZE commands.\\n\\nWhat do you think?\\n\\n-- \\nBest regards,\\nIlia Evdokimov,\\nTantor Labs LLC,\\nhttps://tantorlabs.com/\\n","threadId":"19be5000123f9d5e","snippet":"I spent some more time thinking about this new option. On 22.01.2026 23:18, Sami Imseih wrote: I can't help but think that this SMART option is not as smart as it should be to actually be valuable.","historyId":"8706","internalDate":"1769116924000","receivedAtUtc":"2026-01-22T21:22:04.000Z","from":"Ilia Evdokimov <ilya.evdokimov@tantorlabs.com>"},{"id":"19be7efae3354117","messageId":"<CAA5RZ0tbcydhZ5PwqLMXpMRKuWkwZtvxAiiq6=UH-j2Z7boC2w@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"> I can't help but think that this SMART option is not as smart as it\\n> should be to actually\\n> be valuable.\\n>\\n> I agree that we should never skip a table that has never been\\n> analyzed. My concern\\n> is that n_mod_since_analyze == 0 is not very useful.\\n>\\n> IMO, for the purpose of ensuring that we never skip relations that have never been analyzed,\\n> checking last_analyze / last_autoanalyze being NULL seems sufficient and reliable.\\n\\nedba754f052 introduced --missing-stats-only for vacuumdb. Although\\nthis was intended\\nfor pg_upgrade, it does note in the commit message that \\"it might be\\nuseful in other situations\\"\\nPerhaps, this is one of the situations.\\n\\nSo, instead of a smart mode, maybe we should be thinking about an\\nANALYZE (missing_stats_only) option that follows what is done in\\nvacuumdb; and will skip tables that don't need to be analyzed.\\nUltimately vacuumdb can just use this option.\\n\\nThe criteria for tables missing stats is more comprehensive than a simple\\nlast_analyze / last_autoanalyze being NULL.\\n\\nA followup commit 984d7165dd also mentions:\\n\\n\\"\\nFor v19, perhaps we could introduce a simple, inexpensive way to\\ndiscover which relations are missing statistics, such as a system\\nfunction or view with similar privilege requirements to ANALYZE.\\nUnfortunately, it is far too late for anything like that in v18.\\n\\"\\n\\nWhat do you think?\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"> I can't help but think that this SMART option is not as smart as it > should be to actually > be valuable. > > I agree that we should never skip a table that has never been >","historyId":"8706","internalDate":"1769122779000","receivedAtUtc":"2026-01-22T22:59:39.000Z","from":"Sami Imseih <samimseih@gmail.com>"},{"id":"19be98ed513d73e0","messageId":"<CAE2r8H4+SoMrCXZx987em2VW5tR=N_0xtj28B8R6dzuLon=bzQ@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"Hi all,\\n\\nThanks a lot for the detailed feedback — this has been very\\nhelpful.Answering to all mails in one.\\n\\nA few clarifications on intent and scope, and how this relates to the\\npoints raised:\\n\\nAutovacuum overlap\\nI agree there is some conceptual overlap with autovacuum's analyze decision\\nlogic. The intent here is not to replace or duplicate autovacuum\\nheuristics, but to reduce clearly redundant work during explicit ANALYZE\\nruns (especially plain ANALYZE; across the whole database). Autovacuum\\nalready handles threshold-based decisions well; this option is meant to be\\na lightweight, explicit opt-in for manual ANALYZE usage.\\n\\nThresholds vs n_mod_since_analyze\\nI agree that n_mod_since_analyze == 0 is a very simple condition and not\\n"smart" in the general sense. That is intentional for now. This option is\\nnot trying to answer when statistics should be refreshed optimally, but\\nonly to skip relations that are known to be unchanged since the last\\nanalyze. If even a single tuple is modified, SMART ANALYZE will still\\nre-run, preserving conservative behavior.\\n\\nTables never analyzed\\nAs Christoph and Ilia pointed out earlier, skipping tables that were never\\nanalyzed would be incorrect. The current logic explicitly avoids that by\\nrequiring last_analyze or last_autoanalyze to be present before skipping.\\nTables without prior statistics are always analyzed.\\n\\nRelation to vacuumdb --missing-stats-only\\nI agree this is related but slightly different in intent.\\n--missing-stats-only answers "does this table have any statistics at all?",\\nwhile SMART ANALYZE answers "has this table changed since the last\\nstatistics collection?". Both seem useful, but they target different use\\ncases. I see SMART ANALYZE primarily as a performance optimization for\\nrepeated manual ANALYZE runs on mostly-static schemas.\\n\\nExtended statistics / partitions / inheritance\\nThese are valid concerns. The current patch intentionally does not attempt\\nto handle extended statistics, partitioned tables, inheritance, foreign\\ntables, etc. I wanted to start with a minimal, explicit, and conservative\\nbehavior for regular relations only. I agree these areas need careful\\nconsideration before extending the logic further, and I plan to look into\\nthem based on feedback.\\n\\nVACUUM vs ANALYZE\\nI also agree with the concern about adding more options to VACUUM. The\\ncurrent patch focuses on ANALYZE usage; I'm not proposing this as a VACUUM\\noption.\\n\\nNAMING\\nAlthough as sami said this SMART is not smart enough as it should be , I\\nwill change name accordingly in the further patches  based on urs and\\nothers opinion once it is decided.\\nBased on feedback, I'm happy to revise direction, naming, or scope before\\ntaking this further.\\n\\nThanks again for the thoughtful discussion — really appreciate the guidance.\\n\\nBest regards,\\nVasuki M\\nC-DAC,Chennai.\\n","threadId":"19be5000123f9d5e","snippet":"Hi all, Thanks a lot for the detailed feedback — this has been very helpful.Answering to all mails in one. A few clarifications on intent and scope, and how this relates to the points raised:","historyId":"12864","internalDate":"1769150007000","receivedAtUtc":"2026-01-23T06:33:27.000Z","from":"VASUKI M <vasukianand0119@gmail.com>"},{"id":"19bea74af4824988","messageId":"<65da80c0-52fb-454e-b29e-b1d5a254ec38@tantorlabs.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"\\nOn 23.01.2026 09:33, VASUKI M wrote:\\n> Relation to vacuumdb --missing-stats-only\\n> I agree this is related but slightly different in intent. > --missing-stats-only answers "does this table have any statistics at > all?", while SMART ANALYZE answers "has this table changed since the > last statistics collection?". Both seem useful, but they target > different use cases. I see SMART ANALYZE primarily as a performance > optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n\\nLGTM. Thanks to Sami for pointing this out.\\n\\nIt seems reasonable to start by introducing an option for plain ANALYZE (without specifying tables or columns) that follows the same idea as vacuumdb --missing-stats-only. While this flag was originally introduced primarily to support pg_upgrade workflows, exposing similar functionality at the ANALYZE level also seems useful on its own. That would give us a clear and well-defined first step. At the SQL level, a name such as ANALYZE (MISSING_STATS_ONLY) would be a good fit and remain consistent with the vacuumdb option.\\n\\nThoughts?\\n\\n-- \\nBest regards,\\nIlia Evdokimov,\\nTantor Labs LLC,\\nhttps://tantorlabs.com/\\n\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"On 23.01.2026 09:33, VASUKI M wrote: > Relation to vacuumdb --missing-stats-only > I agree this is related but slightly different in intent. > --missing-stats-only answers "does this table","historyId":"12864","internalDate":"1769165058000","receivedAtUtc":"2026-01-23T10:44:18.000Z","from":"Ilia Evdokimov <ilya.evdokimov@tantorlabs.com>"},{"id":"19bec8e508a88c43","messageId":"<CAA5RZ0tYuhHapyVBTw8tVfrKp6fyS5YBTVdQhYGOcWFg-ERyFA@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"Thanks for the detailed summary!\\n\\nIt is important to point out that this feature is trying to do 2 distinct\\nthings in 1 command. run analyze under when either one of these conditions\\nis true:\\n\\n1/ Table has not been analyzed yet.\\n2/ Table has been modified.\\n\\n> Thanks a lot for the detailed feedback — this has been very helpful.Answering to all mails in one.\\n>\\n> A few clarifications on intent and scope, and how this relates to the points raised:\\n>\\n> Autovacuum overlap\\n> I agree there is some conceptual overlap with autovacuum's analyze decision logic.\\n> The intent here is not to replace or duplicate autovacuum heuristics, but to reduce\\n\\nYes, I agree with this.\\n\\n> I agree that n_mod_since_analyze == 0 is a very simple condition\\n> and not "smart" in the general sense. That is intentional for now.\\n> This option is not trying to answer when statistics should be refreshed optimally,\\n> but only to skip relations that are known to be unchanged since the last analyze.\\n> If even a single tuple is modified, SMART ANALYZE will still re-run, preserving\\n> conservative behavior.\\n\\nYes, this is my concern. Why would I want to analyze if 1 row or a negligible\\namount of rows are modified? I understand that this feature is trying to\\nkeep the decision making very simple, but I think it's too simple to actually\\nbe helpful in addressing the wasted effort of an ANALYZE command.\\n\\n> Tables never analyzed\\n> As Christoph and Ilia pointed out earlier, skipping tables that were never analyzed would be incorrect.\\n> The current logic explicitly avoids that by requiring last_analyze or last_autoanalyze to be present\\n> before skipping. Tables without prior statistics are always analyzed.\\n\\nI agree with this, but I think it's more than just tables that have\\nnot been analyzed.\\nWhat if a new column is added after the last (auto)analyze. Would we not want to\\ntrigger an analyze in that case?\\n\\n> Relation to vacuumdb --missing-stats-only\\n> I agree this is related but slightly different in intent. --missing-stats-only\\n> answers "does this table have any statistics at all?", while SMART ANALYZE\\n> answers "has this table changed since the last statistics collection?". Both seem\\n> useful, but they target different use cases. I see SMART ANALYZE primarily\\n> as a performance optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n\\nSMART ANALYZE is trying to answer 2 questions \\"which table does not\\nhave any statistics at all\\"\\nand \\"has this table changed since the last statistics collection?", right?\\n\\nSo, maybe they need to be 2 separate options.\\n\\n> Although as sami said this SMART is not smart enough as it should be ,\\n> I will change name accordingly in the further patches\\n\\nYup, I am not too fond of SMART in the name. Also, then name itself\\nis vague. SKIP_LOCKED and BUFFER_USAGE_LIMIT on the other\\nhand tell you exactly what they[re used for.\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"Thanks for the detailed summary! It is important to point out that this feature is trying to do 2 distinct things in 1 command. run analyze under when either one of these conditions is true: 1/ Table","historyId":"13172","internalDate":"1769200286000","receivedAtUtc":"2026-01-23T20:31:26.000Z","from":"Sami Imseih <samimseih@gmail.com>"}]	The thread discusses a proposed SMART option for PostgreSQL's ANALYZE command that would skip analyzing relations unchanged since their last analysis. The original proposal by VASUKI M would skip relations only when n_mod_since_analyze == 0 and they have been previously analyzed. Several concerns emerged: Robert Treat questioned combining more options with VACUUM, suggesting ANALYZE-only usage. Sami Imseih argued that skipping analysis for just one modified tuple seems insufficient, proposing threshold-based decisions similar to autovacuum logic. Ilia Evdokimov suggested the approach is too conservative and noted complexities with partitioned tables, inheritance, and extended statistics. The discussion evolved toward considering a MISSING_STATS_ONLY option similar to vacuumdb's existing functionality, which would address tables never analyzed rather than unchanged tables. VASUKI clarified the intent as performance optimization for repeated manual ANALYZE runs on mostly-static schemas, acknowledging the current approach's limitations and openness to refining the scope and naming.\n\n该讨论涉及为PostgreSQL的ANALYZE命令提出的SMART选项，该选项将跳过自上次分析以来未发生变化的关系。VASUKI M的原始提案仅在n_mod_since_analyze == 0且关系之前已被分析过时跳过关系。出现了几个担忧：Robert Treat质疑在VACUUM中组合更多选项，建议仅使用ANALYZE。Sami Imseih认为仅为一个修改的元组跳过分析是不够的，提议基于阈值的决策类似于自动清理逻辑。Ilia Evdokimov建议该方法过于保守，并指出分区表、继承和扩展统计的复杂性。讨论转向考虑类似于vacuumdb现有功能的MISSING_STATS_ONLY选项，该选项将处理从未分析过的表而不是未变化的表。VASUKI澄清了意图是为主要静态模式上重复手动ANALYZE运行的性能优化，承认当前方法的局限性并愿意改进范围和命名。	2026-01-23 20:31:26+00	\N
12	19becac12ff1c79d	Don't synchronously wait for already-in-progress IO in read stream	["andres@anarazel.de","melanieplageman@gmail.com","pg@bowt.ie","thomas.munro@gmail.com","tv@fuzzy.cz"]	[{"id":"19becac12ff1c79d","messageId":"<CAAKRu_atdnPCCy=kfxqWT62Ckaiz3G5t=S97tW24CuL3i3fFfQ@mail.gmail.com>","subject":"Re: Don't synchronously wait for already-in-progress IO in read stream","body":"On Sun, Nov 9, 2025 at 5:21 PM Thomas Munro <thomas.munro@gmail.com> wrote:\\n>\\n> I suppose (or perhaps vaguely recall from an off-list discussion?)\\n> that you must have considered merging the new\\n> is-it-already-in-progress check into ReadBuffersCanStartIO().  I\\n> suppose the nowait argument would become a tri-state argument with a\\n> value that means \\"don't wait for an in-progress read, just give me the\\n> IO handle so I can 'join' it as a foreign waiter\\", with a new output\\n> argument to receive the handle, or something along those lines, and I\\n> guess you'd need a tri-state result, and perhaps s/Can/Try/ in the\\n> name.  That'd remove the double-check (extra header lock-unlock cycle)\\n> and associated race that can cause that rare synchronous wait (which\\n> must still happen sometimes in the duelling concurrent scan use\\n> case?), at the slight extra cost of having to allocate and free a\\n> handle in the case of repeated blocks (eg the index->heap scan use\\n> case), but at least that's just backend-local list pushups and doesn't\\n> do extra work otherwise.  Is there some logical problem with that\\n> approach?  Is the code just too clumsy?\\n\\nAttached v3 basically does what you suggested above. Now, we should\\nonly have to wait if the backend encounters a buffer after another\\nbackend has set BM_IO_IN_PROGRESS but before that other backend has\\nset the buffer descriptor's wait reference.\\n\\n0001 and 0002 are Andres' test-related patches. 0003 is a change I\\nthink is required to make one of the tests stable (esp on the BSDs).\\n0004 is a bit of preliminary refactoring and 0005 is Andres' foreign\\nIO concept but with your suggested structure and my suggested styling.\\nI could potentially break out more into smaller refactoring commits,\\nbut I don't think it's too bad the way it is.\\n\\nA few things about the patch that I'm not sure about:\\n\\n- I don't know if pgaio_submit_staged() is in all the right places\\n(and not in too many places). I basically do it before we would wait\\nwhen starting read IO on the buffer. In the permanent buffers case,\\nthat's now only when BM_IO_IN_PROGRESS is set but the wait reference\\nisn't valid yet. This can't happen in the temporary buffers case, so\\nI'm not sure we need to call pgaio_submit_staged().\\n\\n- StartBufferIO() is no longer invoked in the AsyncReadBuffers() path.\\nWe could refactor it so that it works for AsyncReadBuffers(), but that\\nwould involve returning something that distinguishes between\\nIO_IN_PROGRESS and IO already done.  And StartBufferIO()'s comment\\nexplicitly says it wants to avoid that.\\nIf we keep my structure, with AsyncReadBuffers() using its own helper\\n(PrepareNewReadBufferIO()) instead of StartBufferIO(), then it seems\\nlike we need some way to make it clear what StartBufferIO() is for.\\nI'm not sure what would collectively describe its current users,\\nthough. It also now has no non-test callers passing nowait as true.\\nHowever, once we add write combining, it will, so it seems like we\\nshould leave it the way it is to avoid churn. However, other\\ndevelopers might be confused in the interim.\\n\\n- In the 004_read_stream tests, I wonder if there is a way to test\\nthat we don't wait for foreign IO until WaitReadBuffers(). We have\\ntests for the stream accessing the same block, which in some cases\\nwill exercise the foreign IO path. But it doesn't distinguish between\\nthe old behavior -- waiting for the IO to complete when starting read\\nIO on it -- and the new behavior -- not waiting until\\nWaitReadBuffers(). That may not be possible to test, though.\\n\\n- Melanie\\n","threadId":"19becac12ff1c79d","snippet":"On Sun, Nov 9, 2025 at 5:21 PM Thomas Munro <thomas.munro@gmail.com> wrote: > > I suppose (or perhaps vaguely recall from an off-list discussion?) > that you must have considered merging","historyId":"13226","internalDate":"1769202233000","receivedAtUtc":"2026-01-23T21:03:53.000Z","from":"Melanie Plageman <melanieplageman@gmail.com>"}]	Melanie Plageman submitted v3 patches that implement Thomas Munro's suggested approach for avoiding synchronous waits during already-in-progress IO operations. The solution merges the progress check into ReadBuffersCanStartIO() using a tri-state argument system. Backends now only wait when encountering buffers after BM_IO_IN_PROGRESS is set but before the wait reference is established. The patch series includes Andres' test-related changes and preliminary refactoring. Key concerns include proper placement of pgaio_submit_staged() calls, refactoring of StartBufferIO() which no longer serves AsyncReadBuffers(), and testing challenges for distinguishing old synchronous behavior from new deferred waiting until WaitReadBuffers(). The approach should eliminate double-check race conditions while maintaining performance.\n\nMelanie Plageman提交了v3补丁，实现了Thomas Munro建议的方法来避免在已进行中的IO操作期间出现同步等待。该解决方案将进度检查合并到ReadBuffersCanStartIO()中，使用三状态参数系统。后端现在只有在遇到缓冲区后设置了BM_IO_IN_PROGRESS但尚未建立等待引用时才等待。补丁系列包括Andres的测试相关更改和初步重构。主要关注点包括pgaio_submit_staged()调用的正确位置、不再服务于AsyncReadBuffers()的StartBufferIO()重构，以及区分旧同步行为和新的延迟等待直到WaitReadBuffers()的测试挑战。该方法应该能够消除双重检查竞争条件，同时保持性能。	2026-01-23 21:03:53+00	\N
12	19becb0c36643fab	[PATCH] tests: verify renamed index functionality in alter_table	["dharinshah95@gmail.com","suryapoondla4@gmail.com"]	[{"id":"19becb0c36643fab","messageId":"<CAOj6k6fmk_wc3Rk-9hdoXdBq06iGx7AdAO2Md9HCf=QBsREz8w@mail.gmail.com>","subject":"Re: [PATCH] tests: verify renamed index functionality in alter_table","body":"Thanks Surya, Vasuki\\n\\nI have rebased it against master and is now ready to be merged.\\n\\nThanks,\\nDharin\\n\\nOn Fri, Jan 16, 2026 at 4:09 AM surya poondla <suryapoondla4@gmail.com>\\nwrote:\\n\\n> Hi Dharin,\\n>\\n> Thank you for the patch.\\n>\\n> I reviewed your patch and the changes look good.\\n>\\n> I applied your patch and all the tests pass.\\n>\\n> Regards,\\n> Surya Poondla\\n>\\n>\\n","threadId":"19becb0c36643fab","snippet":"Thanks Surya, Vasuki I have rebased it against master and is now ready to be merged. Thanks, Dharin On Fri, Jan 16, 2026 at 4:09 AM surya poondla <suryapoondla4@gmail.com> wrote: Hi Dharin, Thank","historyId":"13286","internalDate":"1769202538000","receivedAtUtc":"2026-01-23T21:08:58.000Z","from":"Dharin Shah <dharinshah95@gmail.com>"}]	Dharin Shah submitted a patch to add tests for verifying renamed index functionality in the alter_table operation. Surya Poondla reviewed the patch and confirmed that the changes look good, with all tests passing successfully after applying the patch. Following the positive review feedback, Dharin rebased the patch against the master branch and indicated it is now ready to be merged. The discussion represents a straightforward code review process where a testing enhancement for PostgreSQL's ALTER TABLE index renaming functionality has been reviewed, approved, and prepared for integration into the main codebase.\nDharin Shah提交了一个补丁，用于添加测试来验证alter_table操作中重命名索引的功能。Surya Poondla审查了该补丁并确认更改看起来不错，应用补丁后所有测试都成功通过。在收到积极的审查反馈后，Dharin将补丁重新基于主分支并表示现在已准备好合并。该讨论代表了一个直接的代码审查过程，其中PostgreSQL的ALTER TABLE索引重命名功能的测试增强已被审查、批准并准备集成到主代码库中。	2026-01-23 21:08:58+00	\N
12	19becb3a39d89c6a	[PATCH] Reserve protocol 3.1 explicitly in pqcomm.h	["jacob.champion@enterprisedb.com","postgres@jeltef.nl","tgl@sss.pgh.pa.us"]	[{"id":"19becb3a39d89c6a","messageId":"<CAOYmi+mbza4JbqZ2_tAbpWKQuLiUn-FQhJC8e-eFvayA_bNV9A@mail.gmail.com>","subject":"Re: [PATCH] Reserve protocol 3.1 explicitly in pqcomm.h","body":"On Tue, Jan 20, 2026 at 11:50 PM Jelte Fennema-Nio <postgres@jeltef.nl> wrote:\\n> RESERVED seems clearer to me. And for people interested in why, the\\n> comment above its definition describes it suffiecently.\\n\\nPushed as PG_PROTOCOL_RESERVED_31. Thank you both!\\n\\n--Jacob\\n\\n\\n","threadId":"19becb3a39d89c6a","snippet":"On Tue, Jan 20, 2026 at 11:50 PM Jelte Fennema-Nio <postgres@jeltef.nl> wrote: > RESERVED seems clearer to me. And for people interested in why, the > comment above its definition describes","historyId":"13355","internalDate":"1769202732000","receivedAtUtc":"2026-01-23T21:12:12.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"}]	A patch discussion about reserving protocol 3.1 in PostgreSQL's pqcomm.h has been concluded. The discussion involved determining the appropriate naming convention for the reserved protocol constant. Jelte Fennema-Nio suggested using "RESERVED" as a clearer identifier, noting that the accompanying comment would provide sufficient explanation for those interested in the reasoning. Jacob Champion agreed with this approach and successfully committed the patch using the name "PG_PROTOCOL_RESERVED_31". The change has been pushed to the repository, completing this protocol reservation implementation.\n\n关于在PostgreSQL的pqcomm.h中保留协议3.1的补丁讨论已经结束。讨论涉及确定保留协议常量的适当命名约定。Jelte Fennema-Nio建议使用"RESERVED"作为更清晰的标识符，并指出附带的注释将为那些对原因感兴趣的人提供足够的解释。Jacob Champion同意这种方法，并成功使用名称"PG_PROTOCOL_RESERVED_31"提交了补丁。更改已推送到代码库，完成了此协议保留实现。	2026-01-23 21:12:12+00	\N
12	19becc3788596085	New year, new commitfest app improvements	["me@jeltef.nl"]	[{"id":"19becc3788596085","messageId":"<CAGECzQSdK5vc-zVkqEFztRvSAc9E=csZdW+Tp5gH0U=oCpyxzg@mail.gmail.com>","subject":"Re: New year, new commitfest app improvements","body":"On Tue, 6 Jan 2026 at 19:46, Jelte Fennema-Nio <me@jeltef.nl> wrote:\\n> There are some big changes lined up for the next release of the\\n> commitfest app. I'm intending to deploy these to prod in on the 20th\\n> of January.\\n\\nA few days delayed. But it's deployed now. Please report any issues\\nyou encounter.\\n\\nThe 1st of Feb will be a special day. That'll be the first time that\\npatches will be auto-moved and emails for unmoved patches will be sent\\nto authors. So please keep an eye out for bugs/problems around that\\ndate too.\\n\\n\\n","threadId":"19becc3788596085","snippet":"On Tue, 6 Jan 2026 at 19:46, Jelte Fennema-Nio <me@jeltef.nl> wrote: > There are some big changes lined up for the next release of the > commitfest app. I'm intending to deploy these to","historyId":"13427","internalDate":"1769203768000","receivedAtUtc":"2026-01-23T21:29:28.000Z","from":"Jelte Fennema-Nio <me@jeltef.nl>"}]	The PostgreSQL commitfest application has been updated with significant improvements. Jelte Fennema-Nio announced that the deployment, originally scheduled for January 20th, was completed a few days later. The update introduces automated patch management functionality that will begin operating on February 1st. On this date, the system will automatically move patches between commitfest phases and send notification emails to authors of patches that haven't been moved. Users are encouraged to monitor the system for any issues following the deployment and to watch particularly closely around February 1st when the automated features activate for the first time.\n\nPostgreSQL 提交节应用程序已更新，包含重大改进。Jelte Fennema-Nio 宣布原定于1月20日的部署已延迟几天完成。此次更新引入了自动补丁管理功能，将于2月1日开始运行。在该日期，系统将自动在提交节阶段之间移动补丁，并向未被移动补丁的作者发送通知邮件。鼓励用户在部署后监控系统是否存在任何问题，特别是在2月1日自动化功能首次激活时要密切关注。	2026-01-23 21:29:28+00	\N
12	19bebeb32c2a6da1	alignas (C11)	["peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19bebeb32c2a6da1","messageId":"<3119480.1769189606@sss.pgh.pa.us>","subject":"Re: alignas (C11)","body":"Peter Eisentraut <peter@eisentraut.org> writes:\\n> This patch set has been committed, it looks like without buildfarm \\n> complaints.\\n\\nThings were fine until test_cplusplusext was added, but now\\nsome older compilers seem to reject this in C++ mode.\\nFor example at [1]:\\n\\nmake[1]: Entering directory '/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/src/test/modules/test_cplusplusext'\\ng++ -Wall -Wpointer-arith -Wendif-labels -Wmissing-format-attribute -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -g -O2 -fPIC -fvisibility=hidden -fvisibility-inlines-hidden -I. -I/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/test/modules/test_cplusplusext -I../../../../src/include -I/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include -D_GNU_SOURCE  -I/usr/include/libxml2     -c -o test_cplusplusext.o /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/test/modules/test_cplusplusext/test_cplusplusext.cpp\\nIn file included from /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/postgres.h:48:0,\\n                 from /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/test/modules/test_cplusplusext/test_cplusplusext.cpp:18:\\n/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/c.h:1126:44: warning: requested alignment 4096 is larger than 128 [-Wattributes]\\n  alignas(PG_IO_ALIGN_SIZE) char data[BLCKSZ];\\n                                            ^\\n/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/c.h:1132:49: warning: requested alignment 4096 is larger than 128 [-Wattributes]\\n  alignas(PG_IO_ALIGN_SIZE) char data[XLOG_BLCKSZ];\\n                                                 ^\\n\\nNot sure what to do about that, but I do read it as indicating that we\\ncannot put any faith in the compiler to honor such large alignment\\ndemands.\\n\\nA possible short-term(?) workaround is to wrap those two declarations\\nin \\"#ifndef __cplusplus\\", so that C++ code can't declare such\\nvariables.\\n\\n\\t\\t\\tregards, tom lane\\n\\n[1] https://buildfarm.postgresql.org/cgi-bin/show_stage_log.pl?nm=chimaera&dt=2026-01-23%2011%3A44%3A01&stg=make-testmodules\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"Peter Eisentraut <peter@eisentraut.org> writes: > This patch set has been committed, it looks like without buildfarm > complaints. Things were fine until test_cplusplusext was added, but","historyId":"12900","internalDate":"1769189606000","receivedAtUtc":"2026-01-23T17:33:26.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19becdffc0ba40ed","messageId":"<48e2bb94-be07-4f22-ba8a-545e252e4ac4@eisentraut.org>","subject":"Re: alignas (C11)","body":"On 23.01.26 18:33, Tom Lane wrote:\\n                                           ^\\n> /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/c.h:1132:49: warning: requested alignment 4096 is larger than 128 [-Wattributes]\\n>    alignas(PG_IO_ALIGN_SIZE) char data[XLOG_BLCKSZ];\\n>                                                   ^\\n> > Not sure what to do about that, but I do read it as indicating that we\\n> cannot put any faith in the compiler to honor such large alignment\\n> demands.\\n> > A possible short-term(?) workaround is to wrap those two declarations\\n> in \\"#ifndef __cplusplus\\", so that C++ code can't declare such\\n> variables.\\n\\nIt looks like this was a bug in g++:\\n\\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=70066\\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=89357\\n\\nThe suggestion there appears to be that it was fixed in gcc 9, but on the buildfarm it only goes up to 6.\\n\\nI think we could work around it like this:\\n\\n    #if defined(__cplusplus) && defined(__GNUC__) && __GNUC__ <= 6\\n    #define alignas(a) __attribute__((aligned(a)))\\n    #endif\\n\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"On 23.01.26 18:33, Tom Lane wrote: ^ > /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/ch:1132:49: warning: requested alignment 4096 is larger than 128 [-Wattributes] >","historyId":"13493","internalDate":"1769205643000","receivedAtUtc":"2026-01-23T22:00:43.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"},{"id":"19becf07d0cc9f24","messageId":"<3148330.1769206724@sss.pgh.pa.us>","subject":"Re: alignas (C11)","body":"Peter Eisentraut <peter@eisentraut.org> writes:\\n> On 23.01.26 18:33, Tom Lane wrote:\\n>> Not sure what to do about that, but I do read it as indicating that we\\n>> cannot put any faith in the compiler to honor such large alignment\\n>> demands.\\n\\n> I think we could work around it like this:\\n\\n>      #if defined(__cplusplus) && defined(__GNUC__) && __GNUC__ <= 6\\n>      #define alignas(a) __attribute__((aligned(a)))\\n>      #endif\\n\\nHmm, yeah, their bug #70066 shows clearly that the __attribute__\\nspelling should work.  But I think we'd better make the cutoff be\\nversion 9 not version 6, because that same bug is quite clear\\nabout when they fixed it.  The lack of complaints from the buildfarm\\nmay just indicate a lack of animals running the intermediate versions.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"Peter Eisentraut <peter@eisentraut.org> writes: > On 23.01.26 18:33, Tom Lane wrote: >> Not sure what to do about that, but I do read it as indicating that we >> cannot put any","historyId":"13541","internalDate":"1769206724000","receivedAtUtc":"2026-01-23T22:18:44.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19becf1dc8cd9f76","messageId":"<3148476.1769206820@sss.pgh.pa.us>","subject":"Re: alignas (C11)","body":"I wrote:\\n> Hmm, yeah, their bug #70066 shows clearly that the __attribute__\\n> spelling should work.\\n\\nSorry, copy-and-paste-o; it's\\n\\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=89357\\n\\nthat has the full statement of the problem and ACK of the fix.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"I wrote: > Hmm, yeah, their bug #70066 shows clearly that the __attribute__ > spelling should work. Sorry, copy-and-paste-o; it's https://gcc.gnu.org/bugzilla/show_bug.cgi?id=89357 that has","historyId":"13578","internalDate":"1769206820000","receivedAtUtc":"2026-01-23T22:20:20.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	PostgreSQL developers are addressing C++ compilation issues with the recently committed alignas (C11) patch. The problem emerged in the test_cplusplusext module, where older g++ compilers (version 6 and below) reject large alignment requests (4096 bytes) with warnings about exceeding maximum alignment (128 bytes). Tom Lane reported buildfarm failures and initially suggested wrapping problematic declarations with "#ifndef __cplusplus". Peter Eisentraut identified this as a known g++ bug (gcc bug #89357) fixed in gcc 9, proposing a workaround using __attribute__((aligned(a))) for affected compiler versions. Lane agreed but recommended setting the version cutoff at gcc 9 rather than 6 to ensure comprehensive coverage of the bug.\n\nPostgreSQL开发人员正在解决最近提交的alignas (C11)补丁的C++编译问题。问题出现在test_cplusplusext模块中，旧版g++编译器（版本6及以下）拒绝大对齐请求（4096字节），并警告超过最大对齐（128字节）。Tom Lane报告了构建农场故障，最初建议用"#ifndef __cplusplus"包装有问题的声明。Peter Eisentraut确认这是gcc 9中已修复的已知g++错误（gcc bug #89357），建议对受影响的编译器版本使用__attribute__((aligned(a)))作为解决方案。Lane同意但建议将版本截止设为gcc 9而不是6，以确保全面覆盖该错误。	2026-01-23 22:20:20+00	\N
14	19be89dcf6d8511e	UPDATE run check constraints for affected columns only	["jian.universality@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19be89dcf6d8511e","messageId":"<CACJufxFimkvG8B+h1cNB7PoPHQiGVxe9-S=poWbJPtbi58XuOA@mail.gmail.com>","subject":"Re: UPDATE run check constraints for affected columns only","body":"hi.\\n\\ncode has been further simplified and is now more neat.\\nThe test is kind of verbose now.\\n\\n\\n--\\njian\\nhttps://www.enterprisedb.com/\\n","threadId":"19be89dcf6d8511e","snippet":"hi. code has been further simplified and is now more neat. The test is kind of verbose now. -- jian https://www.enterprisedb.com/","historyId":"8744","internalDate":"1769134167000","receivedAtUtc":"2026-01-23T02:09:27.000Z","from":"jian he <jian.universality@gmail.com>"}]	Jian He provides an update on code simplification for running check constraints only on affected columns during UPDATE operations. The developer reports that the code has been further simplified and is now more organized and cleaner. However, they note that the associated test has become more verbose as part of these changes. No specific technical details about the implementation approach, performance improvements, or the nature of the verbosity in the test are provided in this brief update. The message appears to be a progress report on an ongoing patch development effort focused on optimizing constraint checking during UPDATE statements to improve performance by avoiding unnecessary constraint evaluations on unmodified columns.\nJian He就UPDATE操作中仅对受影响列运行检查约束的代码简化提供了更新。开发者报告说代码已经进一步简化，现在更加整洁和清晰。但是，他们注意到相关的测试变得更加冗长。这个简短的更新中没有提供关于实现方法、性能改进或测试冗长性质的具体技术细节。该消息似乎是关于正在进行的补丁开发工作的进展报告，专注于优化UPDATE语句期间的约束检查，通过避免对未修改列进行不必要的约束评估来提高性能。	2026-01-23 02:09:27+00	\N
14	19be981582954d3e	Limit memory usage by postgres_fdw batches	["a.pyhalov@postgrespro.ru","tomas@vondra.me"]	[{"id":"19be981582954d3e","messageId":"<e39d964cb5ed91ede13a87109376a463@postgrespro.ru>","subject":"Re: Limit memory usage by postgres_fdw batches","body":"Alexander Pyhalov писал(а) 2026-01-13 13:44:\\n> For now I start thinking we need some form of FETCH, which stops > fetching data based on batch size...\\n\\nHi.\\n\\nTo limit memory consumption, we actually have to retreive less data. And we can do it only on the side of the foreign server. I've rewritten the third patch. We introduce a new parameter - cursor_fetch_limit, which is set by postgres_fdw. When it is set, fetching limited count of records from the cursor is also limited by memory consumed by the records. Of course, record size is some estimation (for example, we don't know what out function will do).\\n\\nThis works as expected - in my tests with tables of large records, backends, executing selects, were always restricted by about 2 GB of RAM overall (without patch memory consumption easily grows up to 8 GB). However, now when we got less tuples from executor, than expected, we should recheck, if these are all tuples we can get. I've introduced es_eof EState field to signal that there's no more tuples. Don't know if it's the best way.\\n\\n-- \\nBest regards,\\nAlexander Pyhalov,\\nPostgres Professional","threadId":"19be981582954d3e","snippet":"Alexander Pyhalov писал(а) 2026-01-13 13:44: > For now I start thinking we need some form of FETCH, which stops > fetching data based on batch size... Hi. To limit memory consumption, we actually","historyId":"12877","internalDate":"1769149109000","receivedAtUtc":"2026-01-23T06:18:29.000Z","from":"Alexander Pyhalov <a.pyhalov@postgrespro.ru>"}]	Alexander Pyhalov has rewritten a patch to limit memory consumption in postgres_fdw batches by introducing a new parameter called cursor_fetch_limit. This parameter restricts fetching from cursors based on both record count and estimated memory consumption on the foreign server side. Testing shows the approach successfully constrains backend memory usage to approximately 2GB instead of the previous 8GB without the patch. However, the implementation requires handling cases where fewer tuples are retrieved than expected, leading to the introduction of an es_eof EState field to signal when no more tuples are available. The author acknowledges uncertainty about whether this is the optimal approach for signaling end-of-fetch conditions.\n\nAlexander Pyhalov重写了一个补丁来限制postgres_fdw批处理的内存消耗，通过引入名为cursor_fetch_limit的新参数。该参数基于记录数量和外部服务器端估计的内存消耗来限制从游标获取数据。测试表明该方法成功将后端内存使用限制在约2GB，而不使用补丁时会达到8GB。然而，该实现需要处理检索到的元组少于预期的情况，因此引入了es_eof EState字段来标识没有更多元组可用。作者承认对于标识获取结束条件这是否为最优方法存在不确定性。	2026-01-23 06:18:29+00	\N
14	19be6ab0ee643388	Patch: dumping tables data in multiple chunks in pg_dump	["ashutosh.bapat.oss@gmail.com","dgrowleyml@gmail.com","hannuk@google.com","nathandbossart@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be8a3180fc0318","messageId":"<CAApHDvo29-vQz=xV6+x5hU--NZ9qGPXsCNBuOAf88pAHjTpvvQ@mail.gmail.com>","subject":"Re: Patch: dumping tables data in multiple chunks in pg_dump","body":"On Fri, 23 Jan 2026 at 06:05, Hannu Krosing <hannuk@google.com> wrote:\\n>\\n> Fixing all the warnings\\n\\nI think overall this needs significantly more care and precision than\\nwhat you've given it so far. For example, you have:\\n\\n+    if(dopt->max_table_segment_pages != InvalidBlockNumber)\\n+        appendPQExpBufferStr(query,\\n\\"pg_relation_size(c.oid)/current_setting('block_size')::int AS\\nrelpages, \\");\\n+    else\\n+        appendPQExpBufferStr(query, \\"c.relpages, \\");\\n\\nNote that pg_class.relpages is \\"int\\". Later the code in master does:\\n\\ntblinfo[i].relpages = atoi(PQgetvalue(res, i, i_relpages));\\n\\nIf you look in vacuum.c, you'll see \\"pgcform->relpages = (int32)\\nnum_pages;\\" that the value stored in relpages will be negative when\\nthe table is >= 16TB (assuming 8k pages). Your pg_relation_size\\nexpression is not going to produce an INT. It'll produce a BIGINT, per\\n\\"select pg_typeof(pg_relation_size('pg_class') /\\ncurrent_setting('block_size')::int);\\". So the atoi() can receive a\\nstring of digits representing an integer larger than INT_MAX in this\\ncase. Looking at [1], I see:\\n\\n\\"7.22.1 Numeric conversion functions 1 The functions atof, atoi, atol,\\nand atoll need not affect the value of the integer expression errno on\\nan error. If the value of the result cannot be represented, *the\\nbehavior is undefined.*\\"\\n\\nAnd testing locally, I see that my Microsoft compiler will just return\\nINT_MAX on overflow, whereas I see gcc does nothing to prevent\\noverflows and just continues to multiply by 10 regardless of what\\noverflows occur, which I think would just make the code work by\\naccident.\\n\\nAside from that, nothing in the documentation mentions that this is\\nfor \\"heap\\" tables only. That should be mentioned as it'll just result\\nin people posting questions about why it's not working for some other\\ntable access method. There's also not much care for white space.\\nYou've introduced a bunch of whitespace changes unrelated to code\\nchanges you've made, plus there's not much regard for following\\nproject standard. For example, you commonly do \\"if(\\" and don't\\nconsistently follow the bracing rules, e.g:\\n\\n+ for(chkptr = optarg; *chkptr != '\\\\0'; chkptr++)\\n+     if(*chkptr == '-')\\n\\nThings like the following help convey the level of care that's gone into this:\\n\\n+/*\\n+ * option_parse_int\\n+ *\\n+ * Parse integer value for an option.  If the parsing is successful, returns\\n+ * true and stores the result in *result if that's given; if parsing fails,\\n+ * returns false.\\n+ */\\n+bool\\n+option_parse_uint32(const char *optarg, const char *optname,\\n\\ni.e zero effort gone in to modify the comments after pasting them from\\noption_parse_int().\\n\\nAnother example:\\n\\n+ pg_log_error(\\"%s musst be in range %lu..%lu\\",\\n\\nAlso, I have no comprehension of why you'd use uint64 for the valid\\nrange when the function is for processing uint32 types in:\\n\\n+bool\\n+option_parse_uint32(const char *optarg, const char *optname,\\n+ uint64 min_range, uint64 max_range,\\n+ uint32 *result)\\n\\nIn its current state, it's quite hard to take this patch seriously.\\nPlease spend longer self-reviewing it before posting. You could\\ntemporarily hard-code something for testing which makes at least 1\\ntable appear to be larger than 16TB and ensure your code works. What\\nyou have is visually broken and depends on whatever the atoi\\nimplementation opts to do in the overflow case. These are all things\\ndiligent commiters will be testing and it's sad to see how little\\neffort you're putting into this. How do you expect this community to\\nscale with this quality level of patch submissions? You've been around\\nlong enough and should know and do better.  Are you just expecting the\\ncommitter to fix these things for you? That work does not get done via\\nmagic wand. Being on v10 already, I'd have expected the patch to be\\nfar beyond proof of concept grade. If you're withholding investing\\ntime on this until you see more community buy-in, then I'd suggest you\\nwrite that and withhold further revisions until you're happy with the\\nlevel of buy-in.\\n\\nI'm also still not liking your de-normalised TableInfo representation\\nfor \\"is_segment\\". IMO, InvalidBlockNumber should be used to represent\\nopen bounded ranges, and if there's no chunking, then startPage and\\nendPage will both be InvalidBlockNumber. IMO, what you have now\\nneedlessly allows invalid states where is_segment == true and\\nstartPage, endPage are not set correctly. If you want to keep the code\\nsimple, hide the complexity in a macro or an inline function. There's\\njust no performance reason to materialise the more complex condition\\ninto a dedicated boolean flag.\\n\\nIf the quality level of this has not improved significantly by v11,\\ncount me out.\\n\\nDavid\\n\\n[1] https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1548.pdf\\n\\n\\n","threadId":"19be6ab0ee643388","snippet":"On Fri, 23 Jan 2026 at 06:05, Hannu Krosing <hannuk@google.com> wrote: > > Fixing all the warnings I think overall this needs significantly more care and precision than what you've","historyId":"8092","internalDate":"1769134537000","receivedAtUtc":"2026-01-23T02:15:37.000Z","from":"David Rowley <dgrowleyml@gmail.com>"}]	David Rowley provides detailed technical criticism of Hannu Krosing's v10 patch for implementing table data chunking in pg_dump. He identifies critical issues including integer overflow problems with pg_relation_size calculations that could cause undefined behavior when tables exceed 16TB, inconsistent code formatting and style violations, copy-paste errors in comments, and poor variable type choices. Rowley emphasizes that the patch lacks the precision and care expected for a v10 revision, suggesting it's still at proof-of-concept quality. He recommends using InvalidBlockNumber for unbounded ranges instead of the current denormalized TableInfo representation and warns he'll withdraw support if quality doesn't improve significantly by v11.\nDavid Rowley对Hannu Krosing的pg_dump表数据分块功能第10版补丁进行了详细的技术批评。他指出了关键问题，包括pg_relation_size计算中的整数溢出问题（当表超过16TB时可能导致未定义行为）、代码格式和风格不一致、注释中的复制粘贴错误，以及变量类型选择不当。Rowley强调该补丁缺乏第10版修订应有的精确性和细心程度，认为仍处于概念验证质量水平。他建议使用InvalidBlockNumber表示无界范围，而不是当前的非规范化TableInfo表示，并警告如果第11版质量没有显著改善，他将撤回支持。	2026-01-23 02:15:37+00	\N
14	19be802be712bae9	Refactor recovery conflict signaling a little	["hlinnaka@iki.fi","li.evan.chao@gmail.com"]	[{"id":"19be8bb4f5354dc2","messageId":"<EA619211-93E3-40BF-8EC0-AED29B87AC33@gmail.com>","subject":"Re: Refactor recovery conflict signaling a little","body":"\\n\\n> On Jan 23, 2026, at 07:20, Heikki Linnakangas <hlinnaka@iki.fi> wrote:\\n> \\n> I had a look at recovery conflict signaling and a few things caught my eye. No functional changes, but some cleanups and readability improvements:\\n> \\n> Patch 0001: Remove useless errdetail_abort()\\n> --------------------------------------------\\n> \\n> The function is supposed to add DETAIL to errors when you are in an aborted transaction, if the transaction was aborted by a recovery conflict, like this:\\n> \\n> ERROR:  current transaction is aborted, commands ignored until end of transaction block\\"\\n> DETAIL:  Abort reason: recovery conflict\\n> \\n> But I don't see how to reach that. If a transaction is aborted by recovery conflict, you get a different error like this:\\n> \\n> ERROR:  canceling statement due to conflict with recovery\\n> DETAIL:  User was holding a relation lock for too long.\\n> \\n> The transaction abort clears the 'recoveryConflictPending' flag, so even if that happens in a transaction block, you don't get that \\"DETAIL: Abort reason: recovery conflict\\" in the subsequent errors.\\n> \\n> errdetail_abort() was introduced in commit a8ce974cdd. I suppose it was needed back then, but the signal handling has changed a lot since. Looking at that commit now, though, I don't really understand how it was reachable even back then. (Except with a race with an unrelated transaction abort, see commit message)\\n> \\n> Has anyone seen the \\"DETAIL:  Abort reason: recovery conflict\\" in recent years, or ever? If not, let's rip it out.\\n> \\n\\nI did a Google search and couldn't find any post reporting the message, which seems to prove that message can be removed.\\n\\n> \\n> 0002: Don't hint that you can reconnect when the database is dropped\\n> --------------------------------------------------------------------\\n> \\n> If you're connected to a database is being dropped, during recovery, you get an error like this:\\n> \\n> FATAL:  terminating connection due to conflict with recovery\\n> DETAIL:  User was connected to a database that must be dropped.\\n> HINT:  In a moment you should be able to reconnect to the database and repeat your command.\\n> \\n> The hint seems misleading. The database is being dropped, you most likely can *not* reconnect to it. Let's remove it.\\n> \\n\\nI like this change. Not only removing the misleading error message, the code is also clearer now.\\n\\n> \\n> 0003-0004:  Separate RecoveryConflictReasons from procsignals\\n> -------------------------------------------------------------\\n> \\n> We're currently using different PROCSIG_* flags to indicate different kinds of recovery conflicts. We're also abusing the same flags in functions like LogRecoveryConflict, which isn't related to inter-process signaling. It seems better to have a separate enum for the recovery conflict reasons. With this patch, there's just a single PROCSIG_RECOVERY_CONFLICT to wake up a process on a recovery conflict, and the reason is communicated by setting a flag in a bitmask in PGPROC.\\n> \\n> I was inspired to do this in preparation of my project to replaces latches with \\"interrupts\\". By having just a single PROCSIG flag, we reduce the need for \\"interrupt bits\\" with that project. But it seems nicer on its own merits too.\\n> \\n> \\n> 0005: Refactor ProcessRecoveryConflictInterrupt for readability\\n> ---------------------------------------------------------------\\n> \\n> The function had a switch-statement with fallthrough through all the cases. It took me a while to understand how it works. Once I finally understood it, I refactored it to not rely on the fallthrough. I hope this makes it easier for others too.\\n> \\n> - Heikki\\n> <0001-Remove-useless-errdetail_abort.patch><0002-Don-t-hint-that-you-can-reconnect-when-the-database-.patch><0003-Use-ProcNumber-rather-than-pid-in-ReplicationSlot.patch><0004-Separate-RecoveryConflictReasons-from-procsignals.patch><0005-Refactor-ProcessRecoveryConflictInterrupt-for-readab.patch>\\n\\nA few comments on 003-0005:\\n\\n1 - 0003\\n```\\n ReplicationSlotAcquire(const char *name, bool nowait, bool error_if_invalid)\\n {\\n \\tReplicationSlot *s;\\n-\\tint\\t\\t\\tactive_pid;\\n+\\tProcNumber\\tactive_proc;\\n+\\tpid_t\\t\\tactive_pid;\\n```\\n\\nActive_pid is only used inside the \\"if (active_proc != MyProcNumber)" clause, so it can be only defined within the "if" clause.\\n\\n\\n2 - 0003\\n```\\n \\t\\t\\t\\tif (MyBackendType == B_STARTUP)\\n-\\t\\t\\t\\t\\t(void) SendProcSignal(active_pid,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  PROCSIG_RECOVERY_CONFLICT_LOGICALSLOT,\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  INVALID_PROC_NUMBER);\\n+\\t\\t\\t\\t\\tSendProcSignal(active_pid,\\n+\\t\\t\\t\\t\\t\\t\\t\\t   PROCSIG_RECOVERY_CONFLICT_LOGICALSLOT,\\n+\\t\\t\\t\\t\\t\\t\\t\\t   active_proc);\\n```\\n\\nHere active_proc!=INVALID_PROC_NUMBER, so this changes the original logic without an explanation. Is the change intentional?\\n\\n3 - 0004\\n```\\n+\\t * This is a bitmask of RecoveryConflictReasons\\n+\\t */\\n+\\tpg_atomic_uint32 pendingRecoveryConflicts;\\n```\\n\\nI just feel this comment is a little bit confusing because RecoveryConflictReasons is an enum. Maybe we can say something like: This is a bitmask; each bit corresponds to one RecoveryConflictReason enum value.\\n\\n4 - 0004\\n```\\n-\\t\\t\\t\\t(void) SendProcSignal(pid, sigmode, vxid.procNumber);\\n+\\t\\t\\t\\t(void) SendProcSignal(pid, PROCSIG_RECOVERY_CONFLICT, vxid.procNumber);\\n```\\n\\nNit: Here (void) is retained for SendProcSignal, but in the place of commit 2 for 0003, (void) is deleted when calling SendProcSignal, is there any reason for retaining this one and deleting that one?\\n\\n5 - 0004\\n```\\n+\\t * doesn't check for deadlock direcly, because we want to kill one of the\\n```\\n\\nTypo: direcly -> directly\\n\\n6 - 0005\\n```\\ndiff --git a/src/backend/tcop/postgres.c b/src/backend/tcop/postgres.c\\nindex a2fa98ee971..bbf2254ca67 100644\\n--- a/src/backend/tcop/postgres.c\\n+++ b/src/backend/tcop/postgres.c\\n@@ -179,11 +179,15 @@ static bool IsTransactionExitStmt(Node *parsetree);\\n static bool IsTransactionExitStmtList(List *pstmts);\\n static bool IsTransactionStmtList(List *pstmts);\\n static void drop_unnamed_stmt(void);\\n+static void ProcessRecoveryConflictInterrupts(void);\\n+static void ProcessRecoveryConflictInterrupt(RecoveryConflictReason reason);\\n+static void report_recovery_conflict(RecoveryConflictReason reason);\\n static void log_disconnections(int code, Datum arg);\\n static void enable_statement_timeout(void);\\n static void disable_statement_timeout(void);\\n \\n \\n+\\n /* ----------------------------------------------------------------\\n```\\n\\nNit: No need to add this empty line.\\n\\n7 - 0005\\n```\\n+static void\\n+report_recovery_conflict(RecoveryConflictReason reason)\\n+{\\n+\\tbool\\t\\tfatal;\\n \\n+\\tif (RECOVERY_CONFLICT_DATABASE)\\n+\\t{\\n```\\n\\nI believe this should be if (reason == RECOVERY_CONFLICT_DATABASE).\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be802be712bae9","snippet":"> On Jan 23, 2026, at 07:20, Heikki Linnakangas <hlinnaka@iki.fi> wrote: > > I had a look at recovery conflict signaling and a few things caught my eye. No functional changes, but some","historyId":"8736","internalDate":"1769136100000","receivedAtUtc":"2026-01-23T02:41:40.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	Heikki Linnakangas proposed a series of patches to refactor PostgreSQL's recovery conflict signaling without functional changes. The patches include removing an unreachable errdetail_abort() function that was supposed to show "Abort reason: recovery conflict" messages, eliminating misleading reconnection hints when databases are being dropped, separating RecoveryConflictReasons from PROCSIG flags by introducing a single PROCSIG_RECOVERY_CONFLICT signal with reason communicated via bitmask in PGPROC, and refactoring ProcessRecoveryConflictInterrupt to remove confusing switch-statement fallthrough logic. Chao Li provided detailed feedback identifying several issues: a variable scoping optimization, a logic change that may be unintentional, unclear comment wording, inconsistent void casting, a typo, an unnecessary empty line, and a missing equality check in condition statement. The reviewer generally supports the changes for improved code clarity.\nHeikki Linnakangas提出了一系列补丁来重构PostgreSQL的恢复冲突信号处理，不涉及功能性更改。这些补丁包括：移除无法到达的errdetail_abort()函数（该函数本应显示"中止原因：恢复冲突"消息）；当数据库正在被删除时，消除误导性的重连提示；通过引入单一的PROCSIG_RECOVERY_CONFLICT信号将RecoveryConflictReasons与PROCSIG标志分离，原因通过PGPROC中的位掩码传达；重构ProcessRecoveryConflictInterrupt以移除令人困惑的switch语句穿透逻辑。Chao Li提供了详细反馈，指出了几个问题：变量作用域优化、可能是无意的逻辑更改、注释措辞不清、void转换不一致、拼写错误、不必要的空行以及条件语句中缺少相等检查。审查者总体上支持这些更改以提高代码清晰度。	2026-01-23 02:41:40+00	\N
14	19be8d7e8b61b753	Fix a typo in comment	["dingyi_yale@163.com","michael@paquier.xyz"]	[{"id":"19be8d7e8b61b753","messageId":"<5cfb747.2f21.19be8d77431.Coremail.dingyi_yale@163.com>","subject":"Fix a typo in comment","body":"Hi Hackers,\\n\\n\\nRecently, I found a comment error in multixact.c. To address this, I've prepared a relevant patch.\\n\\n\\nFor the details,please see the attached patch file.\\n\\n\\nLooking forward to your feedback.\\n\\n\\nBest regards,\\n--\\nYi Ding\\n\\n","threadId":"19be8d7e8b61b753","snippet":"Hi Hackers, Recently, I found a comment error in multixact.c. To address this, I've prepared a relevant patch. For the details,please see the attached patch file. Looking forward to your feedback.","historyId":"8748","internalDate":"1769137992000","receivedAtUtc":"2026-01-23T03:13:12.000Z","from":"Yi Ding <dingyi_yale@163.com>"},{"id":"19be91cdf4d420fe","messageId":"<aXL4_Zx7zWGuvktz@paquier.xyz>","subject":"Re: Fix a typo in comment","body":"On Fri, Jan 23, 2026 at 11:13:12AM +0800, Yi Ding wrote:\\n> Recently, I found a comment error in multixact.c. To address this,\\n> I've prepared a relevant patch.\\n> \\n> For the details,please see the attached patch file.\\n\\nThanks for the report, picked up for later.\\n--\\nMichael\\n","threadId":"19be8d7e8b61b753","snippet":"On Fri, Jan 23, 2026 at 11:13:12AM +0800, Yi Ding wrote: > Recently, I found a comment error in multixact.c. To address this, > I've prepared a relevant patch. > > For the details,","historyId":"8748","internalDate":"1769142525000","receivedAtUtc":"2026-01-23T04:28:45.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	Yi Ding reported a comment error in multixact.c and prepared a patch to fix the typo. The patch details were provided in an attached file. Michael Paquier acknowledged the report and confirmed it has been picked up for later review. This appears to be a straightforward documentation fix with no technical controversy or complex implementation issues. The next step involves Michael reviewing the attached patch file to validate and potentially commit the typo correction.\n\n易鼎报告了 multixact.c 中的注释错误，并准备了一个补丁来修复这个错字。补丁详细信息在附件文件中提供。Michael Paquier 确认收到了报告，并表示已将其纳入后续审查。这似乎是一个直接的文档修复，没有技术争议或复杂的实现问题。下一步涉及 Michael 审查附件补丁文件以验证并可能提交这个错字更正。	2026-01-23 04:28:45+00	\N
14	19be57f2bef34a1b	Assert the timestamp is available for ORIGN_DIFFERS conflicts	["amit.kapila16@gmail.com","kuroda.hayato@fujitsu.com","li.evan.chao@gmail.com","shveta.malik@gmail.com"]	[{"id":"19be8cb67e7e4cf0","messageId":"<CAA4eK1K_g7bi+6=rut3CFV0rSyBPoFVbZ1k8zeLNRE5SFnmtuA@mail.gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"On Thu, Jan 22, 2026 at 6:30 PM Chao Li <li.evan.chao@gmail.com> wrote:\\n>\\n> > On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> >\\n> > Dear Shveta,\\n> >\\n> > Thanks for ideas, I prefer first one. Also, pgindent told me that Line blank\\n> > should be before the code comment. PSA the new version.\\n> >\\n> > Best regards,\\n> > Hayato Kuroda\\n> > FUJITSU LIMITED\\n> >> Shveta\\n> > <v2-0001-Add-Assert-for-UPDATE-DELETE-_ORIGIN_DIFFERS.patch>\\n>\\n> Hi Hayato-san,\\n>\\n> Thanks for the patch. Though the change is simple, I see some problems:\\n>\\n> ```\\n> +                       /*\\n> +                        * We reach this point only if track_commit_timestamp is enabled.\\n> +                        * Therefore, localts must contain a valid timestamp.\\n> +                        */\\n> +                       Assert(localts);\\n> ```\\n>\\n> 1. The same code appears twice, so kinda redundant.\\n> 2. The comment is unclear. It asserts localts, but the comment talks about GUC track_commit_timestamp.\\n> 3. Assert(localts) technically works, because C treat un-zero integer as true, but as we are check localts is valid, it's better to be explicit as Assert(localts != 0).\\n>\\n> So, I would suggest add the assert in the very beginning of the function as:\\n> ```\\n> /*\\n>  * UPDATE_ORIGIN_DIFFERS and DELETE_ORIGIN_DIFFERS conflicts are only\\n>  * reported when track_commit_timestamp is enabled, and a valid local\\n>  * commit timestamp is available for the conflicting row.\\n>  */\\n> Assert(type != CT_UPDATE_ORIGIN_DIFFERS && type != CT_DELETE_ORIGIN_DIFFERS || localts != 0);\\n>\\n\\nWe can follow your suggestion to reduce minor code duplicacy but OTOH\\nit leads to type specific checks (Assert in this case) which can make\\ncode difficult to follow if we continue such a practice. But your idea\\nto have a bit more explicit assert like Assert(localts != 0) sounds\\nokay to me.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"On Thu, Jan 22, 2026 at 6:30 PM Chao Li <li.evan.chao@gmail.com> wrote: > > > On Jan 21, 2026, at 15:10, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > >","historyId":"8712","internalDate":"1769137180000","receivedAtUtc":"2026-01-23T02:59:40.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>"},{"id":"19be9207a168ce05","messageId":"<TY7PR01MB145546B9A4725551D8D662669F594A@TY7PR01MB14554.jpnprd01.prod.outlook.com>","subject":"RE: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"Dear Amit, Chao,\\n\\nThanks for giving comments. But I do not want to move the Assert() atop\\nswitch-case statements; the function would be dirty for other cases.\\nAttached patch updates condition and comments based on your suggestions.\\n\\nBest regards,\\nHayato Kuroda\\nFUJITSU LIMITED\\n\\n","threadId":"19be57f2bef34a1b","snippet":"Dear Amit, Chao, Thanks for giving comments. But I do not want to move the Assert() atop switch-case statements; the function would be dirty for other cases. Attached patch updates condition and","historyId":"8712","internalDate":"1769142758000","receivedAtUtc":"2026-01-23T04:32:38.000Z","from":"\\"Hayato Kuroda (Fujitsu)\\" <kuroda.hayato@fujitsu.com>"},{"id":"19be9324dfa77273","messageId":"<5901BDE1-4726-4823-B69E-3111AE368C60@gmail.com>","subject":"Re: Assert the timestamp is available for ORIGN_DIFFERS conflicts","body":"\\n\\n> On Jan 23, 2026, at 12:32, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> \\n> Dear Amit, Chao,\\n> \\n> Thanks for giving comments. But I do not want to move the Assert() atop\\n> switch-case statements; the function would be dirty for other cases.\\n> Attached patch updates condition and comments based on your suggestions.\\n> \\n> Best regards,\\n> Hayato Kuroda\\n> FUJITSU LIMITED\\n> \\n> <v3-0001-Add-Assert-for-UPDATE-DELETE-_ORIGIN_DIFFERS.patch>\\n\\nThanks for updating the patch. V3 looks good to me.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be57f2bef34a1b","snippet":"> On Jan 23, 2026, at 12:32, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > Dear Amit, Chao, > > Thanks for giving comments. But I do not want to move the Assert()","historyId":"8712","internalDate":"1769143895000","receivedAtUtc":"2026-01-23T04:51:35.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	The discussion centers on a PostgreSQL patch by Hayato Kuroda to add Assert statements for UPDATE_ORIGIN_DIFFERS and DELETE_ORIGIN_DIFFERS conflicts. Chao Li provided feedback on the v2 patch, identifying three issues: code redundancy with duplicate assertions, unclear comments linking localts assertion to track_commit_timestamp GUC, and preference for explicit Assert(localts != 0) over Assert(localts). Chao suggested consolidating the assertions at the function's beginning with a single comprehensive check. Amit Kapila acknowledged the suggestion to reduce duplication but expressed concern about type-specific checks making code harder to follow, while agreeing that Assert(localts != 0) is more explicit. Hayato declined to move the Assert to the top of switch-case statements, citing concerns about code cleanliness for other cases, and updated the patch to v3 addressing the feedback on conditions and comments. Chao approved the v3 version, indicating the discussion has reached consensus.\n\n该讨论围绕PostgreSQL的一个补丁展开，该补丁由Kuroda Hayato编写，用于为UPDATE_ORIGIN_DIFFERS和DELETE_ORIGIN_DIFFERS冲突添加Assert语句。Chao Li对v2补丁提供了反馈，指出了三个问题：重复断言导致的代码冗余、将localts断言与track_commit_timestamp GUC联系的注释不清晰，以及倾向于使用明确的Assert(localts != 0)而非Assert(localts)。Chao建议在函数开始处用单个综合检查来整合断言。Amit Kapila承认减少重复的建议，但表达了对特定类型检查可能使代码更难理解的担忧，同时同意Assert(localts != 0)更加明确。Hayato拒绝将Assert移至switch-case语句顶部，担心会影响其他情况的代码整洁性，并更新补丁至v3版本，解决了关于条件和注释的反馈。Chao批准了v3版本，表明讨论已达成共识。	2026-01-23 04:51:35+00	\N
14	19be8ba53541a4cd	DOCS - "\\d mytable" also shows any publications that publish mytable	["li.evan.chao@gmail.com","masao.fujii@gmail.com","smithpb2250@gmail.com"]	[{"id":"19be8ba53541a4cd","messageId":"<CAHGQGwFhkhdK79fTeYEnxxfgmzjjshfXuBBnfwoD7GneEdBokQ@mail.gmail.com>","subject":"Re: DOCS - \\"\\\\d mytable\\" also shows any publications that publish mytable","body":"On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote:\\n> > Regarding whole patch, I'm not clear about whether this patch is worthwhile\\n> > if it only adds phrasing like \\"such as\\" or \\"for example\\". That said, if some\\n> > users currently interpret the list as exhaustive, this change could help\\n> > clarify the intent...\\n> >\\n>\\n> Yes. The patch is not doing much now, but OTOH the reason for this\\n> patch adding the \\"missing\\" publication entry in the first place was\\n> precisely because I thought the docs page was was documenting\\n> exhaustive lists; so there might be some merit to clear up that\\n> illusion.\\n\\nOK, let's commit the patch as a documentation improvement to\\nreduce user confusion.\\n\\n> PSA v4.\\n\\nThanks for updating the patch! I've applied a few small tweaks and\\nattached an updated version.\\n\\n+        Associated objects, such as indexes, constraints, rules, publications,\\n+        triggers, and so on, are also shown. For foreign tables, the\\n\\nI removed \\"and so on\\" because using both \\"such as\\" and \\"and so on\\"\\nin the same sentence felt redundant.\\n\\n+        more information is displayed, such as: any comments associated with\\n\\nI removed \\"such as\\" and instead added \\"for example\\" before \\"any comments\\",\\nwhich felt more natural here at least for me.\\n\\n-         identity</link> setting and the\\n+         identity</link> settings and the\\n\\nI'm not sure this change is necessary, so I restored the original wording.\\n\\nI also updated the commit message.\\n\\nRegards,\\n\\n-- \\nFujii Masao\\n","threadId":"19be8ba53541a4cd","snippet":"On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote: > > Regarding whole patch, I'm not clear about whether this patch is worthwhile > > if it only adds","historyId":"8746","internalDate":"1769136058000","receivedAtUtc":"2026-01-23T02:40:58.000Z","from":"Fujii Masao <masao.fujii@gmail.com>"},{"id":"19be8c1bf9900460","messageId":"<21B1E0AE-665B-4BEA-9894-65632F36FA06@gmail.com>","subject":"Re: DOCS - \\"\\\\d mytable\\" also shows any publications that publish mytable","body":"\\n\\n> On Jan 23, 2026, at 10:40, Fujii Masao <masao.fujii@gmail.com> wrote:\\n> \\n> On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote:\\n>>> Regarding whole patch, I'm not clear about whether this patch is worthwhile\\n>>> if it only adds phrasing like \\"such as\\" or \\"for example\\". That said, if some\\n>>> users currently interpret the list as exhaustive, this change could help\\n>>> clarify the intent...\\n>>> \\n>> \\n>> Yes. The patch is not doing much now, but OTOH the reason for this\\n>> patch adding the \\"missing\\" publication entry in the first place was\\n>> precisely because I thought the docs page was was documenting\\n>> exhaustive lists; so there might be some merit to clear up that\\n>> illusion.\\n> \\n> OK, let's commit the patch as a documentation improvement to\\n> reduce user confusion.\\n> \\n>> PSA v4.\\n> \\n> Thanks for updating the patch! I've applied a few small tweaks and\\n> attached an updated version.\\n> \\n> +        Associated objects, such as indexes, constraints, rules, publications,\\n> +        triggers, and so on, are also shown. For foreign tables, the\\n> \\n> I removed \\"and so on\\" because using both \\"such as\\" and \\"and so on\\"\\n> in the same sentence felt redundant.\\n> \\n> +        more information is displayed, such as: any comments associated with\\n> \\n> I removed \\"such as\\" and instead added \\"for example\\" before \\"any comments\\",\\n> which felt more natural here at least for me.\\n> \\n> -         identity</link> setting and the\\n> +         identity</link> settings and the\\n> \\n> I'm not sure this change is necessary, so I restored the original wording.\\n> \\n> I also updated the commit message.\\n> \\n> Regards,\\n> \\n> -- \\n> Fujii Masao\\n> <v5-0001-doc-Clarify-that-d-and-d-output-lists-are-illustr.patch>\\n\\n```\\n+        Associated objects, such as indexes, constraints, rules,triggers,\\n```\\n\\nA while-space is missed before "triggers". I tried to render the page, on the rendered html page, the white-space is also missed.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be8ba53541a4cd","snippet":"> On Jan 23, 2026, at 10:40, Fujii Masao <masao.fujii@gmail.com> wrote: > > On Thu, Jan 22, 2026 at 3:15 PM Peter Smith <smithpb2250@gmail.com> wrote: >>> Regarding whole","historyId":"8746","internalDate":"1769136524000","receivedAtUtc":"2026-01-23T02:48:44.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be96709d5e0640","messageId":"<CAHut+PuYw21ipjrNEj2PFDCRxVKQpbCabNOT8N4BkoVMbKBzuQ@mail.gmail.com>","subject":"Re: DOCS - \\"\\\\d mytable\\" also shows any publications that publish mytable","body":"v5 LGTM, except for the missing space that Chao has already reported.\\n\\n======\\nKind Regards,\\nPeter Smith.\\nFujitsu Australia\\n\\n\\n","threadId":"19be8ba53541a4cd","snippet":"v5 LGTM, except for the missing space that Chao has already reported. ====== Kind Regards, Peter Smith. Fujitsu Australia","historyId":"12876","internalDate":"1769147366000","receivedAtUtc":"2026-01-23T05:49:26.000Z","from":"Peter Smith <smithpb2250@gmail.com>"}]	Fujii Masao is preparing to commit a documentation patch that clarifies the `\\d` command output lists are illustrative, not exhaustive. The patch adds phrases like "such as" and "for example" to indicate that the listed associated objects (indexes, constraints, rules, publications, triggers) are examples rather than complete lists. Peter Smith originally proposed this change after initially thinking the documentation presented exhaustive lists. Fujii made several editorial refinements to the v4 patch, removing redundant phrasing like "and so on" when "such as" was already used, and changing some instances to "for example" for better flow. Chao Li identified a missing whitespace before "triggers" in the rendered documentation that needs correction. Peter Smith approved v5 except for this spacing issue.\n\nFujii Masao正在准备提交一个文档补丁，该补丁明确说明`\\d`命令输出列表是示例性的，而非详尽的。补丁添加了"such as"和"for example"等短语，表明列出的关联对象（索引、约束、规则、发布、触发器）是示例而非完整列表。Peter Smith最初提出此更改，因为他之前认为文档呈现的是详尽列表。Fujii对v4补丁进行了几处编辑改进，在已使用"such as"时删除了冗余的"and so on"短语，并将某些实例改为"for example"以改善表达流畅性。Chao Li发现渲染文档中"triggers"前缺少空格需要修正。Peter Smith批准了v5版本，除了这个间距问题。	2026-01-23 05:49:26+00	\N
14	19be76a420b81e68	pg_upgrade: optimize replication slot caught-up check	["li.evan.chao@gmail.com","sawada.mshk@gmail.com","shveta.malik@gmail.com"]	[{"id":"19be86d26e5beafb","messageId":"<B098C626-EE7D-4E98-8685-FBB7980C795E@gmail.com>","subject":"Re: pg_upgrade: optimize replication slot caught-up check","body":"\\n\\n> On Jan 23, 2026, at 04:33, Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> \\n> On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote:\\n>> \\n>> On Thu, Jan 22, 2026 at 5:19 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n>>> \\n>>> On Mon, Jan 19, 2026 at 10:38 PM shveta malik <shveta.malik@gmail.com> wrote:\\n>>>> \\n>>>> On Wed, Jan 14, 2026 at 11:24 PM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n>>>>> \\n>>>>> I've attached the updated patch.\\n>>>>> \\n>>>> \\n>>>> Thank You for the patch. I like the idea of optimization. Few initial comments:\\n>>> \\n>>> Thank you for reviewing the patch!\\n>>> \\n>>>> \\n>>>> 1)\\n>>>> + * The query returns the slot names and their caught-up status in\\n>>>> + * the same order as the results collected by\\n>>>> + * get_old_cluster_logical_slot_infos(). If this query is changed,\\n>>>> \\n>>>> I could not find the function get_old_cluster_logical_slot_infos(), do\\n>>>> you mean get_old_cluster_logical_slot_infos_query()?\\n>>> \\n>>> It seems an oversight in commit 6d3d2e8e541f0. I think it should be\\n>>> get_db_rel_and_slot_infos().\\n>>> \\n>>>> \\n>>>> 2)\\n>>>> \\"  WHERE database = current_database() AND \\"\\n>>>> \\"    slot_type = 'logical' AND \\"\\n>>>> \\n>>>> Is there a reason why database = current_database() is placed before\\n>>>> slot_type = 'logical'? I am not sure how the PostgreSQL optimizer and\\n>>>> executor will order these predicates, but from the first look,\\n>>>> slot_type = 'logical' appears cheaper and could be placed first,\\n>>>> consistent with the ordering used at other places.\\n>>> \\n>>> Changed.\\n>>> \\n>>>> \\n>>>> 3)\\n>>>> Shouldn't we add a sanity check inside\\n>>>> get_old_cluster_logical_slot_infos_query() to ensure that when\\n>>>> skip_caught_up_check is true, we are on PostgreSQL 18 or lower? This\\n>>>> would make the function safer for future use if it's called elsewhere.\\n>>>> I understand the caller already performs a similar check, but I think\\n>>>> it's more appropriate here since we call\\n>>>> binary_upgrade_logical_slot_has_caught_up() from inside, which doesn't\\n>>>> even exist on newer versions.\\n>>> \\n>>> What kind of sanity check did you mean? We can have a check with\\n>>> pg_fatal() but it seems almost the same to me even if pg_upgrade fails\\n>>> with an error due to missing\\n>>> binary_upgrade_logical_slot_has_caught_up().\\n>> \\n>> I was referring to a development-level sanity check, something like:\\n>> \\n>> /* skip_caught_up_check is required iff PG19 or newer */\\n>> Assert((GET_MAJOR_VERSION(cluster->major_version) >= 1900) ==\\n>>   skip_caught_up_check);\\n>> \\n>> But performing this check requires access to the cluster version (or\\n>> cluster information), which this function currently does not have.\\n>> Given that, do you think it would make sense to pass the cluster as an\\n>> argument to this function in order to perform the sanity check here?\\n> \\n> Hmm, I think it's better not to have the same check in multiple\\n> places, but it might make sense to have\\n> get_old_cluster_logical_slot_infos_query() decide whether to use the\\n> fast method. I've updated the patch accordingly, please review it.\\n> \\n>> \\n>>>> \\n>>>> 4)\\n>>>> +# Check the file content. While both test_slot1 and test_slot2 should\\n>>>> be reporting\\n>>>> +# that they have unconsumed WAL records, test_slot3 should not be reported as\\n>>>> +# it has caught up.\\n>>>> \\n>>>> Can you please elaborate the reason behind test_slot3 not being\\n>>>> reported? Also mention in the comment if possible.\\n>>> \\n>>> We advance test_slot3 to the current WAL LSN before executing\\n>>> pg_upgrade, so the test_slot3 should have consumed all pending WALs.\\n>>> Please refer to the following changes:\\n>> \\n>> I understand the test, and the comments are clear to me. I also\\n>> understand that only test_slot3 is expected to be in the caught-up\\n>> state. My questions were specifically about the following points:\\n>> 1)  Why do we expect 'slot3 caught-up' not to be mentioned in the LOG?\\n>> Is it simply because there is no corresponding logging in the code, or\\n>> is this behavior related to some aspect of your fix that I may have\\n>> missed?\\n>> \\n>> 2) In general, we do not validate the absence of LOG messages in\\n>> tests. Why is this considered a special case where such a check is\\n>> appropriate?\\n> \\n> What LOG do you refer to? In these tests, we check the\\n> invalid_logical_slots.txt file where pg_upgrade reports only invalid\\n> slots (in terms of pg_upgrade). For test_slot3, it should not be\\n> mentioned in that file as it has caught up. Given that the file has\\n> only invalid slots, checking the absence of test_slot3 in the file\\n> makes sense to me.\\n> \\n> \\n> Regards,\\n> \\n> --\\n> Masahiko Sawada\\n> Amazon Web Services: https://aws.amazon.com\\n> <v7-0001-pg_upgrade-Optimize-replication-slot-caught-up-ch.patch>\\n\\nI just went through v7, and overall looks good to me.\\n\\nOnly nitpick is:\\n```\\n+ *\\n+ * use_fast_caught_up_check is set to true on return if available in the given\\n+ * cluster.\\n```\\n\\nStrictly speaking, use_fast_caught_up_check is a pointer, it cannot be set, it is *use_fast_caught_up_check that is set to true. So, please add a star sign in front of use_fast_caught_up_check.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be76a420b81e68","snippet":"> On Jan 23, 2026, at 04:33, Masahiko Sawada <sawada.mshk@gmail.com> wrote: > > On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote: >> >> On","historyId":"8730","internalDate":"1769130977000","receivedAtUtc":"2026-01-23T01:16:17.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be9a9fb4ead83a","messageId":"<CAJpy0uAf-S-MWsnTk17VY8AkpbBGSpjxKeZNGCh_dCRLJJW4-Q@mail.gmail.com>","subject":"Re: pg_upgrade: optimize replication slot caught-up check","body":"On Fri, Jan 23, 2026 at 2:04 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n>\\n> On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> >\\n> > On Thu, Jan 22, 2026 at 5:19 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> > >\\n> > > On Mon, Jan 19, 2026 at 10:38 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> > > >\\n> > > > On Wed, Jan 14, 2026 at 11:24 PM Masahiko Sawada <sawada.mshk@gmail.com> wrote:\\n> > > > >\\n> > > > > I've attached the updated patch.\\n> > > > >\\n> > > >\\n> > > > Thank You for the patch. I like the idea of optimization. Few initial comments:\\n> > >\\n> > > Thank you for reviewing the patch!\\n> > >\\n> > > >\\n> > > > 1)\\n> > > > + * The query returns the slot names and their caught-up status in\\n> > > > + * the same order as the results collected by\\n> > > > + * get_old_cluster_logical_slot_infos(). If this query is changed,\\n> > > >\\n> > > > I could not find the function get_old_cluster_logical_slot_infos(), do\\n> > > > you mean get_old_cluster_logical_slot_infos_query()?\\n> > >\\n> > > It seems an oversight in commit 6d3d2e8e541f0. I think it should be\\n> > > get_db_rel_and_slot_infos().\\n> > >\\n> > > >\\n> > > > 2)\\n> > > > \\"  WHERE database = current_database() AND \\"\\n> > > > \\"    slot_type = 'logical' AND \\"\\n> > > >\\n> > > > Is there a reason why database = current_database() is placed before\\n> > > > slot_type = 'logical'? I am not sure how the PostgreSQL optimizer and\\n> > > > executor will order these predicates, but from the first look,\\n> > > > slot_type = 'logical' appears cheaper and could be placed first,\\n> > > > consistent with the ordering used at other places.\\n> > >\\n> > > Changed.\\n> > >\\n> > > >\\n> > > > 3)\\n> > > > Shouldn't we add a sanity check inside\\n> > > > get_old_cluster_logical_slot_infos_query() to ensure that when\\n> > > > skip_caught_up_check is true, we are on PostgreSQL 18 or lower? This\\n> > > > would make the function safer for future use if it's called elsewhere.\\n> > > > I understand the caller already performs a similar check, but I think\\n> > > > it's more appropriate here since we call\\n> > > > binary_upgrade_logical_slot_has_caught_up() from inside, which doesn't\\n> > > > even exist on newer versions.\\n> > >\\n> > > What kind of sanity check did you mean? We can have a check with\\n> > > pg_fatal() but it seems almost the same to me even if pg_upgrade fails\\n> > > with an error due to missing\\n> > > binary_upgrade_logical_slot_has_caught_up().\\n> >\\n> > I was referring to a development-level sanity check, something like:\\n> >\\n> > /* skip_caught_up_check is required iff PG19 or newer */\\n> > Assert((GET_MAJOR_VERSION(cluster->major_version) >= 1900) ==\\n> >    skip_caught_up_check);\\n> >\\n> > But performing this check requires access to the cluster version (or\\n> > cluster information), which this function currently does not have.\\n> > Given that, do you think it would make sense to pass the cluster as an\\n> > argument to this function in order to perform the sanity check here?\\n>\\n> Hmm, I think it's better not to have the same check in multiple\\n> places, but it might make sense to have\\n> get_old_cluster_logical_slot_infos_query() decide whether to use the\\n> fast method. I've updated the patch accordingly, please review it.\\n>\\n\\nOkay, looks good. Just one minor thing:\\n\\n+ * Note that binary_upgrade_logical_slot_has_caught_up() is available only\\n+ * PG18 or older. For PG19 or newer *use_fast_caught_up_check should be\\n+ * set true, and use binary_upgrade_check_logical_slot_pending_wal()\\n+ * instead in the separate query (see slot_caught_up_info_query).\\n\\nShall we tweak it slightly:\\n\\n * Note that binary_upgrade_logical_slot_has_caught_up() is available\\n * only in PG18 and earlier. For PG19 and later, set *use_fast_caught_up_check\\n * to true and use binary_upgrade_check_logical_slot_pending_wal() instead,\\n * in a separate query (see slot_caught_up_info_query in\\nget_db_rel_and_slot_infos()).\\n\\n\\n> >\\n> > > >\\n> > > > 4)\\n> > > > +# Check the file content. While both test_slot1 and test_slot2 should\\n> > > > be reporting\\n> > > > +# that they have unconsumed WAL records, test_slot3 should not be reported as\\n> > > > +# it has caught up.\\n> > > >\\n> > > > Can you please elaborate the reason behind test_slot3 not being\\n> > > > reported? Also mention in the comment if possible.\\n> > >\\n> > > We advance test_slot3 to the current WAL LSN before executing\\n> > > pg_upgrade, so the test_slot3 should have consumed all pending WALs.\\n> > > Please refer to the following changes:\\n> >\\n> > I understand the test, and the comments are clear to me. I also\\n> > understand that only test_slot3 is expected to be in the caught-up\\n> > state. My questions were specifically about the following points:\\n> > 1)  Why do we expect 'slot3 caught-up' not to be mentioned in the LOG?\\n> > Is it simply because there is no corresponding logging in the code, or\\n> > is this behavior related to some aspect of your fix that I may have\\n> > missed?\\n> >\\n> > 2) In general, we do not validate the absence of LOG messages in\\n> > tests. Why is this considered a special case where such a check is\\n> > appropriate?\\n>\\n> What LOG do you refer to? In these tests, we check the\\n> invalid_logical_slots.txt file where pg_upgrade reports only invalid\\n> slots (in terms of pg_upgrade). For test_slot3, it should not be\\n> mentioned in that file as it has caught up. Given that the file has\\n> only invalid slots, checking the absence of test_slot3 in the file\\n> makes sense to me.\\n>\\n\\nOkay, I get the intent now. Thanks!\\n\\nOther than the comment suggestion above, the patch LGTM.\\n\\nthanks\\nShveta\\n\\n\\n","threadId":"19be76a420b81e68","snippet":"On Fri, Jan 23, 2026 at 2:04 AM Masahiko Sawada <sawada.mshk@gmail.com> wrote: > > On Wed, Jan 21, 2026 at 7:49 PM shveta malik <shveta.malik@gmail.com> wrote: > > > > On","historyId":"12873","internalDate":"1769151767000","receivedAtUtc":"2026-01-23T07:02:47.000Z","from":"shveta malik <shveta.malik@gmail.com>"}]	Masahiko Sawada has submitted version 7 of a patch to optimize pg_upgrade's replication slot caught-up check. The optimization involves using a faster method for PostgreSQL 19+ by leveraging binary_upgrade_check_logical_slot_pending_wal() in a separate query, while maintaining backward compatibility with older versions using binary_upgrade_logical_slot_has_caught_up(). Reviewers Shveta Malik and Chao Li provided feedback on function naming, query predicate ordering, sanity checks, and documentation clarity. Sawada addressed the concerns by refactoring the code to have get_old_cluster_logical_slot_infos_query() automatically decide which method to use based on version. Minor documentation improvements were suggested regarding pointer notation and comment wording. The reviewers expressed overall approval of the approach and implementation.\n\nMasahiko Sawada 提交了第 7 版补丁，用于优化 pg_upgrade 的复制槽追赶检查。该优化通过在 PostgreSQL 19+ 中使用 binary_upgrade_check_logical_slot_pending_wal() 在单独查询中实现更快的方法，同时保持与使用 binary_upgrade_logical_slot_has_caught_up() 的旧版本的向后兼容性。审查者 Shveta Malik 和 Chao Li 就函数命名、查询谓词排序、完整性检查和文档清晰度提供了反馈。Sawada 通过重构代码来解决这些问题，让 get_old_cluster_logical_slot_infos_query() 根据版本自动决定使用哪种方法。审查者建议对指针符号和注释措辞进行小的文档改进。审查者对该方法和实现表示整体认可。	2026-01-23 07:02:47+00	\N
14	19be4f0789a66a7c	tablecmds: reject CLUSTER ON for partitioned tables earlier	["li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be859463d03e42","messageId":"<EA6CB317-60C2-4BA9-8E02-DBCAD384F107@gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"\\n\\n> On Jan 23, 2026, at 07:30, Chao Li <li.evan.chao@gmail.com> wrote:\\n> \\n> \\n> \\n>> On Jan 22, 2026, at 17:01, Chao Li <li.evan.chao@gmail.com> wrote:\\n>> \\n>> \\n>> \\n>>> On Jan 21, 2026, at 11:55, Chao Li <li.evan.chao@gmail.com> wrote:\\n>>> \\n>>> Hi Hacker,\\n>>> \\n>>> I noticed this while working other patches related to "ALTER TABLE".\\n>>> \\n>>> "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for partitioned tables, but currently ATPrepCmd() allows them through and they only fail later at execution time.\\n>>> \\n>>> This patch rejects these commands earlier by using the existing ATSimplePermissions() infrastructure in ATPrepCmd(), matching the handling of other unsupported ALTER TABLE actions on partitioned tables (such as SET LOGGED / SET UNLOGGED). This makes the behavior more consistent and simplifies the code path.\\n>>> \\n>>> As a result, the error reported for partitioned tables changes:\\n>>> \\n>>> Before the patch:\\n>>> ```\\n>>> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n>>> ERROR:  cannot mark index clustered in partitioned table\\n>>> ```\\n>>> \\n>>> With the patch:\\n>>> ```\\n>>> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n>>> ERROR:  ALTER action CLUSTER ON cannot be performed on relation \\"p_test\\"\\n>>> DETAIL:  This operation is not supported for partitioned tables.\\n>>> ```\\n>>> \\n>>> Best regards,\\n>>> --\\n>>> Chao Li (Evan)\\n>>> HighGo Software Co., Ltd.\\n>>> https://www.highgo.com/\\n>>> \\n>>> \\n>>> \\n>>> \\n>>> <v1-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch>\\n>> \\n>> \\n>> \\n>> Applying the same change to INHERIT/NO INHeRIT in v2-0002. Other than that, fixing 2 more things for INHERIT/NO INHERIT:\\n>> \\n>> * The header comment of ATPrepAddInherit() was a copy-paste mistake, it described something totally unrelated.\\n>> * NO INHERIT didn't call ATPrepAddInherit() to check early, so it had to go deeper and run unnecessary checks.\\n>> \\n>> Basically, 0001 and 0002 do the same thing on two sub-commands. If accepted, they can be squashed.\\n>> \\n>> Best regards,\\n>> --\\n>> Chao Li (Evan)\\n>> HighGo Software Co., Ltd.\\n>> https://www.highgo.com/\\n>> \\n>> <v2-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch><v2-0002-tablecmds-reject-INHERIT-NO-INHERIT-for-partition.patch>\\n> \\n> PFA v3:\\n> \\n> 0001 is the same as v2. In 0002:\\n> \\n> * Restored the header comment of ATPrepAddInherit, because I realized the should belong to ATExecAddInherit.\\n> * Renamed ATPrepAddInherit to ATPrepChangeInherit.\\n> \\n> Best regards,\\n> --\\n> Chao Li (Evan)\\n> HighGo Software Co., Ltd.\\n> https://www.highgo.com/\\n> \\n> \\n> \\n> \\n> <v3-0001-tablecmds-reject-CLUSTER-ON-for-partitioned-table.patch><v3-0002-tablecmds-reject-INHERIT-NO-INHERIT-for-partition.patch>\\n\\nPlease ignore v3 that was badly generated.\\n\\nPFA v4:\\n\\n> 0001 is the same as v2. In 0002:\\n> \\n> * Restored the header comment of ATPrepAddInherit, because I realized the should belong to ATExecAddInherit.\\n> * Renamed ATPrepAddInherit to ATPrepChangeInherit.\\n\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n","threadId":"19be4f0789a66a7c","snippet":"> On Jan 23, 2026, at 07:30, Chao Li <li.evan.chao@gmail.com> wrote: > > > >> On Jan 22, 2026, at 17:01, Chao Li <li.evan.chao@gmail.com> wrote: >> >> >>","historyId":"8704","internalDate":"1769129673000","receivedAtUtc":"2026-01-23T00:54:33.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19be9cedd50133b5","messageId":"<CAN4CZFMUJWM0veLK93Ew8mYaL5pcU6G550STh6AZ-_LWV2zS+w@mail.gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"Hello!\\n\\nA simple patch and generally looks good, I only have a few observations.\\n\\n> "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for\\n> partitioned tables, but currently ATPrepCmd() allows them through and they\\n> only fail later at execution time.\\n\\nLooking at the ALTER TABLE documentation, for other options there is a\\nmention like \\"This form is not currently supported on partitioned\\ntables.\\" / \\"This form is not supported for partitioned tables.\\"\\n\\nI don't see this mentioned for CLUSTER or INHERIT. Maybe it would be\\nbetter to also mention this in the documentation?\\n\\nAlso, there seems to be no test for partitioned NO INHERIT, since the\\npatch changes it, it could also add a test case to verify the\\nbehavior.\\n\\nrg \\"INHERIT\\" | grep \\"cannot be performed\\"\\nsrc/test/regress/expected/alter_table.out:ERROR:  ALTER action INHERIT\\ncannot be performed on relation \\"partitioned\\"\\n\\nrg \\"NO INHERIT\\" | grep \\"cannot be performed\\"\\n# no result\\n\\ntablecmds.c:5202\\n  case AT_DropInherit: /* NO INHERIT */\\n  ATSimplePermissions(cmd->subtype, rel,\\n- ATT_TABLE | ATT_PARTITIONED_TABLE | ATT_FOREIGN_TABLE);\\n+ ATT_TABLE | ATT_FOREIGN_TABLE);\\n  /* This command never recurses */\\n+ ATPrepChangeInherit(rel);\\n  /* No command-specific prep needed */\\n\\nThat last comment seems to be a leftover, it's no longer true with this change.\\n\\ntablecmds.c:17289 trailing whitespace (in the empty line)\\n /*\\n+ * ALTER TABLE INHERIT\\n+ *\\n+ * Add a parent to the child's parents. This verifies that all the columns and\\n+ * check constraints of the parent appear in the child and that they have the\\n+ * same data types and expressions.\\n+ *\\n  * Return the address of the new parent relation.\\n  */\\n\\ntablecmds.c:17860 - this check in ATExecDropInherit is now redundant,\\nsince we already have it in ATPrepChangeInherit\\n\\n> Before the patch:\\n> ```\\n> evantest=# ALTER TABLE p_test CLUSTER ON idx_p_test_id;\\n> ERROR: cannot mark index clustered in partitioned table\\n\\nCan we still reach the original error in mark_index_clustered somehow?\\nI don't see any examples in the test suite, or execution paths when I\\nhave looked at the code, and it can be confusing to see a different\\nerror code/message there.\\n\\n\\n","threadId":"19be4f0789a66a7c","snippet":"Hello! A simple patch and generally looks good, I only have a few observations. > "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for > partitioned tables, but","historyId":"12863","internalDate":"1769154187000","receivedAtUtc":"2026-01-23T07:43:07.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"},{"id":"19be9d8794eb777b","messageId":"<B9E960BD-9E45-46E7-951E-D11841D43431@gmail.com>","subject":"Re: tablecmds: reject CLUSTER ON for partitioned tables earlier","body":"\\n\\n> On Jan 23, 2026, at 15:43, Zsolt Parragi <zsolt.parragi@percona.com> wrote:\\n> \\n> Hello!\\n> \\n> A simple patch and generally looks good, I only have a few observations.\\n> \\n>> "ALTER TABLE … CLUSTER ON" and \\"SET WITHOUT CLUSTER\\" are not supported for\\n>> partitioned tables, but currently ATPrepCmd() allows them through and they\\n>> only fail later at execution time.\\n> \\n> Looking at the ALTER TABLE documentation, for other options there is a\\n> mention like \\"This form is not currently supported on partitioned\\n> tables.\\" / \\"This form is not supported for partitioned tables.\\"\\n> \\n> I don't see this mentioned for CLUSTER or INHERIT. Maybe it would be\\n> better to also mention this in the documentation?\\n> \\n\\nHi Zsolt,\\n\\nThank you very much for your review.\\n\\nI have the other patch for the documentation update, see [1], that is an overall clarification for alter table behaviors against partition tables. Actually, I just found this issue while working on that patch.\\n\\nI will handle rest of your comments soon.\\n\\n[1] https://www.postgresql.org/message-id/CAEoWx2%3DmYhCfsnHaN96Qqwq5b0GVS2YgO3zpVqPPRd_iO52wRw%40mail.gmail.com\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be4f0789a66a7c","snippet":"> On Jan 23, 2026, at 15:43, Zsolt Parragi <zsolt.parragi@percona.com> wrote: > > Hello! > > A simple patch and generally looks good, I only have a few observations. > >>","historyId":"12863","internalDate":"1769154786000","receivedAtUtc":"2026-01-23T07:53:06.000Z","from":"Chao Li <li.evan.chao@gmail.com>"}]	Chao Li proposes a patch to reject ALTER TABLE CLUSTER ON and SET WITHOUT CLUSTER commands for partitioned tables earlier in the process, moving the validation from execution time to preparation phase using ATSimplePermissions() infrastructure. This makes error handling consistent with other unsupported ALTER TABLE operations on partitioned tables and provides clearer error messages. The patch extends to similar changes for INHERIT/NO INHERIT commands. Zsolt Parragi reviews positively but suggests documentation updates for unsupported operations, adding test cases for NO INHERIT, fixing code comments, removing redundant checks, and clarifying whether the original error path can still be reached. Chao acknowledges the feedback and mentions having a separate documentation patch already in progress.\n\n李超提出一个补丁，用于在更早的阶段拒绝分区表上的ALTER TABLE CLUSTER ON和SET WITHOUT CLUSTER命令，将验证从执行时移到准备阶段，使用ATSimplePermissions()基础设施。这使得错误处理与分区表上其他不支持的ALTER TABLE操作保持一致，并提供更清晰的错误消息。补丁扩展到对INHERIT/NO INHERIT命令的类似更改。Zsolt Parragi给出积极评价，但建议更新不支持操作的文档，为NO INHERIT添加测试用例，修复代码注释，删除冗余检查，并澄清是否仍能到达原始错误路径。李超确认反馈并提及已有单独的文档补丁正在进行中。	2026-01-23 07:53:06+00	\N
14	19be543e22dcee9b	Race conditions in logical decoding	["ah@cybertec.at","alvherre@kurilemu.de","andres@anarazel.de"]	[{"id":"19be98f086a58ea0","messageId":"<3805.1769150012@localhost>","subject":"Re: Race conditions in logical decoding","body":"Álvaro Herrera <alvherre@kurilemu.de> wrote:\\n\\n> I think this algorithm is strange -- if you do have to wait more than\\n> once for one transaction, it would lead to doing the\\n> TransactionIdDidCommit again times for _all_ transactions by starting\\n> the inner loop from scratch, which sounds really wasteful.  Why not nest\\n> the for() loops the other way around?\\n\\nI'm quite sure I wanted to iterate through committed.xnt in the outer loop,\\nbut probably got distracted by something else and messed things up.\\n\\n> Something like this perhaps,\\n> \\n>     for (int i = 0; i < builder->committed.xcnt; i++)\\n>     {\\n>         for (;;)\\n>         {\\n>             if (TransactionIdDidCommit(builder->committed.xip[i]))\\n>                 break;\\n>             else\\n>             {\\n>                 (void) WaitLatch(MyLatch,\\n>                                  WL_LATCH_SET, WL_TIMEOUT, WL_EXIT_ON_PM_DEATH,\\n>                                  10L,\\n>                                  WAIT_EVENT_SNAPBUILD_CLOG);\\n>                 ResetLatch(MyLatch);\\n>             }\\n>             CHECK_FOR_INTERRUPTS();\\n>         }\\n>     }\\n> \\n> This way you wait repeatedly for one transaction until it is marked\\n> committed; and once it does, you don't test it again.\\n\\nSure, that's much beter. Thanks.\\n\\n-- \\nAntonin Houska\\nWeb: https://www.cybertec-postgresql.com\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"Álvaro Herrera <alvherre@kurilemu.de> wrote: > I think this algorithm is strange -- if you do have to wait more than > once for one transaction, it would lead to doing the >","historyId":"12866","internalDate":"1769150012000","receivedAtUtc":"2026-01-23T06:33:32.000Z","from":"Antonin Houska <ah@cybertec.at>"},{"id":"19be9e03a86c208a","messageId":"<5698.1769155332@localhost>","subject":"Re: Race conditions in logical decoding","body":"Andres Freund <andres@anarazel.de> wrote:\\n\\n> > Attached here is what I consider a possible fix - simply wait for the CLOG\\n> > update before building a new snapshot.\\n> \\n> I don't think that's enough - during non-timetravel visibility semantics, you\\n> can only look at the clog if the transaction isn't marked as in-progress in\\n> the procarray.  ISTM that we need to do that here too?\\n\\nI understand that CLOG must be up-to-date by the time the snapshot is used for\\nvisibility checks, but I think that - from the snapshot user POV - what\\nmatters is \\"snapshot->xip vs CLOG\\" rather than \\"procarray vs CLOG\\".\\n\\nFor procarray-based snapshots, this consistency is ensured by 1) not removing\\nthe XID from procarray until the status is set in CLOG and 2) getting the list\\nof running transactions from procarray. Thus if an MVCC snapshot does not have\\nparticular XID in its \\"xip\\" array, it implies that it's no longer in procarray\\nand therefore it's been marked in CLOG.\\n\\nAs for logical decoding based snapshots (whether HISTORIC_MVCC or those\\nconverted eventually to regular MVCC), we currently do not check if CLOG is\\nconsistent with the transaction list in snapshot->xip. What I proposed is that\\nwe enforce this consistency by checking CLOG (and possibly waiting) before we\\nfinalize the snapshot. Thus the snapshot user can safely assume that the\\nsnapshot->xip array is consistent with CLOG, as if the snapshot was based on\\nprocarray.\\n\\nOr is there another issue with the CLOG itself? I thought about wraparound\\n(i.e. getting the XID status from a CLOG slot which is still being used by old\\ntransactions) but I wouldn't expect that (AFAICS, CLOG truncation takes place\\nduring XID freezing). Concurrent access to the slot should neither be a\\nproblem since only a single byte (which is atomic) needs to be fetched during\\nthe XID status check.\\n\\nAnother hypothetical problem that occurs to me is memory access ordering,\\ni.e. one backend creates and exports the snapshot and another one imports it\\nbefore it can see the CLOG update. It's hard to imagine though.\\n\\nOr are there other concerns?\\n\\n-- \\nAntonin Houska\\nWeb: https://www.cybertec-postgresql.com\\n\\n\\n","threadId":"19be543e22dcee9b","snippet":"Andres Freund <andres@anarazel.de> wrote: > > Attached here is what I consider a possible fix - simply wait for the CLOG > > update before building a new snapshot. > > I don","historyId":"12866","internalDate":"1769155332000","receivedAtUtc":"2026-01-23T08:02:12.000Z","from":"Antonin Houska <ah@cybertec.at>"}]	The discussion focuses on race conditions in PostgreSQL's logical decoding, specifically regarding snapshot building and CLOG consistency. Álvaro Herrera identified an inefficient algorithm in Antonin Houska's code that repeatedly checks TransactionIdDidCommit for all transactions when waiting, suggesting a nested loop restructure to wait for each transaction individually before moving to the next. Antonin acknowledged the improvement. The broader issue involves ensuring CLOG (commit log) consistency with snapshot transaction lists. Antonin argues that waiting for CLOG updates before finalizing snapshots would ensure consistency similar to procarray-based snapshots, where transactions are only removed from procarray after CLOG status is set. He addresses concerns about CLOG wraparound and concurrent access, noting that single-byte atomic reads should be safe, though questions about memory ordering remain unresolved.\n讨论集中在PostgreSQL逻辑解码中的竞态条件问题，特别是快照构建和CLOG一致性。Álvaro Herrera指出Antonin Houska代码中存在低效算法，在等待时会对所有事务重复检查TransactionIdDidCommit，建议重构嵌套循环以逐个等待每个事务后再处理下一个。Antonin承认了这个改进。更广泛的问题涉及确保CLOG（提交日志）与快照事务列表的一致性。Antonin认为在最终确定快照前等待CLOG更新可确保与基于procarray的快照类似的一致性，后者只在CLOG状态设置后才从procarray中移除事务。他讨论了CLOG回绕和并发访问的担忧，指出单字节原子读取应该是安全的，但内存排序问题仍未解决。	2026-01-23 08:02:12+00	\N
14	19be9e661ca52f1f	Remove redundant initialization of smgr pointer for relcache	["mrdrivingduck@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19be9e661ca52f1f","messageId":"<CAN4CZFP4zaFWXx2cP=X=6+VoDnoJ8Dh9cTpT4SjGdAAp=Ui2AQ@mail.gmail.com>","subject":"Re: Remove redundant initialization of smgr pointer for relcache","body":"Hello!\\n\\nThis is a simple change, and should work correctly.\\n\\nHowever, I think I would do more, as this part of the code is just confusing.\\n\\n* AllocateRelationDesc only has one caller\\n* Its description comment only mentions some things it does, not all\\nof them. The call site explains it differently, but also not\\ncompletely.\\n\\nI would at least also modify the comments so that they are only at one\\nplace and explain the function correctly. But maybe it would be even\\nbetter to remove this function completely or to modify it so it's\\nusable at multiple places?\\n\\n\\n","threadId":"19be9e661ca52f1f","snippet":"Hello! This is a simple change, and should work correctly. However, I think I would do more, as this part of the code is just confusing. * AllocateRelationDesc only has one caller * Its description","historyId":"12882","internalDate":"1769155727000","receivedAtUtc":"2026-01-23T08:08:47.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	A contributor submitted a patch to remove redundant initialization of the smgr pointer for relcache in PostgreSQL. While the reviewer acknowledges this is a simple and correct change, they suggest additional improvements to the confusing code structure. Specifically, they note that AllocateRelationDesc has only one caller and its documentation comments are incomplete and scattered between the function and call site. The reviewer recommends either consolidating and improving the comments, removing the function entirely, or refactoring it for broader reusability. No final decision has been made on these suggested enhancements.\n\n一位贡献者提交了一个补丁，用于移除PostgreSQL中relcache的smgr指针的冗余初始化。虽然审查者承认这是一个简单且正确的更改，但他们建议对令人困惑的代码结构进行额外改进。具体来说，他们指出AllocateRelationDesc只有一个调用者，其文档注释不完整且分散在函数和调用点之间。审查者建议要么整合并改进注释，要么完全移除该函数，或者重构它以提高重用性。对于这些建议的改进尚未做出最终决定。	2026-01-23 08:08:47+00	\N
14	19be740d3737841d	warning: dereferencing type-punned pointer	["andres@anarazel.de","ishii@postgresql.org","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19be9f10d50bf30c","messageId":"<581db49e-2a12-4f89-8c3e-334ba5889ff7@eisentraut.org>","subject":"Re: warning: dereferencing type-punned pointer","body":"On 22.01.26 20:46, Andres Freund wrote:\\n> However, you qualified your answer with \\"to a different pointer-to-struct\\",\\n> but afaict the rules would be the same if the \\"initial member\\" of two\\n> different structs were a struct.\\n> > > There's also C23's §6.5 7):\\n>    An object shall have its stored value accessed only by an lvalue expression that has one of\\n>    the following types:\\n>    ...\\n>    — an aggregate or union type that includes one of the aforementioned types among its\\n>    members (including, recursively, a member of a subaggregate or contained union), or\\n> > which afaict means that if we *can* cast between different equivalent structs,\\n> as long as they have the same initial sequence?\\n\\nI think what this means is that if you have\\n\\ntypedef struct Append\\n{\\n    Plan        plan;\\n    ...\\n}\\n\\nand you have an object of type Plan, then you can access that object via a pointer of type Append.\\n\\nNow that I see this again, this is the opposite the direction of what we would need (have object of type Append, access via pointer to Plan, or pointer to Node).  Also note that it doesn't require that member to be the first member.  So this consideration seems to be unrelated to what we are looking for.\\n\\n\\n\\n","threadId":"19be740d3737841d","snippet":"On 22.01.26 20:46, Andres Freund wrote: > However, you qualified your answer with \\"to a different pointer-to-struct\\", > but afaict the rules would be the same if the \\"initial","historyId":"12872","internalDate":"1769156429000","receivedAtUtc":"2026-01-23T08:20:29.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"}]	Peter Eisentraut responds to a discussion about C standard rules for type-punned pointer dereferencing. He analyzes C23's §6.5 7) rule regarding accessing stored values through different lvalue expression types. Eisentraut explains that the rule allows accessing a Plan object via an Append pointer (since Append contains Plan as a member), but notes this is the opposite direction of what PostgreSQL needs - accessing an Append object via a Plan or Node pointer. He clarifies that the rule doesn't require the member to be first and concludes this consideration is unrelated to solving PostgreSQL's type-punning warnings.\nPeter Eisentraut回应了关于类型双关指针解引用的C标准规则的讨论。他分析了C23的§6.5 7)规则，该规则涉及通过不同左值表达式类型访问存储值。Eisentraut解释说该规则允许通过Append指针访问Plan对象（因为Append包含Plan作为成员），但指出这与PostgreSQL需要的方向相反——通过Plan或Node指针访问Append对象。他澄清该规则不要求成员必须是第一个，并得出结论认为这个考虑与解决PostgreSQL的类型双关警告无关。	2026-01-23 08:20:29+00	\N
14	19be9aafca8cce45	Some tests for TOAST, STORAGE MAIN/EXTENDED	["michael@paquier.xyz","veldanda.nikhilkumar17@gmail.com"]	[{"id":"19be9aafca8cce45","messageId":"<aXMdX1UTHnzYPkHk@paquier.xyz>","subject":"Some tests for TOAST, STORAGE MAIN/EXTENDED","body":"Hi all,\\n\\nWhile playing with the TOAST code this week, I have managed to break\\nthe handling of inline compressible entries, and noticed that the main\\nregression test suite did not complain following that.\\n\\nBreaking that stuff is my issue, but I would like to add some\\nregression tests to cover all that, giving the attached.  This also\\nincludes tests with EXTENDED in the same area, while on it, with\\nchecks for the TOAST table itself.\\n\\nThoughts or comments?\\n--\\nMichael\\n","threadId":"19be9aafca8cce45","snippet":"Hi all, While playing with the TOAST code this week, I have managed to break the handling of inline compressible entries, and noticed that the main regression test suite did not complain following that","historyId":"12881","internalDate":"1769151839000","receivedAtUtc":"2026-01-23T07:03:59.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19be9f5cbdfd3eef","messageId":"<CAFAfj_Hq_rMqUKDyz573gZhjd8bEpBx5j4MLNJvZ9PnouJCxDg@mail.gmail.com>","subject":"Re: Some tests for TOAST, STORAGE MAIN/EXTENDED","body":"Hi Michael,\\n\\nOn Thu, Jan 22, 2026 at 11:04 PM Michael Paquier <michael@paquier.xyz> wrote:\\n> Thoughts or comments?\\n\\nTwo nits on the new toasttest block:\\n\\nThe `SELECT count(*) FROM :reltoastname` assertion is a bit brittle\\nfor `STORAGE EXTENDED`: depending on the toast compression method /\\neffectiveness, the value may end up as >1 chunk, which would flip the\\nexpected count(*) = 1. Prefer SELECT count(DISTINCT chunk_id) FROM\\n:reltoastname (or WHERE chunk_seq = 0) and adjust expected.\\n\\npg_column_compression() expects pglz, but default_toast_compression\\nisn't pinned here. Suggest SET default_toast_compression = 'pglz';\\nnear this block; otherwise this can fail on builds with a different\\ndefault.\\n\\n-- \\nNikhil Veldanda\\n\\n\\n","threadId":"19be9aafca8cce45","snippet":"Hi Michael, On Thu, Jan 22, 2026 at 11:04 PM Michael Paquier <michael@paquier.xyz> wrote: > Thoughts or comments? Two nits on the new toasttest block: The `SELECT count(*) FROM :reltoastname`","historyId":"12881","internalDate":"1769156733000","receivedAtUtc":"2026-01-23T08:25:33.000Z","from":"Nikhil Kumar Veldanda <veldanda.nikhilkumar17@gmail.com>"}]	Michael Paquier proposes adding regression tests for PostgreSQL's TOAST (The Oversized-Attribute Storage Technique) functionality, specifically covering STORAGE MAIN/EXTENDED options. He discovered that breaking inline compressible entry handling didn't trigger test failures in the main regression suite, indicating insufficient test coverage. The proposed tests include checks for both EXTENDED storage and the TOAST table itself. Nikhil Veldanda provides feedback on two issues: the `SELECT count(*) FROM :reltoastname` assertion could be brittle for EXTENDED storage due to potential multi-chunk values, suggesting using `SELECT count(DISTINCT chunk_id)` instead, and the `pg_column_compression()` test assumes pglz compression but doesn't set `default_toast_compression`, which could cause failures on builds with different defaults.\nMichael Paquier提议为PostgreSQL的TOAST（超大属性存储技术）功能添加回归测试，特别涵盖STORAGE MAIN/EXTENDED选项。他发现破坏内联可压缩条目处理时主回归测试套件未报错，表明测试覆盖不足。建议的测试包括对EXTENDED存储和TOAST表本身的检查。Nikhil Veldanda针对两个问题提供反馈：`SELECT count(*) FROM :reltoastname`断言对EXTENDED存储可能不稳定，因为潜在的多块值，建议改用`SELECT count(DISTINCT chunk_id)`；`pg_column_compression()`测试假设pglz压缩但未设置`default_toast_compression`，这可能在使用不同默认值的构建上失败。	2026-01-23 08:25:33+00	\N
14	19be9fc3e3e03f83	Hackorum - a new mailing list frontend	["kai.wagner@percona.com","zsolt.parragi@percona.com"]	[{"id":"19be9fc3e3e03f83","messageId":"<CAG0qCNhxpzE4hHozO2fgQ13oeqkWgkAGv4kUfnqxbPRxke-1PA@mail.gmail.com>","subject":"Re: Hackorum - a new mailing list frontend","body":"I've reworked the mobile view, so it should now be way easier to use\\non smaller screens.\\n\\nPlease let me know how it looks and behaves, and if anyone is missing\\nanything, I'd be happy to help.\\n\\nKai\\n\\nOn Sat, Jan 17, 2026 at 10:28 PM Zsolt Parragi\\n<zsolt.parragi@percona.com> wrote:\\n>\\n> Hello!\\n>\\n> Thank you for all the feedback so far!\\n>\\n>\\n>\\n> David Geier <geidav.pg@gmail.com> wrote:\\n>\\n> > - Threads with more than a couple of messages take a very long time to load\\n>\\n> While the performance stabilized after the initial issues, generally\\n> the speed of hackorum should be a lot faster now after a few\\n> performance fixes, both for the index and the topic views.\\n>\\n> > - I find it difficult to match the thread outline to the actual message. Making a visual connection between the thread outline and the currently viewed message would be helpful.\\n>\\n> Done! To be honest, I'm not entirely happy with the topic\\n> view/outline, but I also don't know how to make it significantly\\n> better.\\n>\\n> For now:\\n>\\n> * message headers include the same colors as the outline view\\n> * the currently visible message is highlighted in the outline\\n>\\n> I hope this helps match the two together.\\n>\\n> If you have any other ideas, please share, maybe we can make it even better.\\n>\\n>\\n>\\n> Marcos Pegoraro <marcos@f10.com.br> wrote:\\n>\\n> > Maybe an option to show in descending order and show only the first 10 or 20 messages\\n> > Sometimes there are hundreds of messages on that thread, so this way would be faster and would show the current status of it and not how it started.\\n>\\n> We had multiple listing options in an earlier version, but it can be\\n> confusing - the outline and the actual messages would go in a\\n> different order.\\n>\\n> But the idea about \\"showing the current status\\" sounds interesting,\\n> I'm playing with the idea of some automatic grouping based on date\\n> period (months/years) and automatically collapsing older entries\\n> (especially if all read already) could work.\\n>\\n>\\n>\\n> Nico Williams <nico@cryptonector.com> wrote:\\n>\\n> > This one feature in particular is very nice.  I wonder if you can make it so you can subscribe in the sense of being an approved sender but not in the sense of getting copies sent.\\n>\\n> I don't understand this question, subscribe where? If you mean to the\\n> mailing list, you can turn off receiving messages in the settings, and\\n> you can still continue sending emails. That's how I've been using the\\n> list since I started using hackorum. If I want to reply to a new\\n> thread where I don't have a local email yet, I'm using the \\"resend\\n> email\\" (paper plane icon) in hackorum to get an email, and then I can\\n> reply as normally from my email client.\\n>\\n> > A read-only IMAP/JMAP server might also be nice, especially if it could mark messages as read/replied-to/marked like this.  But yeah, the web interface is not limited by IMAP/JMAP and can do so much more.\\n>\\n> IMAP/JMAP are also much more complex than just marking messages read,\\n> I'm not sure how well that would work out. For now, we have the CSV\\n> import option, and I plan to release a downloadable script in the near\\n> future that generates CSVs using IMAP for initial status import.\\n>\\n>\\n>\\n> Other than the performance fix and outline change I mentioned above,\\n> hackorum now also has a button to download the latest patchset as a\\n> single tar.gz file for every topic.\\n>\\n> There is also a downloadable script that helps with adding it to a\\n> local git checkout automatically, works with all attachments, doesn't\\n> require a commitfest entry. It's available and documented at:\\n> https://hackorum.dev/help/hackorum-patch\\n>\\n>\\n\\n\\n","threadId":"19be9fc3e3e03f83","snippet":"I've reworked the mobile view, so it should now be way easier to use on smaller screens. Please let me know how it looks and behaves, and if anyone is missing anything, I'd be happy to help.","historyId":"12883","internalDate":"1769157158000","receivedAtUtc":"2026-01-23T08:32:38.000Z","from":"Kai Wagner <kai.wagner@percona.com>"}]	The discussion focuses on improvements to Hackorum, a new PostgreSQL mailing list frontend. Key updates include a reworked mobile view for better usability on smaller screens and significant performance fixes for both index and topic views. Visual enhancements were made to help users match thread outlines to messages, including color-coded headers and highlighting of currently visible messages in the outline. A new feature allows downloading the latest patchset as a tar.gz file for each topic, along with a script for automatic integration into local git checkouts. Suggestions were discussed regarding message ordering options and IMAP/JMAP server integration, though the latter was deemed complex. The developer continues seeking feedback on usability and potential improvements.\n\n讨论重点关注Hackorum（一个新的PostgreSQL邮件列表前端）的改进。主要更新包括重新设计的移动视图以提高在小屏幕上的可用性，以及对索引和主题视图的显著性能修复。为帮助用户匹配线程大纲和消息，进行了视觉增强，包括颜色编码的标题和在大纲中突出显示当前可见消息。新功能允许为每个主题下载最新补丁集作为tar.gz文件，并提供一个脚本用于自动集成到本地git检出中。讨论了关于消息排序选项和IMAP/JMAP服务器集成的建议，但后者被认为过于复杂。开发者继续寻求关于可用性和潜在改进的反馈。	2026-01-23 08:32:38+00	\N
14	19be4bfe79e845a8	Add WALRCV_CONNECTING state to walreceiver	["li.evan.chao@gmail.com","michael@paquier.xyz","noah@leadboat.com","rahilasyed90@gmail.com","xunengzhou@gmail.com"]	[{"id":"19be909b2bf50fd5","messageId":"<CABPTF7VQ5tGOSG5TS-Cg+Fb8gLCGFzxJ_eX4qg+WZ3ZPt=FtwQ@mail.gmail.com>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"Hi,\\n\\nOn Fri, Jan 23, 2026 at 6:54 AM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote:\\n> >> Before this patch, this is no state change here, thus rest logic\\n> >> can handle STOPPING. After this patch, if the race occurs, in dev\\n> >> mode, the Assert is fired; in production mode, STOPPING is overwritten\\n> >> by STREAMING, which is wrong.\\n> >>\\n> >> So, instead of Assert(), I think we should check if current state\\n> >> is CONNECTING, if not, it should not proceed.\\n> >\\n> > It makes sense to me. Please check the updated patch.\\n>\\n> +            if (state != WALRCV_CONNECTING)\\n> +            {\\n> +                if (state == WALRCV_STOPPING)\\n> +                    proc_exit(0);\\n> +                elog(FATAL, \\"unexpected walreceiver state\\");\\n> +            }\\n>\\n> Sorry, but this addition does not make sense to me.  Before this\\n> patch, if the startup process decides to mark a WAL receiver as\\n> stopping after it has been started in WalReceiverMain(), then we would\\n> run at least one loop until we reach WalRcvWaitForStartPosition(),\\n> which is the path where the WAL receiver exits.  Aka, I don't think we\\n> should increase the number of paths where we decide if a WAL receiver\\n> should fast-exit or not (I'd rather try to reduce them, but I don't\\n> think we can do that currently based on the ping-pong game between the\\n> startup process and WAL receiver process).  Saying that, you are right\\n> about the fact that the assertion is wrong, and that we should not\\n> upgrade the status to STREAMING if the WAL receiver is not CONNECTING.\\n>\\n> So it seems to me that this code should remain as simple as followed,\\n> documenting that we switch to STREAMING when the first connection has\\n> been established after the WAL receiver has started, or when the WAL\\n> receiver is switched after WalRcvWaitForStartPosition() once\\n> startstreaming() has acknowledged that streaming is happening (I would\\n> add a comment saying that):\\n> if (state == WALRCV_CONNECTING)\\n>    walrcv->walRcvState = WALRCV_STREAMING;\\n> --\\n> Michael\\n\\nThanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and\\nkept the change minimal: only switch to STREAMING if the state is\\nstill CONNECTING, otherwise leave it unchanged.\\n\\n-- \\nBest,\\nXuneng\\n","threadId":"19be4bfe79e845a8","snippet":"Hi, On Fri, Jan 23, 2026 at 6:54 AM Michael Paquier <michael@paquier.xyz> wrote: > > On Thu, Jan 22, 2026 at 06:02:54PM +0800, Xuneng Zhou wrote: > >> Before this patch, this is no","historyId":"8702","internalDate":"1769141256000","receivedAtUtc":"2026-01-23T04:07:36.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>"},{"id":"19be955eb092dc5d","messageId":"<aXMHlwhEURdLB9-d@paquier.xyz>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote:\\n> Thanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and\\n> kept the change minimal: only switch to STREAMING if the state is\\n> still CONNECTING, otherwise leave it unchanged.\\n\\nThanks for the newer version of the patch.  I have been playing with\\nit today, even before you have sent this v7, with a set of injection\\npoints to make the WAL receiver wait at some of its steps, then\\ndouble-checked that the startup process was able to control the WAL\\nreceiver as it should, flipping primary_conninfo with reloads.  AFAIK\\nas I can see, that felt OK, so applied as a36164e7465f.\\n--\\nMichael\\n","threadId":"19be4bfe79e845a8","snippet":"On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote: > Thanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and > kept the change minimal: only switch to STREAMING if the","historyId":"12861","internalDate":"1769146263000","receivedAtUtc":"2026-01-23T05:31:03.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19bea0a13c3de89e","messageId":"<CABPTF7WQbywas2Fog8NP79xzLKSc8dvgVjSJfe_iPdmFRMy6pA@mail.gmail.com>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"Hi,\\n\\nOn Fri, Jan 23, 2026 at 1:31 PM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote:\\n> > Thanks Michael — agreed. Patch v7 dropped the extra fast‑exit path and\\n> > kept the change minimal: only switch to STREAMING if the state is\\n> > still CONNECTING, otherwise leave it unchanged.\\n>\\n> Thanks for the newer version of the patch.  I have been playing with\\n> it today, even before you have sent this v7, with a set of injection\\n> points to make the WAL receiver wait at some of its steps, then\\n> double-checked that the startup process was able to control the WAL\\n> receiver as it should, flipping primary_conninfo with reloads.  AFAIK\\n> as I can see, that felt OK, so applied as a36164e7465f.\\n> --\\n> Michael\\n\\nThanks for checking and applying it. I'm playing with exposing\\nXLogRecoveryCtlData metrics at the SQL level, following your input.\\nI'll post the patches and possibly start a new thread for discussion.\\n\\n-- \\nBest,\\nXuneng\\n\\n\\n","threadId":"19be4bfe79e845a8","snippet":"Hi, On Fri, Jan 23, 2026 at 1:31 PM Michael Paquier <michael@paquier.xyz> wrote: > > On Fri, Jan 23, 2026 at 12:07:36PM +0800, Xuneng Zhou wrote: > > Thanks Michael — agreed. Patch v7","historyId":"12861","internalDate":"1769158063000","receivedAtUtc":"2026-01-23T08:47:43.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>"}]	The discussion centers on a patch to add a WALRCV_CONNECTING state to PostgreSQL's WAL receiver. Xuneng Zhou initially proposed using an Assert() to handle race conditions between startup and WAL receiver processes, but Michael Paquier identified this as problematic. The Assert could fire inappropriately in development mode, and in production, a STOPPING state could be incorrectly overwritten by STREAMING. Zhou initially suggested adding a fast-exit path for STOPPING states, but Paquier preferred a minimal approach to avoid increasing exit paths. The final solution in patch v7 simply checks if the state is CONNECTING before switching to STREAMING, leaving other states unchanged. Paquier tested the patch with injection points to verify WAL receiver control mechanisms work correctly with primary_conninfo reloads, then applied it as commit a36164e7465f. Zhou plans to work on exposing XLogRecoveryCtlData metrics at SQL level next.\n讨论围绕为PostgreSQL的WAL接收器添加WALRCV_CONNECTING状态的补丁展开。周旭能最初提议使用Assert()处理启动进程和WAL接收器进程之间的竞态条件，但Michael Paquier发现这存在问题。Assert可能在开发模式下不当触发，而在生产环境中，STOPPING状态可能被错误地覆盖为STREAMING。周最初建议为STOPPING状态添加快速退出路径，但Paquier倾向于采用最小化方法以避免增加退出路径。补丁v7的最终解决方案是在切换到STREAMING之前简单检查状态是否为CONNECTING，其他状态保持不变。Paquier使用注入点测试了补丁，验证WAL接收器控制机制在primary_conninfo重载时正常工作，然后将其应用为提交a36164e7465f。周计划接下来在SQL层面公开XLogRecoveryCtlData指标。	2026-01-23 08:47:43+00	\N
14	19be897af3bbca01	Newly created replication slot may be invalidated by checkpoint	["aekorotkov@gmail.com","amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","houzj.fnst@fujitsu.com","kuroda.hayato@fujitsu.com","mengjuan.cmj@alibaba-inc.com","michael@paquier.xyz","sawada.mshk@gmail.com","tomas@vondra.me","v.davydov@postgrespro.ru","vignesh21@gmail.com"]	[{"id":"19be897af3bbca01","messageId":"<TY4PR01MB169074400DA851B425BA5D4219494A@TY4PR01MB16907.jpnprd01.prod.outlook.com>","subject":"RE: Newly created replication slot may be invalidated by checkpoint","body":"On Thursday, January 22, 2026 2:54 PM Kuroda, Hayato/黒田 隼人 <kuroda.hayato@fujitsu.com> wrote:\\n> \\n> Thanks for updating the patch. Further comments.\\n\\nThanks for the comments.\\n\\n> \\n> 01.\\n> ```\\n> +#include \\"access/xlog.h\\"\\n> ```\\n> \\n> I could build without the inclusion because \\"replication/logical.h\\" already\\n> includes it. Can we remove or we should retain?\\n\\nRemoved.\\n\\n> \\n> 02.\\n> Should we increase checkpoint_timeout for stabilizing tests?\\n\\nI think we don't need this as concurrent checkpoint won't\\ncause the slot to be invalidated.\\n\\n> \\n> 03.\\n> To confirm, you've removed the logic that checks the oldest segment and try\\n> reserving, but it can be removed same as ReplicationSlotReserveWal(), right?\\n\\nIf you meant we can remove the retry logic similar to what 3510ebe did, the\\nunderstanding is correct.\\n\\n> XLogGetOldestSegno() is also not needed anymore because race can't happen\\n> if standby have never discarded.\\n\\nYes\\n\\n> \\n> 04.\\n> ```\\n> $primary->psql('postgres',\\n> \\tq{SELECT pg_create_logical_replication_slot('failover_slot',\\n> 'test_decoding', false, false, true);\\n> \\t SELECT pg_create_physical_replication_slot('phys_slot');}\\n> );\\n> ...\\n> $primary->psql('postgres', \\"CHECKPOINT\\"); ```\\n> \\n> I found two lines use `psql()`, but should be `safe_psql()`.\\n\\nChanged.\\n\\n> \\n> 05.\\n> Per my tests, the issue exists till PG17 and your patch can be backpatched till\\n> it, right?\\n\\nThis patch cannot be applied cleanly on backbranches, I can prepare patches for\\nthose once the main patch is stable.\\n\\nBest Regards,\\nHou zj\\n","threadId":"19be897af3bbca01","snippet":"On Thursday, January 22, 2026 2:54 PM Kuroda, Hayato/黒田 隼人 <kuroda.hayato@fujitsu.com> wrote: > > Thanks for updating the patch. Further comments. Thanks for the comments. > > 01.","historyId":"8742","internalDate":"1769133796000","receivedAtUtc":"2026-01-23T02:03:16.000Z","from":"\\"Zhijie Hou (Fujitsu)\\" <houzj.fnst@fujitsu.com>"},{"id":"19bea1b30f5e683b","messageId":"<CAA4eK1+T8a7JysOcM6PL1ycfQ6yXvJdDkzrkGOBZGj=fo7S7Lw@mail.gmail.com>","subject":"Re: Newly created replication slot may be invalidated by checkpoint","body":"On Fri, Jan 23, 2026 at 7:33 AM Zhijie Hou (Fujitsu)\\n<houzj.fnst@fujitsu.com> wrote:\\n>\\n> This patch cannot be applied cleanly on backbranches, I can prepare patches for\\n> those once the main patch is stable.\\n>\\n\\nSome comments:\\n1.\\n+ /*\\n+ * Determine the minimum non-removable LSN by comparing the redo pointer\\n+ * with the minimum slot LSN.\\n+ */\\n+ min_safe_lsn = GetRedoRecPtr();\\n+ slot_min_lsn = XLogGetReplicationSlotMinimumLSN();\\n\\nCan we expand these comments a bit to state why we need both\\nRedoRecPtr and slot's minimum LSN?\\n\\n2.\\n+# Verify that while syncing a slot to the standby server, if the WAL before the\\n+# remote restart_lsn is at risk of being removed by a checkpoint, the slot\\n+# cannot be synced. Otherwise, even if the slot syncing succeeds, it may be\\n+# immediately invalidated by the checkpoint.\\n+my $primary = $node;\\n\\nThis comment atop the testcase is not very clear. Because, it is\\ntesting that the slot is synced and is not invalidated. How about:\\n\\"Verify that the synchronized slots won't be invalidated immediately\\nafter synchronization in the presence of a concurrent checkpoint.\\"?\\n\\n3.\\n+# Increase the log_min_messages setting to DEBUG2 on both the standby and\\n+# primary to debug test failures, if any.\\n+my $connstr_1 = $primary->connstr;\\n\\nDo we need this DEBUG2? I don't think we should add too many DEBUG2\\ntests as it increases Log volume.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n","threadId":"19be897af3bbca01","snippet":"On Fri, Jan 23, 2026 at 7:33 AM Zhijie Hou (Fujitsu) <houzj.fnst@fujitsu.com> wrote: > > This patch cannot be applied cleanly on backbranches, I can prepare patches for > those once the","historyId":"12875","internalDate":"1769159185000","receivedAtUtc":"2026-01-23T09:06:25.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>"}]	The discussion focuses on a PostgreSQL patch addressing replication slot invalidation by checkpoints. Zhijie Hou responds to code review feedback from Kuroda, making several adjustments: removing unnecessary header inclusion, changing psql() calls to safe_psql() in tests, and confirming that retry logic can be removed similar to ReplicationSlotReserveWal(). The patch addresses race conditions where newly created slots get invalidated, with the fix preventing concurrent checkpoints from causing invalidation. Amit Kapila provides additional review comments requesting expanded code comments explaining why both RedoRecPtr and slot minimum LSN are needed, suggesting clearer test case comments, and questioning the necessity of DEBUG2 logging level. The patch affects PostgreSQL versions back to PG17, though backporting will require separate patches once the main fix is stabilized.\n讨论重点关注一个解决检查点使复制槽失效问题的PostgreSQL补丁。Zhijie Hou回应了Kuroda的代码审查反馈，进行了几项调整：移除不必要的头文件包含，将测试中的psql()调用改为safe_psql()，并确认可以移除类似于ReplicationSlotReserveWal()的重试逻辑。该补丁解决了新创建槽被失效的竞态条件，修复方案防止并发检查点导致失效。Amit Kapila提供了额外的审查意见，要求扩展代码注释来解释为什么需要RedoRecPtr和槽最小LSN，建议更清晰的测试用例注释，并质疑DEBUG2日志级别的必要性。该补丁影响PostgreSQL版本直到PG17，尽管回移需要在主补丁稳定后准备单独的补丁。	2026-01-23 09:06:25+00	\N
14	19bea3ae7835bc64	[PATCH] Avoid potential NULL dereference in LIKE/ILIKE with C locale	["gorcom2012@gmail.com"]	[{"id":"19bea3ae7835bc64","messageId":"<CABg3sZo30PKF-AYZ_eih=5snxqp73bVOGX7O_hBMqoFhcOWbjQ@mail.gmail.com>","subject":"[PATCH] Avoid potential NULL dereference in LIKE/ILIKE with C locale","body":"Hi hackers,\\n\\nWhile reviewing the MatchText function in backend/utils/adt/like_match.c, I\\nnoticed a potential NULL pointer dereference when using LIKE or ILIKE with\\nthe C locale.\\n\\nThe issue arises because the locale argument (of type pg_locale_t, which is\\na pointer) can be NULL when the C collation is in use. However, the GETCHAR\\nmacro unconditionally passes this locale to MATCH_LOWER, which - depending\\non its definition - may attempt to dereference it (e.g., to access\\nlocale->provider or other fields).\\n\\nThis can lead to a crash in builds or configurations where MATCH_LOWER is\\nnot safe to call with a NULL locale.\\n\\nThe proposed patch adds an explicit check for locale == NULL in the GETCHAR\\nmacro and falls back to pg_ascii_tolower() in that case, which is both safe\\nand correct for the C locale (since no locale-specific case folding is\\nneeded).\\n\\nThe change aligns with existing patterns in the codebase (e.g., in text_cmp\\nand other collation-aware functions) where NULL locale is treated as\\nequivalent to C/POSIX behavior.\\n\\nBest regards, Eugeny Goryachev.\\n\\nPatch:\\nSubject: [PATCH] Avoid potential NULL dereference in LIKE/ILIKE with C\\nlocale\\n\\n---\\n src/backend/utils/adt/like_match.c | 3 ++-\\n 1 file changed, 2 insertions(+), 1 deletion(-)\\n\\ndiff --git a/src/backend/utils/adt/like_match.c\\nb/src/backend/utils/adt/like_match.c\\nindex 892f8a745ea..884edc7ff42 100644\\n--- a/src/backend/utils/adt/like_match.c\\n+++ b/src/backend/utils/adt/like_match.c\\n@@ -71,7 +71,8 @@\\n  */\\n\\n #ifdef MATCH_LOWER\\n-#define GETCHAR(t, locale) MATCH_LOWER(t, locale)\\n+#define GETCHAR(t, locale) \\\\\\n+ ((locale) == 0 ? pg_ascii_tolower((unsigned char)(t)) : MATCH_LOWER(t,\\nlocale))\\n #else\\n #define GETCHAR(t, locale) (t)\\n #endif\\n--\\n2.42.4\\n","threadId":"19bea3ae7835bc64","snippet":"Hi hackers, While reviewing the MatchText function in backend/utils/adt/like_match.c , I noticed a potential NULL pointer dereference when using LIKE or ILIKE with the C locale. The issue arises","historyId":"12884","internalDate":"1769161263000","receivedAtUtc":"2026-01-23T09:41:03.000Z","from":"Eugeny Goryachev <gorcom2012@gmail.com>"}]	Eugeny Goryachev identified a potential NULL pointer dereference in PostgreSQL's LIKE/ILIKE operations when using the C locale. The issue occurs in the MatchText function where the GETCHAR macro unconditionally passes a locale argument to MATCH_LOWER, but this locale can be NULL for C collations. This could cause crashes when MATCH_LOWER attempts to dereference the NULL pointer to access locale fields. The proposed patch adds a NULL check to the GETCHAR macro, falling back to pg_ascii_tolower() when locale is NULL, which is safe and appropriate for C locale behavior. This approach aligns with existing patterns in other PostgreSQL collation-aware functions that treat NULL locale as equivalent to C/POSIX behavior.\n\nEugeny Goryachev 发现了 PostgreSQL 在使用 C 语言环境时 LIKE/ILIKE 操作中的潜在 NULL 指针解引用问题。该问题出现在 MatchText 函数中，GETCHAR 宏无条件地将语言环境参数传递给 MATCH_LOWER，但对于 C 排序规则，该语言环境可能为 NULL。当 MATCH_LOWER 尝试解引用 NULL 指针以访问语言环境字段时，这可能导致崩溃。提议的补丁在 GETCHAR 宏中添加了 NULL 检查，当语言环境为 NULL 时回退到 pg_ascii_tolower()，这对于 C 语言环境行为既安全又合适。这种方法与 PostgreSQL 其他排序规则感知函数中的现有模式一致，将 NULL 语言环境视为等同于 C/POSIX 行为。	2026-01-23 09:41:03+00	\N
14	19be72cf98864068	ALTER TABLE: warn when actions do not recurse to partitions	["david.g.johnston@gmail.com","htamfids@gmail.com","jim.jones@uni-muenster.de","li.evan.chao@gmail.com"]	[{"id":"19be831e29cb001a","messageId":"<8ECD9403-F0BB-4971-94CF-2709EEB4E3B9@gmail.com>","subject":"Re: ALTER TABLE: warn when actions do not recurse to partitions","body":"\\n\\n> On Jan 23, 2026, at 03:27, Jim Jones <jim.jones@uni-muenster.de> wrote:\\n> \\n> Hi Chao\\n> \\n> On 22/01/2026 06:45, Chao Li wrote:\\n>> evantest=# alter table p_test replica identity full, alter column\\n>> username set (n_distinct = 0.1);\\n>> NOTICE:  ALTER action REPLICA IDENTITY on relation \\"p_test\\" does not\\n>> affect present partitions\\n>> HINT:  partitions may be modified individually, or specify ONLY to\\n>> suppress this message\\n>> NOTICE:  ALTER action ALTER COLUMN ... SET on relation \\"p_test\\" does not\\n>> affect present partitions\\n>> HINT:  partitions may be modified individually, or specify ONLY to\\n>> suppress this message\\n>> ALTER TABLE\\n> \\n> \\n> One could argue that encapsulating all conditions in\\n> EmitPartitionNoRecurseNotice(), meaning it is called all the time, is\\n> slightly inefficient, but the impact is really negligible in this case -\\n> and it is how it is done in similar functions in tablecmds.c :) The code\\n> LGTM.\\n\\nHi Jim, thanks a lot for the review.\\n\\n> \\n> One small thing:\\n> \\n> errhint is supposed to be capitalised - see Error Message Style Guide[1]\\n\\nThanks for the info, I wasn't aware of that. When I wrote the code, I searched "errhint" over the source tree, and didn't find a standard to follow.\\n\\n> \\n> \\"Detail and hint messages: Use complete sentences, and end each with a\\n> period. Capitalize the first word of sentences. Put two spaces after the\\n> period if another sentence follows (for English text; might be\\n> inappropriate in other languages).\\"\\n> \\n> ereport(NOTICE,\\n> errmsg(\\"ALTER action %s on relation \\\\\\"%s\\\\\\" does not affect present\\n> partitions\\",\\n>   action_str,\\n>   RelationGetRelationName(rel)),\\n> errhint(\\"partitions may be modified individually, or specify ONLY to\\n> suppress this message\\"));\\n> \\n> What about this?\\n> \\n> HINT: To update partitions, apply the command to each one individually,\\n> or specify ONLY to suppress this message.\\n\\nLooks good. I will integrate your edit to the next version.\\n\\n> \\n> I'll test the newly covered subcomands tomorrow.\\n\\nThanks again for testing. I will wait to see the test results and address all issues together in next version.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n","threadId":"19be72cf98864068","snippet":"> On Jan 23, 2026, at 03:27, Jim Jones <jim.jones@uni-muenster.de> wrote: > > Hi Chao > > On 22/01/2026 06:45, Chao Li wrote: >> evantest=# alter table p_test replica","historyId":"8722","internalDate":"1769127095000","receivedAtUtc":"2026-01-23T00:11:35.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19bea4a13acdcbb4","messageId":"<f4f70647-8738-48b3-abbd-5b52cde97374@uni-muenster.de>","subject":"Re: ALTER TABLE: warn when actions do not recurse to partitions","body":"\\n\\nOn 23/01/2026 01:11, Chao Li wrote:\\n> I will wait to see the test results and address all issues together in next version.\\n\\nWhile testing some edge cases I found out that the NOTICE is being\\nemitted too early in the code path, e.g.\\n\\npostgres=# ALTER TABLE m ALTER COLUMN b SET COMPRESSION pglz;\\nNOTICE:  ALTER action ALTER COLUMN ... SET COMPRESSION on relation \\"m\\"\\ndoes not affect present partitions\\nHINT:  partitions may be modified individually, or specify ONLY to\\nsuppress this message\\nERROR:  column data type integer does not support compression\\n\\nI'd argue that emitting only the ERROR message in this case would be the\\nright approach. What about moving the EmitPartitionNoRecurseNotice()\\ncall to ATExecCmd, right **after** the changes were successfully\\nexecuted? For instance, in the case I mentioned above, you could explore:\\n\\n@@ -5446,6 +5475,8 @@ ATExecCmd(List **wqueue, AlteredTableInfo *tab,\\n                case AT_SetCompression: /* ALTER COLUMN SET COMPRESSION */\\n                        address = ATExecSetCompression(rel, cmd->name,\\ncmd->def,\\n\\n          lockmode);\\n+                       /* Emit notice after validation passes */\\n+                       EmitPartitionNoRecurseNotice(cmd->subtype, rel,\\ncmd->recurse, false);\\n                        break;\\n\\nNot sure if cmd->recurse is propagated in this code path. If not, you\\nmight need to do it manually, e.g.\\n\\n@@ -4936,6 +4937,14 @@ ATPrepCmd(List **wqueue, Relation rel,\\nAlterTableCmd *cmd,\\n         */\\n        cmd = copyObject(cmd);\\n\\n+       if (recurse)\\n+               cmd->recurse = true;\\n+\\n\\nI'm not saying it should be exactly this way, but it sounds more\\nreasonable to me to emit the NOTICE only if we know that the command is\\ngoing to be successfully executed (or was successfully executed).\\n\\nThis patch touches a lot of regression tests, but mostly to add the\\nkeyword ONLY to the ALTER TABLE statements, to avoid the NOTICE message,\\nso that's ok.\\n\\nThanks!\\n\\nBest, Jim\\n\\n\\n","threadId":"19be72cf98864068","snippet":"On 23/01/2026 01:11, Chao Li wrote: > I will wait to see the test results and address all issues together in next version. While testing some edge cases I found out that the NOTICE is being emitted","historyId":"12871","internalDate":"1769162268000","receivedAtUtc":"2026-01-23T09:57:48.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"}]	Jim Jones reviewed Chao Li's patch for adding warnings when ALTER TABLE actions don't recurse to partitions in PostgreSQL. The patch successfully emits NOTICE messages with hints about modifying partitions individually or using ONLY to suppress warnings. Jim suggested improving the hint message capitalization per PostgreSQL's Error Message Style Guide and provided better wording. However, Jim discovered a timing issue where the NOTICE is emitted before validation, causing confusing output when commands fail (e.g., showing partition warnings before compression errors). He proposed moving the EmitPartitionNoRecurseNotice() call to ATExecCmd after successful execution rather than during preparation. Chao acknowledged the feedback and will integrate the suggestions in the next patch version.\nJim Jones审查了Chao Li关于在PostgreSQL中ALTER TABLE操作不递归到分区时添加警告的补丁。该补丁成功发出NOTICE消息，提示如何单独修改分区或使用ONLY抑制警告。Jim建议按照PostgreSQL错误消息样式指南改进提示消息的大小写，并提供了更好的措辞。然而，Jim发现了时序问题，即在验证之前就发出NOTICE，当命令失败时会产生混乱的输出（例如在压缩错误之前显示分区警告）。他建议将EmitPartitionNoRecurseNotice()调用移至ATExecCmd中成功执行后，而不是在准备阶段。Chao承认了反馈，将在下一个补丁版本中整合这些建议。	2026-01-23 09:57:48+00	\N
14	19bea5d6a1b05fd5	Reduce build times of pg_trgm GIN indexes	["boekewurm+postgres@gmail.com","geidav.pg@gmail.com","hlinnaka@iki.fi"]	[{"id":"19bea5d6a1b05fd5","messageId":"<ef8782c9-68b7-4915-9f79-497765a8e205@gmail.com>","subject":"Re: Reduce build times of pg_trgm GIN indexes","body":"Hi Matthias,\\n\\nOn 21.01.2026 21:50, Matthias van de Meent wrote:\\n> On Wed, 21 Jan 2026 at 16:45, David Geier <geidav.pg@gmail.com> wrote:\\n>>\\n>> How do we usually go about such backwards-compatibility breaking\\n>> changes?\\n> \\n> When it concerns a bug, we mention the change in the release notes\\n> with a warning to reindex affected indexes to be sure no known\\n> corruption remains. See e.g. the final entry in the PG18 release\\n> notes' migration section here:\\n> https://www.postgresql.org/docs/18/release-18.html#RELEASE-18-MIGRATION.\\n> \\n>> Could we have pg_upgrade reindex all GIN indexes? Would that be\\n>> acceptable?\\n> \\n> No. We'd handle this like any other collation/opclass fixes; we ask\\n> users to reindex their indexes in their own time after they've\\n> upgraded their cluster. Note that in this case it concerns an issue\\n> with just one GIN opclass, not all GIN indexes; so even if we were to\\n> address this in pg_upgrade it wouldn't be a correct choice to reindex\\n> every GIN index, as only a subset of those would be affected by this\\n> issue.\\n> \\n> Generally speaking, pg_upgrade doesn't concern itself with the\\n> validity of the data structures that are described by the catalogs\\n> that it upgrades, it only concerns itself with that it correctly\\n> transcribes the catalogs from one version to another, and that the\\n> data files of the old cluster are transfered correctly without\\n> changes.\\n\\nThanks for the clarifications and the link to the release notes. That's\\nvery helpful. Then I know how to move on and will update the patch\\naccordingly.\\n\\n--\\nDavid Geier\\n\\n\\n","threadId":"19bea5d6a1b05fd5","snippet":"Hi Matthias, On 21.01.2026 21:50, Matthias van de Meent wrote: > On Wed, 21 Jan 2026 at 16:45, David Geier <geidav.pg@gmail.com> wrote: >> >> How do we usually go about such","historyId":"12886","internalDate":"1769163536000","receivedAtUtc":"2026-01-23T10:18:56.000Z","from":"David Geier <geidav.pg@gmail.com>"}]	David Geier is working on a patch to reduce build times of pg_trgm GIN indexes, which appears to involve a backwards-compatibility breaking change that could affect existing indexes. Matthias van de Meent provided guidance on PostgreSQL's standard approach for handling such changes: when the change concerns a bug fix, it should be documented in release notes with a warning for users to reindex affected indexes after upgrading. He clarified that pg_upgrade doesn't automatically reindex data structures and only handles catalog transcription and data file transfer. The fix would only affect the specific pg_trgm GIN opclass, not all GIN indexes. David accepted this guidance and plans to update his patch accordingly.\nDavid Geier正在开发一个补丁来减少pg_trgm GIN索引的构建时间，该补丁涉及向后兼容性破坏性更改，可能影响现有索引。Matthias van de Meent提供了PostgreSQL处理此类更改的标准方法指导：当更改涉及错误修复时，应在发布说明中记录并警告用户在升级后重新索引受影响的索引。他澄清pg_upgrade不会自动重新索引数据结构，只处理目录转录和数据文件传输。修复仅影响特定的pg_trgm GIN操作符类，而非所有GIN索引。David接受了这一指导并计划相应更新补丁。	2026-01-23 10:18:56+00	\N
14	19bea617c6c8099e	Time to drop RADIUS support?	["thomas.munro@gmail.com"]	[{"id":"19bea617c6c8099e","messageId":"<CA+hUKG+SH309V8KECU5=xuLP9Dks0v9f9UVS2W74fPAE5O21dg@mail.gmail.com>","subject":"Time to drop RADIUS support?","body":"Hi,\\n\\nA bit over a year ago, I wrote about a RADIUS vulnerability and a\\nrecommended mitigation[1].  I was grateful for the reviews, but I lost\\nsteam on those patches because:\\n\\n1.  Our implementation seems to have accidental (?) resilience because\\nit has a short hard-coded timeout.  The RADIUS/UDP Considered\\nHarmful[0] people used 47 servers to get \\"2% of the successful runs to\\nfinish before 240s and 16% before 300s\\", but we time out after 3\\nseconds.  Assuming perfect scaling, maybe they could use 4700 servers\\nto get a 16% chance of success in 3s... or maybe I have the maths\\nwrong but it's fairly extreme anyway...\\n\\n2.  It seems increasingly likely that there are no users, since\\nRADIUS/UDP without the mitigation spews warnings from FreeRADIUS, and\\nMicrosoft RADIUS's 2024 update (KB5040456) recommended requiring it\\n(though you didn't have to accept IIUC).  I'm pretty sure we'd have\\nheard about it from users if there were any.\\n\\n3.  That mitigation would help, but in the end it's still leaky\\nobfuscation of credentials + MD5-based technology that is being\\nformally deprecated with a mandated replacement[2], and de facto has\\nbeen for a long time.\\n\\nThe real recommendation of the paper was \\"don't use RADIUS/UDP at\\nall\\", and I don't want to expend energy writing a RADIUS/TLS client\\nfor a hypothetical user, so I think we should just delete it all, and\\nstick a deprecation notice in the release branch documentation, as\\nattached.  That'd also mean our Windows select() and non-thread-safe\\nUDP kludges can be VACUUMed.\\n\\nAFAICS you can already do RADIUS better with PAM using a module\\nmaintained by the FreeRADIUS project (see below for quick and dirty\\ndemo).  That way it's not our problem, follows the standards etc.  The\\nonly issue I can think of with that is that Windows and OpenBSD\\nprobably don't have PAM. But then, recall that we are talking about\\napproximately zero users so I think we can still hit 100% of them this\\nway?\\n\\n\\n\\n=== Example of RADIUS via PAM ===\\n\\nTell PAM how to authenticate for service postgresql in /etc/pam.d/postgresql:\\n#%PAM-1.0\\nauth required pam_radius.so require_message_authenticator\\naccount required pam_permit.so\\n\\nTell pam_radius.so how to talk to RADIUS server in /etc/radius.conf:\\n# Server[:port] SharedSecret Timeout Retries\\n127.0.0.1 shared_secret 3 3\\n\\nTell PostgreSQL to use PAM service postgresql in pg_hba.conf:\\nhost all all 127.0.0.1/32 pam pamservice=postgresql\\n\\n=== Setting up a test server to try it out ===\\n\\nTell FreeRADIUS how to be a RADIUS server in /tmp/radiusd/radiusd.conf:\\n/tmp/radiusd/radiusd.conf\\nclient default {\\n  ipaddr = \\"127.0.0.1\\"\\n  secret = \\"shared_secret\\"\\n}\\nmodules {\\n  files {\\n    filename = \\"/tmp/radiusd/users.txt\\"\\n  }\\n  pap {\\n  }\\n}\\nserver default {\\n  listen {\\n    type   = \\"auth\\"\\n    ipv4addr = \\"127.0.0.1\\"\\n    port = \\"1812\\"\\n  }\\n  authenticate {\\n    Auth-Type PAP {\\n      pap\\n    }\\n  }\\n  authorize {\\n    files\\n    pap\\n  }\\n}\\nlog {\\n  destination = \\"files\\"\\n  localstatedir = \\"/tmp/radiusd\\"\\n  logdir = \\"/tmp/radiusd\\"\\n  file = \\"/tmp/radiusd/radiusd.log\\"\\n}\\npidfile = \\"/tmp/radiusd/radiusd.pid\\"\\n\\nTell FreeRADIUS the passwords in /tmp/radiusd/users.txt:\\ntestuser Cleartext-Password := \\"xxx\\"\\n\\nThen run it in the foreground with \\"radiusd -d /tmp/radiusd -f\\".  If\\nyou leave out \\"require_message_authenticator\\" from\\n/etc/pam.d/postgresql then you'll get log messages just like when\\nPostgreSQL speaks RADIUS natively:\\n\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\nBlastRADIUS check: Received packet without Message-Authenticator.\\nSetting \\"require_message_authenticator = false\\" for client default\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\nUPGRADE THE CLIENT AS YOUR NETWORK IS VULNERABLE TO THE BLASTRADIUS ATTACK.\\nOnce the client is upgraded, set \\"require_message_authenticator =\\ntrue\\" for  client default\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\\nBoth client and server should ideally be set to require\\nMessage-Authenticator.  Presumably with more coffee and man pages you\\ncould also configure it to use RADIUS/TLS instead of RADIUS/UDP, etc.\\n\\n[0] https://www.usenix.org/conference/usenixsecurity24/presentation/goldberg\\n[1] https://www.postgresql.org/message-id/flat/CA%2BhUKGLRSPTOC_ygx4_sJjWeKOkOpWGCBCJiRq8cPNuMisuzgw%40mail.gmail.com\\n[2] https://datatracker.ietf.org/doc/draft-ietf-radext-deprecating-radius/\\n","threadId":"19bea617c6c8099e","snippet":"Hi, A bit over a year ago, I wrote about a RADIUS vulnerability and a recommended mitigation[1]. I was grateful for the reviews, but I lost steam on those patches because: 1. Our implementation seems","historyId":"12887","internalDate":"1769163765000","receivedAtUtc":"2026-01-23T10:22:45.000Z","from":"Thomas Munro <thomas.munro@gmail.com>"}]	Thomas Munro proposes dropping PostgreSQL's built-in RADIUS authentication support due to security vulnerabilities and lack of users. He notes that PostgreSQL's implementation has accidental resilience with a 3-second timeout, but the underlying RADIUS/UDP protocol suffers from the BlastRADIUS vulnerability. The mitigation would help but RADIUS/UDP uses outdated MD5-based technology being formally deprecated. Munro argues there are likely zero users since the vulnerability causes warnings in FreeRADIUS and Microsoft recommended requiring mitigations in 2024. He suggests users can achieve better RADIUS authentication through PAM modules maintained by the FreeRADIUS project, which follows standards and isn't PostgreSQL's responsibility. Removing RADIUS would also eliminate Windows select() and UDP threading workarounds. He provides detailed PAM configuration examples and test server setup instructions.\nThomas Munro提议移除PostgreSQL内置的RADIUS身份验证支持，原因是存在安全漏洞且缺乏用户。他指出PostgreSQL的实现因3秒超时而具有意外的弹性，但底层的RADIUS/UDP协议存在BlastRADIUS漏洞。缓解措施会有帮助，但RADIUS/UDP使用正被正式弃用的基于MD5的过时技术。Munro认为可能没有用户，因为该漏洞会在FreeRADIUS中产生警告，而Microsoft在2024年建议要求缓解措施。他建议用户可以通过FreeRADIUS项目维护的PAM模块实现更好的RADIUS身份验证，这遵循标准且不是PostgreSQL的责任。移除RADIUS还将消除Windows select()和UDP线程处理的变通方案。他提供了详细的PAM配置示例和测试服务器设置说明。	2026-01-23 10:22:45+00	\N
14	19bea7defb8a17b6	Proposal: Conflict log history table for Logical Replication	["amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","sawada.mshk@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19bea7defb8a17b6","messageId":"<CAFiTN-t_4XvofM3an-WmykqnPE+9wf9U+o2M7p1CWd9eXkN88Q@mail.gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","body":"On Tue, Jan 20, 2026 at 6:48 PM vignesh C <vignesh21@gmail.com> wrote:\\n>\\n> On Mon, 19 Jan 2026 at 10:57, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n> >\\n> > On Mon, Jan 19, 2026 at 9:42 AM Peter Smith <smithpb2250@gmail.com> wrote:\\n> > >\\n> > > Some review comments for v22-0003.\\n> > >\\n> > > ======\\n> > >\\n> > > 1.\\n> > > It looks like none of my previous v20-0003 review comments [1] have\\n> > > been addressed. Maybe accidentally overlooked?\\n> > >\\n> > > ======\\n> > >\\n> > > 2.\\n> > > +         <caution>\\n> > > +          <para>\\n> > > +           The internal conflict logging table is strictly tied to\\n> > > the lifecycle of the\\n> > > +           subscription or the\\n> > > <literal>conflict_log_destination</literal> setting. If\\n> > > +           the subscription is dropped, or if the destination is changed to\\n> > > +           <literal>log</literal>, the table and all its recorded\\n> > > conflict data are\\n> > > +           <emphasis>permanently deleted</emphasis>. To perform a\\n> > > post-mortem analysis\\n> > > +           after removing a subscription, users must manually back up\\n> > > or rename the\\n> > > +           conflict table before the deletion occurs.\\n> > > +          </para>\\n> > > +         </caution>\\n> > >\\n> > > 2a.\\n> > > Let's consistently call this the \\"Conflict log table\\", same as\\n> > > everywhere else, not \\"logging table\\".\\n> > >\\n> > > ~\\n> > >\\n> > > 2b.\\n> > > This is only a caution for the CLT, so I felt it's better to put this\\n> > > in the scope of the 'table' param value.\\n> > >\\n> > > ~~~\\n> > >\\n> > > 3.\\n> > > +             analysis of conflicts. This table is automatically\\n> > > dropped when the\\n> > > +             subscription is removed.\\n> > >\\n> > > If you move the <caution> to this scope, as suggested above in #2b,\\n> > > then you can remove the sentence \\"This table is automatically dropped\\n> > > when the subscription is removed\\", because that is duplicate\\n> > > information you already wrote in the caution.\\n> >\\n> > The attached patch fixes above comments and other comments reported in\\n> > v22-0001 and v22-0002\\n>\\n> The tests are failing randomly at the following places\\n> +# Wait for the conflict to be logged in the CLT\\n> +my $log_check = $node_subscriber->poll_query_until(\\n> +    'postgres',\\n> +    \\"SELECT count(*) > 0 FROM $clt;\\"\\n> +);\\n> +\\n> +my $conflict_check = $node_subscriber->safe_psql('postgres',\\n> +    \\"SELECT count(*) FROM $clt WHERE conflict_type =\\n> 'multiple_unique_conflicts';\\");\\n> +is($conflict_check, 1, 'Verified multiple_unique_conflicts logged\\n> into conflict log table');\\n>\\n>\\n> +# Wait for the conflict to be logged in the CLT\\n> +$log_check = $node_subscriber->poll_query_until(\\n> +    'postgres',\\n> +    \\"SELECT count(*) > 0 FROM $clt;\\"\\n> +);\\n> +\\n> +$conflict_check = $node_subscriber->safe_psql('postgres',\\n> +    \\"SELECT count(*) FROM $clt WHERE conflict_type =\\n> 'multiple_unique_conflicts';\\");\\n> +is($conflict_check, 1, 'Verified multiple_unique_conflicts logged\\n> into conflict log table');\\n>\\n>\\n> In both places it fails because the number of conflict records\\n> inserted can be more than 1 like below:\\n> [18:35:58.342](1.786s) not ok 1 - Verified multiple_unique_conflicts\\n> logged into conflict log table\\n> [18:35:58.346](0.004s)\\n> [18:35:58.347](0.002s) #   Failed test 'Verified\\n> multiple_unique_conflicts logged into conflict log table'\\n> #   at t/035_conflicts.pl line 104.\\n> [18:35:58.348](0.000s) #          got: '2'\\n> #     expected: '1'\\n>\\n> How about we check that the record count >= 1 and check for 't'.\\n\\nYeah that makes sense, fixed that and also fixed Shveta's comments,\\nnow only doc changes suggestions from Peter are pending.\\n\\n\\n-- \\nRegards,\\nDilip Kumar\\nGoogle\\n","threadId":"19bea7defb8a17b6","snippet":"On Tue, Jan 20, 2026 at 6:48 PM vignesh C <vignesh21@gmail.com> wrote: > > On Mon, 19 Jan 2026 at 10:57, Dilip Kumar <dilipbalaut@gmail.com> wrote: > > > > On Mon, Jan 19,","historyId":"12888","internalDate":"1769165645000","receivedAtUtc":"2026-01-23T10:54:05.000Z","from":"Dilip Kumar <dilipbalaut@gmail.com>"}]	The discussion centers on a PostgreSQL proposal to implement a conflict log history table for logical replication. Developers are reviewing v22 patches that add functionality to log replication conflicts to a dedicated table instead of just server logs. Key issues being addressed include documentation consistency (using "Conflict log table" terminology), proper handling of table lifecycle when subscriptions are dropped, and test reliability problems. The tests are failing intermittently because conflict records can be inserted multiple times, causing count mismatches. Vignesh C identified that test assertions expecting exactly 1 conflict record sometimes get 2, suggesting the fix should check for >= 1 records instead. Dilip Kumar has addressed most feedback except pending documentation changes from Peter Smith's review.\n\n讨论围绕PostgreSQL逻辑复制冲突日志历史表的提案展开。开发者正在审查v22补丁，该补丁添加了将复制冲突记录到专用表而非仅记录到服务器日志的功能。正在解决的关键问题包括文档术语的一致性（使用"冲突日志表"术语）、订阅删除时表生命周期的正确处理，以及测试可靠性问题。测试间歇性失败是因为冲突记录可能被多次插入，导致计数不匹配。Vignesh C发现期望恰好1条冲突记录的测试断言有时会得到2条，建议修复应检查>=1条记录。Dilip Kumar已解决了大部分反馈，除了Peter Smith审查中待处理的文档更改。	2026-01-23 10:54:05+00	\N
14	19bea86b1ad24288	Fix gistkillitems & add regression test to microvacuum	["reshkekirill@gmail.com","x4mmm@yandex-team.ru"]	[{"id":"19bea86b1ad24288","messageId":"<CALdSSPiGnqgvpfQDCydBf-=0hzyUs6Y0o0xNvd53BbcMWTVO=w@mail.gmail.com>","subject":"Re: Fix gistkillitems & add regression test to microvacuum","body":"On Tue, 20 Jan 2026 at 15:30, Andrey Borodin <x4mmm@yandex-team.ru> wrote:\\n>\\n>\\n>\\n> > On 15 Jan 2026, at 22:59, Kirill Reshke <reshkekirill@gmail.com> wrote:\\n> >\\n> > PFA v2 which leaves the test in-place.\\n> >\\n> > Also commit message improvements.\\n>\\n> Yeah, killtuples for GiST root page is broken. Your patch is fixing it.\\n> I don't think we should backpatch this, the bug is harmless, but for master the patch LGTM.\\n\\nThank you\\n\\n> It would be good to assign so->curBlkno and so->curBlkno together. But gistScanPage() is the only place with access to the block number.\\n\\nSorry, didnt get this take.\\n\\n> +# Test gist, but with fewer rows - that killitems used to be buggy.\\n>\\n> Probably, in this comment we can explicitly say that killitems was buggy, but now is fixed.\\n>\\n\\nHmm, what would be a good wording here?\\n\\n\\n-- \\nBest regards,\\nKirill Reshke\\n\\n\\n","threadId":"19bea86b1ad24288","snippet":"On Tue, 20 Jan 2026 at 15:30, Andrey Borodin <x4mmm@yandex-team.ru> wrote: > > > > > On 15 Jan 2026, at 22:59, Kirill Reshke <reshkekirill@gmail.com> wrote: > > >","historyId":"12889","internalDate":"1769166230000","receivedAtUtc":"2026-01-23T11:03:50.000Z","from":"Kirill Reshke <reshkekirill@gmail.com>"}]	Kirill Reshke submitted a v2 patch to fix a bug in GiST killtuples functionality for root pages and add a regression test to microvacuum. Andrey Borodin confirmed the bug exists and that the patch fixes it, noting the issue is harmless but should be addressed in master without backporting. Borodin suggested improving variable assignment in gistScanPage() and recommended updating the test comment to explicitly mention the bug was fixed. Reshke acknowledged the feedback and requested clarification on appropriate wording for the comment update.\n\nKirill Reshke 提交了 v2 补丁，修复 GiST killtuples 功能在根页面的错误，并为 microvacuum 添加回归测试。Andrey Borodin 确认错误存在，补丁能修复问题，指出该问题无害但应在主分支中修复，不需要回移植。Borodin 建议改进 gistScanPage() 中的变量赋值，并建议更新测试注释以明确提及错误已修复。Reshke 确认了反馈并请求关于注释更新合适措辞的澄清。	2026-01-23 11:03:50+00	\N
14	19beab27f07b7cd3	Deadlock detector fails to activate on a hot standby replica	["v.davydov@postgrespro.ru"]	[{"id":"19beab27f07b7cd3","messageId":"<b178ea8d-9ed9-48b3-b4f7-5cfc3ff6ee44@postgrespro.ru>","subject":"Re: Deadlock detector fails to activate on a hot standby replica","body":"Dear Hackers,\\n\\nI would like to propose a patch that fixes the problem, which has the roots in\\nthe possibility of spontaneous SIGALRM signals when waiting for some timeouts.\\nThe idea of the patch - ignore spontaneous SIGALRM signals and continue waiting\\nfor expected timeouts or buffer unpinning by the conflicting backend. This\\npatch is not a final version. I plan to add a tap-test for this case.\\n\\nI'm in doubt to put the calls of some page buffer specific functions into\\nResolveRecoveryConflictWithBufferPin (standby.c), but otherwise we have to\\ndo more changes in LockBufferForCleanup and ResolveRecoveryConflictWithBufferPin.\\n\\nI also think, we have to add some description of the found problem in timeout.c,\\nbecause the implemented optimization of setitimer calls leads to some not\\nevident consequences. The optimization seems to be implemented in the commit:\\n09cf1d52267644cdbdb734294012cf1228745aaa\\n\\nWith best regards,\\nVitaly","threadId":"19beab27f07b7cd3","snippet":"Dear Hackers, I would like to propose a patch that fixes the problem, which has the roots in the possibility of spontaneous SIGALRM signals when waiting for some timeouts. The idea of the patch -","historyId":"12890","internalDate":"1769169109000","receivedAtUtc":"2026-01-23T11:51:49.000Z","from":"Vitaly Davydov <v.davydov@postgrespro.ru>"}]	Vitaly Davydov proposes a patch to fix a deadlock detector activation issue on hot standby replicas. The problem stems from spontaneous SIGALRM signals occurring during timeout waits, which interfere with expected timeout behavior. The proposed solution ignores these spontaneous signals and continues waiting for proper timeouts or buffer unpinning by conflicting backends. The patch is not final, with plans to add tap-tests for verification. There are concerns about placing buffer-specific function calls in ResolveRecoveryConflictWithBufferPin, and the author suggests adding documentation in timeout.c to explain the non-obvious consequences of setitimer optimization implemented in commit 09cf1d52267644cdbdb734294012cf1228745aaa.\n\nVitaly Davydov提出了一个修复补丁，用于解决热备副本上死锁检测器激活失败的问题。问题源于在等待超时期间出现的自发SIGALRM信号，这些信号干扰了预期的超时行为。建议的解决方案是忽略这些自发信号，继续等待正确的超时或冲突后端的缓冲区解除固定。该补丁尚未最终完成，计划添加tap测试进行验证。作者担心在ResolveRecoveryConflictWithBufferPin中放置缓冲区特定函数调用，并建议在timeout.c中添加文档来解释在提交09cf1d52267644cdbdb734294012cf1228745aaa中实现的setitimer优化所带来的不明显后果。	2026-01-23 11:51:49+00	\N
14	19be9aa372b5fabc	Checkpointer write combining	["andres@anarazel.de","byavuz81@gmail.com","li.evan.chao@gmail.com","melanieplageman@gmail.com","soumyamurali.work@gmail.com"]	[{"id":"19be9aa372b5fabc","messageId":"<CAMtXxw-2xFGrFzQ7O_9_a0zSJytkh6v-se5JvroCCQXtXUt=VA@mail.gmail.com>","subject":"Re: Checkpointer write combining","body":"Hi all,\\n\\nThank you all for the patches.\\nI am keeping this as a single patch because the refactoring, batching\\nbehavior and instrumentation are tightly coupled and all serve one\\npurpose to reduce checkpoint writeback overhead while making the\\neffect observable. Due to version and context differences, the patches\\ndid not apply cleanly in my development environment. Instead, I\\nstudied the patches and went through the logic in detail and then\\nimplemented the same ideas directly in my current tree adapting them\\nwherever needed. The implementation was then validated with\\ninstrumentation and measurements.\\n\\nBefore batching:\\n2026-01-22 17:27:26.969 IST [148738] LOG:  checkpoint complete: wrote\\n15419 buffers (94.1%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\nremoved, 25 recycled; write=0.325 s, sync=0.284 s, total=0.754 s; sync\\nfiles=30, longest=0.227 s, average=0.010 s; distance=407573 kB,\\nestimate=407573 kB; lsn=0/1A5B8E30, redo lsn=0/1A5B8DD8\\n\\nAfter batching:\\n2026-01-22 17:31:36.165 IST [148738] LOG:  checkpoint complete: wrote\\n13537 buffers (82.6%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\nremoved, 25 recycled; write=0.260 s, sync=0.211 s, total=0.625 s; sync\\nfiles=3, longest=0.205 s, average=0.070 s; distance=404310 kB,\\nestimate=407247 kB; lsn=0/3308E738, redo lsn=0/3308E6E0\\n\\nDebug instrumentation with (batch size = 16) confirms the batching\\nbehavior itself,\\nbuffers_written = 6196\\nwriteback_calls = 389\\nOn average: I am getting 15.9 i.e approx 16 buffers per writeback\\nThis shows that writebacks are issued per batch rather than per\\nbuffer, while WAL ordering and durability semantics remain unchanged.\\nThe change remains localized to BufferSync() and is intended to be a\\nconservative and measurable improvement to checkpoint I/O behavior. I\\nam attaching the patches herewith for review.\\nI am happy to adjust the approach if there are concerns or\\nsuggestions. Looking forward to more feedback.\\n\\nRegards,\\nSoumya\\n","threadId":"19be9aa372b5fabc","snippet":"Hi all, Thank you all for the patches. I am keeping this as a single patch because the refactoring, batching behavior and instrumentation are tightly coupled and all serve one purpose to reduce","historyId":"12880","internalDate":"1769151820000","receivedAtUtc":"2026-01-23T07:03:40.000Z","from":"Soumya S Murali <soumyamurali.work@gmail.com>"},{"id":"19beac9b17fb9c86","messageId":"<CAMtXxw9cqxgNH6=8NDAA2o11GoF=4P4JO=7-FCkhr=vJCmQiJA@mail.gmail.com>","subject":"Re: Checkpointer write combining","body":"Hi all,\\n\\n\\n> Thank you all for the patches.\\n> I am keeping this as a single patch because the refactoring, batching\\n> behavior and instrumentation are tightly coupled and all serve one\\n> purpose to reduce checkpoint writeback overhead while making the\\n> effect observable. Due to version and context differences, the patches\\n> did not apply cleanly in my development environment. Instead, I\\n> studied the patches and went through the logic in detail and then\\n> implemented the same ideas directly in my current tree adapting them\\n> wherever needed. The implementation was then validated with\\n> instrumentation and measurements.\\n>\\n> Before batching:\\n> 2026-01-22 17:27:26.969 IST [148738] LOG:  checkpoint complete: wrote\\n> 15419 buffers (94.1%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\n> removed, 25 recycled; write=0.325 s, sync=0.284 s, total=0.754 s; sync\\n> files=30, longest=0.227 s, average=0.010 s; distance=407573 kB,\\n> estimate=407573 kB; lsn=0/1A5B8E30, redo lsn=0/1A5B8DD8\\n>\\n> After batching:\\n> 2026-01-22 17:31:36.165 IST [148738] LOG:  checkpoint complete: wrote\\n> 13537 buffers (82.6%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0\\n> removed, 25 recycled; write=0.260 s, sync=0.211 s, total=0.625 s; sync\\n> files=3, longest=0.205 s, average=0.070 s; distance=404310 kB,\\n> estimate=407247 kB; lsn=0/3308E738, redo lsn=0/3308E6E0\\n>\\n> Debug instrumentation with (batch size = 16) confirms the batching\\n> behavior itself,\\n> buffers_written = 6196\\n> writeback_calls = 389\\n> On average: I am getting 15.9 i.e approx 16 buffers per writeback\\n> This shows that writebacks are issued per batch rather than per\\n> buffer, while WAL ordering and durability semantics remain unchanged.\\n> The change remains localized to BufferSync() and is intended to be a\\n> conservative and measurable improvement to checkpoint I/O behavior. I\\n> am attaching the patches herewith for review.\\n> I am happy to adjust the approach if there are concerns or\\n> suggestions. Looking forward to more feedback.\\n>\\n\\nWith reference to my previous patch related to the batching behavior,\\nI evaluated batch sizes 8, 16, and 32 under identical workloads. I am\\nattaching the log for 8, 16 and 32. All conclusions are based on\\nactual checkpoint logs and DEBUG BufferSync statistics:\\n\\nBatch size = 8\\nLOG: checkpoint complete: wrote 12622 buffers (77.0%); write=0.113 s,\\nsync=0.195 s, total=0.485 s; sync files=37\\nDEBUG:  checkpoint BufferSync stats: buffers_written=9923, writeback_calls=1242\\nAvg: 7.989 approx 8 buffers per writeback.\\n\\nBatch size = 16\\nLOG: checkpoint complete: wrote 13537 buffers (82.6%); write=0.260 s,\\nsync=0.211 s, total=0.625 s; sync files=3\\nDEBUG:  checkpoint BufferSync stats: buffers_written=6196, writeback_calls=389\\nAvg: 15.9 approx 16 buffers per writeback.\\n\\nBatch size = 32\\nLOG: checkpoint complete: wrote 12914 buffers (78.8%); write=0.116 s,\\nsync=0.136 s, total=0.442 s; sync files=5\\nDEBUG:  checkpoint BufferSync stats: buffers_written=12914, writeback_calls=1616\\nAvg: 7.99 approx 8 buffers per writeback.\\n\\nBatch 16 significantly reduces sync fan-out (as low as 3 files per\\ncheckpoint), but this comes at the cost of longer individual sync\\noperations, resulting in higher total checkpoint time (≈0.625 s).\\nBatch 32 provides a better balance, maintaining low sync fragmentation\\nwhile avoiding long sync stalls, yielding the lowest overall\\ncheckpoint time (≈0.442 s). I am attaching the patch with batch size\\nfixed as 32 for now for further review.\\nPlease let me know if further workloads or instrumentation would be useful.\\n\\nRegards\\nSoumya\\n","threadId":"19be9aa372b5fabc","snippet":"Hi all, > Thank you all for the patches. > I am keeping this as a single patch because the refactoring, batching > behavior and instrumentation are tightly coupled and all serve one >","historyId":"12880","internalDate":"1769170658000","receivedAtUtc":"2026-01-23T12:17:38.000Z","from":"Soumya S Murali <soumyamurali.work@gmail.com>"}]	Soumya S Murali presents an implementation of checkpointer write combining that batches buffer writebacks to reduce checkpoint I/O overhead. The patch combines refactoring, batching behavior, and instrumentation into a single implementation localized to BufferSync(). Performance testing shows significant improvements: batching reduced sync files from 30 to 3, total checkpoint time from 0.754s to 0.625s, and confirmed ~16 buffers per writeback call instead of per-buffer writebacks. Further evaluation of batch sizes 8, 16, and 32 revealed that batch size 32 provides optimal balance, achieving lowest total checkpoint time (0.442s) while maintaining low sync fragmentation. The implementation preserves WAL ordering and durability semantics while delivering measurable I/O performance improvements.\n\nSoumya S Murali 提出了检查点写入合并的实现，通过批处理缓冲区写回来减少检查点I/O开销。该补丁将重构、批处理行为和监控整合到一个局限于BufferSync()的实现中。性能测试显示显著改进：批处理将同步文件从30个减少到3个，总检查点时间从0.754秒减少到0.625秒，并确认每次写回调用处理约16个缓冲区而非每缓冲区写回。对批次大小8、16和32的进一步评估显示，批次大小32提供最佳平衡，实现最低总检查点时间(0.442秒)，同时保持低同步碎片化。该实现保持WAL顺序和持久性语义，同时提供可测量的I/O性能改进。	2026-01-23 12:17:38+00	\N
14	19bead36276a5204	pg_waldump: support decoding of WAL inside tarfile	["jakub.wartak@enterprisedb.com","li.evan.chao@gmail.com","robertmhaas@gmail.com","sulamul@gmail.com"]	[{"id":"19bead36276a5204","messageId":"<CAAJ_b95FOeW38gw-3BLmpdnTWHFimopTvf=eTObYUbTOC0x8qg@mail.gmail.com>","subject":"Re: pg_waldump: support decoding of WAL inside tarfile","body":"On Mon, Jan 19, 2026 at 7:01 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n>\\n> > But, I am thinking that instead of setting privateInfo->cur_wal to\\n> > NULL, we could simply discard the buffer data at that place and let\\n> > memcpy in astreamer_content copy if it would be that much of an issue.\\n>\\n> I don't think doing unnecessary copying is the right way forward. The\\n> copying itself could be expensive, but I am a little concerned about\\n> the memory utilization of this code. Suppose the user has increased\\n> the WAL segment size to 1GB or even higher. It seems like we could\\n> buffer a whole segment or maybe even more in some scenarios. If we\\n> avoid copying data we don't need, then we also avoid buffering it in\\n> memory.\\n>\\n> In terms of the separation of concerns, we could view setting\\n> privateInfo->cur_wal = NULL as a form of signaling, a way for this\\n> code to tell the astreamer that it doesn't need the data buffering.\\n> However, I think it might be better to make the signaling more\\n> explicit. Instead of having the caller directly set the buffer to\\n> NULL, or directly trim data out of the buffer, maybe it should set\\n> some value in privateInfo that tells the astreamer what to do. For\\n> instance, suppose it sets the oldest LSN that it might still care\\n> about in privateInfo, and then the astreamer is free to do skip\\n> copying of any data prior to that LSN, and discard any that it already\\n> has. Especially if properly commented, I think this might be more\\n> clear than what you have now. I am not 100% sure that's the right\\n> idea, though. I just think right now it's a bit murky who does what\\n> and why the division of responsibilities is what it is.\\n>\\n\\nThe current implementation of astreamer_waldump_content() does not\\nhave sufficient information to skip WAL segments during the initial\\nhash entry preparation and data-copying phase. Because the filtration\\nparameters -- which determine if a segment should be skipped -- depend\\non the WAL segment size, we must first read a WAL page through the\\nstreamer to calculate that size, which is done in\\ninit_archive_reader(). Therefore, the responsibility of the archive\\nstreamer is strictly to copy the WAL segment data to the buffer.\\n\\nThe skipping decision is handled inside get_archive_wal_entry(), which\\nsets privateInfo->cur_wal to NULL. In the next version, I am planning\\nto add a separate routine (with better commenting) that, along with\\nsetting the pointer to NULL, releases that hash entry to avoid\\nunnecessary memory usage.\\n\\nAnother option I previously considered was adding the filtration logic\\ninside the archive streamer itself. However, since the very first read\\nis required to calculate the WAL segment size, the filter check cannot\\nbe performed immediately. However, we could send a signal to the\\narchive streamer via privateInfo (e.g., a read_any_wal or\\nskip_wal_check boolean flag) to disable the filtration check until the\\nsize is calculated. But that approach isn't very elegant; if the first\\nWAL page we read belongs to a segment we actually want to skip, we\\nwould still have to run the filter check and handle the skip/removal\\nlogic outside of the streamer (i.e., inside init_archive_reader()).\\nThis would result in performing the same filtration check in two\\ndifferent places.\\n\\nTherefore, I believe performing the filtration check through\\nget_archive_wal_entry() and then calling a routine to clear\\nprivateInfo->cur_wal and the hash entry is the better approach, IMO.\\nAdditionally, once we consume a WAL file and move to the next one, the\\nhash entry and buffer for that WAL can be released to prevent\\nunnecessary memory consumption by calling the same routine that I am\\nplanning to add.\\n\\n> > > +       if (strstr(member->pathname, \\"PaxHeaders.\\"))\\n> > > +               return false;\\n> > >\\n> > > There is no way that a filename containing the string \\"PaxHeaders.\\"\\n> > > could ever pass the IsXLogFileName test just above. We shouldn't need\\n> > > this.\\n> > >\\n> >\\n> > This checks the directory name (e.g.,\\n> > x_dir/y_dir/PaxHeaders.NNNN/wal_file_name). The name of that metadata\\n> > file is exactly the same as the WAL file name, which is why\\n> > IsXLogFileName() doesn't help here.\\n>\\n> I think this code should only be considering files in the toplevel\\n> directory, and skipping over any directories it finds. I absolutely\\n> promise I am not going to commit anything that is specifically looking\\n> for PaxHeaders. Nothing we've ever done with tar files up to now has\\n> required that, and I don't think this should, either.\\n\\nOk, fair enough, my intention was to allow decoding of valid WAL data\\nfrom any directory in the tar archive, but I will go ahead and add\\nthat restriction as suggested.\\n\\nRegards,\\nAmul\\n\\n\\n","threadId":"19bead36276a5204","snippet":"On Mon, Jan 19, 2026 at 7:01 PM Robert Haas <robertmhaas@gmail.com> wrote: > > > But, I am thinking that instead of setting privateInfo->cur_wal to > > NULL, we could simply","historyId":"12893","internalDate":"1769171231000","receivedAtUtc":"2026-01-23T12:27:11.000Z","from":"Amul Sul <sulamul@gmail.com>"}]	Amul Sul responds to Robert Haas's feedback on pg_waldump tarfile decoding implementation. The discussion centers on memory management and responsibility separation in WAL segment processing. Haas suggested avoiding unnecessary data copying and making signaling more explicit between components. Sul explains that the current astreamer_waldump_content() lacks information to skip WAL segments during initial preparation, as filtration parameters depend on WAL segment size calculated later in init_archive_reader(). Sul proposes adding a separate routine to handle setting privateInfo->cur_wal to NULL while releasing hash entries to prevent memory buildup. Regarding PaxHeaders filtering, Haas objects to hardcoded PaxHeaders checks, preferring to restrict processing to toplevel directory files only. Sul agrees to implement this restriction despite originally intending to allow WAL decoding from any archive directory.\n\nAmul Sul回应了Robert Haas对pg_waldump tar文件解码实现的反馈。讨论集中在WAL段处理中的内存管理和职责分离上。Haas建议避免不必要的数据复制，并使组件间的信号传递更明确。Sul解释当前的astreamer_waldump_content()在初始准备阶段缺乏跳过WAL段的信息，因为过滤参数依赖于稍后在init_archive_reader()中计算的WAL段大小。Sul提议添加一个单独的例程来处理将privateInfo->cur_wal设置为NULL同时释放哈希条目以防止内存堆积。关于PaxHeaders过滤，Haas反对硬编码的PaxHeaders检查，倾向于仅限制处理顶级目录文件。尽管Sul最初打算允许从任何归档目录解码WAL，但他同意实现这一限制。	2026-01-23 12:27:11+00	\N
14	19beac6f0651a93f	Is abort() still needed in WalSndShutdown()?	["hlinnaka@iki.fi","masao.fujii@gmail.com"]	[{"id":"19beac6f0651a93f","messageId":"<CAHGQGwHPX1yoixq+YB5rF4zL90TMmSEa3FpHURtqW3Jc5+=oSA@mail.gmail.com>","subject":"Is abort() still needed in WalSndShutdown()?","body":"Hi,\\n\\nWhile reviewing the patch [1], I found that WalSndShutdown() calls abort()\\nwith the comment \\"keep the compiler quiet\\" just after proc_exit(0).\\n\\n        static void\\n        WalSndShutdown(void)\\n        {\\n        /*\\n        * Reset whereToSendOutput to prevent ereport from attempting to send any\\n        * more messages to the standby.\\n        */\\n        if (whereToSendOutput == DestRemote)\\n        whereToSendOutput = DestNone;\\n\\n        proc_exit(0);\\n        abort(); /* keep the compiler quiet */\\n        }\\n\\nThis may have been necessary in the past, but is it still required?\\nOther functions, such as CheckpointerMain(), simply call proc_exit(0)\\nwithout an abort(), which doesn't seem to cause compiler warnings.\\nThat made me wonder whether the abort() in WalSndShutdown() is\\nstill needed, or which compiler would actually warn if WalSndLoop()\\ndoes not end with an abort().\\n\\nThoughts?\\n\\n[1] https://postgr.es/m/d062db6a-8040-41eb-b3c9-32c3af30ef2b@postgrespro.ru\\n\\n-- \\nFujii Masao\\n\\n\\n","threadId":"19beac6f0651a93f","snippet":"Hi, While reviewing the patch [1], I found that WalSndShutdown() calls abort() with the comment \\"keep the compiler quiet\\" just after proc_exit(0). static void WalSndShutdown(void) { /* *","historyId":"12891","internalDate":"1769170438000","receivedAtUtc":"2026-01-23T12:13:58.000Z","from":"Fujii Masao <masao.fujii@gmail.com>"},{"id":"19bead5a9c7ccb09","messageId":"<796c4d50-b92b-46a7-8c07-60acb3a9b75d@iki.fi>","subject":"Re: Is abort() still needed in WalSndShutdown()?","body":"On 23/01/2026 14:13, Fujii Masao wrote:\\n> Hi,\\n> > While reviewing the patch [1], I found that WalSndShutdown() calls abort()\\n> with the comment \\"keep the compiler quiet\\" just after proc_exit(0).\\n> >          static void\\n>          WalSndShutdown(void)\\n>          {\\n>          /*\\n>          * Reset whereToSendOutput to prevent ereport from attempting to send any\\n>          * more messages to the standby.\\n>          */\\n>          if (whereToSendOutput == DestRemote)\\n>          whereToSendOutput = DestNone;\\n> >          proc_exit(0);\\n>          abort(); /* keep the compiler quiet */\\n>          }\\n> > This may have been necessary in the past, but is it still required?\\n> Other functions, such as CheckpointerMain(), simply call proc_exit(0)\\n> without an abort(), which doesn't seem to cause compiler warnings.\\n> That made me wonder whether the abort() in WalSndShutdown() is\\n> still needed, or which compiler would actually warn if WalSndLoop()\\n> does not end with an abort().\\n\\nSeems useless to me. Looking at the git history, long time ago the proc_exit(0) call was in a function that returned \\"int\\", and I can see how the compiler would complain about that if it didn't know that the function doesn't return. But WalSendShutdown() returns void these days, so you should not get a compiler warning, whether or not the compiler understands that proc_exit(0) doesn't return.\\n\\n- Heikki\\n\\n\\n\\n","threadId":"19beac6f0651a93f","snippet":"On 23/01/2026 14:13, Fujii Masao wrote: > Hi, > > While reviewing the patch [1], I found that WalSndShutdown() calls abort() > with the comment \\"keep the compiler quiet\\" just","historyId":"12891","internalDate":"1769171415000","receivedAtUtc":"2026-01-23T12:30:15.000Z","from":"Heikki Linnakangas <hlinnaka@iki.fi>"}]	Fujii Masao questioned whether the abort() call in WalSndShutdown() is still necessary, noting it appears after proc_exit(0) with a "keep the compiler quiet" comment. He observed that other functions like CheckpointerMain() use only proc_exit(0) without compiler warnings, suggesting the abort() may be obsolete. Heikki Linnakangas agreed the abort() seems useless, explaining that historically it was needed when the function returned "int" and compilers might complain about missing returns. However, since WalSndShutdown() now returns void, compiler warnings should not occur regardless of whether the compiler understands proc_exit(0) doesn't return. Both contributors appear to agree the abort() call can likely be removed.\nFujii Masao质疑WalSndShutdown()中的abort()调用是否仍然必要，注意到它出现在proc_exit(0)之后，带有"keep the compiler quiet"注释。他观察到其他函数如CheckpointerMain()仅使用proc_exit(0)而不产生编译器警告，表明abort()可能已过时。Heikki Linnakangas同意abort()似乎是无用的，解释说历史上当函数返回"int"时需要它，编译器可能会抱怨缺少返回值。然而，由于WalSndShutdown()现在返回void，无论编译器是否理解proc_exit(0)不返回，都不应出现编译器警告。两位贡献者似乎都同意abort()调用可能可以被移除。	2026-01-23 12:30:15+00	\N
14	19be597e72b87c37	Skipping schema changes in publication	["1518981153@qq.com","amit.kapila16@gmail.com","barwick@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","houzj.fnst@fujitsu.com","shlok.kyal.oss@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19be96181f22b678","messageId":"<CAHut+PtKD6zoACwW61MuNBo8iqT8dc6Es4Rwqi5u7jCuEtW=Dw@mail.gmail.com>","subject":"Re: Skipping schema changes in publication","body":"Hi Shlok.\\n\\nSome review comments for v36-0001.\\n\\n======\\n1.\\nIt seems that most of my v35 public/internal review comments from\\naround 8/JAN have not been addressed in v36.\\n\\n======\\ndoc/src/sgml/ref/create_publication.sgml\\n\\nEXCEPT TABLE\\n\\n2.\\n+     <para>\\n+      For partitioned tables, only the root partitioned table may be specified\\n+      in <literal>EXCEPT TABLE</literal>. Doing so excludes the root table and\\n+      all of its partitions from replication, regardless of the value of\\n+      <literal>publish_via_partition_root</literal>. The optional\\n+      <literal>*</literal> has no effect for partitioned tables.\\n+     </para>\\n\\n2a.\\nAFAIK, the 'publish_via_partition_root' value has nothing to do with\\nEXCEPT(partition) in this patch, but why was it really necessary to\\nactually say that?\\n\\n~\\n\\n2b.\\nShould this be saying that \\"ONLY\\" also does not mean anything when a\\npartitioned table is specified?\\n\\n======\\nsrc/backend/catalog/pg_publication.c\\n\\npublication_add_relation:\\n\\n3.\\n+ /*\\n+ * Handle the case where a partition is excluded by EXCEPT TABLE\\n+ */\\n+ if (pub->alltables && pri->except && targetrel->rd_rel->relispartition)\\n+ ereport(ERROR,\\n+ (errmsg(\\"partition \\\\\\"%s\\\\\\" cannot be excluded using EXCEPT TABLE\\",\\n+ RelationGetRelationName(targetrel))));\\n\\nShould we have a hintmsg here to ask/tell the user that they might\\nneed to try EXCEPT the partitioned root instead?\\n\\n======\\nsrc/backend/commands/tablecmds.c\\n\\nATExecAttachPartition:\\n\\n4.\\n+ /* Check if the partiton is part of EXCEPT list of any publication */\\n+ GetRelationPublications(RelationGetRelid(attachrel), NULL, &except_pubids);\\n+ if (except_pubids != NIL)\\n+ ereport(ERROR,\\n+ (errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE),\\n+ errmsg(\\"cannot attach relation \\\\\\"%s\\\\\\" as partition because it is\\npart of EXCEPT list in publication\\",\\n+ RelationGetRelationName(attachrel))));\\n\\nMaybe reword the message\\n\\nSUGGESTION\\n... because it is named in a publication EXCEPT TABLE list\\n\\n======\\nsrc/backend/utils/cache/relcache.c\\n\\nRelationBuildPublicationDesc:\\n\\n5.\\n+ /*\\n+ * Only the topmost ancestor of a partitioned table can be specified\\n+ * in EXCEPT TABLES clause of a FOR ALL TABLES publication. So fetch\\n+ * the publications excluding the topmost ancestor only.\\n+ */\\n+ GetRelationPublications(llast_oid(ancestors), NULL, &exceptpuboids);\\n+\\n\\nI found that \\"So fetch...\\" sentence to be quite ambiguous.\\n\\nSUGGESTION\\n... , so we only need to check the topmost ancestor.\\n\\n======\\n.../t/037_rep_changes_except_table.pl\\n\\n6.\\n+ ALTER TABLE sch1.t1 ATTACH PARTITION sch1.part2 FOR VALUES FROM\\n(101) TO (200);\\n\\nWas there any reason to do this ALTER?\\nAFAIK, you could've said both PARTITION BY and PARTITION OF in the\\noriginal CREATE TABLE.\\n\\n~~~\\n\\n7.\\n+# Partititions cannot be excluded using EXCEPT TABLE\\n\\n7a.\\ntypo: /Partititions/Partitions/\\n\\n~\\n\\n7b.\\nTBH, I don't know if it was necessary to repeat these partition tests\\nall the time with/without publish_via_partition_root set, but if you\\nstill think it is needed, then the comment should say that all\\ncombinations are tested to demonstrate that the parameter has no\\neffect.\\n\\nMeanwhile, the same goes for all the other tests too ... Given that\\n'publish_via_partition_root' has no impact on EXCEPT TABLE, then why\\ndo we need so many combinations of tests to show that it has no\\neffect? IOW, many other parameters also have nothing to do with EXCEPT\\nTABLE, but we don't test those.\\n\\n~~~\\n\\n8.\\n+# Cannot attach partition that is part of EXCEPT list in publication\\n\\nSUGGESTION\\nCannot attach a partition  that is named in the EXCEPT list of any publication\\n\\n======\\nKind Regards,\\nPeter Smith.\\nFujitsu Australia\\n\\n\\n","threadId":"19be597e72b87c37","snippet":"Hi Shlok. Some review comments for v36-0001. ====== 1. It seems that most of my v35 public/internal review comments from around 8/JAN have not been addressed in v36. ====== doc/src/sgml/ref/","historyId":"12867","internalDate":"1769147001000","receivedAtUtc":"2026-01-23T05:43:21.000Z","from":"Peter Smith <smithpb2250@gmail.com>"},{"id":"19beafb3b3fb39e1","messageId":"<CALDaNm2x3fR+AEji0ZruTdss-4WDatraXKs1QA44eVnsBmbUiA@mail.gmail.com>","subject":"Re: Skipping schema changes in publication","body":"On Wed, 21 Jan 2026 at 11:35, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n>\\n> On Mon, Jan 19, 2026 at 3:08 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> >\\n> > Approaches for Supporting EXCEPT in Partitioned Tables\\n> > ------------------------------------------------------------------------\\n> >\\n> > In an offline discussion with Peter Smith, Amit, and Shlok, we\\n> > identified several approaches for supporting EXCEPT with partitioned\\n> > tables and their partitions. I'd like to hear others' opinions on\\n> > these approaches.\\n> >\\n> > Consider the following partition hierarchy:\\n> > tab_root\\n> >   ├─ tab_part_1\\n> >   │   ├─ tab_part_1_p1\\n> >   │   └─ tab_part_1_p2\\n> >   └─ tab_part_2\\n> >       ├─ tab_part_2_p1\\n> >       └─ tab_part_2_p2\\n> >\\n> >\\n> > Approach 1:\\n> > ---------------------------------\\n> > If we exclude a table, then the data in that table and all of its\\n> > partitions (i.e., the entire subtree under that table) should not be\\n> > replicated.\\n> >\\n> > For example EXCEPT (tab_part_1) skips replication of tab_part_1 and\\n> > all of its partitions.\\n> >\\n> > This behaviour remains the same with or without\\n> > publish_via_partition_root. The publish_via_partition_root flag only\\n> > affects publish_via_relid, i.e., the relation through which data is\\n> > published.\\n> >\\n> > This approach involves certain implementation challenges. For brevity,\\n> > these are documented in the attached 'Approach1_challenges' document.\\n> >\\n> > Approach 2:\\n> > ---------------------------------------------------\\n> > Assign meaning to ONLY and '*' for partition tables in the EXCEPT\\n> > list. In HEAD, ONLY and '*' do not have any meaning for partitioned\\n> > tables or partitions, and these keywords are currently ignored.\\n> >\\n> > Examples:\\n> > 1. EXCEPT (ONLY tab_part_1) skips replication of only the table\\n> > tab_part_1. Changes for tab_root, tab_part_1_p1, and tab_part_1_p2 are\\n> > still replicated.\\n> >\\n> > ii. EXCEPT (tab_part_1*) skips replication of tables tab_part_1,\\n> > tab_part_1_p1, and tab_part_1_p2\\n> >\\n> > The challenges described in Approach 1, particularly around tablesync\\n> > handling and COPY behaviour, would still need to be addressed under\\n> > this approach as well. ONLY or '*' with partitioned tables is not\\n> > supported in HEAD, supporting it specifically for ALL TABLES EXCEPT\\n> > may introduce additional confusion for users.\\n> >\\n> > Approach 3:\\n> > ----------------\\n> > Do not allow partitions to be specified in the EXCEPT clause.\\n> >\\n> > Only EXCEPT (tab_root) is supported, which excludes tab_root and all\\n> > of its partitions. Specifying EXCEPT (tab_part_1) or EXCEPT\\n> > (tab_part_1_p1) will result in an error.\\n> >\\n> > ~~\\n> >\\n> > While Approach 1 and Approach 2 offer more flexibility to the user\\n> > compared to Approach 3, they also introduce additional design\\n> > complexity which does not seem simpler to address.\\n>\\n> Thanks for explaining this, overall I like the Approach 1, and I also\\n> see the problem when publish via root is given in that case COPY FROM\\n> is executed on the root and it would be hard to exclude specific\\n> partitions.\\n\\nRegarding the above issue which is also mentioned in\\nApproach1_challenges at [1]:\\nWhen a publication is created with publish_via_partition_root = true\\nand a specific partition(tab_part_1_1) is excluded, the expected\\nbehavior is that changes from non-excluded partitions (for example,\\ntab_part_2 and tab_part_1_2 and their descendants) are replicated,\\nwhile changes from the excluded partition (tab_part_1_1 and its\\nsubtree) are not.\\ntab_root\\n├── tab_part_1\\n│   ├── tab_part_1_1        (except)\\n│   │   ├── tab_part_1_1_1\\n│   │   │   └── tab_part_1_1_1_1\\n│   │   └── tab_part_1_1_2\\n│   └── tab_part_1_2\\n│       ├── tab_part_1_2_1\\n│       └── tab_part_1_2_2\\n└── tab_part_2\\n\\nIn this situation, replication cannot be performed purely via the\\npartition root (tab_root), because doing so would implicitly include\\ndata from the excluded child partitions.\\n\\nTo address this, the publication creation should explicitly record the\\nexcluded partition(tab_part_1_1) in pg_publication_rel with an\\nexcluded = true flag. The publish_via_partition_root setting remains\\nstored at the publication level, as it is today. With\\npublish_via_partition_root = true, the publisher–subscriber mapping is\\nnot partition-to-partition. Instead, all eligible data is mapped to\\nthe subscriber's partition root. Therefore,\\npg_get_publication_tables() should return only the top-level root\\ntable (tab_root) to the subscriber for table synchronization. During\\ninitial table sync, when the tablesync worker prepares the COPY\\ncommand, it can query the publisher to determine the effective set of\\ntables that belong to the publication after applying the exclusion\\nrules. Based on this resolved table list, the tablesync worker can\\nconstruct a COPY query that unions data only from the non-excluded\\npartitions, for example:\\nCOPY (\\n    SELECT * FROM tab_part_1_2_1\\n    UNION ALL\\n    SELECT * FROM tab_part_1_2_2\\n    UNION ALL\\n    SELECT * FROM tab_part_2\\n)\\n\\nThis ensures that only non-excluded data is copied and applied to\\ntab_root on the subscriber, while preserving the semantics of\\npublish_via_partition_root = true.\\nThoughts?\\n\\n[1] - https://www.postgresql.org/message-id/CAJpy0uD81HRrMYr7S-6AV4W2PtbGKM-nf2D89zsoMHJ9jZssUg%40mail.gmail.com\\n\\nRegards,\\nVignesh\\n\\n\\n","threadId":"19be597e72b87c37","snippet":"On Wed, 21 Jan 2026 at 11:35, Dilip Kumar <dilipbalaut@gmail.com> wrote: > > On Mon, Jan 19, 2026 at 3:08 PM shveta malik <shveta.malik@gmail.com> wrote: > > > >","historyId":"12867","internalDate":"1769173869000","receivedAtUtc":"2026-01-23T13:11:09.000Z","from":"vignesh C <vignesh21@gmail.com>"}]	Peter Smith provided detailed review comments on v36 of the EXCEPT TABLE patch for PostgreSQL publications. Key issues include unaddressed feedback from previous reviews, unclear documentation about publish_via_partition_root behavior with EXCEPT clauses, missing hint messages for partition exclusion errors, and redundant test coverage. Vignesh C responded to implementation challenges for partitioned tables, proposing a solution where excluded partitions are marked with a flag in pg_publication_rel, and tablesync workers construct UNION queries to copy only non-excluded partition data when publish_via_partition_root is enabled. The discussion focuses on balancing user flexibility with implementation complexity for partition exclusion in logical replication.\n\nPeter Smith对PostgreSQL发布的EXCEPT TABLE补丁v36版本提供了详细的审查意见。关键问题包括之前审查反馈未得到解决、关于publish_via_partition_root与EXCEPT子句行为的文档不清楚、分区排除错误缺少提示信息，以及冗余的测试覆盖。Vignesh C回应了分区表的实现挑战，提出了一个解决方案：在pg_publication_rel中用标志标记被排除的分区，当启用publish_via_partition_root时，tablesync工作进程构造UNION查询仅复制未被排除的分区数据。讨论重点是在逻辑复制中平衡分区排除的用户灵活性和实现复杂性。	2026-01-23 13:11:09+00	\N
14	19be99f7f3572d65	Non-text mode for pg_dumpall	["jian.universality@gmail.com","mahi6run@gmail.com","tushar.ahuja@enterprisedb.com","vaibhav.dalvi@enterprisedb.com"]	[{"id":"19be99f7f3572d65","messageId":"<CAC6VRoZbP=-=a+a78RoWcs2L4=4VEDZqJMg+7SyUAcSHATyDAQ@mail.gmail.com>","subject":"Re: Non-text mode for pg_dumpall","body":"On Sat, Jan 17, 2026 at 1:39 AM Mahendra Singh Thalor <mahi6run@gmail.com>\\nwrote:\\n\\n> Thanks Tushar for the testing.\\n>\\n> On Wed, 7 Jan 2026 at 13:53, tushar <tushar.ahuja@enterprisedb.com> wrote:\\n> >\\n> >\\n> >\\n> > On Tue, Jan 6, 2026 at 11:56 AM Mahendra Singh Thalor <\\n> mahi6run@gmail.com> wrote:\\n> >>\\n> >>\\n> >>\\n> >>\\n> >> We have another thread for this. We have patches also. Last year, we\\n> >> planned to block these databases at creation time.\\n> >>\\n> >> >\\n> >> > It's probably harmless, we connect to the databases further down to\\n> do actual work. But it's also not nice. The toc.glo seems to have a bunch\\n> of extraneous entries of type COMMENT and CONNECT. Why is that? As far as\\n> poible this should have output pretty much  identical to a plain pg_dumpall.\\n> >> >\\n> >> >\\n> >> > cheer\\n> >> >\\n> >> >\\n> >> > andrew\\n> >>\\n>\\n> Thanks Andrew for the feedback.\\n>\\n> In the attached patch, I fixed some comments. In the next version, I\\n> will try to make it much identical to a plain pg_dumpall.\\n>\\n> >> If we don't dump those comments in non-text format, then the output of\\n> >> \\"pg_restore -f filename dump_non_text\\" will not be the same as the\\n> >> plain dump of pg_dumpall.\\n> >>\\n> >> Here, I am attaching an updated patch for the review and testing.\\n> >>\\n> >\\n> > Hi Mahendra,\\n> >\\n> > I found a scenario  in which the table is not restored if\\n> --transaction-size switch is used  at the time of pg_restore operation\\n> >\\n> > Please refer this scenario:\\n> > Case A --pg_restore operation with \\"--transaction-size\\" against the\\n> dump (taken using pg_dump) -\\n> > create a table ( create table t(n int); )\\n> > perform pg_dump ( ./pg_dump -Ft postgres -f xyz.tar)\\n> > create a database (create database test;)\\n> > perform pg_restore using switch \\"--transaction-size\\" ( ./pg_restore\\n> --transaction-size=1 -d test xyz.tar)\\n> > table is restored into test database\\n> >\\n> > Case B --pg_restore operation with \\"--transaction-size\\" against the\\n> dump (taken using pg_dumpall) -\\n> > create a table ( create table t(n int); )\\n> > perform pg_dumpall ( ./pg_dumpall -Ft -f abc.tar)\\n> > create a new cluster, start the server against a different port\\n> > perform pg_restore using switch \\"--transaction-size\\" (./pg_restore -Ft\\n> --transaction-size=10 -d postgres abc.tar -p 9000 -C)\\n> > table is not restored\\n> >\\n> > if i remove --transaction-size switch then this works.\\n> >\\n> > regards,\\n> >\\n>\\n> Fixed.\\n>\\n> On Mon, 12 Jan 2026 at 13:39, tushar <tushar.ahuja@enterprisedb.com>\\n> wrote:\\n> >\\n> >\\n> >\\n> > On Tue, Jan 6, 2026 at 11:56 AM Mahendra Singh Thalor <\\n> mahi6run@gmail.com> wrote:\\n> >>\\n> >>\\n> >> Here, I am attaching an updated patch for the review and testing.\\n> >>\\n> >> Note: some of the review comments are still not fixed. I am working on\\n> >> those and will post an updated patch.\\n> >>\\n> > Hi Mahendra,\\n> > Please refer this scenario - if we are using with \\"--jobs\\" switch then\\n> getting an error at the time of restore\\n> >\\n> > Create a table (  create table t(n int); insert into t values (1);  )\\n> > Perform pg_dumpall ( ./pg_dumpall -Fd -f abc1.dr )\\n> > Create a new cluster, start the server against a different port\\n> > Perform pg_restore using switch \\"--jobs 4 \\" (./pg_restore -j 4 -d\\n> postgres abc1.dr/  -p 9000 -C )\\n> >\\n> > \\"\\n> > [edb@1a1c15437e7c bin]$ ./pg_restore -j 4 -d postgres abc1.dr/  -p 9000\\n> -C\\n> > pg_restore: error: could not execute query: ERROR:  role \\"edb\\" already\\n> exists\\n> > Command was: CREATE ROLE edb;\\n> > ALTER ROLE edb WITH SUPERUSER INHERIT CREATEROLE CREATEDB LOGIN\\n> REPLICATION BYPASSRLS;\\n> >\\n> >\\n> > pg_restore: error: could not execute query: ERROR:  syntax error at or\\n> near \\"\\\\\\"\\n> > LINE 1: \\\\connect template1\\n> >         ^\\n> > Command was: \\\\connect template1\\n> >\\n> >\\n> >\\n> > pg_restore: error: could not execute query: ERROR:  syntax error at or\\n> near \\"\\\\\\"\\n> > LINE 1: \\\\connect postgres\\n> >         ^\\n> > Command was: \\\\connect postgres\\n> >\\n> >\\n> >\\n> > pg_restore: warning: errors ignored on restore: 3\\n> > [edb@1a1c15437e7c bin]$\\n> > \\"\\n> >\\n> > regards,\\n>\\n> Fixed this syntax error but user error is still there for parallel\\n> mode(for non-parallel, fixed). This will be fixed in the next version.\\n>\\n> Here, I am attaching an updated patch for the review and testing.\\n>\\n>\\nThanks Mahendra, a minor  observation -  The pg_restore output shows a\\ndouble slash in the map.dat path (e.g., abc.tar//map.dat).\\nWhile it doesn't break the restore, we may want to clean up the path\\njoining logic.\\n\\n[edb@1a1c15437e7c bin]$ ./pg_restore -Ft -C abc.tar/ -d postgres -p 9011\\n -U  ed -v\\npg_restore: found database \\"template1\\n\\" (OID: 1) in file \\"abc.tar//map.dat\\"\\npg_restore: found database \\"postgres\\n\\" (OID: 5) in file \\"abc.tar//map.dat\\"\\n\\nregards,\\n","threadId":"19be99f7f3572d65","snippet":"On Sat, Jan 17, 2026 at 1:39 AM Mahendra Singh Thalor <mahi6run@gmail.com> wrote: Thanks Tushar for the testing. On Wed, 7 Jan 2026 at 13:53, tushar <tushar.ahuja@enterprisedb.com> wrote:","historyId":"12879","internalDate":"1769151077000","receivedAtUtc":"2026-01-23T06:51:17.000Z","from":"tushar <tushar.ahuja@enterprisedb.com>"},{"id":"19beb12cb27fa5c4","messageId":"<CAC6VRoY-1WC_O5UDwKzNc18LXLwjuTFb+qMNY3gaF3cCov6M6g@mail.gmail.com>","subject":"Re: Non-text mode for pg_dumpall","body":"On Fri, Jan 23, 2026 at 12:21 PM tushar <tushar.ahuja@enterprisedb.com>\\nwrote:\\n\\n>\\n> Thanks Mahendra, a minor  observation -  The pg_restore output shows a\\n> double slash in the map.dat path (e.g., abc.tar//map.dat).\\n> While it doesn't break the restore, we may want to clean up the path\\n> joining logic.\\n>\\n> [edb@1a1c15437e7c bin]$ ./pg_restore -Ft -C abc.tar/ -d postgres -p 9011\\n>  -U  ed -v\\n> pg_restore: found database \\"template1\\n> \\" (OID: 1) in file \\"abc.tar//map.dat\\"\\n> pg_restore: found database \\"postgres\\n> \\" (OID: 5) in file \\"abc.tar//map.dat\\"\\n>\\n>\\n>\\nPlease refer to this scenario where - Objects  created under template1 and\\nthe postgres database by a specific user are failing during a cross-cluster\\nrestore.\\nWhen restoring to a new cluster as a different superuser, pg_restore throws\\nthe error: ERROR: role \\"edb\\" does not exist.\\nIt appears the restore is attempting to preserve the original ownership of\\ntemplate1 objects even when the target environment lacks those specific\\nroles.\\n\\n*Steps to reproduce:*\\ninitdb ( ./initdb -U edb -D data) , start the server , connect to postgres\\nand  template1 database one by one and  create\\nthis table ( create table test(n int); )\\nperform pg_dumpall operation ( ./pg_dumpall -Ft -f abc.tar)\\ninitdb (./initdb -U xyz) , start the server , create a database ( create\\ndatabase abc;)\\nperform pg_restore operation ( ./pg_restore -Ft -C abc.tar/ -d postgres -p\\n9033 -U xyz)\\n--getting an error,  table 'test' will be created on 'template1' database\\nbut failed to create on an another database ( in this case - 'abc' database)\\n\\nregards,\\n","threadId":"19be99f7f3572d65","snippet":"On Fri, Jan 23, 2026 at 12:21 PM tushar <tushar.ahuja@enterprisedb.com> wrote: Thanks Mahendra, a minor observation - The pg_restore output shows a double slash in the map.dat path (eg, abc.tar//","historyId":"12879","internalDate":"1769175407000","receivedAtUtc":"2026-01-23T13:36:47.000Z","from":"tushar <tushar.ahuja@enterprisedb.com>"}]	Tushar is testing Mahendra's patch for adding non-text format support to pg_dumpall and reporting several issues. Key problems include: tables not being restored when using --transaction-size switch with pg_restore, syntax errors with \\\\connect commands when using --jobs parallel mode, and cross-cluster restore failures when role ownership differs between source and target clusters. Mahendra has fixed some issues including the transaction-size problem and syntax errors, but parallel mode user errors and role ownership issues remain unresolved. Minor cosmetic issues like double slashes in file paths (abc.tar//map.dat) have also been identified. The discussion focuses on making pg_dumpall's non-text output behavior identical to plain text dumps while addressing restore compatibility problems.\n该讨论涉及Tushar测试Mahendra为pg_dumpall添加非文本格式支持的补丁并报告了几个问题。主要问题包括：使用--transaction-size选项进行pg_restore时表无法恢复，使用--jobs并行模式时\\\\connect命令出现语法错误，以及当源集群和目标集群之间角色所有权不同时跨集群恢复失败。Mahendra已修复了一些问题，包括transaction-size问题和语法错误，但并行模式用户错误和角色所有权问题仍未解决。还发现了文件路径中双斜杠（abc.tar//map.dat）等小的外观问题。讨论重点是让pg_dumpall的非文本输出行为与纯文本转储相同，同时解决恢复兼容性问题。	2026-01-23 13:36:47+00	\N
14	19beb15ac21a714b	Optimize IS DISTINCT FROM with non-nullable inputs	["guofenglinux@gmail.com"]	[{"id":"19beb15ac21a714b","messageId":"<CAMbWs49BMAOWvkdSHxpUDnniqJcEcGq3_8dd_5wTR4xrQY8urA@mail.gmail.com>","subject":"Optimize IS DISTINCT FROM with non-nullable inputs","body":"Unlike ordinary comparison operators, the IS [NOT] DISTINCT FROM\\npredicate treats NULL as a normal data value rather than \\"unknown\\".\\nFor non-null inputs, its semantics are identical to standard\\noperators: IS DISTINCT FROM is equivalent to <>, and IS NOT DISTINCT\\nFROM is equivalent to =.\\n\\nCurrently, the planner simplifies DistinctExpr only if all inputs are\\nconstants.  I'm thinking that maybe we can optimize cases where inputs\\nare non-constant but proven to be non-nullable, by converting \\"x IS\\nDISTINCT FROM y\\" to \\"x <> y\\".  This representation exposes the\\ncomparison to the planner as a standard operator.  If the clause is\\nnegated (e.g. IS NOT DISTINCT FROM), the resulting \\"=\\" operator can\\nallow the planner to use index scans, merge joins, hash joins, and\\nEC-based qual deductions.\\n\\nAttached is a draft patch for this optimization.\\n\\nI'm kind of concerned about whether there are edge cases where this\\ntransformation is not safe, specifically regarding \\"rowtype\\" inputs.\\nAny feedback would be appreciated.\\n\\n- Richard\\n","threadId":"19beb15ac21a714b","snippet":"Unlike ordinary comparison operators, the IS [NOT] DISTINCT FROM predicate treats NULL as a normal data value rather than \\"unknown\\". For non-null inputs, its semantics are identical to","historyId":"12894","internalDate":"1769175601000","receivedAtUtc":"2026-01-23T13:40:01.000Z","from":"Richard Guo <guofenglinux@gmail.com>"}]	Richard Guo proposes optimizing PostgreSQL's IS DISTINCT FROM predicate when inputs are proven non-nullable. Currently, the planner only simplifies DistinctExpr with constant inputs. The proposed optimization would convert "x IS DISTINCT FROM y" to "x <> y" and "x IS NOT DISTINCT FROM y" to "x = y" when inputs are non-nullable, since the semantics are identical for non-null values. This transformation would expose comparisons as standard operators, enabling the planner to use index scans, merge joins, hash joins, and equivalence class-based optimizations. A draft patch is provided, but concerns remain about potential edge cases with rowtype inputs that might make the transformation unsafe.\n\nRichard Guo提议优化PostgreSQL的IS DISTINCT FROM谓词，当输入被证明为非空时。目前，规划器仅在所有输入都是常量时才简化DistinctExpr。提议的优化将在输入非空时将"x IS DISTINCT FROM y"转换为"x <> y"，将"x IS NOT DISTINCT FROM y"转换为"x = y"，因为对于非空值语义相同。此转换将比较暴露为标准操作符，使规划器能够使用索引扫描、合并连接、哈希连接和等价类优化。已提供草案补丁，但对于可能使转换不安全的rowtype输入边缘情况仍有担忧。	2026-01-23 13:40:01+00	\N
14	19be4e79751331f7	Use correct collation in pg_trgm	["geidav.pg@gmail.com","hlinnaka@iki.fi","reshkekirill@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19beb684a47b67d5","messageId":"<1981b5f0-7d06-4911-a231-23bbb6bf504c@gmail.com>","subject":"Re: Use correct collation in pg_trgm","body":"Hi!\\n\\nThanks for reviewing.\\n\\nOn 22.01.2026 07:32, Zsolt Parragi wrote:\\n> Hello!\\n> \\n> The patch is simple and it does what it says it does, I verified the\\n> difference in behavior with/without it.\\n\\nWhile reading through [1] I realized that the word boundary detection\\nalso uses the wrong collation. Patch 0002 fixes that.\\n\\n> I think the test case included in the email should be part of the\\n> patch, maybe as a new file contrib/pg_trgm/sql/pg_trgm_collation.sql?\\n> It also needs a proper commit message, and seems like the affected\\n> indexes will need a REINDEX after this fix.\\n\\n- I've added tests to 0001 and 0002 based on what each commit fixes.\\n- I've improved the commit messages.\\n\\nLooking at [2], it seems like we don't include release note changes in\\nbug fix commits but rather collect them retroactively before cutting the\\nrelease.\\n\\n[1]\\nhttps://www.postgresql.org/message-id/f30299bf-ad8e-4125-bf80-e0a8663991b6%40eisentraut.org\\n\\n[2]\\nhttps://git.postgresql.org/gitweb/?p=postgresql.git;a=commitdiff;h=fb1a18810f0\\n\\n--\\nDavid Geier","threadId":"19be4e79751331f7","snippet":"Hi! Thanks for reviewing. On 22.01.2026 07:32, Zsolt Parragi wrote: > Hello! > > The patch is simple and it does what it says it does, I verified the > difference in behavior with/without","historyId":"12862","internalDate":"1769181022000","receivedAtUtc":"2026-01-23T15:10:22.000Z","from":"David Geier <geidav.pg@gmail.com>"}]	David Geier responds to feedback on his pg_trgm collation fix patch. He acknowledges Zsolt Parragi's review confirming the patch works as intended and addresses the suggestion to include test cases. Geier has added a second patch (0002) to fix word boundary detection which also uses incorrect collation, discovered while reading related discussions. He has enhanced both patches with appropriate test cases and improved commit messages. Geier notes that release notes are typically collected retroactively before releases rather than included in individual bug fix commits. The patches address collation issues in pg_trgm that would require REINDEX after applying the fix.\nDavid Geier回应了对他的pg_trgm排序规则修复补丁的反馈。他确认了Zsolt Parragi的审查意见，证实补丁按预期工作，并处理了包含测试用例的建议。Geier添加了第二个补丁(0002)来修复单词边界检测中同样使用错误排序规则的问题，这是在阅读相关讨论时发现的。他为两个补丁都增强了适当的测试用例并改进了提交消息。Geier指出，发布说明通常在发布前追溯收集，而不是包含在个别错误修复提交中。这些补丁解决了pg_trgm中的排序规则问题，应用修复后需要REINDEX。	2026-01-23 15:10:22+00	\N
14	19beb80a82747bcf	Auto-tune shared_buffers to use available huge pages	["anthonin.bonnefoy@datadoghq.com"]	[{"id":"19beb80a82747bcf","messageId":"<CAO6_Xqq6w5hTY_W+gJWp29t15NRtNLSTzD6khDC=Xy2P0BWPTQ@mail.gmail.com>","subject":"Auto-tune shared_buffers to use available huge pages","body":"Hi,\\n\\nUnder a normal environment, the instance's number of huge pages can be\\nadjusted to the size reported by shared_memory_size_in_huge_pages,\\nthen Postgres can be started and the requested shared memory fit in\\nthe available huge pages.\\n\\nA similar approach is harder to implement with environments like\\nkubernetes. If I want to modify the huge pages on a pod, I need to:\\n- Modify the host's huge pages\\n- Restart the host's kubelet so it detects the new amount of huge pages\\n- Modify the pod's huge page request\\n\\nMost of those steps are far from practical. An alternative would be to\\nhave a fixed number of huge pages (like 25% of the node's memory), and\\nto adjust the configuration, like the amount of shared_buffers.\\nHowever, adjusting the configuration to fit in a fixed amount of\\nmemory is tricky:\\n- shared_buffers is used to auto-tune multiple parameters so there's\\nno easy formula to get the correct amount. The only way I've found is\\nto basically increase shared_buffers until\\nshared_memory_size_in_huge_pages matches the desired amount of huge\\npages\\n- changing other parameters like max_connections mean shared_buffers\\nhas to be adjusted again\\n\\nTo help with that, the attached patch provides a new option,\\nhuge_pages_autotune_buffers, to automatically use leftover huge pages\\nas shared_buffers. This requires some changes in the auto-tune logic:\\n- Subsystems that are using shared_buffers for auto-tuning will rely\\non the configured shared_buffers, not the auto-tuned shared_buffers\\nand they should save the auto-tuned value in a GUC. This will be done\\nin dedicated auto-tune functions.\\n- Once the auto-tune functions are called, modifying NBuffers won't\\nchange the requested memory except for the shared buffer pool in\\nBufferManagerShmemSize\\n- We can get the leftover memory (free huge pages - requested memory),\\nand estimate how much shared_buffers we can add\\n- Increasing shared_buffers will also increase the freelist hashmap,\\nso the auto-tuned shared_buffers needs to be reduced\\n\\nThe patch is split in the following sub-patches:\\n\\n0001: Extract the current auto-tune logic in dedicated functions,\\nmaking the behaviour more consistent across subsystems.\\n\\n0002: The checkpointer auto-tunes the request size using NBuffers, but\\ndoesn't save the result in a GUC. This adds a new\\ncheckpoint_request_size GUC with the same auto-tune logic.\\n\\n0003: Extract HugePages_Free value when /proc/meminfo is parsed in\\nGetHugePageSize.\\n\\n0004: Pass NBuffers as parameters to StrategyShmemSize. This is\\nnecessary to get how much memory will be used by the freelist using\\n'StrategyShmemSize(candidate_nbuffers) - StrategyShmemSize(NBuffers)'.\\n\\n0005: Add BufferManagerAutotune to auto-tune the amount of shared_buffers.\\n\\nRegards,\\nAnthonin Bonnefoy\\n","threadId":"19beb80a82747bcf","snippet":"Hi, Under a normal environment, the instance's number of huge pages can be adjusted to the size reported by shared_memory_size_in_huge_pages, then Postgres can be started and the requested shared","historyId":"12895","internalDate":"1769182611000","receivedAtUtc":"2026-01-23T15:36:51.000Z","from":"Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com>"}]	The proposal introduces a new configuration option `huge_pages_autotune_buffers` to automatically adjust shared_buffers based on available huge pages in containerized environments like Kubernetes. Currently, tuning shared_buffers to fit fixed huge page allocations is complex because it requires iterative adjustments and affects multiple auto-tuned parameters. The patch modifies the auto-tune logic by having subsystems rely on configured rather than auto-tuned shared_buffers values, calculating leftover huge page memory, and estimating optimal shared_buffers size while accounting for the freelist hashmap overhead. The implementation spans five sub-patches covering auto-tune function extraction, checkpoint request size GUC addition, huge page parsing improvements, parameter passing modifications, and the core BufferManagerAutotune functionality.\n\n该提案引入了新的配置选项`huge_pages_autotune_buffers`，用于在Kubernetes等容器化环境中根据可用的大页面自动调整shared_buffers。目前，调整shared_buffers以适应固定的大页面分配非常复杂，因为需要迭代调整并影响多个自动调优参数。该补丁修改了自动调优逻辑，让子系统依赖配置的而非自动调优的shared_buffers值，计算剩余的大页面内存，并估算最优的shared_buffers大小，同时考虑空闲列表哈希映射的开销。实现涵盖五个子补丁，包括自动调优函数提取、检查点请求大小GUC添加、大页面解析改进、参数传递修改以及核心的BufferManagerAutotune功能。	2026-01-23 15:36:51+00	\N
14	19beacbb6938d144	WIP - xmlvalidate implementation from TODO list	["jim.jones@uni-muenster.de","maguetamarcos@gmail.com","reshkekirill@gmail.com","x4mmm@yandex-team.ru"]	[{"id":"19beacbb6938d144","messageId":"<08052569-9384-41b5-bcb7-33929fcc6c71@uni-muenster.de>","subject":"Re: WIP - xmlvalidate implementation from TODO list","body":"\\n\\nOn 21/01/2026 21:44, Marcos Magueta wrote:\\n>> Any particular reason for that? If not, take a look at other options,\\n> e.g. a_expr\\n> No particular reason apart from it being simpler since I didn't need to\\n> invoke an execution at the cmd. Changed it now.\\n> \\n>> Why did you choose text over xml for schemadata?\\n> My original thought was that XML schemas require additional validation\\n> in contrast to normal XML, but it being additive, we would have\\n> redundant checks. But in reconsideration, perhaps keeping the field with\\n> an XML type is more intuitive for anyone introspecting over the catalog.\\n> Also applied the change on the latest version of the patch.\\n\\nData type for schemadata in pg_xmlschema is now xml.\\n\\npostgres=# \\\\d pg_xmlschema\\n               Table \\"pg_catalog.pg_xmlschema\\"\\n     Column      |   Type    | Collation | Nullable | Default\\n-----------------+-----------+-----------+----------+---------\\n oid             | oid       |           | not null |\\n schemaname      | name      |           | not null |\\n schemanamespace | oid       |           | not null |\\n schemaowner     | oid       |           | not null |\\n schemadata      | xml       |           | not null |\\n schemaacl       | aclitem[] |           |          |\\nIndexes:\\n    \\"pg_xmlschema_oid_index\\" PRIMARY KEY, btree (oid)\\n    \\"pg_xmlschema_name_nsp_index\\" UNIQUE CONSTRAINT, btree (schemaname,\\nschemanamespace)\\n\\nI agree it's more intuitive this way. It also facilitates function calls\\nthat require the parameter to be xml, e.g. xmlserialize\\n\\npostgres=# CREATE XMLSCHEMA x AS\\n '<xs:schema xmlns:xs=\\"http://www.w3.org/2001/XMLSchema\\"><xs:element\\nname=\\"duplicate\\" type=\\"xs:string\\"/></xs:schema>';\\nCREATE XMLSCHEMA\\n\\npostgres=# SELECT xmlserialize(DOCUMENT schemadata AS text INDENT) FROM\\npg_xmlschema;\\n                      xmlserialize\\n---------------------------------------------------------\\n <xs:schema xmlns:xs=\\"http://www.w3.org/2001/XMLSchema\\">+\\n   <xs:element name=\\"duplicate\\" type=\\"xs:string\\"/>      +\\n </xs:schema>\\n(1 row)\\n\\n\\n> I noticed DefineXmlSchema() calls IsThereXmlSchemaInNamespace() right\\n> after XmlSchemaCreate() returns a valid OID. Since XmlSchemaCreate()\\n> already inserted the tuple into the catalog (via CatalogTupleInsert at\\n> pg_xmlschema.c:166), wouldn't SearchSysCacheExists2() find it and always\\n> throw \\"already exists\\"? We all tested the original code and it worked\\n> fine, so I'm missing something about syscache visibility or timing; that\\n> was an early function I did to check for duplicates that ended up in the\\n> wrong place. I removed the call (and function) as I judged it to be\\n> redundant (the duplicate check already happens inside\\n> XmlSchemaCreate()), but is there something subtle about intra-command\\n> visibility I'm not understanding? If anyone knows, please let me know.\\n\\nI couldn't find any IsThereXmlSchemaInNamespace call in DefineXmlSchema\\nin the current version, so I cannot say much here. But I agree that the\\na further check is not necessary, since XmlSchemaCreate is already doing it.\\n\\n> Also, I added tab completion on psql and fixed pg_dump.\\n\\nNice. pg_dump now exports CREATE XMLSCHEMA statements.\\n\\nTab completion for CREATE, ALTER, and DROP XMLSCHEMA now also works.\\n\\nA few other comments\\n\\n== patch version ==\\n\\nYou forgot to include the version to the patch name.\\n\\nFor instance, instead of\\n0001-Add-CREATE-ALTER-DROP-XMLSCHEMA-DDL-commands.patch the file could\\nbe named v3-0001-Add-CREATE-ALTER-DROP-XMLSCHEMA-DDL-commands.patch\\n\\n== IS_XMLVALIDATE dependency ==\\n\\nThe patches 0001, 0002, and 0003 depend on IS_XMLVALIDATE, which is only\\nintroduced in 0004, so they cannot be compiled and tested independently.\\n\\n== permissions ==\\n\\nIn the tests I see you added a few GRANTs to set the visibility of\\ncertain xmlschemas:\\n\\nGRANT USAGE ON XMLSCHEMA permission_test_schema TO regress_xmlschema_user2\\n\\nI could not find anything regarding this in the docs. If we are to\\nsupport it, shouldn't we add it to grant.sgml?\\n\\nAs I mentioned upthread, I believe that schema registration and usage\\nshould be privilege-controlled, for example via dedicated roles\\n\\nGRANT pg_read_xmlschemas TO u;\\nGRANT pg_write_xmlschemas TO u;\\n\\nWhat do you think?\\n\\nBut being able to grant or revoke access to a certain xmlschema also has\\nits appeal :)\\n\\nBest, Jim\\n\\n\\n\\n","threadId":"19beacbb6938d144","snippet":"On 21/01/2026 21:44, Marcos Magueta wrote: >> Any particular reason for that? If not, take a look at other options, > eg a_expr > No particular reason apart from it being simpler since I","historyId":"12892","internalDate":"1769170765000","receivedAtUtc":"2026-01-23T12:19:25.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"},{"id":"19beb86bd5471dc7","messageId":"<cfd2c12a-41fb-4a8b-9b14-390e53f4c898@uni-muenster.de>","subject":"Re: WIP - xmlvalidate implementation from TODO list","body":"\\n\\nOn 23/01/2026 13:19, Jim Jones wrote:\\n> On 21/01/2026 21:44, Marcos Magueta wrote:\\n>>> Any particular reason for that? If not, take a look at other options,\\n>> e.g. a_expr\\n>> No particular reason apart from it being simpler since I didn't need to\\n>> invoke an execution at the cmd. Changed it now.\\n\\nOn second thought, is there any scenario where we'll need a_expr for \\"y\\"\\nat all in \\"CREATE XMLSCHEMA x AS y\\"? Isn't it always going to be a\\nstring? I see now that my example in the previous post was somewhat\\nmisleading (sorry for the noise).\\n\\nBest, Jim\\n\\n\\n","threadId":"19beacbb6938d144","snippet":"On 23/01/2026 13:19, Jim Jones wrote: > On 21/01/2026 21:44, Marcos Magueta wrote: >>> Any particular reason for that? If not, take a look at other options, >> eg a_expr >> No","historyId":"12892","internalDate":"1769183020000","receivedAtUtc":"2026-01-23T15:43:40.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"}]	Jim Jones is reviewing Marcos Magueta's XML schema validation implementation patch. Key changes discussed include switching the schemadata column in pg_xmlschema from text to xml type, which Jones agrees makes the system more intuitive and facilitates functions like xmlserialize. Jones notes that a redundant duplicate check function (IsThereXmlSchemaInNamespace) was properly removed from DefineXmlSchema since XmlSchemaCreate already handles this validation. The patch now includes tab completion for psql and pg_dump support for CREATE XMLSCHEMA statements. Outstanding issues include missing patch versioning, compilation dependencies between patches due to IS_XMLVALIDATE requirements, and incomplete documentation for GRANT USAGE permissions on XML schemas. Jones questions whether dedicated roles (pg_read_xmlschemas, pg_write_xmlschemas) might be preferable for privilege control. A follow-up clarification asks whether a_expr is actually needed in CREATE XMLSCHEMA syntax since the schema data appears to always be a string literal.\nJim Jones正在审查Marcos Magueta的XML模式验证实现补丁。讨论的关键变更包括将pg_xmlschema中的schemadata列从text类型改为xml类型，Jones同意这使系统更直观并便于xmlserialize等函数使用。Jones指出冗余的重复检查函数(IsThereXmlSchemaInNamespace)已从DefineXmlSchema中正确移除，因为XmlSchemaCreate已处理此验证。补丁现在包含psql的制表符补全和pg_dump对CREATE XMLSCHEMA语句的支持。待解决问题包括缺少补丁版本控制、由于IS_XMLVALIDATE要求导致补丁间编译依赖，以及XML模式GRANT USAGE权限的文档不完整。Jones质疑专用角色(pg_read_xmlschemas, pg_write_xmlschemas)是否更适合权限控制。后续澄清询问CREATE XMLSCHEMA语法中是否真正需要a_expr，因为模式数据似乎总是字符串字面量。	2026-01-23 15:43:40+00	\N
14	19beb9adc5e1e332	display hot standby state in psql prompt	["andreas@proxel.se","htamfids@gmail.com","jim.jones@uni-muenster.de","li.evan.chao@gmail.com","masao.fujii@gmail.com","nathandbossart@gmail.com","srinath2133@gmail.com"]	[{"id":"19beb9adc5e1e332","messageId":"<d81c08f6-1a4f-48ee-b1ff-e78b145c9e12@uni-muenster.de>","subject":"Re: display hot standby state in psql prompt","body":"Hi Fujii\\n\\nOn 12/11/2025 04:48, Fujii Masao wrote:\\n> I'm fine with the initial proposal. I think showing whether the connected\\n> server is a primary or standby in the prompt would be helpful when managing\\n> multiple servers. OTOH, I'm not sure how useful it would be to display\\n> whether the current transaction is read-only.\\n> \\n> That said, this is just my view, so I'd like to hear what others think.\\n\\nSince we haven't heard any objections from the other reviewers, do you\\nthink we should switch back to the initial \\"primary\\" or \\"standby\\" proposal?\\n\\nBest, Jim\\n\\n\\n","threadId":"19beb9adc5e1e332","snippet":"Hi Fujii On 12/11/2025 04:48, Fujii Masao wrote: > I'm fine with the initial proposal. I think showing whether the connected > server is a primary or standby in the prompt would be helpful","historyId":"12896","internalDate":"1769184341000","receivedAtUtc":"2026-01-23T16:05:41.000Z","from":"Jim Jones <jim.jones@uni-muenster.de>"}]	Jim Jones proposes reverting to the original suggestion of displaying "primary" or "standby" server status in the psql prompt, following Fujii Masao's preference for this approach over showing read-only transaction state. Fujii had expressed support for indicating server role in the prompt as helpful for managing multiple PostgreSQL servers, while questioning the utility of displaying transaction read-only status. With no objections from other reviewers, Jim seeks consensus on switching back to the primary/standby indicator implementation. The discussion appears ready to move forward with the simplified server role display feature.\nJim Jones 提议回到最初建议，在 psql 提示符中显示"主"或"备"服务器状态，这是基于 Fujii Masao 偏好此方法而非显示只读事务状态。Fujii 曾表示支持在提示符中显示服务器角色，认为这对管理多个 PostgreSQL 服务器有帮助，但质疑显示事务只读状态的实用性。由于其他审阅者没有反对意见，Jim 寻求就切换回主/备指示器实现达成共识。讨论似乎准备推进这个简化的服务器角色显示功能。	2026-01-23 16:05:41+00	\N
14	19be67781ef21b94	AIX support	["peter@eisentraut.org","sriram.rk@in.ibm.com"]	[{"id":"19beba0a8a39c464","messageId":"<SJ4PPFB81778326EC35CBFA16B5449CFA97DB94A@SJ4PPFB81778326.namprd15.prod.outlook.com>","subject":"RE: AIX support","body":"Hi Peter,\\n\\n> It's ok to split changes into multiple patches, and then recommend which parts you want\\n> reviewed first.  But we need to see at least a rough outline of the\\n> complete plan before spending significant effort on reviewing the pieces.\\nPlease find attached patches.\\n    Meson changes    - 0001-Support-for-AIX-pg19-meson.2.diff\\n    Complete changes - 0001-Support-for-AIX.pg19.v11.patch\\n\\nWe have updated couple of changes in the full patch wrt to your previous\\ncomments as well. Also, we are working to get the stats for the s_lock.h wrt\\nTAS. Will submit in a different thread.\\n\\nKindly request you to review the meson related changes.\\n\\n\\nWarm regards,\\n\\nSriram.\\n\\n\\n\\n\\n\\n\\n","threadId":"19be67781ef21b94","snippet":"Hi Peter, > It's ok to split changes into multiple patches, and then recommend which parts you want > reviewed first. But we need to see at least a rough outline of the > complete plan","historyId":"12868","internalDate":"1769184685000","receivedAtUtc":"2026-01-23T16:11:25.000Z","from":"Srirama Kucherlapati <sriram.rk@in.ibm.com>"}]	Sriram has submitted updated patches for AIX support in PostgreSQL, following Peter's request for a complete plan before detailed review. The submission includes two patches: Meson build system changes (0001-Support-for-AIX-pg19-meson.2.diff) and complete AIX support changes (0001-Support-for-AIX.pg19.v11.patch). The patches incorporate fixes based on Peter's previous comments. Sriram specifically requests review of the Meson-related changes and mentions that statistics for s_lock.h regarding TAS (Test-and-Set) operations will be submitted separately in a different thread. This represents progress on enabling PostgreSQL compilation and functionality on IBM's AIX operating system.\n\nSriram已提交了PostgreSQL AIX支持的更新补丁，这是根据Peter要求在详细审查前提供完整计划而提交的。提交包括两个补丁：Meson构建系统更改（0001-Support-for-AIX-pg19-meson.2.diff）和完整的AIX支持更改（0001-Support-for-AIX.pg19.v11.patch）。补丁根据Peter之前的评论进行了修复。Sriram特别请求审查与Meson相关的更改，并提到关于TAS（测试并设置）操作的s_lock.h统计数据将在不同的线程中单独提交。这代表了在IBM AIX操作系统上启用PostgreSQL编译和功能的进展。	2026-01-23 16:11:25+00	\N
14	19be86e8f63a302d	More speedups for tuple deformation	["andres@anarazel.de","dgrowleyml@gmail.com","li.evan.chao@gmail.com"]	[{"id":"19be86e8f63a302d","messageId":"<pmik622adey6fnddivkt4uvkulvnc6rasmq3tcbrzeglx4hsn7@f3x6e2eph3w5>","subject":"Re: More speedups for tuple deformation","body":"Hi,\\n\\nI haven't yet looked at the new version of the patch, but I ran your benchmark\\nfrom upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results\\nseem stable enough anyway) on two intel machines, as you mentioned that you\\nsaw a lot variation in Azure.\\n\\nFor both I disabled turbo boost, cpu idling and pinned the backend to a single\\nCPU core.\\n\\nThere's a bit of noise on \\"awork3\\" (basically an editor and an idle browser\\nwindow), but everything is pinned to the other socket. \\"awork4\\" is entirely\\nidle.\\n\\n\\nLooks like overall the results are quite impressive!  Some of the extra_cols=0\\nruns saphire rapids are a bit slower, but the losses are much smaller than the\\ngains in other cases.\\n\\n\\nI think it'd be good to add a few test cases of \\"incremental deforming\\" to the\\nbenchmark. E.g. a qual that accesses column 10, but projection then deforms up\\nto 20.  I'm a bit worried that e.g. the repeated first_null_attr()\\ncomputations could cause regressions.\\n\\n\\nGreetings,\\n\\nAndres Freund\\n","threadId":"19be86e8f63a302d","snippet":"Hi, I haven't yet looked at the new version of the patch, but I ran your benchmark from upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results seem stable enough anyway) on two","historyId":"8740","internalDate":"1769131101000","receivedAtUtc":"2026-01-23T01:18:21.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19be954d8c090dc0","messageId":"<82AD055C-3280-4DFB-ADA8-A7A4DE3844A5@gmail.com>","subject":"Re: More speedups for tuple deformation","body":"\\n\\n> On Jan 23, 2026, at 09:18, Andres Freund <andres@anarazel.de> wrote:\\n> \\n> Hi,\\n> \\n> I haven't yet looked at the new version of the patch, but I ran your benchmark\\n> from upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results\\n> seem stable enough anyway) on two intel machines, as you mentioned that you\\n> saw a lot variation in Azure.\\n> \\n> For both I disabled turbo boost, cpu idling and pinned the backend to a single\\n> CPU core.\\n> \\n> There's a bit of noise on \\"awork3\\" (basically an editor and an idle browser\\n> window), but everything is pinned to the other socket. \\"awork4\\" is entirely\\n> idle.\\n> \\n> \\n> Looks like overall the results are quite impressive!  Some of the extra_cols=0\\n> runs saphire rapids are a bit slower, but the losses are much smaller than the\\n> gains in other cases.\\n> \\n> \\n> I think it'd be good to add a few test cases of \\"incremental deforming\\" to the\\n> benchmark. E.g. a qual that accesses column 10, but projection then deforms up\\n> to 20.  I'm a bit worried that e.g. the repeated first_null_attr()\\n> computations could cause regressions.\\n> \\n> \\n> Greetings,\\n> \\n> Andres Freund\\n> <deform_bench.csv>\\n\\nToday I ran the benchmark on my MacBook M4 against 3 versions (all without assert and with -O2):\\n\\n1) Master (f9a468c664a)\\n2) Master + v4\\n3) Master + v4 + My tweak (first_null_attr immediately returns 0 when natts == 0)\\n\\nOverall, v4 shows significant improvements across most configuration combinations. In the best case, v4 is about 43% faster than master.\\n\\nThe tweak version is only slightly faster than v4. In the best case, the tweak achieves an additional ~3.5% improvement over v4.\\n\\nNote that the MacBook is my working laptop. I didn't actively work on it while the tests were running, but it was still not fully idle, as some other applications (Email, VScode, etc.) were running in the background. That said, I suppose this is still fair for the three rounds of test runs.\\n\\nSee the attached Excel sheet for details.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n","threadId":"19be86e8f63a302d","snippet":"> On Jan 23, 2026, at 09:18, Andres Freund <andres@anarazel.de> wrote: > > Hi, > > I haven't yet looked at the new version of the patch, but I ran your benchmark > from","historyId":"12874","internalDate":"1769146162000","receivedAtUtc":"2026-01-23T05:29:22.000Z","from":"Chao Li <li.evan.chao@gmail.com>"},{"id":"19bebb44f89e0b11","messageId":"<rvlc7pb6zn4kydqovcqh72lf2qfcgs3qkj2seq7tcpvxyqwtqt@nrvv6lpehwwa>","subject":"Re: More speedups for tuple deformation","body":"Hi,\\n\\nOn 2026-01-22 20:18:21 -0500, Andres Freund wrote:\\n> I haven't yet looked at the new version of the patch, but I ran your benchmark\\n> from upthread (fwiw, I removed the sleep 10 to reduce runtimes, the results\\n> seem stable enough anyway) on two intel machines, as you mentioned that you\\n> saw a lot variation in Azure.\\n>\\n> For both I disabled turbo boost, cpu idling and pinned the backend to a single\\n> CPU core.\\n>\\n> There's a bit of noise on \\"awork3\\" (basically an editor and an idle browser\\n> window), but everything is pinned to the other socket. \\"awork4\\" is entirely\\n> idle.\\n>\\n>\\n> Looks like overall the results are quite impressive!  Some of the extra_cols=0\\n> runs saphire rapids are a bit slower, but the losses are much smaller than the\\n> gains in other cases.\\n>\\n>\\n> I think it'd be good to add a few test cases of \\"incremental deforming\\" to the\\n> benchmark. E.g. a qual that accesses column 10, but projection then deforms up\\n> to 20.  I'm a bit worried that e.g. the repeated first_null_attr()\\n> computations could cause regressions.\\n\\nThe overhead of the aggregation etc makes it harder to see efficiency changes\\nin deformation speed:\\n\\nI think it'd be worth replacing the SUM(a) with WHERE a < 0 (filtering all\\nrows), to reduce the cost of the executor dispatch.\\n\\nHere's a profile of the SUM(a):\\n\\n-   99.90%     0.00%  postgres         postgres           [.] standard_ExecutorRun\\n   - standard_ExecutorRun\\n      - 96.83% ExecAgg\\n         - 49.86% ExecInterpExpr\\n            - 28.30% slot_getsomeattrs_int\\n                 tts_buffer_heap_getsomeattrs\\n              0.67% tts_buffer_heap_getsomeattrs\\n            + 0.02% asm_sysvec_apic_timer_interrupt\\n         - 37.44% fetch_input_tuple\\n            - 31.42% ExecSeqScan\\n               + 20.58% heap_getnextslot\\n                 3.58% MemoryContextReset\\n                 0.52% heapgettup_pagemode\\n                 0.32% ExecStoreBufferHeapTuple\\n              0.99% heap_getnextslot\\n              0.79% MemoryContextReset\\n           2.81% int4_sum\\n           1.39% MemoryContextReset\\n\\nWhich takes ~93ms on average for the first generated bench.sql\\n\\n\\n-   99.88%     0.00%  postgres  postgres           [.] standard_ExecutorRun\\n   - standard_ExecutorRun\\n      - 95.78% ExecSeqScanWithQual\\n         - 57.65% ExecInterpExpr\\n            - 29.08% slot_getsomeattrs_int\\n                 tts_buffer_heap_getsomeattrs\\n              0.49% tts_buffer_heap_getsomeattrs\\n         - 25.40% heap_getnextslot\\n            + 15.00% heapgettup_pagemode\\n            + 4.71% ExecStoreBufferHeapTuple\\n              0.05% UnlockBuffer\\n           1.80% MemoryContextReset\\n           0.77% int4lt\\n           0.52% heapgettup_pagemode\\n           0.47% ExecStoreBufferHeapTuple\\n           0.37% slot_getsomeattrs_int\\n        2.11% heap_getnextslot\\n        1.49% ExecInterpExpr\\n        0.50% MemoryContextReset\\n\\nSame data, but with a WHERE a < 0, takes on average ~74m.\\n\\n\\nI wonder if it's worth writing a C helper to test deformation in a bit more\\ntargeted way.\\n\\n\\nLooking at the profile of ExecSeqScanWithQual() made me a bit sad, turns out\\nthat some of the generated code isn't great :(. I'll start a separate thread\\nabout that.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19be86e8f63a302d","snippet":"Hi, On 2026-01-22 20:18:21 -0500, Andres Freund wrote: > I haven't yet looked at the new version of the patch, but I ran your benchmark > from upthread (fwiw, I removed the sleep 10 to reduce","historyId":"12874","internalDate":"1769186006000","receivedAtUtc":"2026-01-23T16:33:26.000Z","from":"Andres Freund <andres@anarazel.de>"}]	Andres Freund tested a tuple deformation speedup patch (v4) on Intel machines with controlled benchmarking conditions, finding impressive overall results despite some minor slowdowns in extra_cols=0 cases on Sapphire Rapids. Chao Li confirmed significant improvements on MacBook M4, showing up to 43% faster performance with v4 compared to master, and an additional 3.5% improvement with a minor tweak optimizing first_null_attr() for natts == 0. Andres suggested adding incremental deforming test cases to the benchmark and recommended using WHERE a < 0 instead of SUM(a) to reduce executor overhead and better isolate deformation performance changes. He also noted concerns about potential regressions from repeated first_null_attr() computations and mentioned plans for a separate discussion about suboptimal generated code in ExecSeqScanWithQual().\n\nAndres Freund在Intel机器上对元组变形加速补丁(v4)进行了受控基准测试，发现总体结果令人印象深刻，尽管在Sapphire Rapids的extra_cols=0情况下有轻微的性能下降。Chao Li在MacBook M4上证实了显著的性能提升，v4相比master版本快了43%，而优化natts == 0时first_null_attr()的小调整又额外提升了3.5%的性能。Andres建议在基准测试中增加增量变形测试用例，并推荐使用WHERE a < 0代替SUM(a)以减少执行器开销，更好地隔离变形性能变化。他还担心重复的first_null_attr()计算可能导致性能退化，并提到计划就ExecSeqScanWithQual()中的次优生成代码单独讨论。	2026-01-23 16:33:26+00	\N
14	19bebbb1bd6c2d07	Proposal: Adding compression of temporary files	["fjanus@redhat.com","lakshmigcdac@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bebbb1bd6c2d07","messageId":"<CAFjYY+LMTciR=3SLh+8EbAFjumQTrcTKbyU703Srzy3j_yEhSw@mail.gmail.com>","subject":"Re: Proposal: Adding compression of temporary files","body":"Hi all,\\nThanks for the feedback and the provided patch.\\nI've addressed your findings and proposals. Lakshmi's documentation patch\\nwas incorporated.\\n\\n    -Filip-\\n\\n\\nst 21. 1. 2026 v 7:30 odesílatel lakshmi <lakshmigcdac@gmail.com> napsal:\\n\\n> HI all,\\n> While testing the temp file compression patch,noticed that the new\\n> temp_file_compression GUC isn't documented yet.I put together a small docs\\n> patch to add a short description and clarify that the effect of compression\\n> depends on the workload(for example ,hash join spills may not show visible\\n> size reduction due to fixed_size chunks).\\n>\\n> patch is attached.Happy to adjust the wording if needed.\\n> thanks,\\n> lakshmi\\n>\\n> On Tue, Jan 20, 2026 at 4:21 PM lakshmi <lakshmigcdac@gmail.com> wrote:\\n>\\n>> Hi Filip,\\n>>\\n>> I tested both patches on current master using git am -3 .They apply\\n>> cleanly,build fine,and the temp_file _compression GUC works as expected.\\n>> Query results are unchanged.\\n>>\\n>> For hash join spill test,temp files were created as expected,but the\\n>> logged size were same for no,lz4,and pglz,which seems consistent with\\n>> fixed-size fileset chunking.It might be helpful to briefly note this in the\\n>> documentation to avoid confusion.\\n>>\\n>> Thanks for working on this .\\n>> best regards,\\n>> lakshmi\\n>>\\n>> On Tue, Jan 20, 2026 at 4:10 AM Zsolt Parragi <zsolt.parragi@percona.com>\\n>> wrote:\\n>>\\n>>> Hello!\\n>>>\\n>>> I tried to review the code. It compiled, the test suite passed.\\n>>>\\n>>> I noticed two typos:\\n>>>\\n>>> buffile.c:77 - \\"Disaled\\"\\n>>> buffile.c:133 - \\"mathods\\"\\n>>>\\n>>> And a few other small findings:\\n>>>\\n>>> buffile.h:35 and buffile.c:63 - same constants defined first as an\\n>>> Enum and then as #defines - code builds properly without the defines.\\n>>>\\n>>> buffile.c:121 - compress_tempfile is defined, set to false at :167,\\n>>> but never used otherwise\\n>>>\\n>>> guc_tables.c:470 - the comment says that pglz isn't supported yet, but\\n>>> we have a value for it, and I see support for it in the code\\n>>>\\n>>> buffile.c:659: (and at other places) if USE_LZ4 is undefined, the\\n>>> codepath doesn't do anything. I think these ifdefs should follow how\\n>>> other compression code works, such as wal compression where there's an\\n>>> #else path with elog(ERROR, ...)\\n>>> Similarly, maybe there should be an explicit TEMP_NONE_COMPRESSION\\n>>> branch that does nothing, and the default branch should be an error?\\n>>>\\n>>> buffile.c:265: If seek isn't supported/limited, shouldn't there be at\\n>>> least an assertion about it in BufFileSeek? And tell isn't mentioned,\\n>>> but it seems to me that tell also doesn't work properly.\\n>>>\\n>>\\n","threadId":"19bebbb1bd6c2d07","snippet":"Hi all, Thanks for the feedback and the provided patch. I've addressed your findings and proposals. Lakshmi's documentation patch was incorporated. -Filip- st 21. 1. 2026 v 7:30 odesílatel","historyId":"12898","internalDate":"1769186432000","receivedAtUtc":"2026-01-23T16:40:32.000Z","from":"Filip Janus <fjanus@redhat.com>"}]	Filip Janus has updated the temporary file compression patch for PostgreSQL, incorporating feedback from reviewers. The patch adds a new temp_file_compression GUC parameter supporting LZ4 and PGLZ compression methods. Lakshmi tested the functionality and provided a documentation patch, noting that hash join spills may not show visible size reduction due to fixed-size chunking. Zsolt Parragi identified several issues during code review: typos in comments, unused variables, inconsistent constant definitions, missing error handling for undefined compression methods, and potential problems with seek/tell operations on compressed files. Filip acknowledged the feedback and incorporated Lakshmi's documentation improvements, but the technical issues raised by Zsolt still need to be addressed in future iterations.\nFilip Janus已更新了PostgreSQL临时文件压缩补丁，采纳了审查者的反馈。该补丁添加了新的temp_file_compression GUC参数，支持LZ4和PGLZ压缩方法。Lakshmi测试了功能并提供了文档补丁，指出由于固定大小的分块，哈希连接溢出可能不会显示明显的大小减少。Zsolt Parragi在代码审查中发现了几个问题：注释中的拼写错误、未使用的变量、不一致的常量定义、未定义压缩方法缺少错误处理，以及压缩文件的seek/tell操作的潜在问题。Filip确认了反馈并采纳了Lakshmi的文档改进，但Zsolt提出的技术问题仍需在后续版本中解决。	2026-01-23 16:40:32+00	\N
14	19be696a3fcf6343	Fix rounding method used to compute huge pages	["anthonin.bonnefoy@datadoghq.com","michael@paquier.xyz","nathandbossart@gmail.com"]	[{"id":"19be9f26259a1fe7","messageId":"<CAO6_Xqp8NVAeNuDgWaMW_+AKHSQTC4nARbJVW23DkXT6KGh81Q@mail.gmail.com>","subject":"Re: Fix rounding method used to compute huge pages","body":"On Thu, Jan 22, 2026 at 10:24 PM Nathan Bossart\\n<nathandbossart@gmail.com> wrote:\\n> Oops, it looks like this is my fault.  I doubt this causes any practical\\n> problems, but we might as well fix it.\\n\\nYeah, the chance of this being a problem is pretty low.\\n\\n> +               if (size_b % hp_size != 0)\\n> +                       size_b = add_size(size_b, hp_size - (size_b % hp_size));\\n> +               hp_required = size_b / hp_size;\\n>\\n> I think we could simplify this a tad:\\n>\\n>         hp_required = size_b / hp_size;\\n>         if (size_b % hp_size != 0)\\n>                 hp_required = add_size(hp_required, 1);\\n\\nFrom my understanding, 'add_size(hp_required, 1)' will never overflow\\nsince size_b was checked for overflow, and hp_size should always be >1\\n(except if huge pages of 1 byte exist somewhere).\\n\\nFor consistency with CreateAnonymousSegment, using 'add_size(size_b,\\nhp_size - (size_b % hp_size))' will also check that the final\\nrequested allocation doesn't overflow.\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"On Thu, Jan 22, 2026 at 10:24 PM Nathan Bossart <nathandbossart@gmail.com> wrote: > Oops, it looks like this is my fault. I doubt this causes any practical > problems, but we might as well","historyId":"12869","internalDate":"1769156513000","receivedAtUtc":"2026-01-23T08:21:53.000Z","from":"Anthonin Bonnefoy <anthonin.bonnefoy@datadoghq.com>"},{"id":"19bebc2c33dc3ee4","messageId":"<aXOmjM69GVTbzhGE@nathan>","subject":"Re: Fix rounding method used to compute huge pages","body":"Committed.\\n\\nOn Fri, Jan 23, 2026 at 09:21:53AM +0100, Anthonin Bonnefoy wrote:\\n> From my understanding, 'add_size(hp_required, 1)' will never overflow\\n> since size_b was checked for overflow, and hp_size should always be >1\\n> (except if huge pages of 1 byte exist somewhere).\\n\\nThat's true, but for this sort of thing, I usually prefer to avoid relying\\non those kinds of assumptions to reason about the correctness of the code.\\nThe overflow check costs little, and IIUC this function is run exactly once\\nfor the lifetime of the server.\\n\\n> For consistency with CreateAnonymousSegment, using 'add_size(size_b,\\n> hp_size - (size_b % hp_size))' will also check that the final\\n> requested allocation doesn't overflow.\\n\\n*shrug*  I don't see a strong reason for consistency here.  AFAICT you'd\\nhave to be trying to allocate something like 18 exabytes on most systems\\nfor there to be a problem, at which point there are probably bigger issues\\nto sort out.\\n\\nThanks for the patch!\\n\\n-- \\nnathan\\n\\n\\n","threadId":"19be696a3fcf6343","snippet":"Committed. On Fri, Jan 23, 2026 at 09:21:53AM +0100, Anthonin Bonnefoy wrote: > From my understanding, 'add_size(hp_required, 1)' will never overflow > since size_b was checked for","historyId":"12869","internalDate":"1769186956000","receivedAtUtc":"2026-01-23T16:49:16.000Z","from":"Nathan Bossart <nathandbossart@gmail.com>"}]	A bug fix for the rounding method used to compute huge pages in PostgreSQL was discussed and committed. Nathan Bossart acknowledged introducing the bug but noted it's unlikely to cause practical problems. Two approaches were debated for fixing the rounding calculation: Anthonin Bonnefoy's original method using `add_size(size_b, hp_size - (size_b % hp_size))` for consistency with CreateAnonymousSegment, and Nathan's simplified version using `add_size(hp_required, 1)`. Nathan ultimately committed the fix, preferring his approach to avoid relying on assumptions about overflow conditions, despite the extremely low probability of issues occurring (requiring allocation of around 18 exabytes). The patch was successfully applied.\n\nNathan Bossart承认引入了PostgreSQL中用于计算大页面的舍入方法错误，但指出这不太可能造成实际问题。讨论了两种修复舍入计算的方法：Anthonin Bonnefoy提出的使用`add_size(size_b, hp_size - (size_b % hp_size))`与CreateAnonymousSegment保持一致的原始方法，以及Nathan简化的使用`add_size(hp_required, 1)`版本。Nathan最终提交了修复，倾向于他的方法以避免依赖溢出条件假设，尽管出现问题的概率极低（需要分配大约18艾字节）。补丁已成功应用。	2026-01-23 16:49:16+00	\N
14	19be5345d4172528	Import Statistics in postgres_fdw before resorting to sampling.	["ashutosh.bapat.oss@gmail.com","corey.huinker@gmail.com","etsuro.fujita@gmail.com","jkatz@postgresql.org","michael@paquier.xyz","nathandbossart@gmail.com"]	[{"id":"19beb8698b1cd06d","messageId":"<CAExHW5u6ue1hMqjAubLAbz_ZQqZRdnwJAQtWUw=b+3NXTzYy-A@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":"On Fri, Jan 23, 2026 at 3:50 AM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 5:16 AM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> wrote:\\n>>\\n>> On Thu, Jan 22, 2026 at 2:21 AM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>> >>\\n>> >> Changes in this release, aside from rebasing:\\n>> >>\\n>> >> - The generic analyze and fdw.h changes are in their own patch (0001) that ignores contrib/postgres_fdw entirely.\\n>> >> - The option for remote_analyze has been moved to its own patch (0003).\\n>> >> - The errors raised are now warnings, to ensure that we can always fall back to row sampling.\\n>> >> - All local attributes with attstatarget > 0 must get matching remote statistics or the import is considered a failure.\\n>> >> - The pg_restore_attribute_stats() call has been turned into a prepared statement, for clarity and some minor parsing savings.\\n>> >> - The calls to pg_restore_relation_stats() are parameterized, but not prepared as this is rarely called more than once.\\n>> >> - postgresStatisticsAreImportable will now disqualify a table if has extended statistics objects, because we can't compute those without a row sample.\\n>> >\\n>>\\n>> Thanks Corey for breaking down these patches. It makes reviewing easier.\\n>>\\n>> analyze_rel() and acquire_inherited_sample_rows() both call\\n>> fdwroutine->AnalyzeForeignTable() but only the first one uses the\\n>> statistics import facility. Is that intentional? Typical use case of\\n>> sharding will create a partitioned table with foreign tables as\\n>> partitions. The partitions will be analyzed by the second function.\\n>> Thus a big use case of postgres_fdw won't be able to use the import\\n>> statistics facility. That seems like a major drawback of this patch.\\n>> Thinking more about it, acquire_inherited_sample_rows() accumulates\\n>> the sample rows from the child tables and extracts statistics from\\n>> those rows and then updates corresponding pg_statistics rows. Doing\\n>> that through import statistics seems a bit tricky since we need to be\\n>> able to combine statistics from multiple relations. Can we do that?\\n>\\n>\\n> We can't synthesize sample rows from imported statistics, no.\\n>\\n>>\\n>> There's an advantage if we can combine stats across multiple relations\\n>> - we don't have to sample children twice when analyzing the parent\\n>> without ONLY. Instead we could produce parent statistics by combining\\n>> statistics across children and the parent. To me this looks like\\n>> altogether a different beast just like partial aggregates.\\n>\\n>\\n> I think this patch is only ever going to get us out of 1 of the 2 samples, which isn't ideal but it is a savings.\\n>\\n\\nI am not suggesting to synthesize sample rows. Calculate the\\nstatistics of the parent table from that of its children.\\n\\n>>\\n>>\\n>> It will be good to fix this drawback. If not, at least we should\\n>> figure out (plan/POC) how to deal with the child tables? We need to at\\n>> least document this drawback - the documentation in the current patch\\n>> reads as if all foreign tables will use this facility when available.\\n>\\n>\\n>  Yes, we will have to note the limitation. I have made that note, as well as the documentation fix attached.\\n\\nThe note just mentions partition table but the limitation applies to\\nany foreign child table.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n","threadId":"19be5345d4172528","snippet":"On Fri, Jan 23, 2026 at 3:50 AM Corey Huinker <corey.huinker@gmail.com> wrote: > > On Thu, Jan 22, 2026 at 5:16 AM Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> wrote: >> >","historyId":"12865","internalDate":"1769182999000","receivedAtUtc":"2026-01-23T15:43:19.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19bebdb17f886a16","messageId":"<CADkLM=f5e+MvnDG_swTiJ=2ha02ksMY7njK7xuK=ktX3-mxUkQ@mail.gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","body":">\\n> >> There's an advantage if we can combine stats across multiple relations\\n> >> - we don't have to sample children twice when analyzing the parent\\n> >> without ONLY. Instead we could produce parent statistics by combining\\n> >> statistics across children and the parent. To me this looks like\\n> >> altogether a different beast just like partial aggregates.\\n> >\\n> >\\n> > I think this patch is only ever going to get us out of 1 of the 2\\n> samples, which isn't ideal but it is a savings.\\n> >\\n>\\n> I am not suggesting to synthesize sample rows. Calculate the\\n> statistics of the parent table from that of its children.\\n>\\n\\nI'm not sure we can actually do that. The functions that compute the\\nstatistics are all based off of row samples, not already computed\\nstatistics. I don't think we can synthesize a rowsample from the imported\\nstatistics, at least not accurately. If I'm misunderstanding what you're\\nsuggesting, please correct me.\\n\\n\\n> The note just mentions partition table but the limitation applies to\\n> any foreign child table.\\n>\\n\\nNoted. Will fix in next revision.\\n","threadId":"19be5345d4172528","snippet":">> There's an advantage if we can combine stats across multiple relations >> - we don't have to sample children twice when analyzing the parent >> without ONLY. Instead we","historyId":"12865","internalDate":"1769188540000","receivedAtUtc":"2026-01-23T17:15:40.000Z","from":"Corey Huinker <corey.huinker@gmail.com>"}]	The discussion focuses on a postgres_fdw patch that enables importing statistics from remote tables before falling back to row sampling. Ashutosh Bapat raises a significant limitation: the statistics import facility only works with analyze_rel() but not acquire_inherited_sample_rows(), which handles partitioned tables with foreign partitions. This means typical sharding use cases cannot benefit from the feature. He suggests calculating parent table statistics by combining children's statistics rather than synthesizing sample rows. Corey Huinker acknowledges that synthesizing sample rows from imported statistics isn't feasible and agrees the patch can only eliminate one of two required samples. The limitation needs proper documentation, as current docs suggest all foreign tables can use this facility. Corey commits to fixing the documentation to clarify that the limitation applies to any foreign child table, not just partitioned tables.\n该讨论集中在postgres_fdw补丁上，该补丁允许在回退到行采样之前从远程表导入统计信息。Ashutosh Bapat提出了一个重要限制：统计信息导入功能只适用于analyze_rel()而不适用于acquire_inherited_sample_rows()，后者处理具有外部分区的分区表。这意味着典型的分片用例无法从该功能中受益。他建议通过组合子表统计信息来计算父表统计信息，而不是合成样本行。Corey Huinker承认从导入的统计信息合成样本行是不可行的，并同意该补丁只能消除两个所需样本中的一个。该限制需要适当的文档说明，因为当前文档暗示所有外部表都可以使用此功能。Corey承诺修复文档，明确该限制适用于任何外部子表，而不仅仅是分区表。	2026-01-23 17:15:40+00	\N
14	19becc3788596085	New year, new commitfest app improvements	["me@jeltef.nl"]	[{"id":"19becc3788596085","messageId":"<CAGECzQSdK5vc-zVkqEFztRvSAc9E=csZdW+Tp5gH0U=oCpyxzg@mail.gmail.com>","subject":"Re: New year, new commitfest app improvements","body":"On Tue, 6 Jan 2026 at 19:46, Jelte Fennema-Nio <me@jeltef.nl> wrote:\\n> There are some big changes lined up for the next release of the\\n> commitfest app. I'm intending to deploy these to prod in on the 20th\\n> of January.\\n\\nA few days delayed. But it's deployed now. Please report any issues\\nyou encounter.\\n\\nThe 1st of Feb will be a special day. That'll be the first time that\\npatches will be auto-moved and emails for unmoved patches will be sent\\nto authors. So please keep an eye out for bugs/problems around that\\ndate too.\\n\\n\\n","threadId":"19becc3788596085","snippet":"On Tue, 6 Jan 2026 at 19:46, Jelte Fennema-Nio <me@jeltef.nl> wrote: > There are some big changes lined up for the next release of the > commitfest app. I'm intending to deploy these to","historyId":"13642","internalDate":"1769203768000","receivedAtUtc":"2026-01-23T21:29:28.000Z","from":"Jelte Fennema-Nio <me@jeltef.nl>"}]	Jelte Fennema-Nio has deployed major improvements to the commitfest app, slightly delayed from the original January 20th target date. The deployment is now live and users are encouraged to report any issues they encounter. A significant milestone is planned for February 1st, which will mark the first time patches are automatically moved and notification emails are sent to authors for unmoved patches. This represents a key automation enhancement to the commitfest workflow. The community is asked to monitor for bugs or problems around the February 1st date when this new automated functionality goes into effect.\n\nJelte Fennema-Nio已部署了commitfest应用的重大改进，比原定的1月20日目标日期略有延迟。部署现已上线，鼓励用户报告遇到的任何问题。2月1日将是一个重要的里程碑，这将是第一次自动移动补丁并向未移动补丁的作者发送通知邮件。这代表了commitfest工作流程的关键自动化增强。要求社区在2月1日左右监控错误或问题，届时这一新的自动化功能将生效。	2026-01-23 21:29:28+00	\N
14	19bebbb73c919f20	Time to add FIDO2 support?	["joel@compiler.org","zsolt.parragi@percona.com"]	[{"id":"19bebbb73c919f20","messageId":"<b55c256c-1e48-4188-8c7a-629a38d7a021@app.fastmail.com>","subject":"Time to add FIDO2 support?","body":"Hi hackers,\\n\\nWould others be interested in adding support for FIDO2 as a new SASL\\nauthentication mechanism?\\n\\nAs a macOS user, FIDO2 has become very convenient since the release of\\nmacOS Tahoe in September 2025, that added built-in support for Secure\\nEnclave-backed SSH keys [1] [2].  The key pair is generated on the\\nSecurity Enclave and the private key cannot be exported, so even if your\\ncomputer is compromised, you can be quite confident that they at least\\ncouldn't steal your private keys.  When logging in, you have to touch\\nthe TouchID for the Security Enclave to sign the challenge. I really\\nlove how this scores very high on both security and convenience.\\n\\nSo, I think it would be nice if authenticating to PostgreSQL via psql\\ncould be made equally secure and convenient, by simply reusing the same\\nOpenSSH hardware-backed FIDO2 SSH keys, copying the key string from\\n~/.ssh/authorized_keys, and register it with your PostgreSQL role.\\n\\nThis would of course also work with hardware keys, such as Yubikey.\\n\\nExample:\\n\\nALTER ROLE joel ADD CREDENTIAL macos 'sk-ecdsa-sha2-nistp256@openssh.com AAAAInNrLWVjZHNhLXNoYTItbmlzdHAyNTZAb3BlbnNzaC5jb20AAAAIbmlzdHAyNTYAAABBBOG0NTN8AqegdlKrGTuddOFt0G4ANYzwkBtjSS0zCWCB1IuJisW41qBQ/JSGWjJp1B7OXD52AwfyB4sbUs1Kqg0AAAAEc3NoOg==';\\n\\nAdd \\"fido2\\" to pg_hba.conf:\\n\\nhostssl    all             all             0.0.0.0/0               fido2\\nhostssl    all             all             ::/0                    fido2\\n\\nYou would need to load the resident keys from the FIDO2 authenticator,\\nonce per bootup:\\n\\n% ssh-add -K\\nEnter PIN for authenticator:\\nResident identity added: ECDSA-SK SHA256:6/FvVcfzjLTt27bieSk5UpsPFYvGGkL5njORDz1JmM8\\n\\nYou would then specify the sk-provider when connecting via psql:\\n\\n% PGSKPROVIDER=/usr/lib/ssh-keychain.dylib psql\\n\\nThe server sends a random challenge, the user is prompted to touch the\\nTouchID, the client's security key then signs it, and the server\\nverifies the signature.\\n\\nI have some experience of FIDO2/WebAuthn in the application layer,\\nand would be willing to try to draft a patch on this, given there is\\nenough interest in this.\\n\\n/Joel\\n\\n[1] https://gist.github.com/arianvp/5f59f1783e3eaf1a2d4cd8e952bb4acf\\n[2] https://lists.mindrot.org/pipermail/openssh-unix-dev/2024-July/041451.html\\n\\n\\n","threadId":"19bebbb73c919f20","snippet":"Hi hackers, Would others be interested in adding support for FIDO2 as a new SASL authentication mechanism? As a macOS user, FIDO2 has become very convenient since the release of macOS Tahoe in","historyId":"12899","internalDate":"1769186457000","receivedAtUtc":"2026-01-23T16:40:57.000Z","from":"Joel Jacobson <joel@compiler.org>"},{"id":"19bebde48c57b2f6","messageId":"<CAN4CZFNCrY-CrKenU1dVto27XFBE43PuFT8A6rkgxQvWLOPRqA@mail.gmail.com>","subject":"Re: Time to add FIDO2 support?","body":"> Would others be interested in adding support for FIDO2 as a new SASL\\n> authentication mechanism?\\n\\nMe definitely, I was also thinking about the same thing. For context,\\nI did implement fido authentication for Percona Server for MySQL.\\n\\nBut as far as I know, SASL only has drafts[1][2] about fido, not accepted RFCs.\\n\\nThis is also related to why I asked about generic (not oauth related)\\nauthentication plugins on the list a few days ago[3], one of the\\nthings I was thinking about was fido/webauthn.\\n\\n> Add \\"fido2\\" to pg_hba.conf:\\n>\\n> hostssl all all 0.0.0.0/0 fido2\\n> hostssl all all ::/0 fido2\\n\\nIt would be really good to implement MFA properly (allowing users to\\nconfigure password + fido requirement for login), but that would also\\nrequire changes in pg_hba processing.\\n\\n[1] : https://www.ietf.org/archive/id/draft-bucksch-sasl-passkey-00.html\\n[2] : https://www.ietf.org/archive/id/draft-ietf-kitten-scram-2fa-05.html\\n[3] : https://www.postgresql.org/message-id/CAN4CZFN%3D5%3DdWvY%3DYAPeF4PVOMtR5U6jMLc2kCSHdO0EhejPp%2BQ%40mail.gmail.com\\n\\n\\n","threadId":"19bebbb73c919f20","snippet":"> Would others be interested in adding support for FIDO2 as a new SASL > authentication mechanism? Me definitely, I was also thinking about the same thing. For context, I did implement fido","historyId":"12899","internalDate":"1769188751000","receivedAtUtc":"2026-01-23T17:19:11.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"}]	Joel Jacobson proposes adding FIDO2 as a new SASL authentication mechanism for PostgreSQL, inspired by macOS Tahoe's built-in support for Secure Enclave-backed SSH keys. The proposal involves reusing OpenSSH hardware-backed FIDO2 SSH keys, registering them with PostgreSQL roles via ALTER ROLE ADD CREDENTIAL, and configuring "fido2" authentication in pg_hba.conf. Users would load resident keys with ssh-add -K and connect using PGSKPROVIDER environment variable. Zsolt Parragi expresses strong interest, noting he implemented FIDO authentication for Percona Server for MySQL. However, he points out that SASL only has draft specifications for FIDO, not accepted RFCs, and suggests proper multi-factor authentication implementation would require changes to pg_hba processing.\nJoel Jacobson提议为PostgreSQL添加FIDO2作为新的SASL认证机制，受macOS Tahoe内置安全区域支持的SSH密钥启发。该提案涉及重用OpenSSH硬件支持的FIDO2 SSH密钥，通过ALTER ROLE ADD CREDENTIAL将其注册到PostgreSQL角色，并在pg_hba.conf中配置"fido2"认证。用户需要使用ssh-add -K加载常驻密钥，并使用PGSKPROVIDER环境变量连接。Zsolt Parragi表达了强烈兴趣，提到他为Percona Server for MySQL实现了FIDO认证。然而，他指出SASL目前只有FIDO的草案规范，没有被接受的RFC，并建议适当的多因素认证实现需要修改pg_hba处理。	2026-01-23 17:19:11+00	\N
14	19bec03ddcb80663	Unstable path in index regress test query	["hukutoc@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19bec03ddcb80663","messageId":"<CAN-LCVOgBms6==prC48io0kw_muQfYerEbiYxNivqRCcLgL0qw@mail.gmail.com>","subject":"Unstable path in index regress test query","body":"Hi hackers!\\n\\nWhile doing some tests I've stumbled upon an unstable behavior of the query\\n\\nexplain\\nSELECT unique1 FROM tenk1\\nWHERE unique1 IN (1,42,7)\\nORDER BY unique1;\\n\\nfrom create_index regress test.\\n\\nThis test could randomly return any of 2 paths (below is sequential run,\\nclean latest master install, without server restart or any other queries\\nin-between):\\n\\npostgres=# explain SELECT unique1 FROM tenk1\\n WHERE unique1 IN (1,42,7)\\n ORDER BY unique1;\\n                                     QUERY PLAN\\n-------------------------------------------------------------------------------------\\n Sort  (cost=310.65..311.02 rows=150 width=4)\\n   Sort Key: unique1\\n   ->  Bitmap Heap Scan on tenk1  (cost=14.02..305.23 rows=150 width=4)\\n         Recheck Cond: (unique1 = ANY ('{1,42,7}'::integer[]))\\n         ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..13.98 rows=150\\nwidth=0)\\n               Index Cond: (unique1 = ANY ('{1,42,7}'::integer[]))\\n(6 rows)\\n\\npostgres=# explain SELECT unique1 FROM tenk1\\n WHERE unique1 IN (1,42,7)\\n ORDER BY unique1;\\n                                   QUERY PLAN\\n---------------------------------------------------------------------------------\\n Index Only Scan using tenk1_unique1 on tenk1  (cost=0.29..12.91 rows=3\\nwidth=4)\\n   Index Cond: (unique1 = ANY ('{1,42,7}'::integer[]))\\n(2 rows)\\n\\nThe strange thing is that paths are returned quite randomly, but the first\\nmore often than the second.\\nIs it a bug? Or some feature?\\n\\nYou could check the full log in attach.\\n\\nThanks!\\n\\n--\\nRegards,\\nNikita Malakhov\\nPostgres Professional\\nThe Russian Postgres Company\\nhttps://postgrespro.ru/\\n","threadId":"19bec03ddcb80663","snippet":"Hi hackers! While doing some tests I've stumbled upon an unstable behavior of the query explain SELECT unique1 FROM tenk1 WHERE unique1 IN (1,42,7) ORDER BY unique1; from create_index regress test.","historyId":"12901","internalDate":"1769191211000","receivedAtUtc":"2026-01-23T18:00:11.000Z","from":"Nikita Malakhov <hukutoc@gmail.com>"},{"id":"19bec0de1578734b","messageId":"<3123188.1769191879@sss.pgh.pa.us>","subject":"Re: Unstable path in index regress test query","body":"Nikita Malakhov <hukutoc@gmail.com> writes:\\n> While doing some tests I've stumbled upon an unstable behavior of the query\\n\\n> explain\\n> SELECT unique1 FROM tenk1\\n> WHERE unique1 IN (1,42,7)\\n> ORDER BY unique1;\\n\\n> from create_index regress test.\\n\\nI wouldn't call what you're showing here an instability.\\nYou create and populate the table, but your test script\\nisn't giving autovacuum any time to catch up, so the\\nfirst EXPLAIN is based on default behaviors without stats.\\nThen when you do an ANALYZE, the plan changes because the\\nrowcount estimates change.\\n\\nYou probably should make that a VACUUM ANALYZE, actually,\\nto ensure that the whole table is marked all-visible.\\nThat can affect the estimated cost of an index-only scan too.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bec03ddcb80663","snippet":"Nikita Malakhov <hukutoc@gmail.com> writes: > While doing some tests I've stumbled upon an unstable behavior of the query > explain > SELECT unique1 FROM tenk1 > WHERE unique1 IN","historyId":"12901","internalDate":"1769191879000","receivedAtUtc":"2026-01-23T18:11:19.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bec13d2f23211e","messageId":"<CAN-LCVNt552i1=F7Z8OW1VCYa3NSpymQXXfAKcucHFrkJ_N66g@mail.gmail.com>","subject":"Re: Unstable path in index regress test query","body":"Hi,\\n\\nYes, the VACUUM ANALYZE does it, I forgot that the vacuum\\ncould affect estimations.\\nTom, thank you for the clarification!\\n\\n-- \\nRegards,\\nNikita Malakhov\\nPostgres Professional\\nThe Russian Postgres Company\\nhttps://postgrespro.ru/\\n","threadId":"19bec03ddcb80663","snippet":"Hi, Yes, the VACUUM ANALYZE does it, I forgot that the vacuum could affect estimations. Tom, thank you for the clarification! -- Regards, Nikita Malakhov Postgres Professional The Russian Postgres","historyId":"12901","internalDate":"1769192258000","receivedAtUtc":"2026-01-23T18:17:38.000Z","from":"Nikita Malakhov <hukutoc@gmail.com>"}]	Nikita Malakhov reported unstable query execution plans for a SELECT query from the create_index regress test. The same query would randomly return either a Bitmap Heap Scan with Sort or an Index Only Scan plan when executed multiple times. Tom Lane explained that this behavior is not a bug but expected behavior due to timing issues with autovacuum and table statistics. The first execution uses default statistics without autovacuum having processed the table, while subsequent executions may have updated statistics. Lane recommended using VACUUM ANALYZE instead of just ANALYZE to ensure the table is marked all-visible, which affects index-only scan cost estimates. Malakhov confirmed the solution works and thanked Lane for the clarification.\n\nNikita Malakhov 报告了 create_index 回归测试中一个 SELECT 查询执行计划不稳定的问题。同一查询多次执行时会随机返回位图堆扫描加排序或仅索引扫描两种不同的执行计划。Tom Lane 解释说这种行为不是错误，而是由于自动清理和表统计信息的时序问题导致的预期行为。第一次执行使用默认统计信息，此时自动清理尚未处理表，而后续执行可能已更新统计信息。Lane 建议使用 VACUUM ANALYZE 而不是仅使用 ANALYZE，以确保表被标记为全可见，这会影响仅索引扫描的成本估算。Malakhov 确认解决方案有效并感谢 Lane 的澄清。	2026-01-23 18:17:38+00	\N
14	19becac12ff1c79d	Don't synchronously wait for already-in-progress IO in read stream	["andres@anarazel.de","melanieplageman@gmail.com","pg@bowt.ie","thomas.munro@gmail.com","tv@fuzzy.cz"]	[{"id":"19becac12ff1c79d","messageId":"<CAAKRu_atdnPCCy=kfxqWT62Ckaiz3G5t=S97tW24CuL3i3fFfQ@mail.gmail.com>","subject":"Re: Don't synchronously wait for already-in-progress IO in read stream","body":"On Sun, Nov 9, 2025 at 5:21 PM Thomas Munro <thomas.munro@gmail.com> wrote:\\n>\\n> I suppose (or perhaps vaguely recall from an off-list discussion?)\\n> that you must have considered merging the new\\n> is-it-already-in-progress check into ReadBuffersCanStartIO().  I\\n> suppose the nowait argument would become a tri-state argument with a\\n> value that means \\"don't wait for an in-progress read, just give me the\\n> IO handle so I can 'join' it as a foreign waiter\\", with a new output\\n> argument to receive the handle, or something along those lines, and I\\n> guess you'd need a tri-state result, and perhaps s/Can/Try/ in the\\n> name.  That'd remove the double-check (extra header lock-unlock cycle)\\n> and associated race that can cause that rare synchronous wait (which\\n> must still happen sometimes in the duelling concurrent scan use\\n> case?), at the slight extra cost of having to allocate and free a\\n> handle in the case of repeated blocks (eg the index->heap scan use\\n> case), but at least that's just backend-local list pushups and doesn't\\n> do extra work otherwise.  Is there some logical problem with that\\n> approach?  Is the code just too clumsy?\\n\\nAttached v3 basically does what you suggested above. Now, we should\\nonly have to wait if the backend encounters a buffer after another\\nbackend has set BM_IO_IN_PROGRESS but before that other backend has\\nset the buffer descriptor's wait reference.\\n\\n0001 and 0002 are Andres' test-related patches. 0003 is a change I\\nthink is required to make one of the tests stable (esp on the BSDs).\\n0004 is a bit of preliminary refactoring and 0005 is Andres' foreign\\nIO concept but with your suggested structure and my suggested styling.\\nI could potentially break out more into smaller refactoring commits,\\nbut I don't think it's too bad the way it is.\\n\\nA few things about the patch that I'm not sure about:\\n\\n- I don't know if pgaio_submit_staged() is in all the right places\\n(and not in too many places). I basically do it before we would wait\\nwhen starting read IO on the buffer. In the permanent buffers case,\\nthat's now only when BM_IO_IN_PROGRESS is set but the wait reference\\nisn't valid yet. This can't happen in the temporary buffers case, so\\nI'm not sure we need to call pgaio_submit_staged().\\n\\n- StartBufferIO() is no longer invoked in the AsyncReadBuffers() path.\\nWe could refactor it so that it works for AsyncReadBuffers(), but that\\nwould involve returning something that distinguishes between\\nIO_IN_PROGRESS and IO already done.  And StartBufferIO()'s comment\\nexplicitly says it wants to avoid that.\\nIf we keep my structure, with AsyncReadBuffers() using its own helper\\n(PrepareNewReadBufferIO()) instead of StartBufferIO(), then it seems\\nlike we need some way to make it clear what StartBufferIO() is for.\\nI'm not sure what would collectively describe its current users,\\nthough. It also now has no non-test callers passing nowait as true.\\nHowever, once we add write combining, it will, so it seems like we\\nshould leave it the way it is to avoid churn. However, other\\ndevelopers might be confused in the interim.\\n\\n- In the 004_read_stream tests, I wonder if there is a way to test\\nthat we don't wait for foreign IO until WaitReadBuffers(). We have\\ntests for the stream accessing the same block, which in some cases\\nwill exercise the foreign IO path. But it doesn't distinguish between\\nthe old behavior -- waiting for the IO to complete when starting read\\nIO on it -- and the new behavior -- not waiting until\\nWaitReadBuffers(). That may not be possible to test, though.\\n\\n- Melanie\\n","threadId":"19becac12ff1c79d","snippet":"On Sun, Nov 9, 2025 at 5:21 PM Thomas Munro <thomas.munro@gmail.com> wrote: > > I suppose (or perhaps vaguely recall from an off-list discussion?) > that you must have considered merging","historyId":"13638","internalDate":"1769202233000","receivedAtUtc":"2026-01-23T21:03:53.000Z","from":"Melanie Plageman <melanieplageman@gmail.com>"}]	Melanie Plageman has implemented v3 of the patch following Thomas Munro's suggestion to merge the in-progress check into ReadBuffersCanStartIO(). The new approach should only require waiting when a backend encounters a buffer after another backend sets BM_IO_IN_PROGRESS but before setting the buffer descriptor's wait reference. The patch includes Andres' test-related changes, preliminary refactoring, and the foreign IO concept with suggested structure improvements. Several uncertainties remain: proper placement of pgaio_submit_staged() calls, whether StartBufferIO() should work with AsyncReadBuffers() (currently using separate PrepareNewReadBufferIO() helper), and testing methodology to verify the new behavior doesn't wait for foreign IO until WaitReadBuffers(). The implementation aims to eliminate synchronous waits for already-in-progress IO operations while maintaining code clarity and avoiding unnecessary overhead.\nMelanie Plageman 已实现了 v3 补丁，采用了 Thomas Munro 建议的将进行中检查合并到 ReadBuffersCanStartIO() 的方法。新方法应该只在后端遇到缓冲区时需要等待，即当另一个后端设置了 BM_IO_IN_PROGRESS 但尚未设置缓冲区描述符的等待引用时。补丁包含 Andres 的测试相关更改、初步重构和带有建议结构改进的外部 IO 概念。仍存在几个不确定性：pgaio_submit_staged() 调用的正确位置、StartBufferIO() 是否应与 AsyncReadBuffers() 协作（目前使用单独的 PrepareNewReadBufferIO() 辅助函数），以及验证新行为在 WaitReadBuffers() 之前不等待外部 IO 的测试方法。该实现旨在消除对已进行中 IO 操作的同步等待，同时保持代码清晰并避免不必要的开销。	2026-01-23 21:03:53+00	\N
14	19becb0c36643fab	[PATCH] tests: verify renamed index functionality in alter_table	["dharinshah95@gmail.com","suryapoondla4@gmail.com"]	[{"id":"19becb0c36643fab","messageId":"<CAOj6k6fmk_wc3Rk-9hdoXdBq06iGx7AdAO2Md9HCf=QBsREz8w@mail.gmail.com>","subject":"Re: [PATCH] tests: verify renamed index functionality in alter_table","body":"Thanks Surya, Vasuki\\n\\nI have rebased it against master and is now ready to be merged.\\n\\nThanks,\\nDharin\\n\\nOn Fri, Jan 16, 2026 at 4:09 AM surya poondla <suryapoondla4@gmail.com>\\nwrote:\\n\\n> Hi Dharin,\\n>\\n> Thank you for the patch.\\n>\\n> I reviewed your patch and the changes look good.\\n>\\n> I applied your patch and all the tests pass.\\n>\\n> Regards,\\n> Surya Poondla\\n>\\n>\\n","threadId":"19becb0c36643fab","snippet":"Thanks Surya, Vasuki I have rebased it against master and is now ready to be merged. Thanks, Dharin On Fri, Jan 16, 2026 at 4:09 AM surya poondla <suryapoondla4@gmail.com> wrote: Hi Dharin, Thank","historyId":"13640","internalDate":"1769202538000","receivedAtUtc":"2026-01-23T21:08:58.000Z","from":"Dharin Shah <dharinshah95@gmail.com>"}]	Dharin Shah submitted a patch to add tests for verifying renamed index functionality in alter_table operations. Surya Poondla reviewed the patch and confirmed that the changes look good, with all tests passing after applying the patch. Following the positive review, Dharin rebased the patch against the master branch and indicated it is now ready to be merged. The discussion appears to have reached completion with successful code review and testing, awaiting final merge into the codebase.\nDharin Shah 提交了一个补丁，用于添加测试以验证 alter_table 操作中重命名索引的功能。Surya Poondla 审查了该补丁并确认更改看起来不错，应用补丁后所有测试都通过了。在获得积极的审查后，Dharin 将补丁重新基于主分支并表示现在已准备好合并。讨论似乎已经完成，代码审查和测试成功，等待最终合并到代码库中。	2026-01-23 21:08:58+00	\N
14	19becb3a39d89c6a	[PATCH] Reserve protocol 3.1 explicitly in pqcomm.h	["jacob.champion@enterprisedb.com","postgres@jeltef.nl","tgl@sss.pgh.pa.us"]	[{"id":"19becb3a39d89c6a","messageId":"<CAOYmi+mbza4JbqZ2_tAbpWKQuLiUn-FQhJC8e-eFvayA_bNV9A@mail.gmail.com>","subject":"Re: [PATCH] Reserve protocol 3.1 explicitly in pqcomm.h","body":"On Tue, Jan 20, 2026 at 11:50 PM Jelte Fennema-Nio <postgres@jeltef.nl> wrote:\\n> RESERVED seems clearer to me. And for people interested in why, the\\n> comment above its definition describes it suffiecently.\\n\\nPushed as PG_PROTOCOL_RESERVED_31. Thank you both!\\n\\n--Jacob\\n\\n\\n","threadId":"19becb3a39d89c6a","snippet":"On Tue, Jan 20, 2026 at 11:50 PM Jelte Fennema-Nio <postgres@jeltef.nl> wrote: > RESERVED seems clearer to me. And for people interested in why, the > comment above its definition describes","historyId":"13355","internalDate":"1769202732000","receivedAtUtc":"2026-01-23T21:12:12.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"}]	This thread discusses a patch to explicitly reserve protocol version 3.1 in PostgreSQL's pqcomm.h header file. The discussion focused on the naming convention for the reserved protocol constant. Jelte Fennema-Nio suggested using "RESERVED" as it provides better clarity, with the rationale explained in accompanying comments. Jacob Champion accepted this recommendation and committed the patch using the final name PG_PROTOCOL_RESERVED_31. The patch has been successfully integrated into the codebase, resolving the discussion with no remaining open issues.\n这个讨论涉及在PostgreSQL的pqcomm.h头文件中显式保留协议版本3.1的补丁。讨论重点是保留协议常量的命名约定。Jelte Fennema-Nio建议使用"RESERVED"，因为它提供了更好的清晰度，并在相关注释中解释了原理。Jacob Champion接受了这个建议，并使用最终名称PG_PROTOCOL_RESERVED_31提交了补丁。该补丁已成功集成到代码库中，解决了讨论，没有剩余的未决问题。	2026-01-23 21:12:12+00	\N
14	19bebeb32c2a6da1	alignas (C11)	["peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19bebeb32c2a6da1","messageId":"<3119480.1769189606@sss.pgh.pa.us>","subject":"Re: alignas (C11)","body":"Peter Eisentraut <peter@eisentraut.org> writes:\\n> This patch set has been committed, it looks like without buildfarm \\n> complaints.\\n\\nThings were fine until test_cplusplusext was added, but now\\nsome older compilers seem to reject this in C++ mode.\\nFor example at [1]:\\n\\nmake[1]: Entering directory '/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/src/test/modules/test_cplusplusext'\\ng++ -Wall -Wpointer-arith -Wendif-labels -Wmissing-format-attribute -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -g -O2 -fPIC -fvisibility=hidden -fvisibility-inlines-hidden -I. -I/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/test/modules/test_cplusplusext -I../../../../src/include -I/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include -D_GNU_SOURCE  -I/usr/include/libxml2     -c -o test_cplusplusext.o /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/test/modules/test_cplusplusext/test_cplusplusext.cpp\\nIn file included from /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/postgres.h:48:0,\\n                 from /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/test/modules/test_cplusplusext/test_cplusplusext.cpp:18:\\n/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/c.h:1126:44: warning: requested alignment 4096 is larger than 128 [-Wattributes]\\n  alignas(PG_IO_ALIGN_SIZE) char data[BLCKSZ];\\n                                            ^\\n/home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/c.h:1132:49: warning: requested alignment 4096 is larger than 128 [-Wattributes]\\n  alignas(PG_IO_ALIGN_SIZE) char data[XLOG_BLCKSZ];\\n                                                 ^\\n\\nNot sure what to do about that, but I do read it as indicating that we\\ncannot put any faith in the compiler to honor such large alignment\\ndemands.\\n\\nA possible short-term(?) workaround is to wrap those two declarations\\nin \\"#ifndef __cplusplus\\", so that C++ code can't declare such\\nvariables.\\n\\n\\t\\t\\tregards, tom lane\\n\\n[1] https://buildfarm.postgresql.org/cgi-bin/show_stage_log.pl?nm=chimaera&dt=2026-01-23%2011%3A44%3A01&stg=make-testmodules\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"Peter Eisentraut <peter@eisentraut.org> writes: > This patch set has been committed, it looks like without buildfarm > complaints. Things were fine until test_cplusplusext was added, but","historyId":"12900","internalDate":"1769189606000","receivedAtUtc":"2026-01-23T17:33:26.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19becdffc0ba40ed","messageId":"<48e2bb94-be07-4f22-ba8a-545e252e4ac4@eisentraut.org>","subject":"Re: alignas (C11)","body":"On 23.01.26 18:33, Tom Lane wrote:\\n                                           ^\\n> /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/c.h:1132:49: warning: requested alignment 4096 is larger than 128 [-Wattributes]\\n>    alignas(PG_IO_ALIGN_SIZE) char data[XLOG_BLCKSZ];\\n>                                                   ^\\n> > Not sure what to do about that, but I do read it as indicating that we\\n> cannot put any faith in the compiler to honor such large alignment\\n> demands.\\n> > A possible short-term(?) workaround is to wrap those two declarations\\n> in \\"#ifndef __cplusplus\\", so that C++ code can't declare such\\n> variables.\\n\\nIt looks like this was a bug in g++:\\n\\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=70066\\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=89357\\n\\nThe suggestion there appears to be that it was fixed in gcc 9, but on the buildfarm it only goes up to 6.\\n\\nI think we could work around it like this:\\n\\n    #if defined(__cplusplus) && defined(__GNUC__) && __GNUC__ <= 6\\n    #define alignas(a) __attribute__((aligned(a)))\\n    #endif\\n\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"On 23.01.26 18:33, Tom Lane wrote: ^ > /home/debian/20-chimaera/buildroot/HEAD/pgsql.build/../pgsql/src/include/ch:1132:49: warning: requested alignment 4096 is larger than 128 [-Wattributes] >","historyId":"13631","internalDate":"1769205643000","receivedAtUtc":"2026-01-23T22:00:43.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"},{"id":"19becf07d0cc9f24","messageId":"<3148330.1769206724@sss.pgh.pa.us>","subject":"Re: alignas (C11)","body":"Peter Eisentraut <peter@eisentraut.org> writes:\\n> On 23.01.26 18:33, Tom Lane wrote:\\n>> Not sure what to do about that, but I do read it as indicating that we\\n>> cannot put any faith in the compiler to honor such large alignment\\n>> demands.\\n\\n> I think we could work around it like this:\\n\\n>      #if defined(__cplusplus) && defined(__GNUC__) && __GNUC__ <= 6\\n>      #define alignas(a) __attribute__((aligned(a)))\\n>      #endif\\n\\nHmm, yeah, their bug #70066 shows clearly that the __attribute__\\nspelling should work.  But I think we'd better make the cutoff be\\nversion 9 not version 6, because that same bug is quite clear\\nabout when they fixed it.  The lack of complaints from the buildfarm\\nmay just indicate a lack of animals running the intermediate versions.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"Peter Eisentraut <peter@eisentraut.org> writes: > On 23.01.26 18:33, Tom Lane wrote: >> Not sure what to do about that, but I do read it as indicating that we >> cannot put any","historyId":"13631","internalDate":"1769206724000","receivedAtUtc":"2026-01-23T22:18:44.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19becf1dc8cd9f76","messageId":"<3148476.1769206820@sss.pgh.pa.us>","subject":"Re: alignas (C11)","body":"I wrote:\\n> Hmm, yeah, their bug #70066 shows clearly that the __attribute__\\n> spelling should work.\\n\\nSorry, copy-and-paste-o; it's\\n\\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=89357\\n\\nthat has the full statement of the problem and ACK of the fix.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"I wrote: > Hmm, yeah, their bug #70066 shows clearly that the __attribute__ > spelling should work. Sorry, copy-and-paste-o; it's https://gcc.gnu.org/bugzilla/show_bug.cgi?id=89357 that has","historyId":"13631","internalDate":"1769206820000","receivedAtUtc":"2026-01-23T22:20:20.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	A PostgreSQL C11 alignas patch initially passed buildfarm testing but later broke when test_cplusplusext was added. Older G++ compilers (version 6 and below) reject large alignment requests (4096 bytes) in C++ mode, showing warnings that requested alignment exceeds the compiler's 128-byte limit. Peter Eisentraut identified this as a known GCC bug (#89357) that was fixed in GCC version 9. The proposed workaround involves using `__attribute__((aligned(a)))` syntax specifically for affected G++ versions. Tom Lane suggests setting the version cutoff at GCC 9 rather than 6, as intermediate versions may also be affected despite lack of buildfarm complaints.\nPostgreSQL的C11 alignas补丁最初通过了buildfarm测试，但在添加test_cplusplusext后出现问题。较旧的G++编译器（版本6及以下）在C++模式下拒绝大对齐请求（4096字节），显示请求的对齐超过编译器128字节限制的警告。Peter Eisentraut识别这是一个已知的GCC错误（#89357），已在GCC版本9中修复。建议的解决方案是对受影响的G++版本专门使用`__attribute__((aligned(a)))`语法。Tom Lane建议将版本截止点设在GCC 9而不是6，因为尽管buildfarm没有投诉，中间版本也可能受到影响。	2026-01-23 22:20:20+00	\N
14	19bed51841b76f7b	Custom oauth validator options	["david.g.johnston@gmail.com","jacob.champion@enterprisedb.com","myon@debian.org","robertmhaas@gmail.com","vasukianand0119@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bed51841b76f7b","messageId":"<CAOYmi+nhh-fChn-8K7HV4kwVwsTm_gVy5jBgUBMqfM6Hm5E4zg@mail.gmail.com>","subject":"Re: Custom oauth validator options","body":"On Tue, Jan 20, 2026 at 12:31 PM Zsolt Parragi\\n<zsolt.parragi@percona.com> wrote:\\n> > But if someone decides in PG20 that\\n> > pam_use_hostname is a good GUC name for something, we're in trouble,\\n> > because the existing HBA options do not plug into the GUC system.\\n>\\n> We could make them reserved names?\\n\\nI'm wondering if we should maybe do the opposite, and namespace the\\nGUCs instead? The vast majority of settings in an HBA are not going to\\nbe GUCs, they're going to be method-specific parameters. So maybe it's\\nokay to have to do more typing to do the uncommon thing, and reference\\nthem like `guc.log_connections` or something.\\n\\n> Or maybe even accessible as GUC\\n> variables, even if we leave the current parsing/validation logic as\\n> is. Making them proper GUC variables seemed like a clear follow up\\n> patch to me, even if not for pg19.\\n\\nHmm... we may want to discuss my (e) option derailment more seriously,\\nif we're planning to go in that direction (and if other people like\\nthat direction).\\n\\n> > I'm worried that it's about to make a different decision from the\\n> > decision that is being made for the pg_hosts.conf file for SNI.\\n>\\n> I probably should read that thread in more detail, but I assume that\\n> your worry is about pg_hosts being a hardcoded configuration instead\\n> of using a similarly customizable GUC context? Shouldn't that be\\n> fixable in the future similarly?\\n\\n\\"Fixable\\" in what sense? pg_hosts.conf is currently similar to\\npg_ident.conf in that it has no place for key=value pairs, and if you\\nadd them after as an optional \\"column\\" for compatibility, you still\\nhave to write something for all of those columns that you were trying\\nto replace with the GUC settings.\\n\\n> > 3) can your option (b) or (c) make enough use of existing GUC\\n> > infrastructure, so that a future PGC_HBA could easily subsume an\\n> > OAuth-specific solution, if people want to continue down that path in\\n> > a less OAuth-centric thread?\\n>\\n> I'm not sure about reusing existing GUC infrastructure, but  I could\\n> make it look similar from the users perspective for example by adding\\n> a function DefineCustomValidatorStringVariable that has a similar\\n> interface to DefineCustomStringVariable, and in the future, this\\n> function could simply forward to DefineCustomStringVariable.\\n\\nMight work, yeah.\\n\\n--Jacob\\n\\n\\n","threadId":"19bed51841b76f7b","snippet":"On Tue, Jan 20, 2026 at 12:31 PM Zsolt Parragi <zsolt.parragi@percona.com> wrote: > > But if someone decides in PG20 that > > pam_use_hostname is a good GUC name for something, we","historyId":"15686","internalDate":"1769213079000","receivedAtUtc":"2026-01-24T00:04:39.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"}]	Jacob Champion responds to discussions about custom OAuth validator options in PostgreSQL's HBA configuration. He suggests namespacing GUCs instead of making HBA option names reserved, proposing syntax like `guc.log_connections` since most HBA settings will be method-specific parameters rather than GUCs. He expresses concern about consistency with the pg_hosts.conf file approach for SNI, noting that adding key=value pairs later for compatibility would still require writing values for columns they're trying to replace with GUC settings. Champion acknowledges that a DefineCustomValidatorStringVariable function could work as an interim solution that could later forward to DefineCustomStringVariable when a more general PGC_HBA context is implemented.\nJacob Champion回应了关于PostgreSQL HBA配置中自定义OAuth验证器选项的讨论。他建议对GUC进行命名空间化而不是将HBA选项名称设为保留名称，提出类似`guc.log_connections`的语法，因为大多数HBA设置将是特定方法的参数而非GUC。他对SNI的pg_hosts.conf文件方法的一致性表示担忧，指出后续添加键值对以保持兼容性仍需要为试图用GUC设置替换的列编写值。Champion认为DefineCustomValidatorStringVariable函数可以作为临时解决方案，在实现更通用的PGC_HBA上下文时可转发到DefineCustomStringVariable。	2026-01-24 00:04:39+00	\N
14	19bed67824d1f608	eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)	["andres@anarazel.de","hlinnaka@iki.fi","li.evan.chao@gmail.com","melanieplageman@gmail.com","reshkekirill@gmail.com","robertmhaas@gmail.com","x4mmm@yandex-team.ru","xunengzhou@gmail.com"]	[{"id":"19bed67824d1f608","messageId":"<7ib3sa55sapwjlaz4sijbiq7iezna27kjvvvar4dpgkmadml6t@gfpkkwmdnepx>","subject":"Re: eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)","body":"Hi,\\n\\nOn 2026-01-06 12:31:57 -0500, Melanie Plageman wrote:\\n> Subject: [PATCH v33 01/16] Combine visibilitymap_set() cases in\\n>  lazy_scan_prune()\\n>\\n> lazy_scan_prune() previously had two separate cases that called\\n> visibilitymap_set() after pruning and freezing. These branches were\\n> nearly identical except that one attempted to avoid dirtying the heap\\n> buffer. However, that situation can never occur — the heap buffer cannot\\n> be clean at that point (and we would hit an assertion if it were).\\n>\\n> In lazy_scan_prune(), when we change a previously all-visible page to\\n> all-frozen and the page was recorded as all-visible in the visibility\\n> map by find_next_unskippable_block(), the heap buffer will always be\\n> dirty. Either we have just frozen a tuple and already dirtied the\\n> buffer, or the buffer was modified between find_next_unskippable_block()\\n> and heap_page_prune_and_freeze() and then pruned in\\n> heap_page_prune_and_freeze().\\n>\\n> Additionally, XLogRegisterBuffer() asserts that the buffer is dirty, so\\n> attempting to add a clean heap buffer to the WAL chain would assert out\\n> anyway.\\n>\\n> Since the \\"clean heap buffer with already set VM\\" case is impossible,\\n> the two visibilitymap_set() branches in lazy_scan_prune() can be merged.\\n> Doing so makes the intent clearer and emphasizes that the heap buffer\\n> must always be marked dirty before being added to the WAL chain.\\n>\\n> This commit also adds a test case for vacuuming when no heap\\n> modifications are required. Currently this ensures that the heap buffer\\n> is marked dirty before it is added to the WAL chain, but if we later\\n> remove the heap buffer from the VM-set WAL chain or pass it with the\\n> REGBUF_NO_CHANGES flag, this test would guard that behavior.\\n>\\n> Author: Melanie Plageman <melanieplageman@gmail.com>\\n> Reviewed-by: Chao Li <li.evan.chao@gmail.com>\\n> Reviewed-by: Srinath Reddy Sadipiralla <srinath2133@gmail.com>\\n> Reviewed-by: Kirill Reshke <reshkekirill@gmail.com>\\n> Reviewed-by: Xuneng Zhou <xunengzhou@gmail.com>\\n> Discussion: https://postgr.es/m/5CEAA162-67B1-44DA-B60D-8B65717E8B05%40gmail.com\\n> Discussion: https://postgr.es/m/flat/CAAKRu_ZWx5gCbeCf7PWCv8p5%3D%3Db7EEws0VD2wksDxpXCvCyHvQ%40mail.gmail.com\\n> ---\\n>  .../pg_visibility/expected/pg_visibility.out  | 44 ++++++++++\\n>  contrib/pg_visibility/sql/pg_visibility.sql   | 20 +++++\\n>  src/backend/access/heap/vacuumlazy.c          | 87 ++++---------------\\n>  3 files changed, 82 insertions(+), 69 deletions(-)\\n>\\n> diff --git a/contrib/pg_visibility/expected/pg_visibility.out b/contrib/pg_visibility/expected/pg_visibility.out\\n> index 09fa5933a35..e10f1706015 100644\\n> --- a/contrib/pg_visibility/expected/pg_visibility.out\\n> +++ b/contrib/pg_visibility/expected/pg_visibility.out\\n> @@ -1,4 +1,5 @@\\n>  CREATE EXTENSION pg_visibility;\\n> +CREATE EXTENSION pageinspect;\\n\\nI think this would need a EXTRA_INSTALL = contrib/pageinspect to work reliably\\nin make.  You should be able to see a failure without the fix if you remove\\nthe tmp_install/ dir in an autoconf build and then run make check for\\npg_visibility.\\n\\nI'm slightly wary of embedding numerical bitmaks values in the tests, but I\\ndon't see a better alternative right now.\\n\\nOther than the EXTRA_INSTALL thing I think this is ready.\\n\\n\\n\\n> From 4d37243f9fa0dc4e264a28bcee448787fb8d7f65 Mon Sep 17 00:00:00 2001\\n> From: Melanie Plageman <melanieplageman@gmail.com>\\n> Date: Thu, 11 Dec 2025 10:48:13 -0500\\n> Subject: [PATCH v33 02/16] Eliminate use of cached VM value in\\n>  lazy_scan_prune()\\n>\\n> lazy_scan_prune() takes a parameter from lazy_scan_heap() indicating\\n> whether the page was marked all-visible in the VM at the time it was\\n> last checked in find_next_unskippable_block(). This behavior is\\n> historical, dating back to commit 608195a3a365, when we did not pin the\\n> VM page until deciding we must read it. Now that the VM page is already\\n> pinned, there is no meaningful benefit to relying on a cached VM status.\\n>\\n> Removing this cached value simplifies the logic in both lazy_scan_heap()\\n> and lazy_scan_prune(). It also clarifies future work that will set the\\n> visibility map on-access: such paths will not have a cached value\\n> available, which would make the logic harder to reason about. And\\n> eliminating it enables us to detect and repair VM corruption on-access.\\n>\\n> Along with removing the cached value and unconditionally checking the\\n> visibility status of the heap page, this commit also moves the VM\\n> corruption handling to occur first. This reordering should have no\\n> performance impact, since the checks are inexpensive and performed only\\n> once per page. It does, however, make the control flow easier to\\n> understand. The new restructuring also makes it possible to set the VM\\n> after fixing corruption (if pruning found the page all-visible).\\n>\\n> Now that no callers of visibilitymap_set() use its return value, change\\n> its (and visibilitymap_set_vmbits()) return type to void.\\n\\n> @@ -1735,7 +1719,6 @@ find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis)\\n>  \\tBlockNumber next_unskippable_block = vacrel->next_unskippable_block + 1;\\n>  \\tBuffer\\t\\tnext_unskippable_vmbuffer = vacrel->next_unskippable_vmbuffer;\\n>  \\tbool\\t\\tnext_unskippable_eager_scanned = false;\\n> -\\tbool\\t\\tnext_unskippable_allvis;\\n>\\n>  \\t*skipsallvis = false;\\n>\\n> @@ -1745,7 +1728,6 @@ find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis)\\n>  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   next_unskippable_block,\\n>  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   &next_unskippable_vmbuffer);\\n>\\n> -\\t\\tnext_unskippable_allvis = (mapbits & VISIBILITYMAP_ALL_VISIBLE) != 0;\\n>\\n>  \\t\\t/*\\n>  \\t\\t * At the start of each eager scan region, normal vacuums with eager\\n> @@ -1764,7 +1746,7 @@ find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis)\\n>  \\t\\t * A block is unskippable if it is not all visible according to the\\n>  \\t\\t * visibility map.\\n>  \\t\\t */\\n> -\\t\\tif (!next_unskippable_allvis)\\n> +\\t\\tif ((mapbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n>  \\t\\t{\\n>  \\t\\t\\tAssert((mapbits & VISIBILITYMAP_ALL_FROZEN) == 0);\\n>  \\t\\t\\tbreak;\\n\\nThis feels a bit independent from the rest, but it doesn't matter.\\n\\n\\n\\n> @@ -2225,6 +2144,71 @@ lazy_scan_prune(LVRelState *vacrel,\\n>  \\t\\tMarkBufferDirty(buf);\\n>  \\t\\tvisibilitymap_clear(vacrel->rel, blkno, vmbuffer,\\n>  \\t\\t\\t\\t\\t\\t\\tVISIBILITYMAP_VALID_BITS);\\n> +\\t\\t/* VM bits are now clear */\\n> +\\t\\told_vmbits = 0;\\n> +\\t}\\n> +\\n> +\\tif (!presult.all_visible)\\n> +\\t\\treturn presult.ndeleted;\\n> +\\n> +\\t/* Set the visibility map and page visibility hint */\\n> +\\tnew_vmbits = VISIBILITYMAP_ALL_VISIBLE;\\n> +\\n> +\\tif (presult.all_frozen)\\n> +\\t\\tnew_vmbits |= VISIBILITYMAP_ALL_FROZEN;\\n> +\\n> +\\t/* Nothing to do */\\n> +\\tif (old_vmbits == new_vmbits)\\n> +\\t\\treturn presult.ndeleted;\\n>\\n> +\\tAssert(presult.all_visible);\\n\\nGiven that there's an explicit return for this case a few lines above, I don't\\nunderstand what the assert is trying to do?\\n\\n\\n> +\\t/*\\n> +\\t * It should never be the case that the visibility map page is set while\\n> +\\t * the page-level bit is clear\\n\\nI'd perhaps add a parenthetical saying (and if so, we cleared it above) or\\nsuch.\\n\\n\\n> +\\tvisibilitymap_set(vacrel->rel, blkno, buf,\\n> +\\t\\t\\t\\t\\t  InvalidXLogRecPtr,\\n> +\\t\\t\\t\\t\\t  vmbuffer, presult.vm_conflict_horizon,\\n> +\\t\\t\\t\\t\\t  new_vmbits);\\n> +\\n> +\\t/*\\n> +\\t * If the page wasn't already set all-visible and/or all-frozen in the VM,\\n> +\\t * count it as newly set for logging.\\n> +\\t */\\n> +\\tif ((old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n> +\\t{\\n> +\\t\\tvacrel->vm_new_visible_pages++;\\n> +\\t\\tif (presult.all_frozen)\\n> +\\t\\t{\\n> +\\t\\t\\tvacrel->vm_new_visible_frozen_pages++;\\n> +\\t\\t\\t*vm_page_frozen = true;\\n\\nNot this patches fault, but I find \\"vm_new_visible_pages\\" and\\n\\"vm_new_visible_frozen_pages\\" pretty odd names. The concept is all-visible and\\nfrozen. The page itself isn't visible or invisible...\\n\\n\\n\\n> Subject: [PATCH v33 03/16] Refactor lazy_scan_prune() VM clear logic into\\n>  helper\\n\\n> +/*\\n> + * Helper to correct any corruption detected on a heap page and its\\n> + * corresponding visibility map page after pruning but before setting the\\n> + * visibility map. It examines the heap page, the associated VM page, and the\\n> + * number of dead items previously identified.\\n> + *\\n> + * This function must be called while holding an exclusive lock on the heap\\n> + * buffer, and the dead items must have been discovered under that same lock.\\n> +\\n> + * The provided vmbits must reflect the current state of the VM block\\n> + * referenced by vmbuffer. Although we do not hold a lock on the VM buffer, it\\n> + * is pinned, and the heap buffer is exclusively locked, ensuring that no\\n> + * other backend can update the VM bits corresponding to this heap page.\\n> + *\\n> + * Returns true if it cleared corruption and false otherwise.\\n> + */\\n\\nI don't love that the caller now has to assume that old_vmbits is zero after\\nthis function returns.  Somehow that feels like split responsiility.\\n\\nI guess I'd take a pointer to old_vmbits and update it accordingly inside\\nidentify_and_fix_vm_corruption() rather than in the caller.\\n\\n\\n> From 5c65e73246b4968ddfa9d3739f53d0d8734b8727 Mon Sep 17 00:00:00 2001\\n> From: Melanie Plageman <melanieplageman@gmail.com>\\n> Date: Tue, 2 Dec 2025 15:07:42 -0500\\n> Subject: [PATCH v33 04/16] Set the VM in heap_page_prune_and_freeze()\\n>\\n> This has no independent benefit. It is meant for ease of review. As of\\n> this commit, there is still a separate WAL record emitted for setting\\n> the VM after pruning and freezing. But it is easier to review if moving\\n> the logic into pruneheap.c is separate from setting the VM in the same\\n> WAL record.\\n\\nIt seems a bit noisy to refactor the related code in some of the preceding\\ncommits and then refactor it into a slightly different shape as part of this\\ncommit (c.f. heap_page_will_set_vm()).\\n\\nIt's also a bit odd that a function that sounds rather read-only does stuff\\nlike clearing VM/all-visible.\\n\\nWhy are we not doing fixing up of the page *before* we prune it?  It's a bit\\ninsane that we do the WAL logging for pruning, which in turn will often\\ninclude an FPI, before we do the fixups. The fixes aren't WAL logged, so this\\nactually leads to the standby getting further out of sync.\\n\\nI realize this isn't your mess, but brrr.\\n\\n\\nDo we actually forsee a case where only one of HEAP_PAGE_PRUNE_FREEZE |\\nHEAP_PAGE_PRUNE_UPDATE_VM would be set?\\n\\n\\n> --- a/src/backend/access/heap/vacuumlazy.c\\n> +++ b/src/backend/access/heap/vacuumlazy.c\\n> @@ -424,11 +424,7 @@ static void find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis);\\n>  static bool lazy_scan_new_or_empty(LVRelState *vacrel, Buffer buf,\\n>  \\t\\t\\t\\t\\t\\t\\t\\t   BlockNumber blkno, Page page,\\n>  \\t\\t\\t\\t\\t\\t\\t\\t   bool sharelock, Buffer vmbuffer);\\n> -static bool identify_and_fix_vm_corruption(Relation rel, Buffer heap_buffer,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   BlockNumber heap_blk, Page heap_page,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   int nlpdead_items,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   Buffer vmbuffer,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   uint8 vmbits);\\n> +\\n>  static int\\tlazy_scan_prune(LVRelState *vacrel, Buffer buf,\\n>  \\t\\t\\t\\t\\t\\t\\tBlockNumber blkno, Page page,\\n>  \\t\\t\\t\\t\\t\\t\\tBuffer vmbuffer,\\n> @@ -1962,83 +1958,6 @@ cmpOffsetNumbers(const void *a, const void *b)\\n>  \\treturn pg_cmp_u16(*(const OffsetNumber *) a, *(const OffsetNumber *) b);\\n>  }\\n\\nSpurious newline inserted.\\n\\n\\n>  \\t/*\\n>  \\t * If the page wasn't already set all-visible and/or all-frozen in the VM,\\n>  \\t * count it as newly set for logging.\\n>  \\t */\\n> -\\tif ((old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n> +\\tif ((presult.old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0 &&\\n> +\\t\\t(presult.new_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0)\\n>  \\t{\\n>  \\t\\tvacrel->vm_new_visible_pages++;\\n> -\\t\\tif (presult.all_frozen)\\n> +\\t\\tif ((presult.new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n>  \\t\\t{\\n>  \\t\\t\\tvacrel->vm_new_visible_frozen_pages++;\\n>  \\t\\t\\t*vm_page_frozen = true;\\n>  \\t\\t}\\n>  \\t}\\n> -\\telse if ((old_vmbits & VISIBILITYMAP_ALL_FROZEN) == 0 &&\\n> -\\t\\t\\t presult.all_frozen)\\n> +\\telse if ((presult.old_vmbits & VISIBILITYMAP_ALL_FROZEN) == 0 &&\\n> +\\t\\t\\t (presult.new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n>  \\t{\\n> +\\t\\tAssert((presult.new_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0);\\n>  \\t\\tvacrel->vm_new_frozen_pages++;\\n>  \\t\\t*vm_page_frozen = true;\\n>  \\t}\\n\\nIt's a bit odd that we figure out all of this by inspecting old/new vmbits and\\nhave that logic in multiple places.\\n\\n\\n> Subject: [PATCH v33 05/16] Move VM assert into prune/freeze code\\n\\nFeels like a somewhat too narrow description, given that it changes the API\\nfor heap_page_prune_and_freeze() by removing variables from PruneFreezeResult.\\n\\n\\n> +#ifdef USE_ASSERT_CHECKING\\n> +\\n> +/*\\n> + * Wrapper for heap_page_would_be_all_visible() which can be used for callers\\n> + * that expect no LP_DEAD on the page. Currently assert-only, but there is no\\n> + * reason not to use it outside of asserts.\\n> + */\\n\\nIf so, why would we want it in pruneheap.c? Seems a bit odd to have\\nheap_page_would_be_all_visible() defined in vacuumlazy.c but defined\\nheap_page_is_all_visible() in pruneheap.c.\\n\\n\\n\\n> From cdf5776fadeae3430c692999b37f8a7ec944bda1 Mon Sep 17 00:00:00 2001\\n> From: Melanie Plageman <melanieplageman@gmail.com>\\n> Date: Tue, 2 Dec 2025 16:16:22 -0500\\n> Subject: [PATCH v33 06/16] Eliminate XLOG_HEAP2_VISIBLE from vacuum phase I\\n>  prune/freeze\\n>\\n> Vacuum no longer emits a separate WAL record for each page set\\n> all-visible or all-frozen during phase I. Instead, visibility map\\n> updates are now included in the XLOG_HEAP2_PRUNE_VACUUM_SCAN record that\\n> is already emitted for pruning and freezing.\\n>\\n> Previously, heap_page_prune_and_freeze() determined whether a page was\\n> all-visible, but the corresponding VM bits were only set later in\\n> lazy_scan_prune(). Now the VM is updated immediately in\\n> heap_page_prune_and_freeze(), at the same time as the heap\\n> modifications.\\n>\\n> This change applies only to vacuum phase I, not to pruning performed\\n> during normal page access.\\n\\n> +/*\\n> + * Calculate the conflict horizon for the whole XLOG_HEAP2_PRUNE_VACUUM_SCAN\\n> + * or XLOG_HEAP2_PRUNE_ON_ACCESS record.\\n> + */\\n> +static TransactionId\\n> +get_conflict_xid(bool do_prune, bool do_freeze, bool do_set_vm,\\n> +\\t\\t\\t\\t uint8 old_vmbits, uint8 new_vmbits,\\n> +\\t\\t\\t\\t TransactionId latest_xid_removed, TransactionId frz_conflict_horizon,\\n> +\\t\\t\\t\\t TransactionId visibility_cutoff_xid)\\n> +{\\n\\nThe logic for horizons is now split between this and \\"Calculate what the\\nsnapshot conflict horizon should be for a record\\" in heap_page_will_freeze().\\n\\nAlthough I guess I don't understand that code:\\n\\n\\t\\t/*\\n\\t\\t * Calculate what the snapshot conflict horizon should be for a record\\n\\t\\t * freezing tuples. We can use the visibility_cutoff_xid as our cutoff\\n\\t\\t * for conflicts when the whole page is eligible to become all-frozen\\n\\t\\t * in the VM once we're done with it. Otherwise, we generate a\\n\\t\\t * conservative cutoff by stepping back from OldestXmin.\\n\\t\\t */\\n\\t\\tif (prstate->all_frozen)\\n\\t\\t\\tprstate->frz_conflict_horizon = prstate->visibility_cutoff_xid;\\n\\t\\telse\\n\\t\\t{\\n\\t\\t\\t/* Avoids false conflicts when hot_standby_feedback in use */\\n\\t\\t\\tprstate->frz_conflict_horizon = prstate->cutoffs->OldestXmin;\\n\\t\\t\\tTransactionIdRetreat(prstate->frz_conflict_horizon);\\n\\t\\t}\\n\\nWhy does it make sense to use OldestXmin? Consider e.g. the case where there\\nis one very old tuple that needs to be frozen and one new live tuple on a\\npage. Because of the new tuple we can't mark the page all-frozen. But there's\\nalso no reason to not use much less aggressive horizon than OldestXmin, namely\\nthe newer of xmin,xmax of the old frozen tuple?\\n\\nI also don't understand what the \\"false conflicts\\" thing is referencing.\\n\\n\\n> +\\tTransactionId conflict_xid;\\n> +\\n> +\\t/*\\n> +\\t * We can omit the snapshot conflict horizon if we are not pruning or\\n> +\\t * freezing any tuples and are setting an already all-visible page\\n> +\\t * all-frozen in the VM. In this case, all of the tuples on the page must\\n> +\\t * already be visible to all MVCC snapshots on the standby.\\n> +\\t */\\n\\nThe last sentence here is a bit confusing, because they don't just need to\\nalready be visible to everyone, they already need to be frozen. Right?\\n\\n\\n> +\\tif (!do_prune &&\\n> +\\t\\t!do_freeze &&\\n> +\\t\\tdo_set_vm &&\\n\\nI'm confused by the do_set_vm check here. Doesn't it mean that we will *not*\\nreturn InvalidTransactionId if !prstate->attempt_update_vm?  I don't undestand\\nwhy that would make sense.\\n\\nI guess we'll compute a bogus cutoff in that cse, but never use it, since\\nwe'll also not emit WAL?  Or maybe we'll just unnecessarily go through the\\ncode below, because the code turns out to do ok regardles?  It's confusing\\neither way.\\n\\n\\n\\n> +\\t\\t(old_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0 &&\\n> +\\t\\t(new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n\\nI wonder if some of this code would end up cleaner if we tracked the bits we\\nintend to add, rather than the target set of bits is.\\n\\n\\n> +\\t/*\\n> +\\t * The snapshotConflictHorizon for the whole record should be the most\\n> +\\t * conservative of all the horizons calculated for any of the possible\\n> +\\t * modifications.  If this record will prune tuples, any transactions on\\n> +\\t * the standby older than the youngest xmax of the most recently removed\\n> +\\t * tuple this record will prune will conflict.  If this record will freeze\\n> +\\t * tuples, any transactions on the standby with xids older than the\\n> +\\t * youngest tuple this record will freeze will conflict.\\n> +\\t */\\n> +\\tconflict_xid = InvalidTransactionId;\\n\\nI'd move this first assignment into an else.\\n\\n> +\\t/*\\n> +\\t * If we are updating the VM, the conflict horizon is almost always the\\n> +\\t * visibility cutoff XID.\\n> +\\t *\\n> +\\t * Separately, if we are freezing any tuples, as an optimization, we can\\n> +\\t * use the visibility_cutoff_xid as the conflict horizon if the page will\\n> +\\t * be all-frozen.\\n\\nWhat does \\"as an optimization\\" mean here?\\n\\nNote that the code actually uses visibility_cutoff_xid even if the page is\\njust marked all-visible, but not all-frozen (due to the do_set_vm check being\\nearlier)\\n\\n\\n> This is true even if there are LP_DEAD line pointers\\n> +\\t * because we ignored those when maintaining the visibility_cutoff_xid.\\n\\nI must just be missing something because I can't follow this at all.  I guess\\nit could be correct because we later then add in knowledge of removed xids in\\nvia the TransactionIdFollows check below? But if that's it, this is extremely\\nconfusingly worded.\\n\\n\\nSorry, running out of brain power. More another day.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bed67824d1f608","snippet":"Hi, On 2026-01-06 12:31:57 -0500, Melanie Plageman wrote: > Subject: [PATCH v33 01/16] Combine visibilitymap_set() cases in > lazy_scan_prune() > > lazy_scan_prune() previously had two","historyId":"15687","internalDate":"1769214526000","receivedAtUtc":"2026-01-24T00:28:46.000Z","from":"Andres Freund <andres@anarazel.de>"}]	\N	\N	\N
14	19bed86292d80bd8	[oauth] Stabilize the libpq-oauth ABI (and allow alternative implementations?)	["jacob.champion@enterprisedb.com","li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bed86292d80bd8","messageId":"<CAOYmi+mQeneEuoWsO1uOZszrE_tMuF51sKNzT0Z=cevpV5H3_g@mail.gmail.com>","subject":"Re: [oauth] Stabilize the libpq-oauth ABI (and allow alternative implementations?)","body":"On Tue, Jan 20, 2026 at 1:14 PM Zsolt Parragi <zsolt.parragi@percona.com> wrote:\\n> If it's validated on the server, and the issuer matches, that should\\n> be enough?\\n\\nIt's client-side protection against a malicious server; server-side\\nvalidation doesn't help. This is why you have to specify an issuer in\\nyour client's connection string (my original patchset just trusted\\nwhatever the server sent, which would have caused serious problems).\\nSee [1] for a longer discussion.\\n\\nIf I've misunderstood what you mean, please tell me what function call\\nin particular you think can be removed.\\n\\n> I don't think LDAP, or anything else is similarly extensible both on\\n> the server and client side?\\n\\nAny plaintext password method (like LDAP) can tunnel arbitrary data,\\njust like a Bearer token can. So if you control both sides, you can do\\nwhatever you want.\\n\\n> And my question was exactly because of this: OAuth introduced mostly\\n> everything needed for pluggable authentication (without PAM - my\\n> previous experience with that is that it is system specific, slow, and\\n> complex), and it is already possible to misuse it for something else.\\n> It would be really nice to have a generic authentication plugin system\\n> in postgres to implement other authentication methods, not just OAuth.\\n\\nI'm very much on board with pluggable auth [2], but OAUTHBEARER is not\\nthe layer for arbitrary non-OAuth authentication systems, any more\\nthan LDAP is. (SASL is the correct layer for that, IMHO.)\\n\\n> > Are they asking for this because it'd be an easy way around the v18 flow limitation? Because that's been the primary motivation in the conversations I've had.\\n>\\n> One specific use case I know of is CI, for example GitHub simply\\n> provides you an oauth token as an environment variable.\\n\\nMm. I'll try to take a closer look at GitHub and Cirrus.\\n\\nThanks,\\n--Jacob\\n\\n[1] https://postgr.es/m/CAOYmi%2BkLTJ1wZ6gxRbgtR52E%3DEyiCpmp6J3mmSvtc1a6i7sZ3Q%40mail.gmail.com\\n[2] https://postgr.es/m/3d41067ed944e9ce889fc15a6593cb26e72b6c0f.camel%40vmware.com\\n\\n\\n","threadId":"19bed86292d80bd8","snippet":"On Tue, Jan 20, 2026 at 1:14 PM Zsolt Parragi <zsolt.parragi@percona.com> wrote: > If it's validated on the server, and the issuer matches, that should > be enough? It's client-side","historyId":"15688","internalDate":"1769216529000","receivedAtUtc":"2026-01-24T01:02:09.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"}]	Jacob Champion responds to Zsolt Parragi's questions about OAuth implementation in PostgreSQL. He clarifies that client-side validation against malicious servers is necessary even with server-side validation, which is why clients must specify an issuer in connection strings. Champion acknowledges that any plaintext password method like LDAP can tunnel arbitrary data similar to Bearer tokens when both sides are controlled. While supporting the concept of pluggable authentication systems, he argues that OAUTHBEARER is not the appropriate layer for non-OAuth authentication methods, suggesting SASL as the correct layer instead. He mentions examining GitHub and Cirrus use cases where OAuth tokens are provided as environment variables for CI purposes.\nJacob Champion回应了Zsolt Parragi关于PostgreSQL中OAuth实现的问题。他澄清即使有服务器端验证，针对恶意服务器的客户端验证仍是必要的，这就是为什么客户端必须在连接字符串中指定发行者。Champion承认任何明文密码方法如LDAP都可以像Bearer令牌一样在双方受控时传输任意数据。虽然支持可插拔认证系统的概念，但他认为OAUTHBEARER不是非OAuth认证方法的合适层，建议SASL才是正确的层。他提到会检查GitHub和Cirrus的用例，其中OAuth令牌作为环境变量提供给CI使用。	2026-01-24 01:02:09+00	\N
14	19bea52b86e5169b	docs: clarify ALTER TABLE behavior on partitioned tables	["amit.kapila16@gmail.com","david.g.johnston@gmail.com","li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bea52b86e5169b","messageId":"<CAN4CZFNoLSUcVKcOOJgOtTkDuOseCL5j9MQr3tGjb3btD=jHNQ@mail.gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","body":"Hello\\n\\nReally good changes!\\n\\n+ When applied to a partitioned table, the constraint is altered on the\\n+ partitioned table definition is implicitly applied to all partitions.\\n\\nan \\"and\\" is missing here (definition and is)\\n\\n+      When applied to a partitioned table, partition columns constraints\\n+      are implicitly renamed and specifying <literal>ONLY</literal>\\nis not allowed.\\n+     </para>\\n\\n\\"partition columns constraints\\" - that seems like a strange/unclear\\nwording to me. maybe \\", the partition's column constraints are ... \\" ?\\n\\n\\n+     <para>\\n+      When applied to a partitioned table <literal>ONLY</literal> is implicit,\\n+      these forms must be applied separately to the partitioned table and/or to\\n+      individual partitions.\\n+     </para>\\n\\n\\"When applied to a partitioned table, <literal>ONLY</literal> is\\nimplicit and ...\\"  (at multiple places, this is an example)\\n\\n-   <para>\\n-    A recursive <literal>DROP COLUMN</literal> operation will remove a\\n-    descendant table's column only if the descendant does not inherit\\n-    that column from any other parents and never had an independent\\n-    definition of the column.  A nonrecursive <literal>DROP\\n-    COLUMN</literal> (i.e., <command>ALTER TABLE ONLY ... DROP\\n-    COLUMN</command>) never removes any descendant columns, but\\n-    instead marks them as independently defined rather than inherited.\\n-    A nonrecursive <literal>DROP COLUMN</literal> command will fail for a\\n-    partitioned table, because all partitions of a table must have the same\\n-    columns as the partitioning root.\\n-   </para>\\n\\n\\n\\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\nnever removes any descendant columns, but instead marks them as\\nindependently defined rather than inherited.\\"\\n\\nThis part is now undocumented, it was only mentioned in this paragraph.\\n\\n> C2 - Sub-commands where using them with a partitioned table will automatically propagate to child partitions; ONLY prevents propagation; new partitions inherit the parent's new setting; and child partitions can be set to different values than the parent.\\n\\nThe documentation of this group is inconsistent.\\n\\nDROP CONSTRAINT mentions that individual partitions can be dropped separately:\\n\\n+      When applied to a partitioned table, the constraint is dropped from\\n+      all existing partitions unless <literal>ONLY</literal> is specified.\\n+      Individual partitions may drop constraints independently of the\\n+      partitioned table.\\n\\nBut most of the sub commands in the C2 group leave the last sentence\\nout, and also the C7 (ADD table_constraint)\\n\\nAlso, isn't DROP CONSTRAINT on a partition limited to constraints\\ndefined on that partition? So it would be better to say \\"may drop\\nconstraints defined directly on that individual partition\\nindependently\\".\\n\\n  CREATE TABLE parent (id int, val int) PARTITION BY RANGE (id);\\n  ALTER TABLE parent ADD CONSTRAINT val_positive CHECK (val > 0);\\n  CREATE TABLE child PARTITION OF parent FOR VALUES FROM (1) TO (100);\\n  ALTER TABLE child DROP CONSTRAINT val_positive;\\n  -- ERROR: cannot drop inherited constraint \\"val_positive\\" of relation \\"child\\"\\n\\n+      When a new partition is created, it generally inherits the current\\n+      definition-level properties of the parent partitioned table.\\n\\nMaybe something like the following?\\n\\nWhen a new partition is created, it generally inherits structural\\nproperties of the parent partitioned table, such as column\\ndefinitions, constraints, and storage settings.\\n\\nTo be more explicit about what's inherited, and not only focus on\\nwhat's not. (The commit message also says that the change describes\\nboth what's inherited and what's not inherited)\\n\\n\\n","threadId":"19bea52b86e5169b","snippet":"Hello Really good changes! + When applied to a partitioned table, the constraint is altered on the + partitioned table definition is implicitly applied to all partitions. an \\"and\\" is missing","historyId":"12885","internalDate":"1769162823000","receivedAtUtc":"2026-01-23T10:07:03.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>"},{"id":"19bed821ff70d0de","messageId":"<CAKFQuwZwAuO3qXEeqxwV6vM+89BkB-aSkcXqDGG8e_xBy_Q3Xw@mail.gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","body":"Thank you for the review!\\n\\nOn Fri, Jan 23, 2026 at 3:07 AM Zsolt Parragi <zsolt.parragi@percona.com>\\nwrote:\\n\\n> + When applied to a partitioned table, the constraint is altered on the\\n> + partitioned table definition is implicitly applied to all partitions.\\n>\\n> an \\"and\\" is missing here (definition and is)\\n>\\n\\nCorrect.  But I'd go with:\\n\\n...the constraint is altered on the partitioned table and implicitly\\napplied to all partitions.\\n\\n\\n\\n> +      When applied to a partitioned table, partition columns constraints\\n> +      are implicitly renamed and specifying <literal>ONLY</literal>\\n> is not allowed.\\n> +     </para>\\n>\\n> \\"partition columns constraints\\" - that seems like a strange/unclear\\n> wording to me. maybe \\", the partition's column constraints are ... \\" ?\\n>\\n\\nThis is just wrong - only is not permitted for either columns or\\nconstraints.  Only cannot be implicit if cascading is allowed.\\nThe unclear wording noted is just missing an \\"and\\" - of the three things\\nthat can be renamed (relation name, column name, constraint name) only\\nthese two apply.\\n\\"the partition columns and constraints...\\"\\n\\n     <para>\\n      When applied to a partitioned table, partition columns and constraints\\n      are implicitly renamed.\\n      Specifying <literal>ONLY</literal> is not allowed, and this command\\n      cannot be used on individual partitions.\\n     </para>\\n     <para>\\n      For inheritance setups, index-based constraints are always considered\\n      independent.  ~~Dependent columns and constraints are implicitly\\nrenamed\\n      and specifying <literal>ONLY</literal> is not allowed.~~\\n     </para>\\n\\nThe last sentence is redundant with the notes though, I'd remove it as\\nnoted above:\\n\\n   <para>\\n    For inheritance setups, the behavior described for partitioned tables\\napplies\\n    only to the dependent column(s) on the descendant table(s).  It is\\nalways\\n    allowed to target a descendant table with column altering commands on\\nindependent\\n    columns.\\n   </para>\\n\\nBut that note should have \\"dependent constraints\\" added to it.\\n\\n\\n>\\n> +     <para>\\n> +      When applied to a partitioned table <literal>ONLY</literal> is\\n> implicit,\\n> +      these forms must be applied separately to the partitioned table\\n> and/or to\\n> +      individual partitions.\\n> +     </para>\\n>\\n> \\"When applied to a partitioned table, <literal>ONLY</literal> is\\n> implicit and ...\\"  (at multiple places, this is an example)\\n>\\n\\nI've grown unfond of my suggested wording here during reviews too.  But\\nbecause it's too wordy and a bit redundant.\\n\\n\\"When applied to a partitioned table ONLY is implicit, however, this\\ncommand can be used on individual partitions.\\"\\n\\nhas a better symmetry with:\\n\\nSpecifying <literal>ONLY</literal> is not allowed, and this command cannot\\nbe used on individual partitions.\\n\\n\\n> \\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\n> never removes any descendant columns, but instead marks them as\\n> independently defined rather than inherited.\\"\\n>\\n> This part is now undocumented, it was only mentioned in this paragraph.\\n>\\n\\nTrue, it's left implied instead of explicitly stated.  Any column that\\nexists on a child but not the parent is by definition \\"independently\\ndefined\\".  So if either ONLY is supplied or the rules for cascading delete\\nare not met the result is children with independently defined columns with\\nthat name.  The original note was wrong anyway for the two-parent case -\\nthe second parent prevents the marking as independent when the first\\nparent's column is dropped.\\n\\n\\n\\n> > C2 - Sub-commands where using them with a partitioned table will\\n> automatically propagate to child partitions; ONLY prevents propagation; new\\n> partitions inherit the parent's new setting; and child partitions can be\\n> set to different values than the parent.\\n>\\n> The documentation of this group is inconsistent.\\n>\\n> DROP CONSTRAINT mentions that individual partitions can be dropped\\n> separately:\\n>\\n> +      When applied to a partitioned table, the constraint is dropped from\\n> +      all existing partitions unless <literal>ONLY</literal> is specified.\\n> +      Individual partitions may drop constraints independently of the\\n> +      partitioned table.\\n>\\n> But most of the sub commands in the C2 group leave the last sentence\\n> out, and also the C7 (ADD table_constraint)\\n>\\n\\nI didn't try and verify this dynamic or keep to it - though am on board\\nwith considering changes that do so and remain accurate.\\n\\n\\n> Also, isn't DROP CONSTRAINT on a partition limited to constraints\\n> defined on that partition? So it would be better to say \\"may drop\\n> constraints defined directly on that individual partition\\n> independently\\".\\n>\\n\\n\\"When applied to a partitioned table, dependent constraints are dropped\\nfrom ... is specified.\\" should suffice.\\nI'd be fine leaving out the entire \\"Individual partitions may drop...\\"\\nbusiness with that wording.  It implies partitions may have independent\\nconstraints which by extension may be targeted.\\n\\nFor Add Constraint - mention dependent constraints\\n\\"When applied to a partitioned table, the constraint is added to\\nthe partitioned table and dependent constraints are added to all\\npartitions.\\"\\n\\nWhich implies independent ones may exist and the logic for drop constraint\\nthen follows.\\n(We should explain what happens if a partition already has an independent\\nconstraint of the given name as that would be relevant here.)\\n\\n\\n>   CREATE TABLE parent (id int, val int) PARTITION BY RANGE (id);\\n>   ALTER TABLE parent ADD CONSTRAINT val_positive CHECK (val > 0);\\n>   CREATE TABLE child PARTITION OF parent FOR VALUES FROM (1) TO (100);\\n>   ALTER TABLE child DROP CONSTRAINT val_positive;\\n>   -- ERROR: cannot drop inherited constraint \\"val_positive\\" of relation\\n> \\"child\\"\\n>\\n> +      When a new partition is created, it generally inherits the current\\n> +      definition-level properties of the parent partitioned table.\\n>\\n> Maybe something like the following?\\n>\\n> When a new partition is created, it generally inherits structural\\n> properties of the parent partitioned table, such as column\\n> definitions, constraints, and storage settings.\\n>\\n> To be more explicit about what's inherited, and not only focus on\\n> what's not. (The commit message also says that the change describes\\n> both what's inherited and what's not inherited)\\n\\n\\nI concur with the premise but how about:\\n\\n      When a partition is created, it inherits many of the properties\\n      of the parent table.  However, properties related to ownership,\\n      schema, replica identity, row-level security configuration,\\n      per-attribute statistics targets, and per-attribute options\\n      are not inherited.\\n\\n\\"new\\" is superfluous on this page.\\n\\"definition-level\\" are the only kind of properties that exist - I'm not\\nbeing wordy thinking people might believe properties includes data.\\n\\"parent\\" suffices as well.\\nWe did all the work to identify things - use \\"however\\" instead of \\"in\\nparticular\\" to give us credit for the work.\\nEven if a property is explicitly set for the partition it isn't \\"inherited\\"\\n- the partition has its own independent value that in a rare case might\\nhappen to match the parent at the time of creation. (i.e., remove\\nautomatically and 'not inherited unless')\\nI'm not that inclined to mention the inclusion list.  The general premise\\nof assuming inherited unless told otherwise works fine here; minimal\\nfuture-proofing.\\n\\nDavid J.\\n","threadId":"19bea52b86e5169b","snippet":"Thank you for the review! On Fri, Jan 23, 2026 at 3:07 AM Zsolt Parragi <zsolt.parragi@percona.com> wrote: + When applied to a partitioned table, the constraint is altered on the + partitioned","historyId":"15682","internalDate":"1769216239000","receivedAtUtc":"2026-01-24T00:57:19.000Z","from":"\\"David G. Johnston\\" <david.g.johnston@gmail.com>"},{"id":"19bed939249f806d","messageId":"<CAKFQuwbUVLeeooQWc0TY7NJS05RexG_fOY5cz2S4H3sDGKQ_qA@mail.gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","body":"On Fri, Jan 23, 2026 at 5:57 PM David G. Johnston <\\ndavid.g.johnston@gmail.com> wrote:\\n\\n>\\n>> \\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\n>> never removes any descendant columns, but instead marks them as\\n>> independently defined rather than inherited.\\"\\n>>\\n>> This part is now undocumented, it was only mentioned in this paragraph.\\n>>\\n>\\n> True, it's left implied instead of explicitly stated.  Any column that\\n> exists on a child but not the parent is by definition \\"independently\\n> defined\\".  So if either ONLY is supplied or the rules for cascading delete\\n> are not met the result is children with independently defined columns with\\n> that name.\\n>\\n\\n\\n\\n> The original note was wrong anyway for the two-parent case - the second\\n> parent prevents the marking as independent when the first parent's column\\n> is dropped.\\n>\\n\\nDecided to test this one and I see the original wording was correct and we\\nwill need to keep a note that in the two-parent ONLY case the un-dropped\\nchildren are marked both dependent and independent.\\n\\nChange:\\n\\n     <para>\\n      For inheritance setups, a descendant column is removed only if both\\nof the\\n      following are true: this is the only parent defining the column, and\\nthe column\\n      was never independently defined in the descendant.\\n     </para>\\n\\nTo:\\n\\n\\"For inheritance setups, a descendant column is removed only if all the\\nfollowing are true: ONLY is not specified, no other parent defines the\\ncolumn, and the column is not marked as having been independent.\\nOtherwise, the descendant column is instead marked as having\\nbeen independent.\\n\\nIf we think that deserves a bit longer explanation about that/why/how a\\ncolumn can be both dependent and \\"having been independent\\" we should\\ncross-reference to a more appropriate location.  Here we just state this is\\none way that condition can materialize.\\n\\nDavid J.\\n","threadId":"19bea52b86e5169b","snippet":"On Fri, Jan 23, 2026 at 5:57 PM David G. Johnston <david.g.johnston@gmail.com> wrote: \\"A nonrecursive DROP COLUMN (ie, ALTER TABLE ONLY ... DROP COLUMN) never removes any descendant columns,","historyId":"15682","internalDate":"1769217383000","receivedAtUtc":"2026-01-24T01:16:23.000Z","from":"\\"David G. Johnston\\" <david.g.johnston@gmail.com>"}]	A documentation patch for PostgreSQL's ALTER TABLE behavior on partitioned tables is being reviewed. Zsolt Parragi provided detailed feedback on grammar errors, unclear wording, and inconsistencies. Key issues include missing conjunctions ("and"), confusing terminology like "partition columns constraints," and incomplete documentation of inheritance behavior. David Johnston responded with proposed corrections, including better wording for constraint propagation, clearer descriptions of ONLY clause behavior, and improved explanations of property inheritance when partitions are created. Johnston also clarified that dependent constraints are dropped from partitions and acknowledged that some inheritance documentation was incomplete. A follow-up correction addressed the behavior of DROP COLUMN with multiple parents, confirming that descendant columns are marked as independent when certain conditions aren't met.\n关于PostgreSQL分区表ALTER TABLE行为的文档补丁正在接受审查。Zsolt Parragi提供了详细反馈，指出语法错误、措辞不清和不一致问题。主要问题包括缺少连词("and")、"partition columns constraints"等令人困惑的术语，以及继承行为的不完整文档。David Johnston回应了建议的修正，包括约束传播的更好措辞、ONLY子句行为的更清晰描述，以及创建分区时属性继承的改进解释。Johnston还澄清了依赖约束从分区中删除，并承认某些继承文档不完整。后续修正处理了多父级DROP COLUMN的行为，确认当某些条件不满足时，后代列被标记为独立。	2026-01-24 01:16:23+00	\N
15	19bf21e9faabf42e	[PATCH] Refactor *_abbrev_convert() functions	["adigollamudi@gmail.com","aleksander@tigerdata.com"]	[{"id":"19bf21e9faabf42e","messageId":"<CAD-KL_H-jscSsTRa89W9k5+jaovTYQQv24J4f_cKi-Yr7E0PHw@mail.gmail.com>","subject":"Re: [PATCH] Refactor *_abbrev_convert() functions","body":"On Tue, Jan 13, 2026 at 4:34 AM Aleksander Alekseev <\\naleksander@tigerdata.com> wrote:\\n\\n> Hi,\\n>\\n> Now when all Datums are 64-bit values we can simplify the code by\\n> using murmurhash64(). This refactoring was previously suggested by\\n> John Naylor [1].\\n>\\n> [1]:\\n> https://postgr.es/m/CANWCAZbMyrijdR0xc-4SqpNJBHMEwRZccBK4fa0aquNpq2Uj7w%40mail.gmail.com\\n>\\n> --\\n> Best regards,\\n> Aleksander Alekseev\\n>\\n\\nHi,\\n\\nI reviewed this change and the surrounding code and this seems good!\\nAll tests pass locally for me. Hopefully this gets picked up soon.\\n\\nRegards,\\nAdi Gollamudi\\n","threadId":"19bf21e9faabf42e","snippet":"On Tue, Jan 13, 2026 at 4:34 AM Aleksander Alekseev <aleksander@tigerdata.com> wrote: Hi, Now when all Datums are 64-bit values we can simplify the code by using murmurhash64(). This refactoring","historyId":"16018","internalDate":"1769293624000","receivedAtUtc":"2026-01-24T22:27:04.000Z","from":"Aditya Gollamudi <adigollamudi@gmail.com>"}]	Aleksander Alekseev proposed a patch to refactor *_abbrev_convert() functions by simplifying the code to use murmurhash64() now that all Datums are 64-bit values. This refactoring was previously suggested by John Naylor. Aditya Gollamudi reviewed the change and confirmed it looks good, with all tests passing locally. The patch appears ready for integration, with positive feedback from the reviewer indicating no issues found during testing.\n\n现在所有Datums都是64位值，Aleksander Alekseev提出了一个补丁来重构*_abbrev_convert()函数，通过使用murmurhash64()简化代码。这个重构之前由John Naylor建议。Aditya Gollamudi审查了这个变更并确认看起来不错，所有测试在本地都通过了。该补丁看起来已准备好集成，审查者的积极反馈表明在测试期间没有发现问题。	2026-01-24 22:27:04+00	\N
14	19bec7b069713c1b	ON CONFLICT DO SELECT (take 3)	["andreas@proxel.se","dean.a.rasheed@gmail.com","jian.universality@gmail.com","marko@joh.to","v@viktorh.net"]	[{"id":"19bec7b069713c1b","messageId":"<8b107b01-6e94-4919-a3bf-66af22c17899@Spark>","subject":"Re: ON CONFLICT DO SELECT (take 3)","body":"On 21 Jan 2026 at 21:06 +0100, Viktor Holmberg <v@viktorh.net>, wrote:\\n> > There are some white spaces in v19.\\n> > Sorry, what do you mean \\"white spaces"? Is it a problem?\\n> > it's time to squash the patchset into one, IMHO.\\n> > you can also begin to write the draft commit message, explain what this is all\\n> > about.\\n> > Yes, done.\\n> > ExecOnConflictSelect\\n> > if (lockStrength == LCS_NONE)\\n> > {\\n> > /* Evem if the tuple is deleted, it must still be physically present */\\n> > Assert(table_tuple_fetch_row_version(relation, conflictTid,\\n> > SnapshotAny, existing));\\n> > }\\n> > this is wrong, i think.\\n> > buildtype=release, the Assert macro will always be true,\\n> > the whole Assert may be optimized out,\\n> > and later code would have trouble using (TupleTableSlot *existing).\\n> > Yes, you're right. Nice catch. Fixed.\\n> > updatable_views.sql: I did some ON CONFLICT DO SELECT permissions checks, and\\n> > other tests in it, please check attached.\\n> > Added\\n> >\\n> > -----\\n> > I've updated all the comments you mentioned.\\n> > Thanks for the review Jian, I'm hoping we've caught all the issues now.\\n> > Please find v20 attached.\\nI went through all mentions of ON CONFLICT in the codebase to see there are no more forgotten comments/docs, and found 2 more places to update.\\n","threadId":"19bec7b069713c1b","snippet":"On 21 Jan 2026 at 21:06 +0100, Viktor Holmberg <v@viktorh.net>, wrote: There are some white spaces in v19. Sorry, what do you mean \\"white spaces"? Is it a problem? it's time to squash","historyId":"13636","internalDate":"1769199000000","receivedAtUtc":"2026-01-23T20:10:00.000Z","from":"Viktor Holmberg <v@viktorh.net>"},{"id":"19bedccbb83544ef","messageId":"<CACJufxH0sycCGgmSjG=SxvdwmL26T+Jf=ZrTEtQaMZTEbVWiVg@mail.gmail.com>","subject":"Re: ON CONFLICT DO SELECT (take 3)","body":"On Thu, Jan 22, 2026 at 4:05 AM Viktor Holmberg <v@viktorh.net> wrote:\\n>\\n> There are some white spaces in v19.\\n>\\n> Sorry, what do you mean \\"white spaces"? Is it a problem?\\n\\nyou can use ``git diff --check`` to find out these white spaces.\\nThe attached file should be able to fix these issues.\\n\\n+-- DO SELECT FOR UPDATE requires UPDATE rights, should fail for non-novel\\n+INSERT INTO document VALUES (33, (SELECT cid from category WHERE\\ncname = 'science fiction'), 1, 'regress_rls_bob', 'another sci-fi')\\n+    ON CONFLICT (did) DO SELECT FOR UPDATE RETURNING did, dauthor, dtitle;\\n+ERROR:  new row violates row-level security policy for table \\"document\\"\\n\\nThe above comment is wrong. If i place\\n\\nINSERT INTO document VALUES (33, (SELECT cid from category WHERE cname\\n= 'science fiction'), 1, 'regress_rls_bob', 'another sci-fi')\\nON CONFLICT (did) DO NOTHING;\\n\\nbefore the above tests, it will still fail, it will fail on SELECT\\npolicy, p1_select_novels.\\nwe can remove the above tests or rephrase the comment.\\n\\n+CREATE POLICY p3_update_novels ON document FOR UPDATE\\n+  USING (cid = (SELECT cid from category WHERE cname = 'novel') AND dlevel = 1)\\n+  WITH CHECK (dauthor = current_user);\\n\\nMy understanding of the change in get_row_security_policies is that, ON CONFLICT\\nDO SELECT FOR UPDATE, the UPDATE WITH CHECK policy clause is never evaluated.\\nFor testing purposes, we could change  the above\\n+WITH CHECK (dauthor = current_user);\\nto\\n+WITH CHECK (dauthor = current_user AND false);\\n\\nThis leads to the next issue in ExecOnConflictSelect->ExecWithCheckOptions.\\n+ if (resultRelInfo->ri_WithCheckOptions != NIL)\\n+ {\\n+ /*\\n+ * Check target's existing tuple against SELECT-applicable USING\\n+ * security barrier quals (if any), enforced here as RLS checks/WCOs.\\n+ *\\n+ * The rewriter creates SELECT RLS checks/WCOs for SELECT security\\n+ * quals, and stores them as WCOs of \\"kind\\" WCO_RLS_CONFLICT_CHECK. If\\n+ * FOR UPDATE/SHARE was specified, UPDATE rights are required on the\\n+ * target table, and the rewriter also adds UPDATE RLS checks/WCOs for\\n+ * UPDATE security quals, using WCOs of the same kind, so this check\\n+ * enforces them too.\\n+ */\\n+ ExecWithCheckOptions(WCO_RLS_CONFLICT_CHECK, resultRelInfo,\\n+ existing,\\n+ mtstate->ps.state);\\n+ }\\nthe comment I am not sure I fully understand, especially the last sentence.\\n\\nMy understanding is that\\nFor ON CONFLICT DO SELECT FOR UPDATE, both the SELECT USING and UPDATE USING\\nclauses are evaluated.  If either evaluates to false, the row is not silently\\nignored; instead, an error is raised.\\nUPDATE CHECK clause was never evaluated.\\n\\nMaybe we need to rephrase the above comments.\\n\\n>\\n> it's time to squash the patchset into one, IMHO.\\n> you can also begin to write the draft commit message, explain what this is all\\n> about.\\n>\\n> Yes, done.\\n>\\n> ExecOnConflictSelect\\n> if (lockStrength == LCS_NONE)\\n> {\\n> /* Evem if the tuple is deleted, it must still be physically present */\\n> Assert(table_tuple_fetch_row_version(relation, conflictTid,\\n> SnapshotAny, existing));\\n> }\\n> this is wrong, i think.\\n> buildtype=release, the Assert macro will always be true,\\n> the whole Assert may be optimized out,\\n> and later code would have trouble using (TupleTableSlot *existing).\\n>\\n> Yes, you're right. Nice catch. Fixed.\\n>\\n\\nit still have problem with release branch,\\nsee https://cirrus-ci.com/task/5061396800471040?logs=gcc_warning#L454\\n\\nI intended to change it as\\n```\\n    if (lockStrength == LCS_NONE)\\n    {\\n        if (!table_tuple_fetch_row_version(relation,\\n                                           conflictTid,\\n                                           SnapshotAny,\\n                                           existing))\\n            elog(ERROR, \\"failed to fetch conflicting tuple for ON CONFLICT\\");\\n    }\\n```\\n\\n     * For ON CONFLICT .. UPDATE we just need the inner tlist to point to the\\n     * excluded expression's tlist. (Similar to the SubqueryScan we don't want\\n     * to reuse OUTER, it's used for RETURNING in some modify table cases,\\n     * although not INSERT .. CONFLICT).\\nthe above comments in set_deparse_plan need apply to ON CONFLICT DO SELECT\\n\\n\\ntypedef enum WCOKind, WCOKind\\nWCO_RLS_CONFLICT_CHECK,        /* RLS ON CONFLICT DO UPDATE USING policy */\\nthe comments need to be adjusted.\\n\\nThe discussion link should be these three.\\nDiscussion: https://postgr.es/m/5fca222d-62ae-4a2f-9fcb-0eca56277094@Spark\\nDiscussion: https://postgr.es/m/2b5db2e6-8ece-44d0-9890-f256fdca9f7e@proxel.se\\nDiscussion: https://postgr.es/m/d631b406-13b7-433e-8c0b-c6040c4b4663@Spark\\n\\nSince there have been some discussions about the author, we can also mention\\nauthors in the commit message.\\n","threadId":"19bec7b069713c1b","snippet":"On Thu, Jan 22, 2026 at 4:05 AM Viktor Holmberg <v@viktorh.net> wrote: > > There are some white spaces in v19. > > Sorry, what do you mean \\"white spaces"? Is it a problem? you","historyId":"15683","internalDate":"1769221129000","receivedAtUtc":"2026-01-24T02:18:49.000Z","from":"jian he <jian.universality@gmail.com>"}]	Viktor Holmberg submitted version 20 of the ON CONFLICT DO SELECT patch after addressing review feedback from Jian He. The discussion covers several technical issues: whitespace problems detectable with `git diff --check`, incorrect comments in row-level security tests, and a critical bug in release builds where Assert macros are optimized out, potentially causing undefined behavior with the `existing` tuple slot. Jian suggested replacing the problematic Assert with proper error handling using `elog(ERROR)`. Additional concerns include clarifying RLS policy evaluation behavior, updating comments about WCOKind enum values, and ensuring proper documentation links are included in the commit message. Viktor mentioned finding two more places in the codebase requiring updates for ON CONFLICT references.\nViktor Holmberg 提交了 ON CONFLICT DO SELECT 补丁的第 20 版，解决了 Jian He 的审查反馈。讨论涵盖几个技术问题：可通过 `git diff --check` 检测的空白字符问题、行级安全测试中的错误注释，以及发布版本中的关键 bug，其中 Assert 宏被优化掉，可能导致 `existing` 元组槽的未定义行为。Jian 建议用 `elog(ERROR)` 的适当错误处理替换有问题的 Assert。其他关注点包括澄清 RLS 策略评估行为、更新 WCOKind 枚举值的注释，以及确保在提交消息中包含适当的文档链接。Viktor 提到在代码库中发现还有两处需要更新 ON CONFLICT 引用的地方。	2026-01-24 02:18:49+00	\N
14	19be6bab3032bd29	Remove PG_MMAP_FLAGS	["ashutosh.bapat.oss@gmail.com","michael@paquier.xyz","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19be8b43b82e94ad","messageId":"<CAExHW5ugLWtxiLZbAg0vBZac=Aix6J7Xt7DB7Reb8od-+vwkxQ@mail.gmail.com>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 4:53 AM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Thu, Jan 22, 2026 at 02:17:08PM -0500, Tom Lane wrote:\\n> > Ashutosh Bapat <ashutosh.bapat.oss@gmail.com> writes:\\n> >> Over [1] Peter mentioned that PG_MMAP_FLAGS is not used for\\n> >> portability even though it's placed in portability/mem.h. That might\\n> >> have been the intention when it was added in\\n> >> b0fc0df9364d2d2d17c0162cf3b8b59f6cb09f67. But history does not show it\\n> >> being used that way at any point in time. Per suggestion removing that\\n> >> macro and instead using the flags directly in CreateAnonymousSegment()\\n> >> which is the only place where it's used.\\n> >\\n> > I think you attached the wrong patch?  This one doesn't touch\\n> > PG_MMAP_FLAGS.\\n\\nI didn't do a good job writing that email: attached wrong patch and\\nalso didn't provide the required reference. Sorry for that. Corrected\\nin this email.\\n\\n>\\n> PG_MMAP_FLAGS is still used in two places in sysv_shmem.c, where I\\n> guess the intention of Robert back in b0fc0df9364d was to not\\n> copy-paste the same flag values multiple times.  I can still get the\\n> intention even today, so, if we were to do something, why don't you\\n> just make PG_MMAP_FLAGS local to sysv_shmem.c and call it a day?\\n>\\n> Honestly, I don't think that we should change this code at all: I also\\n> like the current idea of PG_MMAP_FLAGS being defined in the same place\\n> where we check for HASSEMAPHORE and ANONYMOUS, so it comes down to\\n> this being a matter of taste.\\n\\nAs Peter mentioned in the shared buffers resizing thread [1] it's\\nplacement and name in mem.h led us to think that it affects all mmap\\ncalls or that all mmap calls should use those flags. Neither of which\\nis true. We have different mmap calls using different set of flags.\\nAttached patch proposes changes similar (not exact) as you suggest\\nabove. Please take a look.\\n\\n[1] https://www.postgresql.org/message-id/12add41a-7625-4639-a394-a5563e349322@eisentraut.org\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 4:53 AM Michael Paquier <michael@paquier.xyz> wrote: > > On Thu, Jan 22, 2026 at 02:17:08PM -0500, Tom Lane wrote: > > Ashutosh Bapat <ashutosh.bapat.oss@","historyId":"8716","internalDate":"1769135658000","receivedAtUtc":"2026-01-23T02:34:18.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19be929c270c15ed","messageId":"<aXL8TKH2dvt7EgLO@paquier.xyz>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote:\\n> As Peter mentioned in the shared buffers resizing thread [1] it's\\n> placement and name in mem.h led us to think that it affects all mmap\\n> calls or that all mmap calls should use those flags. Neither of which\\n> is true. We have different mmap calls using different set of flags.\\n> Attached patch proposes changes similar (not exact) as you suggest\\n> above. Please take a look.\\n> \\n> [1] https://www.postgresql.org/message-id/12add41a-7625-4639-a394-a5563e349322@eisentraut.org\\n\\nOkay, point taken.  I can live with your patch suggestion based on\\nwhat you have attached.\\n--\\nMichael\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote: > As Peter mentioned in the shared buffers resizing thread [1] it's > placement and name in mem.h led us to think that it","historyId":"8716","internalDate":"1769143372000","receivedAtUtc":"2026-01-23T04:42:52.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19bea4f7f8cf29db","messageId":"<CAExHW5uN1T2LRf7WypNT8ZyJ0yY_pp4Zo4uNH7m_Pxr1AuW0nQ@mail.gmail.com>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 10:12 AM Michael Paquier <michael@paquier.xyz> wrote:\\n>\\n> On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote:\\n> > As Peter mentioned in the shared buffers resizing thread [1] it's\\n> > placement and name in mem.h led us to think that it affects all mmap\\n> > calls or that all mmap calls should use those flags. Neither of which\\n> > is true. We have different mmap calls using different set of flags.\\n> > Attached patch proposes changes similar (not exact) as you suggest\\n> > above. Please take a look.\\n> >\\n> > [1] https://www.postgresql.org/message-id/12add41a-7625-4639-a394-a5563e349322@eisentraut.org\\n>\\n> Okay, point taken.  I can live with your patch suggestion based on\\n> what you have attached.\\n\\nThanks.\\n\\nI revised the patch a bit. The macro had parenthesis around the macro\\ndefinition which are not required in the assignment. Removed them.\\nAlso revised the commit message a bit.\\n\\n-- \\nBest Wishes,\\nAshutosh Bapat\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 10:12 AM Michael Paquier <michael@paquier.xyz> wrote: > > On Fri, Jan 23, 2026 at 08:04:18AM +0530, Ashutosh Bapat wrote: > > As Peter mentioned in the shared","historyId":"12870","internalDate":"1769162613000","receivedAtUtc":"2026-01-23T10:03:33.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>"},{"id":"19bede56dbea9902","messageId":"<aXQydVFtu3LTAdqG@paquier.xyz>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 03:33:33PM +0530, Ashutosh Bapat wrote:\\n> I revised the patch a bit. The macro had parenthesis around the macro\\n> definition which are not required in the assignment. Removed them.\\n> Also revised the commit message a bit.\\n\\nWFM.\\n--\\nMichael\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 03:33:33PM +0530, Ashutosh Bapat wrote: > I revised the patch a bit. The macro had parenthesis around the macro > definition which are not required in the assignment.","historyId":"15679","internalDate":"1769222773000","receivedAtUtc":"2026-01-24T02:46:13.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	The discussion centers on removing the PG_MMAP_FLAGS macro from PostgreSQL's portability/mem.h header file. Ashutosh Bapat proposed the change after Peter Eisentraut noted that despite its placement in a portability header, the macro isn't actually used for portability purposes and has never been used that way historically. The macro is only used in CreateAnonymousSegment() and two places in sysv_shmem.c. Initially, Michael Paquier suggested making PG_MMAP_FLAGS local to sysv_shmem.c rather than removing it entirely. However, after Ashutosh explained that the macro's placement and name in mem.h misleadingly suggests it affects all mmap calls when different mmap calls actually use different flag sets, Michael agreed with the proposed patch. Ashutosh refined the patch by removing unnecessary parentheses from the macro definition and revising the commit message, which Michael approved.\n\n讨论的焦点是从PostgreSQL的portability/mem.h头文件中移除PG_MMAP_FLAGS宏。Ashutosh Bapat在Peter Eisentraut指出尽管该宏位于可移植性头文件中，但实际上并未用于可移植性目的且历史上从未这样使用后提出了这一更改。该宏仅在CreateAnonymousSegment()和sysv_shmem.c中的两个地方使用。最初，Michael Paquier建议将PG_MMAP_FLAGS设为sysv_shmem.c的本地宏而不是完全移除它。然而，在Ashutosh解释该宏在mem.h中的位置和名称会误导性地暗示它影响所有mmap调用，而实际上不同的mmap调用使用不同的标志集后，Michael同意了提议的补丁。Ashutosh通过移除宏定义中不必要的括号并修订提交消息来完善了补丁，Michael对此表示认可。	2026-01-24 02:46:13+00	\N
14	19be79057d59089e	[PATCH] Align verify_heapam.c error message offset with test expectations	["khoaduynguyen@gmail.com","zengman@halodbtech.com"]	[{"id":"19bee91d8a6c9fb3","messageId":"<tencent_556F0A9A3E4C0D1E2E20B32F@qq.com>","subject":"Re: [PATCH] Align verify_heapam.c error message offset with test expectations","body":"> Both patches look great to me.\\n\\nHi,\\n\\nI truly appreciate your approval, along with your thorough review and valuable insights. \\nThat said, I don't plan to make further revisions to Patch 1 at this stage—and I tend to think that Patch 2 might just be sufficient on its own. \\nOf course, this will ultimately depend on the committers.\\nThanks again!\\n\\n--\\nRegards,\\nMan Zeng\\nwww.openhalo.org","threadId":"19be79057d59089e","snippet":"> Both patches look great to me. Hi, I truly appreciate your approval, along with your thorough review and valuable insights. That said, I don't plan to make further revisions to Patch 1 at this","historyId":"15680","internalDate":"1769234051000","receivedAtUtc":"2026-01-24T05:54:11.000Z","from":"zengman <zengman@halodbtech.com>"}]	Man Zeng responds to positive feedback on two patches addressing verify_heapam.c error message offset alignment with test expectations. While appreciating the thorough review and approval, Zeng indicates no plans for further revisions to Patch 1 and suggests Patch 2 might be sufficient alone. The decision on which patch to proceed with is deferred to the committers. This appears to be the conclusion of a code review process where the patches have received approval but implementation strategy remains to be determined by project maintainers.\n曼增回应了关于两个补丁的积极反馈，这些补丁解决了verify_heapam.c错误消息偏移量与测试期望的对齐问题。虽然感谢彻底的审查和批准，曾表示不计划进一步修订补丁1，并建议补丁2可能单独就足够了。采用哪个补丁的决定留给提交者决定。这似乎是代码审查过程的结论，补丁已获得批准，但实施策略仍有待项目维护者确定。	2026-01-24 05:54:11+00	\N
14	19bed39e57f8cfa7	libpq: Bump protocol version to version 3.2 at least until the first/second beta	["andres@anarazel.de","hlinnaka@iki.fi","jacob.champion@enterprisedb.com","postgres@jeltef.nl","robertmhaas@gmail.com"]	[{"id":"19bed39e57f8cfa7","messageId":"<CAOYmi+m64_emVRc+33m2W1kK2X0iTeE6oX395joCeVey1ohwyQ@mail.gmail.com>","subject":"Re: libpq: Bump protocol version to version 3.2 at least until the first/second beta","body":"On Wed, Jan 14, 2026 at 2:56 PM Jacob Champion\\n<jacob.champion@enterprisedb.com> wrote:\\n> Thanks, I'll plan to squash those in v5, and probably kick 0005 out\\n> into its own thread to give people a chance to object even if they're\\n> ignoring the grease stuff.\\n\\n0001, 0003, and 0005 are committed. v5 is attached with several\\nchanges, described below.\\n\\nOn Wed, Jan 14, 2026 at 12:23 PM Jacob Champion\\n<jacob.champion@enterprisedb.com> wrote:\\n> I want to more clearly decouple ourselves from TLS's GREASE in the\\n> documentation and comments.\\n\\nDone. Unfortunately the rewrites were too difficult to put into nice\\nsquash! commits, since they ended up being spread across the split\\ndescribed below, so I've also attached an \\"overall\\" diff file to try\\nto highlight what I changed from v3-0002.\\n\\nOne thing I tried to do here was separate the beta-only behavior into\\n<note>s, so that documentation writers can still review and patch the\\nlanguage that's going to be published for release. I don't think that\\nwill confuse the limited audience that is going to be reading this.\\n\\n> I will also work on splitting 0002 into revertable and not-revertable\\n> halves. The grease constant probably needs to remain documented and\\n> reserved even if it doesn't do anything for 19.0.\\n\\nDone. My proposed split is in v5-0002 (which stays) and -0003 (which\\ngets reverted).\\n\\nI also added an 0001 which (IMO) improves our documentation around\\nthis, and adds a registry of sorts for the protocol extension\\nparameters. I'm not completely thrilled about the code and formatting\\nof that new registry table, but I think what I have is better than\\nnothing, so I'm going to stop fighting with docbook about this.\\n\\n> I'd like reserve a (protected?) wiki page, or something of the sort,\\n> that we can point people to directly if they hit any grease failures.\\n\\nThis still needs to be done/discussed, but we have a good amount of time.\\n\\n> Finally: is there any appetite for retaining the ability to grease\\n> connections as production functionality, e.g. via\\n> `max_protocol_version=grease`?\\n\\nThis is on the back burner for now. (As stated upthread, it doesn't\\nneed to block the beta-only behavior.)\\n\\nWDYT?\\n\\nThanks,\\n--Jacob\\n","threadId":"19bed39e57f8cfa7","snippet":"On Wed, Jan 14, 2026 at 2:56 PM Jacob Champion <jacob.champion@enterprisedb.com> wrote: > Thanks, I'll plan to squash those in v5, and probably kick 0005 out > into its own thread to","historyId":"13821","internalDate":"1769211528000","receivedAtUtc":"2026-01-23T23:38:48.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"},{"id":"19bed3ad7a3e8642","messageId":"<DFWD62XXC6TD.A9V3T95DHNNH@jeltef.nl>","subject":"Re: libpq: Bump protocol version to version 3.2 at least until the first/second beta","body":"On Thu Jan 15, 2026 at 1:31 AM CET, Jacob Champion wrote:\\n> Per offline confusion/discussion: I plan to work on a grease feature\\n> for beta _regardless_ of whether a \\"production-grade\\"\\n> max_protocol_version=grease option turns out to be viable before\\n> feature freeze; I saw that you committed a few patches. Given that you said you wanted\\nto wordsmith the last one, this seemed like a good time to send in some\\nof my own improvements in that regard. (I did not change the GREASE\\nmentions, since you clearly had something in mind for those).\\n\\n0001 is mine an your squash commit, squashed together and rebased on top of main.\\n\\n0002 is the improvements to the docs. The one important thing is a\\nchange from 3.2 to 3.0. Other than that it introduces a table for\\ntracking protocol extensions. That way other patches (like GoAway)\\nthat introduce a protocol extension already have some location in\\nthe docs where it can be listed.\\n\\n\\n0003-0005 are an attempt at making a bit more of a robust GREASE. 0003\\nmakes it \\"harder to still implement negotation incorrectly\\". Then 0004\\nmakes it not a hard failure if you connect with\\nmax_protocol_version=grease to a new server. Then 0005 adds some\\npreliminary docs. These almost certainly need some more discussion. And\\nI don't expect them to necessarily get in for PG19, but if you like some\\nof it feel free to pick and take what you want from them. e.g. the\\nrandomized protocol extensions are kinda nice IMO. But I'm not exactly\\nsure if the randomized version number is that much more useful though\\nthan a fixed one.\\n","threadId":"19bed39e57f8cfa7","snippet":"On Thu Jan 15, 2026 at 1:31 AM CET, Jacob Champion wrote: > Per offline confusion/discussion: I plan to work on a grease feature > for beta _regardless_ of whether a \\"production-grade\\"","historyId":"13821","internalDate":"1769211596000","receivedAtUtc":"2026-01-23T23:39:56.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"},{"id":"19bed3ca5d56b427","messageId":"<CAOYmi+nDerbuXOauDBBkZ4KVWf=htKfgW+OHhXZ47qT3UMkf7Q@mail.gmail.com>","subject":"Re: libpq: Bump protocol version to version 3.2 at least until the first/second beta","body":"On Fri, Jan 23, 2026 at 3:40 PM Jelte Fennema-Nio <postgres@jeltef.nl> wrote:\\n> I saw that you committed a few patches. Given that you said you wanted\\n> to wordsmith the last one, this seemed like a good time to send in some\\n> of my own improvements in that regard.\\n\\n(Well, that was impressive timing.)\\n\\n--Jacob\\n\\n\\n","threadId":"19bed39e57f8cfa7","snippet":"On Fri, Jan 23, 2026 at 3:40 PM Jelte Fennema-Nio <postgres@jeltef.nl> wrote: > I saw that you committed a few patches. Given that you said you wanted > to wordsmith the last one, this","historyId":"13821","internalDate":"1769211712000","receivedAtUtc":"2026-01-23T23:41:52.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"},{"id":"19bef7c346ac806a","messageId":"<CAGECzQTtBa6u2-dxv83g_-7ssop-Ds5-DFibrUin+RfDOtsJFg@mail.gmail.com>","subject":"Re: libpq: Bump protocol version to version 3.2 at least until the first/second beta","body":"On Sat, 24 Jan 2026 at 00:38, Jacob Champion\\n<jacob.champion@enterprisedb.com> wrote:\\n> WDYT?\\n\\nOverall, I think the changes and the split look fine. And I'd be happy\\nwith having it committed as is.\\n\\nA few thoughts on the docs:\\n1. I like the version table split. I think it might be better to do\\nthe same for protocol extensions too. Primarily because I think the\\ntiny empty cell at the start of each row looks weird (see screenshot),\\nbut also just for consistency.\\n2. In my v5 I created a dedicated section header for protocol\\nextensions instead of including it in the extension. I think that's\\nslightly nicer, primarily so you can link to that section from the\\nStartupMessage docs (including the introductory paragraph), instead of\\nhaving to link to the table.\\n3. In the table in my v5 I use \\"extension name\\" as a column instead of\\n\\"parameter name\\" so I did not have to include the \\"_pq_.\\" prefix. I'm\\ngoing a bit back and forth between which I like better.\\n4. I think mentioning the \\"_pq_.\\" prefix in the paragraph above the\\nextension table would be good. Otherwise once we get more extensions\\nyou only learn about it once you get to the reserved extensions\\nsection.\\n\\nA few thoughts on the implementation:\\n1. If you like the randomization I did in my v5-0003, but don't want\\nto commit it yet. Then I think it would be good to change the reserved\\nprotocol extension to rename to _pq_.test_protocol_negotiation_0000.\\nSo that if we commit it later we don't have both\\n_pq_.test_protocol_negotiation and _pq_.test_protocol_negotiation_XXXX\\nreserved, but only have the one with a suffix reserved.\\n2. It might be nice to also error duplicate keys in NegotiateProtocolVersion.\\n","threadId":"19bed39e57f8cfa7","snippet":"On Sat, 24 Jan 2026 at 00:38, Jacob Champion <jacob.champion@enterprisedb.com> wrote: > WDYT? Overall, I think the changes and the split look fine. And I'd be happy with having it","historyId":"15685","internalDate":"1769249427000","receivedAtUtc":"2026-01-24T10:10:27.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"}]	Jacob Champion has committed several patches related to libpq protocol version bumping and is working on v5 with significant changes. The discussion focuses on implementing GREASE functionality for beta testing to identify protocol negotiation issues in third-party clients. Champion has split the work into revertable and non-revertable components, with v5-0002 staying and v5-0003 being reverted after beta. Key changes include decoupling from TLS GREASE documentation, adding a protocol extension registry table, and separating beta-only behavior into documentation notes. Jelte Fennema-Nio provided feedback on documentation improvements, suggesting better table formatting for protocol extensions, dedicated section headers, and implementation enhancements like randomized protocol extensions. Both developers agree the current split approach is acceptable, though some refinements to documentation structure and error handling for duplicate keys in NegotiateProtocolVersion are suggested.\n\nJacob Champion已提交了几个与libpq协议版本升级相关的补丁，正在开发包含重大更改的v5版本。讨论重点是为beta测试实现GREASE功能，以识别第三方客户端中的协议协商问题。Champion将工作拆分为可回滚和不可回滚的组件，其中v5-0002保留，v5-0003在beta后回滚。主要更改包括与TLS GREASE文档解耦，添加协议扩展注册表，以及将仅限beta的行为分离到文档注释中。Jelte Fennema-Nio对文档改进提供了反馈，建议改善协议扩展的表格格式、使用专用章节标题，以及实现增强功能如随机化协议扩展。两位开发者都认为当前的拆分方法是可接受的，尽管建议对文档结构和NegotiateProtocolVersion中重复键的错误处理进行一些优化。	2026-01-24 10:10:27+00	\N
14	19beed7dde2b545a	proposal: plpgsql - FOREACH t IN JSON ARRAY expr	["pavel.stehule@gmail.com"]	[{"id":"19beed7dde2b545a","messageId":"<CAFj8pRB858EmA2xqaWQMUs_bYmLNZY8eBS2zP+wrg0vyT97gDA@mail.gmail.com>","subject":"proposal: plpgsql - FOREACH t IN JSON ARRAY expr","body":"Hi,\\n\\nlast year I did a performance audit of some applications and I found a new\\nrelatively common pattern - iteration over jsonb arrays. Because PL/pgSQL\\ndoesn't support this iteration directly, they used some combinations of\\njsonb_array_elements function and FOR IN SELECT.\\n\\nThe overhead of this can be relatively high, and I think we can support\\nFOREACH json(b) arrays without some high cost.\\n\\nMy idea is a support of syntax\\n\\nFOREACH target IN JSON ARRAY expression LOOP .. END LOOP\\n\\ntarget can be a scalar variable of any type - we can use cast rules used in\\nJSON_TABLE\\n\\nWhat do you think about this proposal?\\n\\nRegards\\n\\nPavel\\n","threadId":"19beed7dde2b545a","snippet":"Hi, last year I did a performance audit of some applications and I found a new relatively common pattern - iteration over jsonb arrays. Because PL/pgSQL doesn't support this iteration directly,","historyId":"15689","internalDate":"1769238636000","receivedAtUtc":"2026-01-24T07:10:36.000Z","from":"Pavel Stehule <pavel.stehule@gmail.com>"},{"id":"19befbe438bd85a3","messageId":"<CAFj8pRDKi0m==eAnE0q3Dfjbe=0kY2N9qGhduhJTUr7zOJDn9A@mail.gmail.com>","subject":"Re: proposal: plpgsql - FOREACH t IN JSON ARRAY expr","body":"so 24. 1. 2026 v 8:10 odesílatel Pavel Stehule <pavel.stehule@gmail.com>\\nnapsal:\\n\\n> Hi,\\n>\\n> last year I did a performance audit of some applications and I found a new\\n> relatively common pattern - iteration over jsonb arrays. Because PL/pgSQL\\n> doesn't support this iteration directly, they used some combinations of\\n> jsonb_array_elements function and FOR IN SELECT.\\n>\\n> The overhead of this can be relatively high, and I think we can support\\n> FOREACH json(b) arrays without some high cost.\\n>\\n> My idea is a support of syntax\\n>\\n> FOREACH target IN JSON ARRAY expression LOOP .. END LOOP\\n>\\n\\nI did some simple test\\n\\nCREATE OR REPLACE FUNCTION public.randoma(integer)\\n RETURNS integer[]\\n LANGUAGE sql\\nAS $function$\\nselect array_agg(random()*10000) from generate_series(1,$1)\\n$function$\\n\\nCREATE OR REPLACE FUNCTION public.suma(integer[])\\n RETURNS integer\\n LANGUAGE plpgsql\\n IMMUTABLE\\nAS $function$\\ndeclare s int default 0;\\n f int;\\nbegin\\n  foreach f in array $1 loop s := s + f; end loop;\\n  return s;\\nend;\\n$function$\\n\\nCREATE OR REPLACE FUNCTION public.sumj(jsonb)\\n RETURNS integer\\n LANGUAGE plpgsql\\n IMMUTABLE\\nAS $function$\\ndeclare s int default 0;\\n f int;\\nbegin\\n  for f in select v from jsonb_array_elements($1) g(v) loop s := s +\\nf::int; end loop;\\n  return s;\\nend;\\n$function$\\n\\n(2026-01-24 12:20:07) postgres=# do $$\\ndeclare a int[] = randoma(10000);\\nbegin\\n  for i in 1..1000 loop\\n    perform suma(a);\\n  end loop;\\nend;\\n$$;\\nDO\\nTime: 2705,881 ms (00:02,706)\\n(2026-01-24 12:20:11) postgres=# do $$\\ndeclare a jsonb = array_to_json(randoma(10000));\\nbegin\\n  for i in 1..1000 loop\\n    perform sumj(a);\\n  end loop;\\nend;\\n$$;\\nDO\\nTime: 25809,319 ms (00:25,809)\\n\\nFOREACH is +/- 10 times faster\\n\\n\\n\\n\\n\\n\\n>\\n> target can be a scalar variable of any type - we can use cast rules used\\n> in JSON_TABLE\\n>\\n> What do you think about this proposal?\\n>\\n> Regards\\n>\\n> Pavel\\n>\\n","threadId":"19beed7dde2b545a","snippet":"so 24. 1. 2026 v 8:10 odesílatel Pavel Stehule <pavel.stehule@gmail.com> napsal: Hi, last year I did a performance audit of some applications and I found a new relatively common pattern -","historyId":"15689","internalDate":"1769253735000","receivedAtUtc":"2026-01-24T11:22:15.000Z","from":"Pavel Stehule <pavel.stehule@gmail.com>"}]	Pavel Stehule proposes adding native support for iterating over JSON/JSONB arrays in PL/pgSQL through a new syntax: "FOREACH target IN JSON ARRAY expression LOOP .. END LOOP". This addresses a common performance bottleneck where developers currently use jsonb_array_elements() with FOR IN SELECT loops. Pavel's benchmarks demonstrate that direct array iteration using FOREACH is approximately 10 times faster than the current JSON array iteration approach. The proposal suggests using JSON_TABLE cast rules for type conversion. The target variable can be of any scalar type, leveraging existing casting mechanisms. This enhancement would provide significant performance improvements for applications that frequently iterate over JSONB arrays, which Pavel identified as an increasingly common pattern during performance audits.\n\nPavel Stehule提议在PL/pgSQL中添加对JSON/JSONB数组迭代的原生支持，通过新语法："FOREACH target IN JSON ARRAY expression LOOP .. END LOOP"。这解决了开发者目前使用jsonb_array_elements()与FOR IN SELECT循环的常见性能瓶颈。Pavel的基准测试显示，使用FOREACH进行直接数组迭代比当前JSON数组迭代方法快约10倍。该提案建议使用JSON_TABLE的类型转换规则。目标变量可以是任何标量类型，利用现有的类型转换机制。这一增强将为频繁迭代JSONB数组的应用程序提供显著的性能改进，Pavel在性能审计中发现这是一个日益常见的模式。	2026-01-24 11:22:15+00	\N
14	19bf07c83663338a	unclear OAuth error message	["alvherre@kurilemu.de","jacob.champion@enterprisedb.com"]	[{"id":"19bf07c83663338a","messageId":"<202601241015.y5uvxd7oxnfs@alvherre.pgsql>","subject":"unclear OAuth error message","body":"Hello,\\n\\nWhile updating the translation, I noticed this code\\n\\n    /*\\n     * Log any authentication results even if the token isn't authorized; it\\n     * might be useful for auditing or troubleshooting.\\n     */\\n    if (ret->authn_id)\\n        set_authn_id(port, ret->authn_id);\\n\\n    if (!ret->authorized)\\n    {\\n        ereport(LOG,\\n                errmsg(\\"OAuth bearer authentication failed for user \\\\\\"%s\\\\\\"\\",\\n                       port->user_name),\\n                errdetail_log(\\"Validator failed to authorize the provided token.\\"));\\n\\n        status = false;\\n        goto cleanup;\\n    }\\n\\nI'm not sure I understand the errdetail() part of it.  At first it made\\nme wonder if it was about a user-supplied module that had an internal\\nfailure preventing it from deciding whether the user was authorized or\\nnot (which would have been something like \\"Validator failed while ...\\").\\nBut the code suggests that the module worked fine and made the\\ndetermination not to authorize the user.  If that's so, then why do we\\nhave the errdetail at all?  Can't we just get rid of it and let the\\nerrmsg stand on its own merit?\\n\\nThere is one more case for this exact errmsg to be given:\\n\\n    /* Make sure the validator authenticated the user. */\\n    if (ret->authn_id == NULL || ret->authn_id[0] == '\\\\0')\\n    {\\n        ereport(LOG,\\n                errmsg(\\"OAuth bearer authentication failed for user \\\\\\"%s\\\\\\"\\",\\n                       port->user_name),\\n                errdetail_log(\\"Validator provided no identity.\\"));\\n\\nHere it seems the validator did indeed have an internal problem of some\\nsort, because while it did declare that the user was authorized, it did\\nnot provide what we were expecting from it.  Should in this case the\\nerrmsg() be different?\\n\\n(Actually, there's also auth_failed() giving the same message.)\\n\\n-- \\nÁlvaro Herrera         PostgreSQL Developer  —  https://www.EnterpriseDB.com/\\n\\"The saddest aspect of life right now is that science gathers knowledge faster\\n than society gathers wisdom.\\"  (Isaac Asimov)\\n\\n\\n","threadId":"19bf07c83663338a","snippet":"Hello, While updating the translation, I noticed this code /* * Log any authentication results even if the token isn't authorized; it * might be useful for auditing or troubleshooting. */ if (ret-","historyId":"15691","internalDate":"1769266228000","receivedAtUtc":"2026-01-24T14:50:28.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"}]	Álvaro Herrera raises concerns about unclear OAuth error messaging in PostgreSQL's authentication code while updating translations. He questions the usefulness of the errdetail_log message "Validator failed to authorize the provided token" when the OAuth validator successfully determined that a user should not be authorized, suggesting the detail message might be redundant. He also notes a second case where the same errmsg appears but with different errdetail when the validator fails to provide an identity despite authorizing the user, questioning whether these cases should have different error messages for clarity.\n\nÁlvaro Herrera在更新翻译时发现PostgreSQL OAuth认证代码中的错误消息不够清晰。他质疑当OAuth验证器成功确定用户不应被授权时，errdetail_log消息"Validator failed to authorize the provided token"的有用性，认为详细消息可能是冗余的。他还注意到第二种情况，相同的errmsg出现但errdetail不同，即验证器授权用户但未能提供身份时，他质疑这些情况是否应该使用不同的错误消息以提高清晰度。	2026-01-24 14:50:28+00	\N
14	19be99a6948cab2b	Extended Statistics set/restore/clear functions.	["corey.huinker@gmail.com","li.evan.chao@gmail.com","michael@paquier.xyz","tndrwang@gmail.com","zhjwpku@gmail.com"]	[{"id":"19be99a6948cab2b","messageId":"<CADkLM=c3JivzHNXLt-X_JicYknRYwLTiOCHOPiKagm2_vdrFUg@mail.gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","body":">\\n> How about the multirange range case in extended_statistics_update()\\n> for the mcv/expression path?\\n>\\n\\nAdded.\\n\\n\\n> import_expressions() also complains about a statatt_set_slot() with\\n> histograms.\\n>\\n\\nUnsure what you mean here.\\n\\n\\n> These ones are less consistent in style, the error hints should be the\\n> errmsg, and there are some s/statitisics/statistics/.  The errhint\\n> should be a full sentence, so I guess that you mean to switch both\\n> fields in such cases.\\n>\\n\\nThe 0003 patch of this set addresses this.\\n\\n\\n> s/the the/the/, I think this one's mine.  :D\\n>\\n\\n0002\\n\\n\\n>\\n> While the documentation shows one example with n_distinct,\\n> dependencies and exprs, I'd guess that we should push forward with\\n> something similar regarding most_common_val, most_common_val_nulls,\\n> most_common_freqs, most_common_base_freqs.  It looks particularly\\n> important to expand this part, the relationship they have between each\\n> pther, their expected input format (?), and what they map to in the\\n> catalogs.  If one is specified, all four of them are required, for\\n> example, but that's not the only thing I imagine should keep a track\\n> of.  This data is more complex than the single stats fields.\\n>\\n\\nI think some of this may have been addressed in this patchset.\\n\\nI've left these patches un-squashed to help differentiate what changes\\naddress which problems. They'll likely be re-squashed once those issues are\\naddressed.\\n\\nThe most interesting here is the change I did to statatt_get_type() to get\\nit to work for MCV/expression multiranges. Mostly, the problem arose from\\nthe fact that MCVlist will have multirange as a part of the exported tuple\\ntext array, so there is a legit need to parse the input of a multirange's\\ntext reprepresentation, whereas with attribute stats we only ever need to\\nparse the input of the multirange's element, a plain old range. The fix, as\\nyou may see highlights how statatt_get_type() is doing two things\\n(resolving typ* info for an attribute or expression, and fetching the\\nbasetype and basetype's ltopr and eqopr) and maybe the basetype/operator\\nstuff should be moved to its own function.\\n\\nAnother possible solution is to change the two refactor the\\nexamine_attribute() functions (one in analyze.c, one in extended_stats.c)\\nunifying them where possible, and allowing the unified function to still\\ngenerate a VacAttrStats even if the attstattarget is 0. That's a heavier\\nlift, and I left things as they are now to demonstrate the issue at hand.\\n\\nRebased as well.\\n","threadId":"19be99a6948cab2b","snippet":"How about the multirange range case in extended_statistics_update() for the mcv/expression path? Added. import_expressions() also complains about a statatt_set_slot() with histograms. Unsure what you","historyId":"12878","internalDate":"1769150738000","receivedAtUtc":"2026-01-23T06:45:38.000Z","from":"Corey Huinker <corey.huinker@gmail.com>"},{"id":"19bf09de6bf73015","messageId":"<CAEG8a3+6ibpVjnGiw6AWcM4roMYoge=aOuw1JP7RV5Wv+q4xvA@mail.gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","body":"On Fri, Jan 23, 2026 at 2:46 PM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>>\\n>> How about the multirange range case in extended_statistics_update()\\n>> for the mcv/expression path?\\n>\\n>\\n> Added.\\n>\\n>>\\n>> import_expressions() also complains about a statatt_set_slot() with\\n>> histograms.\\n>\\n>\\n> Unsure what you mean here.\\n>\\n>>\\n>> These ones are less consistent in style, the error hints should be the\\n>> errmsg, and there are some s/statitisics/statistics/.  The errhint\\n>> should be a full sentence, so I guess that you mean to switch both\\n>> fields in such cases.\\n>\\n>\\n> The 0003 patch of this set addresses this.\\n>\\n>>\\n>> s/the the/the/, I think this one's mine.  :D\\n>\\n>\\n> 0002\\n>\\n>>\\n>>\\n>> While the documentation shows one example with n_distinct,\\n>> dependencies and exprs, I'd guess that we should push forward with\\n>> something similar regarding most_common_val, most_common_val_nulls,\\n>> most_common_freqs, most_common_base_freqs.  It looks particularly\\n>> important to expand this part, the relationship they have between each\\n>> pther, their expected input format (?), and what they map to in the\\n>> catalogs.  If one is specified, all four of them are required, for\\n>> example, but that's not the only thing I imagine should keep a track\\n>> of.  This data is more complex than the single stats fields.\\n>\\n>\\n> I think some of this may have been addressed in this patchset.\\n>\\n> I've left these patches un-squashed to help differentiate what changes address which problems. They'll likely be re-squashed once those issues are addressed.\\n>\\n> The most interesting here is the change I did to statatt_get_type() to get it to work for MCV/expression multiranges. Mostly, the problem arose from the fact that MCVlist will have multirange as a part of the exported tuple text array, so there is a legit need to parse the input of a multirange's text reprepresentation, whereas with attribute stats we only ever need to parse the input of the multirange's element, a plain old range. The fix, as you may see highlights how statatt_get_type() is doing two things (resolving typ* info for an attribute or expression, and fetching the basetype and basetype's ltopr and eqopr) and maybe the basetype/operator stuff should be moved to its own function.\\n>\\n> Another possible solution is to change the two refactor the examine_attribute() functions (one in analyze.c, one in extended_stats.c) unifying them where possible, and allowing the unified function to still generate a VacAttrStats even if the attstattarget is 0. That's a heavier lift, and I left things as they are now to demonstrate the issue at hand.\\n>\\n> Rebased as well.\\n>\\n\\nv30-0003-normalize-error-messages.patch introduced a typo:\\n\\n%s/incorect/incorrect\\n\\n-- \\nRegards\\nJunwang Zhao\\n\\n\\n","threadId":"19be99a6948cab2b","snippet":"On Fri, Jan 23, 2026 at 2:46 PM Corey Huinker <corey.huinker@gmail.com> wrote: >> >> How about the multirange range case in extended_statistics_update() >> for the mcv/","historyId":"15681","internalDate":"1769268414000","receivedAtUtc":"2026-01-24T15:26:54.000Z","from":"Junwang Zhao <zhjwpku@gmail.com>"}]	The discussion focuses on addressing code review feedback for extended statistics set/restore/clear functions. Corey Huinker responds to several issues: adding multirange range case handling in extended_statistics_update() for the mcv/expression path, though unclear on import_expressions() histogram complaints. Error message consistency and typos are being fixed in patches 0002 and 0003. The main technical challenge involves modifying statatt_get_type() to handle MCV/expression multiranges, where MCVlist exports multirange text representations requiring different parsing than simple range elements. Two solutions are proposed: refactoring statatt_get_type() to separate basetype/operator functionality, or unifying examine_attribute() functions from analyze.c and extended_stats.c. Junwang Zhao identifies an additional typo ("incorect" should be "incorrect") in the v30-0003 patch.\n\n讨论集中在解决扩展统计信息设置/恢复/清除函数的代码审查反馈。Corey Huinker回应了几个问题：在extended_statistics_update()的mcv/expression路径中添加多范围处理，但对import_expressions()直方图问题不明确。错误消息一致性和拼写错误正在补丁0002和0003中修复。主要技术挑战涉及修改statatt_get_type()以处理MCV/表达式多范围，其中MCVlist导出多范围文本表示需要与简单范围元素不同的解析。提出两个解决方案：重构statatt_get_type()以分离基类型/操作符功能，或统一analyze.c和extended_stats.c中的examine_attribute()函数。Junwang Zhao在v30-0003补丁中发现额外拼写错误（"incorect"应为"incorrect"）。	2026-01-24 15:26:54+00	\N
14	19bef57ec77f7749	Converting README documentation to Markdown	["alvherre@kurilemu.de","daniel@yesql.se","peter@eisentraut.org","robertmhaas@gmail.com","zhjwpku@gmail.com"]	[{"id":"19bef57ec77f7749","messageId":"<202601240907.ccskdsdc5smx@alvherre.pgsql>","subject":"Re: Converting README documentation to Markdown","body":"On 2024-Sep-10, Robert Haas wrote:\\n\\n> On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <daniel@yesql.se> wrote:\\n> > Since there doesn't seem to be much interest in going all the way to Markdown,\\n> \\n> Just for the record, I suspect going to Markdown is actually the right\\n> thing to do.\\n\\nI had occasion to go look at our doxygen this morning, whose box is as\\nof a couple of days ago running Debian Trixie, and realized that it is\\nnow showing the README.md files in the documentation hierarchy -- for\\nexample,\\nhttps://doxygen.postgresql.org/md_src_2backend_2storage_2aio_2README.html\\nThe plain README files don't get this treatment.\\n\\nI don't know if it was already working in the previous version, or it is\\nonly that I happened to notice it now. (*)\\n\\nAnyway, I wonder if this fact would give more fuel to the idea of making\\nour README files gain a .md extension.\\n\\n\\n(*) Now that I look closer, this might be very old actually, because\\nBookworm had doxygen 1.9.4 and trixie has 1.9.8 -- very little\\ndifference there.  I guess I only noticed this now because we now have\\nREADME.me and the aio/README.md file.\\n\\n-- \\nÁlvaro Herrera        Breisgau, Deutschland  —  https://www.EnterpriseDB.com/\\n\\"La vida es para el que se aventura\\"\\n\\n\\n","threadId":"19bef57ec77f7749","snippet":"On 2024-Sep-10, Robert Haas wrote: > On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <daniel@yesql.se> wrote: > > Since there doesn't seem to be much interest in going all the way","historyId":"15690","internalDate":"1769247054000","receivedAtUtc":"2026-01-24T09:30:54.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"},{"id":"19bf0a606cf2b161","messageId":"<CAEG8a3Kehi9=eNdCjYizEJp3+Y7ssa7R6tFfuP8-rpDmYsjz3g@mail.gmail.com>","subject":"Re: Converting README documentation to Markdown","body":"On Sat, Jan 24, 2026 at 5:31 PM Álvaro Herrera <alvherre@kurilemu.de> wrote:\\n>\\n> On 2024-Sep-10, Robert Haas wrote:\\n>\\n> > On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <daniel@yesql.se> wrote:\\n> > > Since there doesn't seem to be much interest in going all the way to Markdown,\\n> >\\n> > Just for the record, I suspect going to Markdown is actually the right\\n> > thing to do.\\n>\\n> I had occasion to go look at our doxygen this morning, whose box is as\\n> of a couple of days ago running Debian Trixie, and realized that it is\\n> now showing the README.md files in the documentation hierarchy -- for\\n> example,\\n> https://doxygen.postgresql.org/md_src_2backend_2storage_2aio_2README.html\\n> The plain README files don't get this treatment.\\n>\\n> I don't know if it was already working in the previous version, or it is\\n> only that I happened to notice it now. (*)\\n>\\n> Anyway, I wonder if this fact would give more fuel to the idea of making\\n> our README files gain a .md extension.\\n\\nGitHub also provides nice rendering for markdown files, see\\n\\nhttps://github.com/postgres/postgres/blob/master/src/backend/storage/aio/README.md\\n\\n>\\n>\\n> (*) Now that I look closer, this might be very old actually, because\\n> Bookworm had doxygen 1.9.4 and trixie has 1.9.8 -- very little\\n> difference there.  I guess I only noticed this now because we now have\\n> README.me and the aio/README.md file.\\n>\\n> --\\n> Álvaro Herrera        Breisgau, Deutschland  —  https://www.EnterpriseDB.com/\\n> \\"La vida es para el que se aventura\\"\\n>\\n>\\n\\n\\n-- \\nRegards\\nJunwang Zhao\\n\\n\\n","threadId":"19bef57ec77f7749","snippet":"On Sat, Jan 24, 2026 at 5:31 PM Álvaro Herrera <alvherre@kurilemu.de> wrote: > > On 2024-Sep-10, Robert Haas wrote: > > > On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <","historyId":"15690","internalDate":"1769268947000","receivedAtUtc":"2026-01-24T15:35:47.000Z","from":"Junwang Zhao <zhjwpku@gmail.com>"}]	The discussion revisits converting PostgreSQL's README files to Markdown format. Álvaro Herrera discovered that Doxygen documentation now properly renders README.md files in the documentation hierarchy, while plain README files lack this treatment. This observation reignites interest in adding .md extensions to README files, building on Robert Haas's earlier support for Markdown conversion despite previous lukewarm reception. Junwang Zhao reinforces the argument by noting that GitHub also provides enhanced rendering for Markdown files, referencing the existing aio/README.md as an example. The discussion suggests growing momentum for README conversion, with improved tooling support from both Doxygen and GitHub serving as compelling technical justifications for the change.\n讨论重新审视将PostgreSQL的README文件转换为Markdown格式。Álvaro Herrera发现Doxygen文档现在能够正确渲染文档层次结构中的README.md文件，而普通README文件缺乏这种处理。这一观察重新激发了为README文件添加.md扩展名的兴趣，基于Robert Haas此前对Markdown转换的支持，尽管之前反响平平。Junwang Zhao通过指出GitHub也为Markdown文件提供增强渲染来强化这一论点，并引用现有的aio/README.md作为例子。讨论表明README转换的势头正在增长，Doxygen和GitHub的改进工具支持为这一变更提供了令人信服的技术理由。	2026-01-24 15:35:47+00	\N
14	19bec801a96f066e	unnecessary executor overheads around seqscans	["amit.kapila16@gmail.com","amitlangote09@gmail.com","andres@anarazel.de","dgrowleyml@gmail.com"]	[{"id":"19beeaa8f697ec9b","messageId":"<CA+HiwqEUDeBaydqYOq4uK6Rz9PBpOagfZqQevD71=JZrmgE3CQ@mail.gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> Hi,\\n>\\n> In [1] I was looking at the profile of a seqscan with a where clause that\\n> doesn't match any of the many rows.  I was a bit saddened by where we were\\n> spending time.\\n>\\n>\\n> - The fetching of variables, as well as the null check of scandesc, in\\n>   SeqNext() is repeated in every loop iteration of ExecScanExtended, despite\\n>   that obviously not being required after the first iteration\\n>\\n>   We could perhaps address this by moving the check to the callers of\\n>   ExecScanExtended() or by extending ExecScanExtended to have an explicit\\n>   beginscan callback that it calls after.\\n>\\n>   Or perhaps we could just make it so that the entire if (scandesc == NULL)\\n>   branch isn't needed?\\n\\nKind of like ExecProcNodeFirst(), what if we replace the variant\\nselection in ExecInitSeqScan() with just:\\n\\n    scanstate->ss.ps.ExecProcNode = ExecSeqScanFirst;\\n\\nExecSeqScanFirst() would:\\n\\n- do the table_beginscan() call that's currently inside the if\\n(scandesc == NULL) block in SeqNext()\\n\\n- select and install the appropriate ExecSeqScan variant based on\\nqual/projection/EPQ\\n\\n- call that variant to fetch and return the first tuple.\\n\\nThen we can just remove the if (scandesc == NULL) block from SeqNext() entirely.\\n\\n> - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n>   show up noticeably and in every loop iteration, despite afaict never being reachable\\n>\\n>   It's not obvious to me that this should\\n>   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n>      change in the middle of a scan? That would require a wrapper around\\n>      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n>   b) not just be an assertion?\\n\\nHaven't thought about this.\\n\\n> - The TupIsNull(slot) check in ExecScanExtended() is redundant with the return\\n>   value of table_scan_getnextslot(), but the compiler doesn't grok that.\\n>\\n>   We can use a pg_assume() in table_scan_getnextslot() to make the compiler\\n>   understand.\\n\\nSomething like this?\\n\\n    result = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\n    pg_assume(result == !TupIsNull(slot));\\n    return result;\\n\\nI assume this relies on table_scan_getnextslot() being inlined into\\nExecScanExtended()?\\n\\n> - We repeatedly store the table oid in the slot, table_scan_getnextslot() and\\n>   then again in ExecStoreBufferHeapTuple(). This shows up in the profile.\\n>\\n>   I wish we had made the slot a property of the scan, that way the scan could\\n>   assume the slot already has the oid set...\\n\\nI've noticed this when working on my batching patch. I set\\ntts_tableOid when creating the slots used in the batch themselves, so\\nthe per-tuple assignment isn't needed.\\n\\n> - heap_getnextslot() calls ExecStoreBufferHeapTuple() and then returns\\n>   true. That prevents the sibiling call optimization.\\n>\\n>   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n>   current return value. Alternatively we should consider just moving it to\\n>   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n>   only ones that should use it anyway.\\n\\nMakes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\nlike the simpler option, unless I misunderstood.\\n\\n-- \\nThanks, Amit Langote\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote: > > Hi, > > In [1] I was looking at the profile of a seqscan with a where clause that > doesn't","historyId":"15684","internalDate":"1769235682000","receivedAtUtc":"2026-01-24T06:21:22.000Z","from":"Amit Langote <amitlangote09@gmail.com>"},{"id":"19beeb7f3964deec","messageId":"<CAApHDvrL7Q41B=gv+3wc8+AJGKZugGegUbBo8FPQ+3+NGTPb+w@mail.gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","body":"On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote:\\n> On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n> >   Or perhaps we could just make it so that the entire if (scandesc == NULL)\\n> >   branch isn't needed?\\n>\\n> Kind of like ExecProcNodeFirst(), what if we replace the variant\\n> selection in ExecInitSeqScan() with just:\\n\\nI imagined moving it to ExecInitSeqScan() and just avoid doing it when\\nwe're doing EXPLAIN or we're doing a parallel scan. Something like the\\nattached, which is giving me a 4% speedup selecting from a million row\\ntable with a single int column running a seqscan query with a WHERE\\nclause matching no rows.\\n\\n> >   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n> >   current return value. Alternatively we should consider just moving it to\\n> >   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n> >   only ones that should use it anyway.\\n>\\n> Makes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\n> like the simpler option, unless I misunderstood.\\n\\nIt's probably too late to change it now, but wouldn't it have been\\nbetter if scan_getnextslot had been coded to return the TupleTableSlot\\nrather than bool? That way you could get the sibling call in\\nExecStoreBufferHeapTuple() and in SeqNext().\\n\\nI also noticed my compiler does not inline SeqNext(). Adding a\\npg_attribute_always_inline results in it getting inlined and gives a\\nsmall speedup.\\n\\nDavid\\n","threadId":"19bec801a96f066e","snippet":"On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote: > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote: > > Or perhaps we could just","historyId":"15684","internalDate":"1769236568000","receivedAtUtc":"2026-01-24T06:36:08.000Z","from":"David Rowley <dgrowleyml@gmail.com>"},{"id":"19bef6ce0f625bef","messageId":"<CAA4eK1LQ2ynGNg=3DHrKXBaU9G7WFh-+Mkef4COhUd0_a0KusA@mail.gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","body":"On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n>   show up noticeably and in every loop iteration, despite afaict never being reachable\\n>\\n>   It's not obvious to me that this should\\n>   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n>      change in the middle of a scan? That would require a wrapper around\\n>      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n>   b) not just be an assertion?\\n>\\n\\nIIRC, the main reason for having this precautionary check in the API\\nis to ensure that during logical decoding we never access the table AM\\nor\\nheap APIs directly when scanning catalog tables. This restriction\\nexists because we only check for concurrent aborts inside the\\nsystable_* APIs.\\n\\nIn practice, the core code should never hit this precautionary check,\\nso it could likely be converted into an assert. The reason it may not\\nhave been an assert originally is to give an ERROR if an output plugin\\nincorrectly invokes these APIs during decoding to access catalogs as\\nnoted in docs [1] (Note that access to user catalog tables or regular\\nsystem catalog tables in the output plugins has to be done via the\\nsystable_* scan APIs only. Access via the heap_* scan APIs will error\\nout.).\\n\\nI'll think some more about it.\\n\\n[1] - https://www.postgresql.org/docs/devel/logicaldecoding-output-plugin-writing.html\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote: > > - The checkXidAlive checks that have been added to table_scan_getnextslot() > show up noticeably and in","historyId":"15684","internalDate":"1769248424000","receivedAtUtc":"2026-01-24T09:53:44.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>"},{"id":"19bf0a18b129f97b","messageId":"<tlpltqm5jjwj7mp66dtebwwhppe4ri36vdypux2zoczrc2i3mp@dhv4v4nikyfg>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn 2026-01-24 15:23:44 +0530, Amit Kapila wrote:\\n> On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote:\\n> >\\n> > - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n> >   show up noticeably and in every loop iteration, despite afaict never being reachable\\n> >\\n> >   It's not obvious to me that this should\\n> >   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n> >      change in the middle of a scan? That would require a wrapper around\\n> >      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n> >   b) not just be an assertion?\\n> >\\n> \\n> IIRC, the main reason for having this precautionary check in the API\\n> is to ensure that during logical decoding we never access the table AM\\n> or\\n> heap APIs directly when scanning catalog tables. This restriction\\n> exists because we only check for concurrent aborts inside the\\n> systable_* APIs.\\n\\nI know why the check exists - but why does it have to be in\\ntable_scan_getnextslot(), which is executed very frequently, rather than\\ntable_beginscan*(), which is executed much less frequently.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-24 15:23:44 +0530, Amit Kapila wrote: > On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote: > > > > - The checkXidAlive checks that have been","historyId":"15684","internalDate":"1769268661000","receivedAtUtc":"2026-01-24T15:31:01.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf0a64f7cd0f93","messageId":"<yk5rybusljgxmsrm2xh2se77lbzq7cz6avxuwa4xjq7flh2dic@4wfcvplykhoj>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn 2026-01-24 19:36:08 +1300, David Rowley wrote:\\n> On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote:\\n> > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n> > >   Or perhaps we could just make it so that the entire if (scandesc == NULL)\\n> > >   branch isn't needed?\\n> >\\n> > Kind of like ExecProcNodeFirst(), what if we replace the variant\\n> > selection in ExecInitSeqScan() with just:\\n> \\n> I imagined moving it to ExecInitSeqScan() and just avoid doing it when\\n> we're doing EXPLAIN or we're doing a parallel scan. Something like the\\n> attached, which is giving me a 4% speedup selecting from a million row\\n> table with a single int column running a seqscan query with a WHERE\\n> clause matching no rows.\\n\\nYes, i think that'd be better. Nice!\\n\\n\\n> > >   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n> > >   current return value. Alternatively we should consider just moving it to\\n> > >   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n> > >   only ones that should use it anyway.\\n> >\\n> > Makes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\n> > like the simpler option, unless I misunderstood.\\n> \\n> It's probably too late to change it now, but wouldn't it have been\\n> better if scan_getnextslot had been coded to return the TupleTableSlot\\n> rather than bool? That way you could get the sibling call in\\n> ExecStoreBufferHeapTuple() and in SeqNext().\\n\\nTupIsNull() is actually more expensive than a bool return value, because it\\nneeds a memory fetch to complete... Except of course if we end up doing both.\\n\\nSeqNext() shouldn't need a sibling call because it ought to be inlined. But:\\n\\n> I also noticed my compiler does not inline SeqNext(). Adding a\\n> pg_attribute_always_inline results in it getting inlined and gives a\\n> small speedup.\\n\\nOh,m that's not good. I think we really had assumed that it would with the 18\\nchanges around this. It does here, but that's probably because I use -O3.\\n\\n\\n> diff --git a/src/backend/executor/nodeSeqscan.c b/src/backend/executor/nodeSeqscan.c\\n> index b8119face43..87420e60dc9 100644\\n> --- a/src/backend/executor/nodeSeqscan.c\\n> +++ b/src/backend/executor/nodeSeqscan.c\\n> @@ -63,17 +63,6 @@ SeqNext(SeqScanState *node)\\n>  \\tdirection = estate->es_direction;\\n>  \\tslot = node->ss.ss_ScanTupleSlot;\\n>  \\n> -\\tif (scandesc == NULL)\\n> -\\t{\\n> -\\t\\t/*\\n> -\\t\\t * We reach here if the scan is not parallel, or if we're serially\\n> -\\t\\t * executing a scan that was planned to be parallel.\\n> -\\t\\t */\\n> -\\t\\tscandesc = table_beginscan(node->ss.ss_currentRelation,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t   estate->es_snapshot,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t   0, NULL);\\n> -\\t\\tnode->ss.ss_currentScanDesc = scandesc;\\n> -\\t}\\n\\nWhat about the \\"if we're serially executing a scan that was planned to be\\nparallel.\\" part? I frankly don't really know what precisely was referencing...\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-24 19:36:08 +1300, David Rowley wrote: > On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote: > > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <","historyId":"15684","internalDate":"1769268979000","receivedAtUtc":"2026-01-24T15:36:19.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf0b8b37b6875d","messageId":"<pxzibbqejp4vdjc3zqtjdzkfgxohn32lwnngyddnwe5ydbajkj@rw5jb54mrjvt>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn 2026-01-24 15:21:22 +0900, Amit Langote wrote:\\n> On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n> > - The TupIsNull(slot) check in ExecScanExtended() is redundant with the return\\n> >   value of table_scan_getnextslot(), but the compiler doesn't grok that.\\n> >\\n> >   We can use a pg_assume() in table_scan_getnextslot() to make the compiler\\n> >   understand.\\n> \\n> Something like this?\\n> \\n>     result = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\n>     pg_assume(result == !TupIsNull(slot));\\n>     return result;\\n\\nYep, that seems to clue at least gcc into understanding the situation. I only\\ntried two pg_assume(!found || !TupIsNull(slot)), but yours should probably\\nalso work.\\n\\n\\n> I assume this relies on table_scan_getnextslot() being inlined into\\n> ExecScanExtended()?\\n\\nYes. But I think that that's a good bet, given that it's an inline function\\nand only used once in nodeSeqscan.c.\\n\\n\\n> > - heap_getnextslot() calls ExecStoreBufferHeapTuple() and then returns\\n> >   true. That prevents the sibiling call optimization.\\n> >\\n> >   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n> >   current return value. Alternatively we should consider just moving it to\\n> >   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n> >   only ones that should use it anyway.\\n> \\n> Makes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\n> like the simpler option, unless I misunderstood.\\n\\nYea. There's probably more to be gained by the other approach, but it's also\\nsomewhat painful due to some functionality being private to execTuples.c right\\nnow.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-24 15:21:22 +0900, Amit Langote wrote: > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote: > > - The TupIsNull(slot) check in ExecScanExtended() is","historyId":"15684","internalDate":"1769270181000","receivedAtUtc":"2026-01-24T15:56:21.000Z","from":"Andres Freund <andres@anarazel.de>"}]	The discussion focuses on optimizing PostgreSQL's sequential scan executor performance by addressing several overhead issues identified through profiling. Key proposals include moving the beginscan() call from SeqNext() to ExecInitSeqScan() to avoid repeated null checks, with David Rowley demonstrating a 4% speedup through this approach. Participants debated relocating checkXidAlive checks from the frequently-called table_scan_getnextslot() to beginscan(), though Amit Kapila noted these checks protect against incorrect API usage during logical decoding. Other optimization suggestions include using pg_assume() to help compilers understand redundant TupIsNull() checks, modifying ExecStoreBufferHeapTuple() to return true for sibling call optimization, and forcing SeqNext() inlining. Questions remain about handling parallel scan scenarios and the precise placement of various checks.\n\n该讨论重点关注通过解决性能分析发现的几个开销问题来优化PostgreSQL顺序扫描执行器性能。主要提议包括将beginscan()调用从SeqNext()移动到ExecInitSeqScan()以避免重复的空检查，David Rowley通过这种方法展示了4%的性能提升。参与者讨论了将checkXidAlive检查从频繁调用的table_scan_getnextslot()重新定位到beginscan()，但Amit Kapila指出这些检查可防止逻辑解码期间错误的API使用。其他优化建议包括使用pg_assume()帮助编译器理解冗余的TupIsNull()检查，修改ExecStoreBufferHeapTuple()返回true以进行兄弟调用优化，以及强制SeqNext()内联。关于处理并行扫描场景和各种检查的精确位置仍存在问题。	2026-01-24 15:56:21+00	\N
14	19bf100b2caf0fc6	Add SQL/JSON ON MISMATCH clause to JSON_VALUE	["florents.tselai@gmail.com"]	[{"id":"19bf100b2caf0fc6","messageId":"<CA+v5N42Kn65HauYbZJ=bAVHjzdp=wCg64dd+WzRmtu=Uu1z+Ow@mail.gmail.com>","subject":"Add SQL/JSON ON MISMATCH clause to JSON_VALUE","body":"Hello hackers,\\n\\nHere's a patch that attempts to $subject.\\n\\nMy original motivation was to implement this for JSON_TABLE,\\nbut I realized it would be better to start with a smaller scope\\nby targeting the basic query functions first.\\n\\nCurrently this v1 passes the tests I've put for JSON_VALUE.\\n\\nI've had trouble making JSON_QUERY work too,\\nso I suspect that although my tests pass,\\nthere may be something I'm missing in the executor side of things.\\nWhile I troubleshoot that it'd be nice to get some feedback for this\\nversion.\\n\\nRegards,\\nFlo\\n","threadId":"19bf100b2caf0fc6","snippet":"Hello hackers, Here's a patch that attempts to $subject. My original motivation was to implement this for JSON_TABLE, but I realized it would be better to start with a smaller scope by targeting","historyId":"15692","internalDate":"1769274862000","receivedAtUtc":"2026-01-24T17:14:22.000Z","from":"Florents Tselai <florents.tselai@gmail.com>"}]	Florents Tselai has submitted a v1 patch to add SQL/JSON ON MISMATCH clause functionality to JSON_VALUE. The patch was originally motivated by implementing this feature for JSON_TABLE, but the developer decided to start with a smaller scope by targeting basic query functions first. The current version passes tests for JSON_VALUE, but the developer is experiencing difficulties making JSON_QUERY work properly and suspects there may be missing implementation on the executor side. They are seeking community feedback on this initial version while troubleshooting the JSON_QUERY issues.\n\nFlorents Tselai 提交了一个 v1 补丁，用于为 JSON_VALUE 添加 SQL/JSON ON MISMATCH 子句功能。该补丁最初是为了在 JSON_TABLE 中实现此功能而开发的，但开发者决定从较小的范围开始，首先针对基本查询函数。当前版本通过了 JSON_VALUE 的测试，但开发者在使 JSON_QUERY 正常工作方面遇到困难，怀疑在执行器方面可能缺少实现。他们在排查 JSON_QUERY 问题的同时，正在寻求社区对这个初始版本的反馈。	2026-01-24 17:14:22+00	\N
15	19be9aafca8cce45	Some tests for TOAST, STORAGE MAIN/EXTENDED	["michael@paquier.xyz","veldanda.nikhilkumar17@gmail.com"]	[{"id":"19bf29e765a386e4","messageId":"<aXVn-xg0bdPc0aGM@paquier.xyz>","subject":"Re: Some tests for TOAST, STORAGE MAIN/EXTENDED","body":"On Fri, Jan 23, 2026 at 12:25:33AM -0800, Nikhil Kumar Veldanda wrote:\\n> The `SELECT count(*) FROM :reltoastname` assertion is a bit brittle\\n> for `STORAGE EXTENDED`: depending on the toast compression method /\\n> effectiveness, the value may end up as >1 chunk, which would flip the\\n> expected count(*) = 1. Prefer SELECT count(DISTINCT chunk_id) FROM\\n> :reltoastname (or WHERE chunk_seq = 0) and adjust expected.\\n\\nYeah, this suggestion sounds sensible and that would still notice what\\nI was able to break.\\n\\n> pg_column_compression() expects pglz, but default_toast_compression\\n> isn't pinned here. Suggest SET default_toast_compression = 'pglz';\\n> near this block; otherwise this can fail on builds with a different\\n> default.\\n\\nAgreed, let's do that as well.\\n--\\nMichael\\n","threadId":"19be9aafca8cce45","snippet":"On Fri, Jan 23, 2026 at 12:25:33AM -0800, Nikhil Kumar Veldanda wrote: > The `SELECT count(*) FROM :reltoastname` assertion is a bit brittle > for `STORAGE EXTENDED`: depending on the toast","historyId":"16325","internalDate":"1769302011000","receivedAtUtc":"2026-01-25T00:46:51.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	Michael Paquier acknowledges feedback from Nikhil Kumar Veldanda regarding TOAST testing improvements. The discussion centers on making test assertions more robust for STORAGE EXTENDED configurations. Veldanda identified that the current `SELECT count(*) FROM :reltoastname` assertion is brittle because toast compression effectiveness can vary, potentially causing chunks to exceed expected counts. He suggests using `SELECT count(DISTINCT chunk_id)` or filtering `WHERE chunk_seq = 0` instead. Additionally, Veldanda notes that `pg_column_compression()` expects pglz compression but `default_toast_compression` isn't explicitly set, which could cause test failures on builds with different defaults. He recommends adding `SET default_toast_compression = 'pglz'`. Paquier agrees with both suggestions, stating they would address the issues he encountered while maintaining test effectiveness.\nMichael Paquier 确认了 Nikhil Kumar Veldanda 关于 TOAST 测试改进的反馈。讨论围绕使 STORAGE EXTENDED 配置的测试断言更加稳健。Veldanda 指出当前的 `SELECT count(*) FROM :reltoastname` 断言很脆弱，因为 toast 压缩效果可能有所不同，可能导致块数超出预期计数。他建议改用 `SELECT count(DISTINCT chunk_id)` 或过滤 `WHERE chunk_seq = 0`。此外，Veldanda 注意到 `pg_column_compression()` 期望 pglz 压缩，但 `default_toast_compression` 没有显式设置，这可能在使用不同默认值的构建中导致测试失败。他建议添加 `SET default_toast_compression = 'pglz'`。Paquier 同意这两个建议，表示它们能解决他遇到的问题，同时保持测试有效性。	2026-01-25 00:46:51+00	\N
14	19be5000123f9d5e	Optional skipping of unchanged relations during ANALYZE?	["dgrowleyml@gmail.com","ilya.evdokimov@tantorlabs.com","myon@debian.org","rob@xzilla.net","robertmhaas@gmail.com","samimseih@gmail.com","vasukianand0119@gmail.com"]	[{"id":"19be98ed513d73e0","messageId":"<CAE2r8H4+SoMrCXZx987em2VW5tR=N_0xtj28B8R6dzuLon=bzQ@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"Hi all,\\n\\nThanks a lot for the detailed feedback — this has been very\\nhelpful.Answering to all mails in one.\\n\\nA few clarifications on intent and scope, and how this relates to the\\npoints raised:\\n\\nAutovacuum overlap\\nI agree there is some conceptual overlap with autovacuum's analyze decision\\nlogic. The intent here is not to replace or duplicate autovacuum\\nheuristics, but to reduce clearly redundant work during explicit ANALYZE\\nruns (especially plain ANALYZE; across the whole database). Autovacuum\\nalready handles threshold-based decisions well; this option is meant to be\\na lightweight, explicit opt-in for manual ANALYZE usage.\\n\\nThresholds vs n_mod_since_analyze\\nI agree that n_mod_since_analyze == 0 is a very simple condition and not\\n"smart" in the general sense. That is intentional for now. This option is\\nnot trying to answer when statistics should be refreshed optimally, but\\nonly to skip relations that are known to be unchanged since the last\\nanalyze. If even a single tuple is modified, SMART ANALYZE will still\\nre-run, preserving conservative behavior.\\n\\nTables never analyzed\\nAs Christoph and Ilia pointed out earlier, skipping tables that were never\\nanalyzed would be incorrect. The current logic explicitly avoids that by\\nrequiring last_analyze or last_autoanalyze to be present before skipping.\\nTables without prior statistics are always analyzed.\\n\\nRelation to vacuumdb --missing-stats-only\\nI agree this is related but slightly different in intent.\\n--missing-stats-only answers "does this table have any statistics at all?",\\nwhile SMART ANALYZE answers "has this table changed since the last\\nstatistics collection?". Both seem useful, but they target different use\\ncases. I see SMART ANALYZE primarily as a performance optimization for\\nrepeated manual ANALYZE runs on mostly-static schemas.\\n\\nExtended statistics / partitions / inheritance\\nThese are valid concerns. The current patch intentionally does not attempt\\nto handle extended statistics, partitioned tables, inheritance, foreign\\ntables, etc. I wanted to start with a minimal, explicit, and conservative\\nbehavior for regular relations only. I agree these areas need careful\\nconsideration before extending the logic further, and I plan to look into\\nthem based on feedback.\\n\\nVACUUM vs ANALYZE\\nI also agree with the concern about adding more options to VACUUM. The\\ncurrent patch focuses on ANALYZE usage; I'm not proposing this as a VACUUM\\noption.\\n\\nNAMING\\nAlthough as sami said this SMART is not smart enough as it should be , I\\nwill change name accordingly in the further patches  based on urs and\\nothers opinion once it is decided.\\nBased on feedback, I'm happy to revise direction, naming, or scope before\\ntaking this further.\\n\\nThanks again for the thoughtful discussion — really appreciate the guidance.\\n\\nBest regards,\\nVasuki M\\nC-DAC,Chennai.\\n","threadId":"19be5000123f9d5e","snippet":"Hi all, Thanks a lot for the detailed feedback — this has been very helpful.Answering to all mails in one. A few clarifications on intent and scope, and how this relates to the points raised:","historyId":"12864","internalDate":"1769150007000","receivedAtUtc":"2026-01-23T06:33:27.000Z","from":"VASUKI M <vasukianand0119@gmail.com>"},{"id":"19bea74af4824988","messageId":"<65da80c0-52fb-454e-b29e-b1d5a254ec38@tantorlabs.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"\\nOn 23.01.2026 09:33, VASUKI M wrote:\\n> Relation to vacuumdb --missing-stats-only\\n> I agree this is related but slightly different in intent. > --missing-stats-only answers "does this table have any statistics at > all?", while SMART ANALYZE answers "has this table changed since the > last statistics collection?". Both seem useful, but they target > different use cases. I see SMART ANALYZE primarily as a performance > optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n\\nLGTM. Thanks to Sami for pointing this out.\\n\\nIt seems reasonable to start by introducing an option for plain ANALYZE (without specifying tables or columns) that follows the same idea as vacuumdb --missing-stats-only. While this flag was originally introduced primarily to support pg_upgrade workflows, exposing similar functionality at the ANALYZE level also seems useful on its own. That would give us a clear and well-defined first step. At the SQL level, a name such as ANALYZE (MISSING_STATS_ONLY) would be a good fit and remain consistent with the vacuumdb option.\\n\\nThoughts?\\n\\n-- \\nBest regards,\\nIlia Evdokimov,\\nTantor Labs LLC,\\nhttps://tantorlabs.com/\\n\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"On 23.01.2026 09:33, VASUKI M wrote: > Relation to vacuumdb --missing-stats-only > I agree this is related but slightly different in intent. > --missing-stats-only answers "does this table","historyId":"12864","internalDate":"1769165058000","receivedAtUtc":"2026-01-23T10:44:18.000Z","from":"Ilia Evdokimov <ilya.evdokimov@tantorlabs.com>"},{"id":"19bec8e508a88c43","messageId":"<CAA5RZ0tYuhHapyVBTw8tVfrKp6fyS5YBTVdQhYGOcWFg-ERyFA@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"Thanks for the detailed summary!\\n\\nIt is important to point out that this feature is trying to do 2 distinct\\nthings in 1 command. run analyze under when either one of these conditions\\nis true:\\n\\n1/ Table has not been analyzed yet.\\n2/ Table has been modified.\\n\\n> Thanks a lot for the detailed feedback — this has been very helpful.Answering to all mails in one.\\n>\\n> A few clarifications on intent and scope, and how this relates to the points raised:\\n>\\n> Autovacuum overlap\\n> I agree there is some conceptual overlap with autovacuum's analyze decision logic.\\n> The intent here is not to replace or duplicate autovacuum heuristics, but to reduce\\n\\nYes, I agree with this.\\n\\n> I agree that n_mod_since_analyze == 0 is a very simple condition\\n> and not "smart" in the general sense. That is intentional for now.\\n> This option is not trying to answer when statistics should be refreshed optimally,\\n> but only to skip relations that are known to be unchanged since the last analyze.\\n> If even a single tuple is modified, SMART ANALYZE will still re-run, preserving\\n> conservative behavior.\\n\\nYes, this is my concern. Why would I want to analyze if 1 row or a negligible\\namount of rows are modified? I understand that this feature is trying to\\nkeep the decision making very simple, but I think it's too simple to actually\\nbe helpful in addressing the wasted effort of an ANALYZE command.\\n\\n> Tables never analyzed\\n> As Christoph and Ilia pointed out earlier, skipping tables that were never analyzed would be incorrect.\\n> The current logic explicitly avoids that by requiring last_analyze or last_autoanalyze to be present\\n> before skipping. Tables without prior statistics are always analyzed.\\n\\nI agree with this, but I think it's more than just tables that have\\nnot been analyzed.\\nWhat if a new column is added after the last (auto)analyze. Would we not want to\\ntrigger an analyze in that case?\\n\\n> Relation to vacuumdb --missing-stats-only\\n> I agree this is related but slightly different in intent. --missing-stats-only\\n> answers "does this table have any statistics at all?", while SMART ANALYZE\\n> answers "has this table changed since the last statistics collection?". Both seem\\n> useful, but they target different use cases. I see SMART ANALYZE primarily\\n> as a performance optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n\\nSMART ANALYZE is trying to answer 2 questions \\"which table does not\\nhave any statistics at all\\"\\nand \\"has this table changed since the last statistics collection?", right?\\n\\nSo, maybe they need to be 2 separate options.\\n\\n> Although as sami said this SMART is not smart enough as it should be ,\\n> I will change name accordingly in the further patches\\n\\nYup, I am not too fond of SMART in the name. Also, then name itself\\nis vague. SKIP_LOCKED and BUFFER_USAGE_LIMIT on the other\\nhand tell you exactly what they[re used for.\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"Thanks for the detailed summary! It is important to point out that this feature is trying to do 2 distinct things in 1 command. run analyze under when either one of these conditions is true: 1/ Table","historyId":"13629","internalDate":"1769200286000","receivedAtUtc":"2026-01-23T20:31:26.000Z","from":"Sami Imseih <samimseih@gmail.com>"},{"id":"19bf1f07cc94d47a","messageId":"<CAJSLCQ3Z9cM2eZNa4aOnLmLyiZmSDrZH2xQm1RfT4PdKWo0ZLg@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"On Fri, Jan 23, 2026 at 9:31 PM Sami Imseih <samimseih@gmail.com> wrote:\\n>\\n> Thanks for the detailed summary!\\n>\\n> It is important to point out that this feature is trying to do 2 distinct\\n> things in 1 command. run analyze under when either one of these conditions\\n> is true:\\n>\\n> 1/ Table has not been analyzed yet.\\n> 2/ Table has been modified.\\n>\\n\\nMaybe this is all an aside, but I don't think that was the vision for\\nwhat the OP was trying to do with his patch, in that sense he was\\napproaching it from a different angle, and I've been reading this\\nthread trying to decide if people are just talking past each other.\\nBut after thinking about it some more, I think the above might be the\\nmore useful mental model for the discussion.\\n\\n> > Thanks a lot for the detailed feedback — this has been very helpful.Answering to all mails in one.\\n> >\\n> > A few clarifications on intent and scope, and how this relates to the points raised:\\n> >\\n> > Autovacuum overlap\\n> > I agree there is some conceptual overlap with autovacuum's analyze decision logic.\\n> > The intent here is not to replace or duplicate autovacuum heuristics, but to reduce\\n>\\n> Yes, I agree with this.\\n>\\n> > I agree that n_mod_since_analyze == 0 is a very simple condition\\n> > and not "smart" in the general sense. That is intentional for now.\\n> > This option is not trying to answer when statistics should be refreshed optimally,\\n> > but only to skip relations that are known to be unchanged since the last analyze.\\n> > If even a single tuple is modified, SMART ANALYZE will still re-run, preserving\\n> > conservative behavior.\\n>\\n> Yes, this is my concern. Why would I want to analyze if 1 row or a negligible\\n> amount of rows are modified? I understand that this feature is trying to\\n> keep the decision making very simple, but I think it's too simple to actually\\n> be helpful in addressing the wasted effort of an ANALYZE command.\\n>\\n> > Tables never analyzed\\n> > As Christoph and Ilia pointed out earlier, skipping tables that were never analyzed would be incorrect.\\n> > The current logic explicitly avoids that by requiring last_analyze or last_autoanalyze to be present\\n> > before skipping. Tables without prior statistics are always analyzed.\\n>\\n> I agree with this, but I think it's more than just tables that have\\n> not been analyzed.\\n> What if a new column is added after the last (auto)analyze. Would we not want to\\n> trigger an analyze in that case?\\n>\\n\\nWell, I don't know that we are \\"triggering\\" anything, but this is\\ndefinitely a case where we have \\"missing stats\\".\\n\\n> > Relation to vacuumdb --missing-stats-only\\n> > I agree this is related but slightly different in intent. --missing-stats-only\\n> > answers "does this table have any statistics at all?", while SMART ANALYZE\\n> > answers "has this table changed since the last statistics collection?". Both seem\\n> > useful, but they target different use cases. I see SMART ANALYZE primarily\\n> > as a performance optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n>\\n> SMART ANALYZE is trying to answer 2 questions \\"which table does not\\n> have any statistics at all\\"\\n> and \\"has this table changed since the last statistics collection?", right?\\n>\\n> So, maybe they need to be 2 separate options.\\n>\\n> > Although as sami said this SMART is not smart enough as it should be ,\\n> > I will change name accordingly in the further patches\\n>\\n> Yup, I am not too fond of SMART in the name. Also, then name itself\\n> is vague. SKIP_LOCKED and BUFFER_USAGE_LIMIT on the other\\n> hand tell you exactly what they[re used for.\\n>\\n\\nSo, tossing out a new proposal here, which is to offer ANALYZE with 2\\nnew options... MISSING_STATS and MODIFIED_STATS.\\n\\nWhen MISSING_STATS is passed, we attempt to analyze only tables that\\nhave missing stats, essentially implementing a version of\\n--missing-stats-only but for the ANALYZE command. In successive runs,\\nthis should reduce towards a no-op, although we need to decide what to\\ndo about system tables, which, iirc --missing-stats-only always\\nassumes to be true, but this version probably doesn't want to assume\\nthat.\\n\\nWhen MODIFIED_STATS is passed, we would instead only analyze tables\\nwhere some threshold of rows has been modified. I feel like the most\\nobvious choice for this calculation would be based on a formula like\\n\\"analyze threshold = analyze base threshold + analyze scale factor *\\nnumber of tuples\\". Astute observers will note that this is the same\\nthreshold used by autoanalyze, which means if you had the same\\ndefaults you are just doing the work manually that autoanalyze would\\neventually get around to doing (which seems potentially useful on its\\nown). But also if these were based on gucs, the OP could modify those\\ngucs to achieve their desired behavior, ie.\\nset analyze_base_threshold=1; set analyze_scale_factor=0; analyze\\n(modified_stats);  // this should analyze anything with 1 modified row\\nGranted, I don't like that it is both more wordy than the original\\nidea, and that we would need to add new gucs, but this would be pretty\\nflexible.\\n\\n\\nRobert Treat\\nhttps://xzilla.net\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"On Fri, Jan 23, 2026 at 9:31 PM Sami Imseih <samimseih@gmail.com> wrote: > > Thanks for the detailed summary! > > It is important to point out that this feature is trying to do 2","historyId":"15957","internalDate":"1769290598000","receivedAtUtc":"2026-01-24T21:36:38.000Z","from":"Robert Treat <rob@xzilla.net>"}]	The PostgreSQL community discusses a proposed ANALYZE optimization feature that would skip analyzing unchanged tables. Vasuki M clarifies the intent is to reduce redundant work during explicit ANALYZE runs, not replace autovacuum logic. The feature checks if n_mod_since_analyze equals zero to skip analysis, ensuring tables never analyzed are always processed. Sami Imseih raises concerns about the simplistic threshold, questioning why analyze should run for minimal row changes. He notes the feature combines two distinct functions: analyzing unanalyzed tables and analyzing modified tables. Ilia Evdokimov suggests starting with a MISSING_STATS_ONLY option similar to vacuumdb. Robert Treat proposes two separate options: MISSING_STATS for tables without statistics and MODIFIED_STATS using configurable thresholds based on autovacuum parameters, offering more flexibility than the current simple approach.\n\nPostgreSQL社区讨论一个建议的ANALYZE优化功能，可以跳过分析未更改的表。Vasuki M澄清其目的是减少显式ANALYZE运行中的冗余工作，而不是替换自动清理逻辑。该功能检查n_mod_since_analyze是否等于零来跳过分析，确保从未分析过的表始终被处理。Sami Imseih对简单阈值表示担忧，质疑为什么要为最少行变化运行分析。他指出该功能结合了两个不同的功能：分析未分析的表和分析修改的表。Ilia Evdokimov建议从类似vacuumdb的MISSING_STATS_ONLY选项开始。Robert Treat提议两个独立选项：MISSING_STATS用于无统计信息的表，MODIFIED_STATS使用基于自动清理参数的可配置阈值，比当前简单方法提供更多灵活性。	2026-01-24 21:36:38+00	\N
14	19bf21e9faabf42e	[PATCH] Refactor *_abbrev_convert() functions	["adigollamudi@gmail.com","aleksander@tigerdata.com"]	[{"id":"19bf21e9faabf42e","messageId":"<CAD-KL_H-jscSsTRa89W9k5+jaovTYQQv24J4f_cKi-Yr7E0PHw@mail.gmail.com>","subject":"Re: [PATCH] Refactor *_abbrev_convert() functions","body":"On Tue, Jan 13, 2026 at 4:34 AM Aleksander Alekseev <\\naleksander@tigerdata.com> wrote:\\n\\n> Hi,\\n>\\n> Now when all Datums are 64-bit values we can simplify the code by\\n> using murmurhash64(). This refactoring was previously suggested by\\n> John Naylor [1].\\n>\\n> [1]:\\n> https://postgr.es/m/CANWCAZbMyrijdR0xc-4SqpNJBHMEwRZccBK4fa0aquNpq2Uj7w%40mail.gmail.com\\n>\\n> --\\n> Best regards,\\n> Aleksander Alekseev\\n>\\n\\nHi,\\n\\nI reviewed this change and the surrounding code and this seems good!\\nAll tests pass locally for me. Hopefully this gets picked up soon.\\n\\nRegards,\\nAdi Gollamudi\\n","threadId":"19bf21e9faabf42e","snippet":"On Tue, Jan 13, 2026 at 4:34 AM Aleksander Alekseev <aleksander@tigerdata.com> wrote: Hi, Now when all Datums are 64-bit values we can simplify the code by using murmurhash64(). This refactoring","historyId":"16018","internalDate":"1769293624000","receivedAtUtc":"2026-01-24T22:27:04.000Z","from":"Aditya Gollamudi <adigollamudi@gmail.com>"}]	Aditya Gollamudi reviewed Aleksander Alekseev's patch to refactor *_abbrev_convert() functions, which aims to simplify code by using murmurhash64() now that all Datums are 64-bit values. This refactoring was previously suggested by John Naylor. Gollamudi confirmed that the change looks good after reviewing both the patch and surrounding code, and reported that all tests pass locally. The reviewer expressed hope that the patch will be picked up soon for integration. The discussion appears positive with no objections or concerns raised about the proposed implementation.\nAditya Gollamudi 审查了 Aleksander Alekseev 提交的重构 *_abbrev_convert() 函数的补丁，该补丁旨在利用所有 Datum 现在都是 64 位值的特性，通过使用 murmurhash64() 来简化代码。这个重构之前由 John Naylor 提出建议。Gollamudi 在审查补丁和相关代码后确认更改看起来不错，并报告所有测试在本地都通过了。审查者希望该补丁能够很快被采纳集成。讨论看起来是积极的，没有对提议的实现提出异议或担忧。	2026-01-24 22:27:04+00	\N
14	19bf160dd2721de6	Buffer locking is special (hints, checksums, AIO writes)	["andres@anarazel.de","boekewurm+postgres@gmail.com","exclusion@gmail.com","hlinnaka@iki.fi","li.evan.chao@gmail.com","melanieplageman@gmail.com","michael.paquier@gmail.com","noah@leadboat.com","pg@bowt.ie","reshkekirill@gmail.com","robertmhaas@gmail.com","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19bf160dd2721de6","messageId":"<90bd2cbb-49ce-4092-9f61-5ac2ab782c94@gmail.com>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hello Andres,\\n\\n16.01.2026 01:02, Tom Lane wrote:\\n> Various buildfarm animals are complaining about fcb9c977a,\\n> similarly to this from calliphoridae [1]:\\n\\nI've discovered another anomaly introduced with fcb9c977a, this time\\nrun-time:\\nfor i in `seq 300`; do\\necho \\"iteration $i\\"\\n\\necho \\"\\ncreate table t(f1 text);\\ncreate index on t using spgist(f1);\\ninsert into t select 'a' from generate_series(1, 9000) g(i);\\nvacuum analyze t;\\ninsert into t select 'b' from generate_series(1, 1000) g(i);\\ndrop table t;\\n\\" | psql >/dev/null -v ON_ERROR_STOP=1 || break;\\ndone\\n\\nfails for me as below:\\n...\\niteration 39\\nserver closed the connection unexpectedly\\n\\nCore was generated by `postgres: law regression [local] INSERT                 '.\\nProgram terminated with signal SIGABRT, Aborted.\\n#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:44\\n\\nwarning: 44     ./nptl/pthread_kill.c: Нет такого файла или каталога\\n(gdb) bt\\n#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:44\\n#1  __pthread_kill_internal (signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:78\\n#2  __GI___pthread_kill (threadid=<optimized out>, signo=signo@entry=6) at ./nptl/pthread_kill.c:89\\n#3  0x000073625aa4527e in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\\n#4  0x000073625aa288ff in __GI_abort () at ./stdlib/abort.c:79\\n#5  0x00005a479e2f685f in ExceptionalCondition (conditionName=conditionName@entry=0x5a479e403cb8 \\"entry->data.lockmode == BUFFER_LOCK_UNLOCK\\", fileName=fileName@entry=0x5a479e37a84f \\"bufmgr.c\\", lineNumber=lineNumber@entry=5908) at assert.c:65\\n#6  0x00005a479e14d87c in BufferLockConditional (buffer=<optimized out>, buf_hdr=0x73624e882b40, mode=mode@entry=BUFFER_LOCK_EXCLUSIVE) at bufmgr.c:5908\\n#7  0x00005a479e14f4d5 in ConditionalLockBuffer (buffer=buffer@entry=13500) at bufmgr.c:6474\\n#8  0x00005a479de44da9 in SpGistNewBuffer (index=index@entry=0x73625b1f6ce8) at spgutils.c:420\\n#9  0x00005a479de45397 in allocNewBuffer (index=index@entry=0x73625b1f6ce8, flags=flags@entry=3) at spgutils.c:528\\n#10 0x00005a479de456a0 in SpGistGetBuffer (index=index@entry=0x73625b1f6ce8, flags=flags@entry=3, needSpace=<optimized out>, needSpace@entry=4088, isNew=isNew@entry=0x7ffd8fa1b2a7) at spgutils.c:663\\n#11 0x00005a479de3c913 in doPickSplit (index=index@entry=0x73625b1f6ce8, state=state@entry=0x7ffd8fa1b740, current=current@entry=0x7ffd8fa1b510, parent=parent@entry=0x7ffd8fa1b530, newLeafTuple=newLeafTuple@entry=0x5a47cbd7adc8, level=level@entry=4, isNulls=false, isNew=false) at spgdoinsert.c:1046\\n#12 0x00005a479de3e542 in spgdoinsert (index=index@entry=0x73625b1f6ce8, state=state@entry=0x7ffd8fa1b740, heapPtr=heapPtr@entry=0x5a47cbe0b248, datums=datums@entry=0x7ffd8fa1b8d0, isnulls=isnulls@entry=0x7ffd8fa1b8b0) at spgdoinsert.c:2134\\n#13 0x00005a479de40137 in spginsert (index=0x73625b1f6ce8, values=0x7ffd8fa1b8d0, isnull=0x7ffd8fa1b8b0, ht_ctid=0x5a47cbe0b248, heapRel=<optimized out>, checkUnique=<optimized out>, indexUnchanged=false, indexInfo=0x5a47cbe0b0b8) at spginsert.c:206\\n#14 0x00005a479df981d8 in ExecInsertIndexTuples (resultRelInfo=resultRelInfo@entry=0x5a47cbe07120, slot=slot@entry=0x5a47cbe0b218, estate=estate@entry=0x5a47cbe06c10, update=update@entry=false, noDupErr=noDupErr@entry=false, specConflict=specConflict@entry=0x0, arbiterIndexes=0x0, onlySummarizing=false) at execIndexing.c:449\\n#15 0x00005a479dfcc6a9 in ExecInsert (context=context@entry=0x7ffd8fa1bb70, resultRelInfo=resultRelInfo@entry=0x5a47cbe07120, slot=slot@entry=0x5a47cbe0b218, canSetTag=<optimized out>, inserted_tuple=inserted_tuple@entry=0x0, insert_destrel=insert_destrel@entry=0x0) at nodeModifyTable.c:1240\\n#16 0x00005a479dfcdf67 in ExecModifyTable (pstate=0x5a47cbe06f10) at nodeModifyTable.c:4485\\n...\\n\\nBest regards,\\nAlexander","threadId":"19bf160dd2721de6","snippet":"Hello Andres, 16.01.2026 01:02, Tom Lane wrote: Various buildfarm animals are complaining about fcb9c977a, similarly to this from calliphoridae [1]: I've discovered another anomaly introduced with","historyId":"15694","internalDate":"1769281200000","receivedAtUtc":"2026-01-24T19:00:00.000Z","from":"Alexander Lakhin <exclusion@gmail.com>"},{"id":"19bf1b46a148e8a3","messageId":"<esihk6vohorlopugumy6ps6zmyh7cgkwi66trm4ocpbkqa4i2i@g5j2hvbzv4lp>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hi,\\n\\nOn 2026-01-24 21:00:00 +0200, Alexander Lakhin wrote:\\n> 16.01.2026 01:02, Tom Lane wrote:\\n> > Various buildfarm animals are complaining about fcb9c977a,\\n> > similarly to this from calliphoridae [1]:\\n>\\n> I've discovered another anomaly introduced with fcb9c977a, this time\\n> run-time:\\n\\nWith the other anomaly, you mean the spurious compiler warning or something\\nelse?\\n\\n\\n> for i in `seq 300`; do\\n> echo \\"iteration $i\\"\\n>\\n> echo \\"\\n> create table t(f1 text);\\n> create index on t using spgist(f1);\\n> insert into t select 'a' from generate_series(1, 9000) g(i);\\n> vacuum analyze t;\\n> insert into t select 'b' from generate_series(1, 1000) g(i);\\n> drop table t;\\n> \\" | psql >/dev/null -v ON_ERROR_STOP=1 || break;\\n> done\\n>\\n> fails for me as below:\\n> ...\\n> iteration 39\\n> server closed the connection unexpectedly\\n\\n\\nThanks for this report, particularly with the easy reproducer!  How did you\\nfind this?\\n\\n\\nI think this is more likely to be a spgist bug, not a bug in the patch.  From\\nwhat I can tell, spgist tries to conditionally lock a buffer that it itself\\nalready has locked exclusively - that's why the assertion is failing.\\n\\nI reproduced this locally, and could see in a bt full stack that the buffer\\nthat spgist is trying to lock conditionally, is also referenced as\\nnewInnerBuffer in doPickSplit(). So it's not an issue of bufmgr.c loosing\\ntrack of which buffers are locked with what mode.\\n\\nI haven't yet figured out why spgist ends up with a buffer it already is\\nusing.\\n\\nWe could of course just accept this case and have the conditional lock\\nacquisition fail, but I think trying to conditionally lock a buffer that you\\nalready lock is indicative of something having gone wrong.  But I'm open to\\ngoing there anyway, just to avoid causing problems with previously \\"working\\"\\ncode.\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Hi, On 2026-01-24 21:00:00 +0200, Alexander Lakhin wrote: > 16.01.2026 01:02, Tom Lane wrote: > > Various buildfarm animals are complaining about fcb9c977a, > > similarly to this from","historyId":"15694","internalDate":"1769286674000","receivedAtUtc":"2026-01-24T20:31:14.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf1d1806f27778","messageId":"<ipf7upm2ooqnx5hkrw63prrcf4tvbcg4hansufiju3hdso35wr@4opaqhl6lwm7>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hi,\\n\\nOn 2026-01-24 15:31:14 -0500, Andres Freund wrote:\\n> I think this is more likely to be a spgist bug, not a bug in the patch.  From\\n> what I can tell, spgist tries to conditionally lock a buffer that it itself\\n> already has locked exclusively - that's why the assertion is failing.\\n> \\n> I reproduced this locally, and could see in a bt full stack that the buffer\\n> that spgist is trying to lock conditionally, is also referenced as\\n> newInnerBuffer in doPickSplit(). So it's not an issue of bufmgr.c loosing\\n> track of which buffers are locked with what mode.\\n> \\n> I haven't yet figured out why spgist ends up with a buffer it already is\\n> using.\\n> \\n> We could of course just accept this case and have the conditional lock\\n> acquisition fail, but I think trying to conditionally lock a buffer that you\\n> already lock is indicative of something having gone wrong.  But I'm open to\\n> going there anyway, just to avoid causing problems with previously \\"working\\"\\n> code.\\n\\nLooking at the spgist code, and the README, I think we may need to accept the\\nuglines of silently failing when a backend tries to conditionally lock a\\nbuffer that it itself has already locked.  Even though I still don't\\nunderstand how it happens in this this specific case, that doesn't even have\\nconcurrency.\\n\\nPretty ... not great ... that spgist does stuff like extending a relation\\nwhile holding an exclusive buffer lock.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Hi, On 2026-01-24 15:31:14 -0500, Andres Freund wrote: > I think this is more likely to be a spgist bug, not a bug in the patch. From > what I can tell, spgist tries to conditionally lock a","historyId":"15698","internalDate":"1769288584000","receivedAtUtc":"2026-01-24T21:03:04.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf1d9d19ff8787","messageId":"<3472929.1769289107@sss.pgh.pa.us>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Andres Freund <andres@anarazel.de> writes:\\n> I think this is more likely to be a spgist bug, not a bug in the patch.  From\\n> what I can tell, spgist tries to conditionally lock a buffer that it itself\\n> already has locked exclusively - that's why the assertion is failing.\\n\\nI dunno.  It looks to me like the previous LWLock-based implementation\\nof ConditionalLockBuffer() had no such restriction as\\n\\n\\t/*\\n\\t * We better not already hold a lock on the buffer.\\n\\t */\\n\\tAssert(entry->data.lockmode == BUFFER_LOCK_UNLOCK);\\n\\nMaybe I'm missing something, but it looks like the old code would\\nreturn false if the buffer was already locked, whether that lock\\nwas held by our process or another one.  SPGist evidently has an\\nassumption in edge cases that that is the behavior, and I'm not\\nconvinced that it's a good idea to change it.  There may be other\\nsuch edge cases we've not tripped over yet.\\n\\n> We could of course just accept this case and have the conditional lock\\n> acquisition fail, but I think trying to conditionally lock a buffer that you\\n> already lock is indicative of something having gone wrong.\\n\\nI don't really buy this argument.  Yes, within a single function it'd\\nbe silly to lock a buffer and immediately try to lock it again, but\\nwhen you consider cases like recursive modifications of index state,\\nit's *far* from obvious that some lower recursion level might not try\\nto lock a buffer that some outer level already locked.  In the case at\\nhand I think it is probably driven by two recursion levels trying to\\nacquire free space out of the same buffer.  SPGist is expecting the\\nlower level to fail to get the lock and then go find some free space\\nelsewhere.  Yeah, we could probably re-code it to get that outcome\\nin another way, but why?\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Andres Freund <andres@anarazel.de> writes: > I think this is more likely to be a spgist bug, not a bug in the patch. From > what I can tell, spgist tries to conditionally lock a buffer that","historyId":"15743","internalDate":"1769289107000","receivedAtUtc":"2026-01-24T21:11:47.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf1e3100d8d12a","messageId":"<CAH2-WzkDSOQfthnB-LYv3dRuTW6tGiSDGfX8F5A6tuGQ_nY9HA@mail.gmail.com>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"On Sat, Jan 24, 2026 at 4:12 PM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> Andres Freund <andres@anarazel.de> writes:\\n> > We could of course just accept this case and have the conditional lock\\n> > acquisition fail, but I think trying to conditionally lock a buffer that you\\n> > already lock is indicative of something having gone wrong.\\n>\\n> I don't really buy this argument.  Yes, within a single function it'd\\n> be silly to lock a buffer and immediately try to lock it again, but\\n> when you consider cases like recursive modifications of index state,\\n> it's *far* from obvious that some lower recursion level might not try\\n> to lock a buffer that some outer level already locked.  In the case at\\n> hand I think it is probably driven by two recursion levels trying to\\n> acquire free space out of the same buffer.\\n\\nEven nbtree has to deal with this. Also in the context of free space\\nmanagement. See the comments in _bt_allocbuf, particularly the ones\\nwhere we explicitly describe a common scenario where we conditionally\\nlock a buffer that our own caller/backend already has a lock on.\\n\\nI actually agree with Andres' general sentiment about this kind of\\ncoding pattern; it also seems sloppy to me. But it's hard to see how\\nwe could do better in places such as _bt_allocbuf. At least within the\\nconfines of the current FSM design.\\n\\n-- \\nPeter Geoghegan\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"On Sat, Jan 24, 2026 at 4:12 PM Tom Lane <tgl@sss.pgh.pa.us> wrote: > Andres Freund <andres@anarazel.de> writes: > > We could of course just accept this case and have the","historyId":"15825","internalDate":"1769289708000","receivedAtUtc":"2026-01-24T21:21:48.000Z","from":"Peter Geoghegan <pg@bowt.ie>"},{"id":"19bf23f4f8e08dd2","messageId":"<cf7prit6zlr64ekyf7ev4x2jxporxplcjnoq6sao3nbrpawtj7@65mndedqeqm2>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hi,\\n\\nOn 2026-01-24 16:11:47 -0500, Tom Lane wrote:\\n> Andres Freund <andres@anarazel.de> writes:\\n> > I think this is more likely to be a spgist bug, not a bug in the patch.  From\\n> > what I can tell, spgist tries to conditionally lock a buffer that it itself\\n> > already has locked exclusively - that's why the assertion is failing.\\n> \\n> I dunno.  It looks to me like the previous LWLock-based implementation\\n> of ConditionalLockBuffer() had no such restriction as\\n> \\n> \\t/*\\n> \\t * We better not already hold a lock on the buffer.\\n> \\t */\\n> \\tAssert(entry->data.lockmode == BUFFER_LOCK_UNLOCK);\\n> \\n> Maybe I'm missing something, but it looks like the old code would\\n> return false if the buffer was already locked, whether that lock\\n> was held by our process or another one.\\n\\nYea. I added that assert when (I think) Melanie complained that the new code\\nwouldn't detect repeated acquisitions or release of the same content lock as\\nnicely as before.  I guess I went a bit overboard and also added the assertion\\nto ConditionalLockBuffer().\\n\\nI'll go and move it into the branch where we actually got the lock, that seems\\nworth continuing to do.\\n\\n\\n> > We could of course just accept this case and have the conditional lock\\n> > acquisition fail, but I think trying to conditionally lock a buffer that you\\n> > already lock is indicative of something having gone wrong.\\n> \\n> I don't really buy this argument.  Yes, within a single function it'd\\n> be silly to lock a buffer and immediately try to lock it again, but\\n> when you consider cases like recursive modifications of index state,\\n> it's *far* from obvious that some lower recursion level might not try\\n> to lock a buffer that some outer level already locked.\\n\\nYea, there's probably something too that. But I'm not entirely convinced -\\nconsider what happens with an index on a temporary table: A higher level think\\nit got a buffer with space, but then a lower level uses up that space...\\n\\n\\n> In the case at hand I think it is probably driven by two recursion levels\\n> trying to acquire free space out of the same buffer.  SPGist is expecting\\n> the lower level to fail to get the lock and then go find some free space\\n> elsewhere.  Yeah, we could probably re-code it to get that outcome in\\n> another way, but why?\\n\\nRegardless of the assertion, it still feels like there may be something off\\nhere. Why is the page marked as empty in the FSM, despite actually not being\\nempty?\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Hi, On 2026-01-24 16:11:47 -0500, Tom Lane wrote: > Andres Freund <andres@anarazel.de> writes: > > I think this is more likely to be a spgist bug, not a bug in the patch. From > >","historyId":"16085","internalDate":"1769295780000","receivedAtUtc":"2026-01-24T23:03:00.000Z","from":"Andres Freund <andres@anarazel.de>"}]	A PostgreSQL commit fcb9c977a introduced a runtime crash in SPGiST operations. Alexander Lakhin reported a reproducible crash during SPGiST index operations that triggers an assertion failure in BufferLockConditional. The issue occurs when SPGiST tries to conditionally lock a buffer it already holds exclusively. Andres Freund initially suspected a SPGiST bug but later acknowledged that the old LWLock-based implementation allowed conditional locking of already-held buffers, returning false regardless of whether the lock was held by the same process or another. Tom Lane and Peter Geoghegan argued this behavior is expected in recursive index modifications where different levels may attempt to lock the same buffer for free space management. The discussion centers on whether to remove the assertion or maintain stricter buffer locking semantics, with concerns about FSM accuracy in SPGiST.\n\nPostgreSQL提交fcb9c977a在SPGiST操作中引入了运行时崩溃。Alexander Lakhin报告了SPGiST索引操作期间可重现的崩溃，触发BufferLockConditional中的断言失败。问题出现在SPGiST尝试有条件地锁定已独占持有的缓冲区时。Andres Freund最初怀疑是SPGiST错误，但后来承认旧的基于LWLock的实现允许对已持有的缓冲区进行条件锁定，无论锁是被同一进程还是其他进程持有都返回false。Tom Lane和Peter Geoghegan认为这种行为在递归索引修改中是预期的，不同层级可能会尝试锁定同一缓冲区以进行空闲空间管理。讨论集中在是否删除断言或维持更严格的缓冲区锁定语义，同时关注SPGiST中FSM准确性问题。	2026-01-24 23:03:00+00	\N
14	19bebb16779ae05d	Time to drop RADIUS support?	["alvherre@kurilemu.de","jacob.champion@enterprisedb.com","mbanck@gmx.net","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19bec39e69aa2b93","messageId":"<3112825.1769185807@sss.pgh.pa.us>","subject":"Re: Time to drop RADIUS support?","body":"=?utf-8?Q?=C3=81lvaro?= Herrera <alvherre@kurilemu.de> writes:\\n> Would it work to add a WARNING (or something) to all back branches to\\n> ask users to write here, so that we can confirm in the next few months\\n> whether the protocol is completely unused or not?  If we do find users,\\n> then we could try to think of workarounds[*], but otherwise we'd just\\n> remove it for pg19 (or pg20 at the latest) and not waste any more time\\n> on it.\\n\\nI don't think that'd prove a lot.  Affected users (if any) wouldn't\\nnecessarily be quick to adopt the latest minor releases.  They're\\nprobably not even up-to-date on their RADIUS server, or they'd have\\nnoticed it spewing complaints.\\n\\n> I don't think removing it entirely from all back branches is a good\\n> idea, without first making sure that there are no users.\\n\\nAgreed, we can't pull it from the back branches.  But I'm in favor of\\npulling it from HEAD if we document how to use PAM-based RADIUS\\ninstead.  I agree with Thomas' argument that the cost-benefit ratio\\nof fixing our implementation would be poor.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"On 2026-Jan-23, Michael Banck wrote: > So you are saying we add a deprecation notice in the back branches and > drop it in V19? If this is a severe security issue then maybe we can > just","historyId":"12897","internalDate":"1769179993000","receivedAtUtc":"2026-01-23T14:53:13.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"},{"id":"19bebb16779ae05d","messageId":"<CAOYmi+kwVHbra-80wSC7Rh9OGttdd8QFV+VcBtSNkEkux6XkyQ@mail.gmail.com>","subject":"Re: Time to drop RADIUS support?","body":"On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> > I don't think removing it entirely from all back branches is a good\\n> > idea, without first making sure that there are no users.\\n>\\n> Agreed, we can't pull it from the back branches.  But I'm in favor of\\n> pulling it from HEAD if we document how to use PAM-based RADIUS\\n> instead.  I agree with Thomas' argument that the cost-benefit ratio\\n> of fixing our implementation would be poor.\\n\\n+1.\\n\\nI still think a WARNING in the back branches would be a kindness, to\\nlet people know that they need to move.\\n\\n--Jacob\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"=?utf-8?Q?=C3=81lvaro?= Herrera <alvherre@kurilemu.de> writes: > Would it work to add a WARNING (or something) to all back branches to > ask users to write here, so that we can confirm in","historyId":"12897","internalDate":"1769185807000","receivedAtUtc":"2026-01-23T16:30:07.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bebfb1d2134b77","messageId":"<202601231423.4522ubhwkcwj@alvherre.pgsql>","subject":"Re: Time to drop RADIUS support?","body":"On 2026-Jan-23, Michael Banck wrote:\\n\\n> So you are saying we add a deprecation notice in the back branches and\\n> drop it in V19? If this is a severe security issue then maybe we can\\n> just remove it everywhere (ugh), or if not, I think it probably warrants\\n> at least one release cycle of deprecation. Do we have a formal\\n> deprecation timeline policy nowadays?\\n\\nI don't think we do.\\n\\nWould it work to add a WARNING (or something) to all back branches to\\nask users to write here, so that we can confirm in the next few months\\nwhether the protocol is completely unused or not?  If we do find users,\\nthen we could try to think of workarounds[*], but otherwise we'd just\\nremove it for pg19 (or pg20 at the latest) and not waste any more time\\non it.\\n\\nI don't think removing it entirely from all back branches is a good\\nidea, without first making sure that there are no users.\\n\\n[*] or even just a way to document a migration to PAM-based Radius.\\n\\n-- \\nÁlvaro Herrera               48°01'N 7°57'E  —  https://www.EnterpriseDB.com/\\n\\"I'm impressed how quickly you are fixing this obscure issue. I came from \\nMS SQL and it would be hard for me to put into words how much of a better job\\nyou all are doing on [PostgreSQL].\\"\\n Steve Midgley, http://archives.postgresql.org/pgsql-sql/2008-08/msg00000.php\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > > I don't think removing it entirely from all back branches is a good > > idea, without first making sure","historyId":"12897","internalDate":"1769190640000","receivedAtUtc":"2026-01-23T17:50:40.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"},{"id":"19bf24a30d7acf52","messageId":"<CA+hUKGKXHBCptORqu2jZf5o0Gw45Q7YMW9wKmrXYDm35uQStoA@mail.gmail.com>","subject":"Re: Time to drop RADIUS support?","body":"On Sat, Jan 24, 2026 at 6:50 AM Jacob Champion\\n<jacob.champion@enterprisedb.com> wrote:\\n> On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> > > I don't think removing it entirely from all back branches is a good\\n> > > idea, without first making sure that there are no users.\\n> >\\n> > Agreed, we can't pull it from the back branches.  But I'm in favor of\\n> > pulling it from HEAD if we document how to use PAM-based RADIUS\\n> > instead.  I agree with Thomas' argument that the cost-benefit ratio\\n> > of fixing our implementation would be poor.\\n>\\n> +1.\\n\\nGreat, it sounds like we have a plan.  I think the wiki might be a\\ngood place for that documentation.  The details are likely to change,\\nand I wouldn't want to have to maintain that information in-tree, so I\\ncreated some PAM how-to documentation at\\nhttps://wiki.postgresql.org/wiki/RADIUS after testing on Debian and\\nFreeBSD.  We could point to that from the 19 release notes and in the\\ndeprecation notice added to the documentation for 14-18, calling it\\n\\"community-maintained guidance on migration to supported\\nconfigurations\\".  Do we need to keep any trace of this in the 19 docs,\\nand if so, where?  A new tombstone section?\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"On Sat, Jan 24, 2026 at 6:50 AM Jacob Champion <jacob.champion@enterprisedb.com> wrote: > On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > > > I don't","historyId":"16168","internalDate":"1769296459000","receivedAtUtc":"2026-01-24T23:14:19.000Z","from":"Thomas Munro <thomas.munro@gmail.com>"}]	PostgreSQL developers are discussing whether to remove RADIUS authentication support due to security issues and maintenance burden. The consensus is emerging to remove RADIUS from the development branch (HEAD) for version 19, while keeping it in back branches with deprecation warnings. Tom Lane argues that fixing the current implementation has a poor cost-benefit ratio and supports removal from HEAD with documentation on PAM-based RADIUS alternatives. Álvaro Herrera suggests adding warnings to back branches to identify any remaining users before complete removal. Thomas Munro has created wiki documentation at https://wiki.postgresql.org/wiki/RADIUS with migration guidance for Debian and FreeBSD, proposing to reference this community-maintained documentation in release notes and deprecation notices for versions 14-18.\n\nPostgreSQL开发者正在讨论是否因安全问题和维护负担而移除RADIUS身份验证支持。目前达成的共识是从开发分支(HEAD)中移除RADIUS用于版本19，同时在后向分支中保留并添加弃用警告。Tom Lane认为修复当前实现的成本效益比很差，支持从HEAD中移除并提供基于PAM的RADIUS替代方案文档。Álvaro Herrera建议在后向分支中添加警告以识别剩余用户，然后再完全移除。Thomas Munro已在https://wiki.postgresql.org/wiki/RADIUS创建了针对Debian和FreeBSD的迁移指导wiki文档，建议在版本14-18的发布说明和弃用通知中引用这个社区维护的文档。	2026-01-24 23:14:19+00	\N
14	19bf12489bc2e8dc	ABI Compliance Checker GSoC Project	["andres@anarazel.de","andrew@dunslane.net","david@justatheory.com","mankiratsingh1315@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19bf12489bc2e8dc","messageId":"<3451994.1769277248@sss.pgh.pa.us>","subject":"Re: ABI Compliance Checker GSoC Project","body":"As per the discussion at [1], our ABI checks would be more helpful if\\nwe include a --headers-dir option in the abidw call, along the lines\\nof the attached patch.  As things stand, changes in structs that\\nare intentionally abstract outside their defining module will\\nnonetheless be reported as ABI breaks, so that the tool completely\\nmisses the point of the abstraction.  But pointing it to the\\ninstalled headers tree alongside the binary seems to be enough to\\nfix that.  I can confirm Andres' observation that the attached is\\nenough to change the currently-reported breakage to mention just\\nthe globally-accessible struct.\\n\\nSome notes:\\n\\n1. It's kind of annoying not to fold this into the abidw_flags_list\\noption, but I don't see a good way to do that given that the headers\\npath is branch-dependent.\\n\\n2. When installing this change into an active BF member, you'd better\\nblow away the abicheck.$animal cache tree, else you'll have a mess\\nfrom cached trees not having been analyzed with the same options.\\n(I experimented and indeed got some very strange ABI-diff complaints\\nwhen I hadn't done that.)\\n\\n3. The same would likely apply to any change in abidw_flags_list.\\nIs it worth trying to automate that somehow, perhaps by recording\\nthe flags used to build an abicheck cache file?\\n\\n\\t\\t\\tregards, tom lane\\n\\n[1] https://www.postgresql.org/message-id/flat/3256998.1769270320%40sss.pgh.pa.us#67ee3d4a9ebfc915dd6fa2cfecdcbedb\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"As per the discussion at [1], our ABI checks would be more helpful if we include a --headers-dir option in the abidw call, along the lines of the attached patch. As things stand, changes in structs","historyId":"15693","internalDate":"1769277248000","receivedAtUtc":"2026-01-24T17:54:08.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf1e1aea4a5902","messageId":"<2CEFC7F6-4D97-4078-97AB-AEF8CAE287A2@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 12:54, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n\\n> 2. When installing this change into an active BF member, you'd better\\n> blow away the abicheck.$animal cache tree, else you'll have a mess\\n> from cached trees not having been analyzed with the same options.\\n> (I experimented and indeed got some very strange ABI-diff complaints\\n> when I hadn't done that.)\\n\\nI've applied this change to baza, and after a couple false starts, it seems to be sending OKs. I did have to delete every directory except for `pgmirror.git`.\\n\\nD\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 12:54, Tom Lane <tgl@sss.pgh.pa.us> wrote: > 2. When installing this change into an active BF member, you'd better > blow away the abicheck.$animal cache tree, else","historyId":"15780","internalDate":"1769289632000","receivedAtUtc":"2026-01-24T21:20:32.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf1e4e55742fb6","messageId":"<3473943.1769289856@sss.pgh.pa.us>","subject":"Re: ABI Compliance Checker GSoC Project","body":"\\"David E. Wheeler\\" <david@justatheory.com> writes:\\n> I've applied this change to baza, and after a couple false starts, it seems to be sending OKs. I did have to delete every directory except for `pgmirror.git`.\\n\\nSome of baza's recent failures indicate out-of-disk-space.\\nYou might have to clear some additional space on that machine.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"\\"David E. Wheeler\\" <david@justatheory.com> writes: > I've applied this change to baza, and after a couple false starts, it seems to be sending OKs. I did have to delete every","historyId":"15871","internalDate":"1769289856000","receivedAtUtc":"2026-01-24T21:24:16.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf1e963d73f90e","messageId":"<139BC930-34CD-42F0-9848-53659529B04E@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 16:24, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n\\n> Some of baza's recent failures indicate out-of-disk-space.\\n> You might have to clear some additional space on that machine.\\n\\nYeah I have a script that runs ahead of the daily cron job that clear space, but forgot to run it before I manually started a run about an hour ago. Killed that run, cleared space, and started another run.\\n\\nD\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 16:24, Tom Lane <tgl@sss.pgh.pa.us> wrote: > Some of baza's recent failures indicate out-of-disk-space. > You might have to clear some additional space on that","historyId":"15912","internalDate":"1769290140000","receivedAtUtc":"2026-01-24T21:29:00.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf245ccf69fb62","messageId":"<9EB6EE0F-72D6-4F74-A479-F13A15BCE551@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 16:29, David E. Wheeler <david@justatheory.com> wrote:\\n\\n> Yeah I have a script that runs ahead of the daily cron job that clear space, but forgot to run it before I manually started a run about an hour ago. Killed that run, cleared space, and started another run.\\n\\nAre ABI failures like this[0] expected?\\n\\nD\\n\\n[0]: https://buildfarm.postgresql.org/cgi-bin/show_stage_log.pl?nm=baza&dt=2026-01-24%2022%3A06%3A20&stg=abi-compliance-check\\n\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 16:29, David E. Wheeler <david@justatheory.com> wrote: > Yeah I have a script that runs ahead of the daily cron job that clear space, but forgot to run it before I manually","historyId":"16127","internalDate":"1769296194000","receivedAtUtc":"2026-01-24T23:09:54.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf25e793c57986","messageId":"<c2lzkkxeyrvucxyl4uf2d6v5l56esymzs3hujc64pdhg2er6j2@xnxpbj6gqcpi>","subject":"Re: ABI Compliance Checker GSoC Project","body":"Hi,\\n\\nOn 2026-01-24 18:09:54 -0500, David E. Wheeler wrote:\\n> Are ABI failures like this[0] expected?\\n\\ncommit b4307ae2e54 (HEAD, upstream/master, upstream/HEAD, master)\\nAuthor: Dean Rasheed <dean.a.rasheed@gmail.com>\\nDate:   2026-01-24 11:30:48 +0000\\n\\n    Fix trigger transition table capture for MERGE in CTE queries.\\n...\\n\\n    This requires changing the TransitionCaptureState structure, replacing\\n    \\"tcs_private\\" with 3 separate pointers to AfterTriggersTableData\\n    structures, one for each of INSERT, UPDATE, and DELETE. Nominally,\\n    this is an ABI break to a public structure in commands/trigger.h.\\n    However, since this is a private field pointing to an opaque data\\n    structure, the only way to create a valid TransitionCaptureState is by\\n    calling MakeTransitionCaptureState(), and no extensions appear to be\\n    doing that anyway, so it seems safe for back-patching.\\n...\\n\\n\\nIn [1] Dean said he's expects to have to push an amendment to\\n.abi-compliance-history soon. But then the discussion got a bit derailed\\nbecause one of the complaints being reported is bogus, as the struct is only\\ndefined in a .c file.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n[1] https://postgr.es/m/CAEZATCX3obg5BP3g36LFDhsZgG9BYPN3qQusz_F-K%3D-yOoPJCw%40mail.gmail.com\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"Hi, On 2026-01-24 18:09:54 -0500, David E. Wheeler wrote: > Are ABI failures like this[0] expected? commit b4307ae2e54 (HEAD, upstream/master, upstream/HEAD, master) Author: Dean Rasheed <dean.a.","historyId":"16225","internalDate":"1769297822000","receivedAtUtc":"2026-01-24T23:37:02.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf26995350fd3b","messageId":"<5AF06D5F-D954-4ECA-8184-98F387265E25@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 18:37, Andres Freund <andres@anarazel.de> wrote:\\n\\n> In [1] Dean said he's expects to have to push an amendment to\\n> .abi-compliance-history soon. But then the discussion got a bit derailed\\n> because one of the complaints being reported is bogus, as the struct is only\\n> defined in a .c file.\\n\\nCool, hopefully we're back on track then.\\n\\nD\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 18:37, Andres Freund <andres@anarazel.de> wrote: > In [1] Dean said he's expects to have to push an amendment to > .abi-compliance-history soon. But then the","historyId":"16276","internalDate":"1769298541000","receivedAtUtc":"2026-01-24T23:49:01.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"}]	Tom Lane proposes an improvement to PostgreSQL's ABI compliance checker by adding a --headers-dir option to the abidw call. This change addresses false positives where intentionally abstract structs are incorrectly flagged as ABI breaks. The patch helps the tool focus on globally-accessible structs by pointing it to the installed headers tree. Key implementation notes include the need to clear abicheck cache trees when applying this change to avoid conflicts from differently-analyzed cached data. David Wheeler successfully applies the change to the baza buildfarm member after clearing cache directories. A recent ABI failure is identified as expected due to Dean Rasheed's commit changing TransitionCaptureState structure, with an amendment to .abi-compliance-history anticipated soon.\n\nTom Lane提议通过在abidw调用中添加--headers-dir选项来改进PostgreSQL的ABI合规性检查器。此更改解决了故意抽象结构被错误标记为ABI破坏的误报问题。该补丁通过指向已安装的头文件树帮助工具专注于全局可访问的结构。关键实现说明包括在应用此更改时需要清除abicheck缓存树，以避免不同分析的缓存数据产生冲突。David Wheeler成功将更改应用到baza构建场成员，在清除缓存目录后运行正常。最近的ABI失败被确认是预期的，这是由于Dean Rasheed的提交更改了TransitionCaptureState结构，预计很快会修正.abi-compliance-history。	2026-01-24 23:49:01+00	\N
15	19bed51841b76f7b	Custom oauth validator options	["david.g.johnston@gmail.com","jacob.champion@enterprisedb.com","myon@debian.org","robertmhaas@gmail.com","vasukianand0119@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bed51841b76f7b","messageId":"<CAOYmi+nhh-fChn-8K7HV4kwVwsTm_gVy5jBgUBMqfM6Hm5E4zg@mail.gmail.com>","subject":"Re: Custom oauth validator options","body":"On Tue, Jan 20, 2026 at 12:31 PM Zsolt Parragi\\n<zsolt.parragi@percona.com> wrote:\\n> > But if someone decides in PG20 that\\n> > pam_use_hostname is a good GUC name for something, we're in trouble,\\n> > because the existing HBA options do not plug into the GUC system.\\n>\\n> We could make them reserved names?\\n\\nI'm wondering if we should maybe do the opposite, and namespace the\\nGUCs instead? The vast majority of settings in an HBA are not going to\\nbe GUCs, they're going to be method-specific parameters. So maybe it's\\nokay to have to do more typing to do the uncommon thing, and reference\\nthem like `guc.log_connections` or something.\\n\\n> Or maybe even accessible as GUC\\n> variables, even if we leave the current parsing/validation logic as\\n> is. Making them proper GUC variables seemed like a clear follow up\\n> patch to me, even if not for pg19.\\n\\nHmm... we may want to discuss my (e) option derailment more seriously,\\nif we're planning to go in that direction (and if other people like\\nthat direction).\\n\\n> > I'm worried that it's about to make a different decision from the\\n> > decision that is being made for the pg_hosts.conf file for SNI.\\n>\\n> I probably should read that thread in more detail, but I assume that\\n> your worry is about pg_hosts being a hardcoded configuration instead\\n> of using a similarly customizable GUC context? Shouldn't that be\\n> fixable in the future similarly?\\n\\n\\"Fixable\\" in what sense? pg_hosts.conf is currently similar to\\npg_ident.conf in that it has no place for key=value pairs, and if you\\nadd them after as an optional \\"column\\" for compatibility, you still\\nhave to write something for all of those columns that you were trying\\nto replace with the GUC settings.\\n\\n> > 3) can your option (b) or (c) make enough use of existing GUC\\n> > infrastructure, so that a future PGC_HBA could easily subsume an\\n> > OAuth-specific solution, if people want to continue down that path in\\n> > a less OAuth-centric thread?\\n>\\n> I'm not sure about reusing existing GUC infrastructure, but  I could\\n> make it look similar from the users perspective for example by adding\\n> a function DefineCustomValidatorStringVariable that has a similar\\n> interface to DefineCustomStringVariable, and in the future, this\\n> function could simply forward to DefineCustomStringVariable.\\n\\nMight work, yeah.\\n\\n--Jacob\\n\\n\\n","threadId":"19bed51841b76f7b","snippet":"On Tue, Jan 20, 2026 at 12:31 PM Zsolt Parragi <zsolt.parragi@percona.com> wrote: > > But if someone decides in PG20 that > > pam_use_hostname is a good GUC name for something, we","historyId":"15686","internalDate":"1769213079000","receivedAtUtc":"2026-01-24T00:04:39.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"}]	Jacob Champion discusses PostgreSQL's custom OAuth validator options, focusing on potential naming conflicts between HBA (Host-Based Authentication) options and GUC (Grand Unified Configuration) variables. He suggests namespacing GUCs instead of making HBA options reserved names, proposing syntax like `guc.log_connections` since most HBA settings will be method-specific parameters rather than GUCs. Champion expresses concerns about consistency with the pg_hosts.conf file for SNI (Server Name Indication) and questions whether it should use similar customizable GUC contexts. He acknowledges that pg_hosts.conf currently lacks key=value pair support like pg_ident.conf. Champion shows interest in exploring a DefineCustomValidatorStringVariable function that could potentially forward to DefineCustomStringVariable in future implementations, suggesting this approach might work for gradual migration toward a more unified configuration system.\nJacob Champion 讨论了 PostgreSQL 的自定义 OAuth 验证器选项，重点关注 HBA（基于主机的身份验证）选项与 GUC（大统一配置）变量之间的潜在命名冲突。他建议对 GUC 进行命名空间化，而不是将 HBA 选项设为保留名称，提出像 `guc.log_connections` 这样的语法，因为大多数 HBA 设置将是特定于方法的参数而不是 GUC。Champion 对与用于 SNI（服务器名称指示）的 pg_hosts.conf 文件的一致性表示担忧，并质疑它是否应该使用类似的可定制 GUC 上下文。他承认 pg_hosts.conf 目前像 pg_ident.conf 一样缺乏键值对支持。Champion 对探索 DefineCustomValidatorStringVariable 函数表示兴趣，该函数可能在未来实现中转发到 DefineCustomStringVariable，表明这种方法可能适用于向更统一的配置系统的渐进迁移。	2026-01-24 00:04:39+00	\N
15	19bed67824d1f608	eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)	["andres@anarazel.de","hlinnaka@iki.fi","li.evan.chao@gmail.com","melanieplageman@gmail.com","reshkekirill@gmail.com","robertmhaas@gmail.com","x4mmm@yandex-team.ru","xunengzhou@gmail.com"]	[{"id":"19bed67824d1f608","messageId":"<7ib3sa55sapwjlaz4sijbiq7iezna27kjvvvar4dpgkmadml6t@gfpkkwmdnepx>","subject":"Re: eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)","body":"Hi,\\n\\nOn 2026-01-06 12:31:57 -0500, Melanie Plageman wrote:\\n> Subject: [PATCH v33 01/16] Combine visibilitymap_set() cases in\\n>  lazy_scan_prune()\\n>\\n> lazy_scan_prune() previously had two separate cases that called\\n> visibilitymap_set() after pruning and freezing. These branches were\\n> nearly identical except that one attempted to avoid dirtying the heap\\n> buffer. However, that situation can never occur — the heap buffer cannot\\n> be clean at that point (and we would hit an assertion if it were).\\n>\\n> In lazy_scan_prune(), when we change a previously all-visible page to\\n> all-frozen and the page was recorded as all-visible in the visibility\\n> map by find_next_unskippable_block(), the heap buffer will always be\\n> dirty. Either we have just frozen a tuple and already dirtied the\\n> buffer, or the buffer was modified between find_next_unskippable_block()\\n> and heap_page_prune_and_freeze() and then pruned in\\n> heap_page_prune_and_freeze().\\n>\\n> Additionally, XLogRegisterBuffer() asserts that the buffer is dirty, so\\n> attempting to add a clean heap buffer to the WAL chain would assert out\\n> anyway.\\n>\\n> Since the \\"clean heap buffer with already set VM\\" case is impossible,\\n> the two visibilitymap_set() branches in lazy_scan_prune() can be merged.\\n> Doing so makes the intent clearer and emphasizes that the heap buffer\\n> must always be marked dirty before being added to the WAL chain.\\n>\\n> This commit also adds a test case for vacuuming when no heap\\n> modifications are required. Currently this ensures that the heap buffer\\n> is marked dirty before it is added to the WAL chain, but if we later\\n> remove the heap buffer from the VM-set WAL chain or pass it with the\\n> REGBUF_NO_CHANGES flag, this test would guard that behavior.\\n>\\n> Author: Melanie Plageman <melanieplageman@gmail.com>\\n> Reviewed-by: Chao Li <li.evan.chao@gmail.com>\\n> Reviewed-by: Srinath Reddy Sadipiralla <srinath2133@gmail.com>\\n> Reviewed-by: Kirill Reshke <reshkekirill@gmail.com>\\n> Reviewed-by: Xuneng Zhou <xunengzhou@gmail.com>\\n> Discussion: https://postgr.es/m/5CEAA162-67B1-44DA-B60D-8B65717E8B05%40gmail.com\\n> Discussion: https://postgr.es/m/flat/CAAKRu_ZWx5gCbeCf7PWCv8p5%3D%3Db7EEws0VD2wksDxpXCvCyHvQ%40mail.gmail.com\\n> ---\\n>  .../pg_visibility/expected/pg_visibility.out  | 44 ++++++++++\\n>  contrib/pg_visibility/sql/pg_visibility.sql   | 20 +++++\\n>  src/backend/access/heap/vacuumlazy.c          | 87 ++++---------------\\n>  3 files changed, 82 insertions(+), 69 deletions(-)\\n>\\n> diff --git a/contrib/pg_visibility/expected/pg_visibility.out b/contrib/pg_visibility/expected/pg_visibility.out\\n> index 09fa5933a35..e10f1706015 100644\\n> --- a/contrib/pg_visibility/expected/pg_visibility.out\\n> +++ b/contrib/pg_visibility/expected/pg_visibility.out\\n> @@ -1,4 +1,5 @@\\n>  CREATE EXTENSION pg_visibility;\\n> +CREATE EXTENSION pageinspect;\\n\\nI think this would need a EXTRA_INSTALL = contrib/pageinspect to work reliably\\nin make.  You should be able to see a failure without the fix if you remove\\nthe tmp_install/ dir in an autoconf build and then run make check for\\npg_visibility.\\n\\nI'm slightly wary of embedding numerical bitmaks values in the tests, but I\\ndon't see a better alternative right now.\\n\\nOther than the EXTRA_INSTALL thing I think this is ready.\\n\\n\\n\\n> From 4d37243f9fa0dc4e264a28bcee448787fb8d7f65 Mon Sep 17 00:00:00 2001\\n> From: Melanie Plageman <melanieplageman@gmail.com>\\n> Date: Thu, 11 Dec 2025 10:48:13 -0500\\n> Subject: [PATCH v33 02/16] Eliminate use of cached VM value in\\n>  lazy_scan_prune()\\n>\\n> lazy_scan_prune() takes a parameter from lazy_scan_heap() indicating\\n> whether the page was marked all-visible in the VM at the time it was\\n> last checked in find_next_unskippable_block(). This behavior is\\n> historical, dating back to commit 608195a3a365, when we did not pin the\\n> VM page until deciding we must read it. Now that the VM page is already\\n> pinned, there is no meaningful benefit to relying on a cached VM status.\\n>\\n> Removing this cached value simplifies the logic in both lazy_scan_heap()\\n> and lazy_scan_prune(). It also clarifies future work that will set the\\n> visibility map on-access: such paths will not have a cached value\\n> available, which would make the logic harder to reason about. And\\n> eliminating it enables us to detect and repair VM corruption on-access.\\n>\\n> Along with removing the cached value and unconditionally checking the\\n> visibility status of the heap page, this commit also moves the VM\\n> corruption handling to occur first. This reordering should have no\\n> performance impact, since the checks are inexpensive and performed only\\n> once per page. It does, however, make the control flow easier to\\n> understand. The new restructuring also makes it possible to set the VM\\n> after fixing corruption (if pruning found the page all-visible).\\n>\\n> Now that no callers of visibilitymap_set() use its return value, change\\n> its (and visibilitymap_set_vmbits()) return type to void.\\n\\n> @@ -1735,7 +1719,6 @@ find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis)\\n>  \\tBlockNumber next_unskippable_block = vacrel->next_unskippable_block + 1;\\n>  \\tBuffer\\t\\tnext_unskippable_vmbuffer = vacrel->next_unskippable_vmbuffer;\\n>  \\tbool\\t\\tnext_unskippable_eager_scanned = false;\\n> -\\tbool\\t\\tnext_unskippable_allvis;\\n>\\n>  \\t*skipsallvis = false;\\n>\\n> @@ -1745,7 +1728,6 @@ find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis)\\n>  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   next_unskippable_block,\\n>  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   &next_unskippable_vmbuffer);\\n>\\n> -\\t\\tnext_unskippable_allvis = (mapbits & VISIBILITYMAP_ALL_VISIBLE) != 0;\\n>\\n>  \\t\\t/*\\n>  \\t\\t * At the start of each eager scan region, normal vacuums with eager\\n> @@ -1764,7 +1746,7 @@ find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis)\\n>  \\t\\t * A block is unskippable if it is not all visible according to the\\n>  \\t\\t * visibility map.\\n>  \\t\\t */\\n> -\\t\\tif (!next_unskippable_allvis)\\n> +\\t\\tif ((mapbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n>  \\t\\t{\\n>  \\t\\t\\tAssert((mapbits & VISIBILITYMAP_ALL_FROZEN) == 0);\\n>  \\t\\t\\tbreak;\\n\\nThis feels a bit independent from the rest, but it doesn't matter.\\n\\n\\n\\n> @@ -2225,6 +2144,71 @@ lazy_scan_prune(LVRelState *vacrel,\\n>  \\t\\tMarkBufferDirty(buf);\\n>  \\t\\tvisibilitymap_clear(vacrel->rel, blkno, vmbuffer,\\n>  \\t\\t\\t\\t\\t\\t\\tVISIBILITYMAP_VALID_BITS);\\n> +\\t\\t/* VM bits are now clear */\\n> +\\t\\told_vmbits = 0;\\n> +\\t}\\n> +\\n> +\\tif (!presult.all_visible)\\n> +\\t\\treturn presult.ndeleted;\\n> +\\n> +\\t/* Set the visibility map and page visibility hint */\\n> +\\tnew_vmbits = VISIBILITYMAP_ALL_VISIBLE;\\n> +\\n> +\\tif (presult.all_frozen)\\n> +\\t\\tnew_vmbits |= VISIBILITYMAP_ALL_FROZEN;\\n> +\\n> +\\t/* Nothing to do */\\n> +\\tif (old_vmbits == new_vmbits)\\n> +\\t\\treturn presult.ndeleted;\\n>\\n> +\\tAssert(presult.all_visible);\\n\\nGiven that there's an explicit return for this case a few lines above, I don't\\nunderstand what the assert is trying to do?\\n\\n\\n> +\\t/*\\n> +\\t * It should never be the case that the visibility map page is set while\\n> +\\t * the page-level bit is clear\\n\\nI'd perhaps add a parenthetical saying (and if so, we cleared it above) or\\nsuch.\\n\\n\\n> +\\tvisibilitymap_set(vacrel->rel, blkno, buf,\\n> +\\t\\t\\t\\t\\t  InvalidXLogRecPtr,\\n> +\\t\\t\\t\\t\\t  vmbuffer, presult.vm_conflict_horizon,\\n> +\\t\\t\\t\\t\\t  new_vmbits);\\n> +\\n> +\\t/*\\n> +\\t * If the page wasn't already set all-visible and/or all-frozen in the VM,\\n> +\\t * count it as newly set for logging.\\n> +\\t */\\n> +\\tif ((old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n> +\\t{\\n> +\\t\\tvacrel->vm_new_visible_pages++;\\n> +\\t\\tif (presult.all_frozen)\\n> +\\t\\t{\\n> +\\t\\t\\tvacrel->vm_new_visible_frozen_pages++;\\n> +\\t\\t\\t*vm_page_frozen = true;\\n\\nNot this patches fault, but I find \\"vm_new_visible_pages\\" and\\n\\"vm_new_visible_frozen_pages\\" pretty odd names. The concept is all-visible and\\nfrozen. The page itself isn't visible or invisible...\\n\\n\\n\\n> Subject: [PATCH v33 03/16] Refactor lazy_scan_prune() VM clear logic into\\n>  helper\\n\\n> +/*\\n> + * Helper to correct any corruption detected on a heap page and its\\n> + * corresponding visibility map page after pruning but before setting the\\n> + * visibility map. It examines the heap page, the associated VM page, and the\\n> + * number of dead items previously identified.\\n> + *\\n> + * This function must be called while holding an exclusive lock on the heap\\n> + * buffer, and the dead items must have been discovered under that same lock.\\n> +\\n> + * The provided vmbits must reflect the current state of the VM block\\n> + * referenced by vmbuffer. Although we do not hold a lock on the VM buffer, it\\n> + * is pinned, and the heap buffer is exclusively locked, ensuring that no\\n> + * other backend can update the VM bits corresponding to this heap page.\\n> + *\\n> + * Returns true if it cleared corruption and false otherwise.\\n> + */\\n\\nI don't love that the caller now has to assume that old_vmbits is zero after\\nthis function returns.  Somehow that feels like split responsiility.\\n\\nI guess I'd take a pointer to old_vmbits and update it accordingly inside\\nidentify_and_fix_vm_corruption() rather than in the caller.\\n\\n\\n> From 5c65e73246b4968ddfa9d3739f53d0d8734b8727 Mon Sep 17 00:00:00 2001\\n> From: Melanie Plageman <melanieplageman@gmail.com>\\n> Date: Tue, 2 Dec 2025 15:07:42 -0500\\n> Subject: [PATCH v33 04/16] Set the VM in heap_page_prune_and_freeze()\\n>\\n> This has no independent benefit. It is meant for ease of review. As of\\n> this commit, there is still a separate WAL record emitted for setting\\n> the VM after pruning and freezing. But it is easier to review if moving\\n> the logic into pruneheap.c is separate from setting the VM in the same\\n> WAL record.\\n\\nIt seems a bit noisy to refactor the related code in some of the preceding\\ncommits and then refactor it into a slightly different shape as part of this\\ncommit (c.f. heap_page_will_set_vm()).\\n\\nIt's also a bit odd that a function that sounds rather read-only does stuff\\nlike clearing VM/all-visible.\\n\\nWhy are we not doing fixing up of the page *before* we prune it?  It's a bit\\ninsane that we do the WAL logging for pruning, which in turn will often\\ninclude an FPI, before we do the fixups. The fixes aren't WAL logged, so this\\nactually leads to the standby getting further out of sync.\\n\\nI realize this isn't your mess, but brrr.\\n\\n\\nDo we actually forsee a case where only one of HEAP_PAGE_PRUNE_FREEZE |\\nHEAP_PAGE_PRUNE_UPDATE_VM would be set?\\n\\n\\n> --- a/src/backend/access/heap/vacuumlazy.c\\n> +++ b/src/backend/access/heap/vacuumlazy.c\\n> @@ -424,11 +424,7 @@ static void find_next_unskippable_block(LVRelState *vacrel, bool *skipsallvis);\\n>  static bool lazy_scan_new_or_empty(LVRelState *vacrel, Buffer buf,\\n>  \\t\\t\\t\\t\\t\\t\\t\\t   BlockNumber blkno, Page page,\\n>  \\t\\t\\t\\t\\t\\t\\t\\t   bool sharelock, Buffer vmbuffer);\\n> -static bool identify_and_fix_vm_corruption(Relation rel, Buffer heap_buffer,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   BlockNumber heap_blk, Page heap_page,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   int nlpdead_items,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   Buffer vmbuffer,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t   uint8 vmbits);\\n> +\\n>  static int\\tlazy_scan_prune(LVRelState *vacrel, Buffer buf,\\n>  \\t\\t\\t\\t\\t\\t\\tBlockNumber blkno, Page page,\\n>  \\t\\t\\t\\t\\t\\t\\tBuffer vmbuffer,\\n> @@ -1962,83 +1958,6 @@ cmpOffsetNumbers(const void *a, const void *b)\\n>  \\treturn pg_cmp_u16(*(const OffsetNumber *) a, *(const OffsetNumber *) b);\\n>  }\\n\\nSpurious newline inserted.\\n\\n\\n>  \\t/*\\n>  \\t * If the page wasn't already set all-visible and/or all-frozen in the VM,\\n>  \\t * count it as newly set for logging.\\n>  \\t */\\n> -\\tif ((old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n> +\\tif ((presult.old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0 &&\\n> +\\t\\t(presult.new_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0)\\n>  \\t{\\n>  \\t\\tvacrel->vm_new_visible_pages++;\\n> -\\t\\tif (presult.all_frozen)\\n> +\\t\\tif ((presult.new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n>  \\t\\t{\\n>  \\t\\t\\tvacrel->vm_new_visible_frozen_pages++;\\n>  \\t\\t\\t*vm_page_frozen = true;\\n>  \\t\\t}\\n>  \\t}\\n> -\\telse if ((old_vmbits & VISIBILITYMAP_ALL_FROZEN) == 0 &&\\n> -\\t\\t\\t presult.all_frozen)\\n> +\\telse if ((presult.old_vmbits & VISIBILITYMAP_ALL_FROZEN) == 0 &&\\n> +\\t\\t\\t (presult.new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n>  \\t{\\n> +\\t\\tAssert((presult.new_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0);\\n>  \\t\\tvacrel->vm_new_frozen_pages++;\\n>  \\t\\t*vm_page_frozen = true;\\n>  \\t}\\n\\nIt's a bit odd that we figure out all of this by inspecting old/new vmbits and\\nhave that logic in multiple places.\\n\\n\\n> Subject: [PATCH v33 05/16] Move VM assert into prune/freeze code\\n\\nFeels like a somewhat too narrow description, given that it changes the API\\nfor heap_page_prune_and_freeze() by removing variables from PruneFreezeResult.\\n\\n\\n> +#ifdef USE_ASSERT_CHECKING\\n> +\\n> +/*\\n> + * Wrapper for heap_page_would_be_all_visible() which can be used for callers\\n> + * that expect no LP_DEAD on the page. Currently assert-only, but there is no\\n> + * reason not to use it outside of asserts.\\n> + */\\n\\nIf so, why would we want it in pruneheap.c? Seems a bit odd to have\\nheap_page_would_be_all_visible() defined in vacuumlazy.c but defined\\nheap_page_is_all_visible() in pruneheap.c.\\n\\n\\n\\n> From cdf5776fadeae3430c692999b37f8a7ec944bda1 Mon Sep 17 00:00:00 2001\\n> From: Melanie Plageman <melanieplageman@gmail.com>\\n> Date: Tue, 2 Dec 2025 16:16:22 -0500\\n> Subject: [PATCH v33 06/16] Eliminate XLOG_HEAP2_VISIBLE from vacuum phase I\\n>  prune/freeze\\n>\\n> Vacuum no longer emits a separate WAL record for each page set\\n> all-visible or all-frozen during phase I. Instead, visibility map\\n> updates are now included in the XLOG_HEAP2_PRUNE_VACUUM_SCAN record that\\n> is already emitted for pruning and freezing.\\n>\\n> Previously, heap_page_prune_and_freeze() determined whether a page was\\n> all-visible, but the corresponding VM bits were only set later in\\n> lazy_scan_prune(). Now the VM is updated immediately in\\n> heap_page_prune_and_freeze(), at the same time as the heap\\n> modifications.\\n>\\n> This change applies only to vacuum phase I, not to pruning performed\\n> during normal page access.\\n\\n> +/*\\n> + * Calculate the conflict horizon for the whole XLOG_HEAP2_PRUNE_VACUUM_SCAN\\n> + * or XLOG_HEAP2_PRUNE_ON_ACCESS record.\\n> + */\\n> +static TransactionId\\n> +get_conflict_xid(bool do_prune, bool do_freeze, bool do_set_vm,\\n> +\\t\\t\\t\\t uint8 old_vmbits, uint8 new_vmbits,\\n> +\\t\\t\\t\\t TransactionId latest_xid_removed, TransactionId frz_conflict_horizon,\\n> +\\t\\t\\t\\t TransactionId visibility_cutoff_xid)\\n> +{\\n\\nThe logic for horizons is now split between this and \\"Calculate what the\\nsnapshot conflict horizon should be for a record\\" in heap_page_will_freeze().\\n\\nAlthough I guess I don't understand that code:\\n\\n\\t\\t/*\\n\\t\\t * Calculate what the snapshot conflict horizon should be for a record\\n\\t\\t * freezing tuples. We can use the visibility_cutoff_xid as our cutoff\\n\\t\\t * for conflicts when the whole page is eligible to become all-frozen\\n\\t\\t * in the VM once we're done with it. Otherwise, we generate a\\n\\t\\t * conservative cutoff by stepping back from OldestXmin.\\n\\t\\t */\\n\\t\\tif (prstate->all_frozen)\\n\\t\\t\\tprstate->frz_conflict_horizon = prstate->visibility_cutoff_xid;\\n\\t\\telse\\n\\t\\t{\\n\\t\\t\\t/* Avoids false conflicts when hot_standby_feedback in use */\\n\\t\\t\\tprstate->frz_conflict_horizon = prstate->cutoffs->OldestXmin;\\n\\t\\t\\tTransactionIdRetreat(prstate->frz_conflict_horizon);\\n\\t\\t}\\n\\nWhy does it make sense to use OldestXmin? Consider e.g. the case where there\\nis one very old tuple that needs to be frozen and one new live tuple on a\\npage. Because of the new tuple we can't mark the page all-frozen. But there's\\nalso no reason to not use much less aggressive horizon than OldestXmin, namely\\nthe newer of xmin,xmax of the old frozen tuple?\\n\\nI also don't understand what the \\"false conflicts\\" thing is referencing.\\n\\n\\n> +\\tTransactionId conflict_xid;\\n> +\\n> +\\t/*\\n> +\\t * We can omit the snapshot conflict horizon if we are not pruning or\\n> +\\t * freezing any tuples and are setting an already all-visible page\\n> +\\t * all-frozen in the VM. In this case, all of the tuples on the page must\\n> +\\t * already be visible to all MVCC snapshots on the standby.\\n> +\\t */\\n\\nThe last sentence here is a bit confusing, because they don't just need to\\nalready be visible to everyone, they already need to be frozen. Right?\\n\\n\\n> +\\tif (!do_prune &&\\n> +\\t\\t!do_freeze &&\\n> +\\t\\tdo_set_vm &&\\n\\nI'm confused by the do_set_vm check here. Doesn't it mean that we will *not*\\nreturn InvalidTransactionId if !prstate->attempt_update_vm?  I don't undestand\\nwhy that would make sense.\\n\\nI guess we'll compute a bogus cutoff in that cse, but never use it, since\\nwe'll also not emit WAL?  Or maybe we'll just unnecessarily go through the\\ncode below, because the code turns out to do ok regardles?  It's confusing\\neither way.\\n\\n\\n\\n> +\\t\\t(old_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0 &&\\n> +\\t\\t(new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n\\nI wonder if some of this code would end up cleaner if we tracked the bits we\\nintend to add, rather than the target set of bits is.\\n\\n\\n> +\\t/*\\n> +\\t * The snapshotConflictHorizon for the whole record should be the most\\n> +\\t * conservative of all the horizons calculated for any of the possible\\n> +\\t * modifications.  If this record will prune tuples, any transactions on\\n> +\\t * the standby older than the youngest xmax of the most recently removed\\n> +\\t * tuple this record will prune will conflict.  If this record will freeze\\n> +\\t * tuples, any transactions on the standby with xids older than the\\n> +\\t * youngest tuple this record will freeze will conflict.\\n> +\\t */\\n> +\\tconflict_xid = InvalidTransactionId;\\n\\nI'd move this first assignment into an else.\\n\\n> +\\t/*\\n> +\\t * If we are updating the VM, the conflict horizon is almost always the\\n> +\\t * visibility cutoff XID.\\n> +\\t *\\n> +\\t * Separately, if we are freezing any tuples, as an optimization, we can\\n> +\\t * use the visibility_cutoff_xid as the conflict horizon if the page will\\n> +\\t * be all-frozen.\\n\\nWhat does \\"as an optimization\\" mean here?\\n\\nNote that the code actually uses visibility_cutoff_xid even if the page is\\njust marked all-visible, but not all-frozen (due to the do_set_vm check being\\nearlier)\\n\\n\\n> This is true even if there are LP_DEAD line pointers\\n> +\\t * because we ignored those when maintaining the visibility_cutoff_xid.\\n\\nI must just be missing something because I can't follow this at all.  I guess\\nit could be correct because we later then add in knowledge of removed xids in\\nvia the TransactionIdFollows check below? But if that's it, this is extremely\\nconfusingly worded.\\n\\n\\nSorry, running out of brain power. More another day.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bed67824d1f608","snippet":"Hi, On 2026-01-06 12:31:57 -0500, Melanie Plageman wrote: > Subject: [PATCH v33 01/16] Combine visibilitymap_set() cases in > lazy_scan_prune() > > lazy_scan_prune() previously had two","historyId":"15687","internalDate":"1769214526000","receivedAtUtc":"2026-01-24T00:28:46.000Z","from":"Andres Freund <andres@anarazel.de>"}]	\N	\N	\N
15	19bed86292d80bd8	[oauth] Stabilize the libpq-oauth ABI (and allow alternative implementations?)	["jacob.champion@enterprisedb.com","li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bed86292d80bd8","messageId":"<CAOYmi+mQeneEuoWsO1uOZszrE_tMuF51sKNzT0Z=cevpV5H3_g@mail.gmail.com>","subject":"Re: [oauth] Stabilize the libpq-oauth ABI (and allow alternative implementations?)","body":"On Tue, Jan 20, 2026 at 1:14 PM Zsolt Parragi <zsolt.parragi@percona.com> wrote:\\n> If it's validated on the server, and the issuer matches, that should\\n> be enough?\\n\\nIt's client-side protection against a malicious server; server-side\\nvalidation doesn't help. This is why you have to specify an issuer in\\nyour client's connection string (my original patchset just trusted\\nwhatever the server sent, which would have caused serious problems).\\nSee [1] for a longer discussion.\\n\\nIf I've misunderstood what you mean, please tell me what function call\\nin particular you think can be removed.\\n\\n> I don't think LDAP, or anything else is similarly extensible both on\\n> the server and client side?\\n\\nAny plaintext password method (like LDAP) can tunnel arbitrary data,\\njust like a Bearer token can. So if you control both sides, you can do\\nwhatever you want.\\n\\n> And my question was exactly because of this: OAuth introduced mostly\\n> everything needed for pluggable authentication (without PAM - my\\n> previous experience with that is that it is system specific, slow, and\\n> complex), and it is already possible to misuse it for something else.\\n> It would be really nice to have a generic authentication plugin system\\n> in postgres to implement other authentication methods, not just OAuth.\\n\\nI'm very much on board with pluggable auth [2], but OAUTHBEARER is not\\nthe layer for arbitrary non-OAuth authentication systems, any more\\nthan LDAP is. (SASL is the correct layer for that, IMHO.)\\n\\n> > Are they asking for this because it'd be an easy way around the v18 flow limitation? Because that's been the primary motivation in the conversations I've had.\\n>\\n> One specific use case I know of is CI, for example GitHub simply\\n> provides you an oauth token as an environment variable.\\n\\nMm. I'll try to take a closer look at GitHub and Cirrus.\\n\\nThanks,\\n--Jacob\\n\\n[1] https://postgr.es/m/CAOYmi%2BkLTJ1wZ6gxRbgtR52E%3DEyiCpmp6J3mmSvtc1a6i7sZ3Q%40mail.gmail.com\\n[2] https://postgr.es/m/3d41067ed944e9ce889fc15a6593cb26e72b6c0f.camel%40vmware.com\\n\\n\\n","threadId":"19bed86292d80bd8","snippet":"On Tue, Jan 20, 2026 at 1:14 PM Zsolt Parragi <zsolt.parragi@percona.com> wrote: > If it's validated on the server, and the issuer matches, that should > be enough? It's client-side","historyId":"15688","internalDate":"1769216529000","receivedAtUtc":"2026-01-24T01:02:09.000Z","from":"Jacob Champion <jacob.champion@enterprisedb.com>"}]	Jacob Champion responds to Zsolt Parragi's questions about OAuth authentication implementation in PostgreSQL. Champion clarifies that client-side issuer validation is essential for protection against malicious servers, not just server-side validation. He explains that while plaintext password methods like LDAP can tunnel arbitrary data similar to Bearer tokens, OAUTHBEARER is not the appropriate layer for implementing arbitrary non-OAuth authentication systems. Champion agrees that pluggable authentication would be valuable but suggests SASL as the correct layer for generic authentication plugins rather than misusing OAuth mechanisms. He acknowledges specific use cases like CI environments where GitHub provides OAuth tokens as environment variables and promises to investigate GitHub and Cirrus implementations further.\nJacob Champion回应了Zsolt Parragi关于PostgreSQL中OAuth认证实现的问题。Champion澄清客户端发行者验证对于防护恶意服务器至关重要，仅有服务器端验证是不够的。他解释虽然像LDAP这样的明文密码方法可以像Bearer令牌一样传输任意数据，但OAUTHBEARER不是实现任意非OAuth认证系统的合适层级。Champion同意可插拔认证很有价值，但建议SASL作为通用认证插件的正确层级，而不是滥用OAuth机制。他承认CI环境等特定用例中GitHub将OAuth令牌作为环境变量提供，并承诺进一步调研GitHub和Cirrus的实现。	2026-01-24 01:02:09+00	\N
15	19bea52b86e5169b	docs: clarify ALTER TABLE behavior on partitioned tables	["amit.kapila16@gmail.com","david.g.johnston@gmail.com","li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bed821ff70d0de","messageId":"<CAKFQuwZwAuO3qXEeqxwV6vM+89BkB-aSkcXqDGG8e_xBy_Q3Xw@mail.gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","body":"Thank you for the review!\\n\\nOn Fri, Jan 23, 2026 at 3:07 AM Zsolt Parragi <zsolt.parragi@percona.com>\\nwrote:\\n\\n> + When applied to a partitioned table, the constraint is altered on the\\n> + partitioned table definition is implicitly applied to all partitions.\\n>\\n> an \\"and\\" is missing here (definition and is)\\n>\\n\\nCorrect.  But I'd go with:\\n\\n...the constraint is altered on the partitioned table and implicitly\\napplied to all partitions.\\n\\n\\n\\n> +      When applied to a partitioned table, partition columns constraints\\n> +      are implicitly renamed and specifying <literal>ONLY</literal>\\n> is not allowed.\\n> +     </para>\\n>\\n> \\"partition columns constraints\\" - that seems like a strange/unclear\\n> wording to me. maybe \\", the partition's column constraints are ... \\" ?\\n>\\n\\nThis is just wrong - only is not permitted for either columns or\\nconstraints.  Only cannot be implicit if cascading is allowed.\\nThe unclear wording noted is just missing an \\"and\\" - of the three things\\nthat can be renamed (relation name, column name, constraint name) only\\nthese two apply.\\n\\"the partition columns and constraints...\\"\\n\\n     <para>\\n      When applied to a partitioned table, partition columns and constraints\\n      are implicitly renamed.\\n      Specifying <literal>ONLY</literal> is not allowed, and this command\\n      cannot be used on individual partitions.\\n     </para>\\n     <para>\\n      For inheritance setups, index-based constraints are always considered\\n      independent.  ~~Dependent columns and constraints are implicitly\\nrenamed\\n      and specifying <literal>ONLY</literal> is not allowed.~~\\n     </para>\\n\\nThe last sentence is redundant with the notes though, I'd remove it as\\nnoted above:\\n\\n   <para>\\n    For inheritance setups, the behavior described for partitioned tables\\napplies\\n    only to the dependent column(s) on the descendant table(s).  It is\\nalways\\n    allowed to target a descendant table with column altering commands on\\nindependent\\n    columns.\\n   </para>\\n\\nBut that note should have \\"dependent constraints\\" added to it.\\n\\n\\n>\\n> +     <para>\\n> +      When applied to a partitioned table <literal>ONLY</literal> is\\n> implicit,\\n> +      these forms must be applied separately to the partitioned table\\n> and/or to\\n> +      individual partitions.\\n> +     </para>\\n>\\n> \\"When applied to a partitioned table, <literal>ONLY</literal> is\\n> implicit and ...\\"  (at multiple places, this is an example)\\n>\\n\\nI've grown unfond of my suggested wording here during reviews too.  But\\nbecause it's too wordy and a bit redundant.\\n\\n\\"When applied to a partitioned table ONLY is implicit, however, this\\ncommand can be used on individual partitions.\\"\\n\\nhas a better symmetry with:\\n\\nSpecifying <literal>ONLY</literal> is not allowed, and this command cannot\\nbe used on individual partitions.\\n\\n\\n> \\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\n> never removes any descendant columns, but instead marks them as\\n> independently defined rather than inherited.\\"\\n>\\n> This part is now undocumented, it was only mentioned in this paragraph.\\n>\\n\\nTrue, it's left implied instead of explicitly stated.  Any column that\\nexists on a child but not the parent is by definition \\"independently\\ndefined\\".  So if either ONLY is supplied or the rules for cascading delete\\nare not met the result is children with independently defined columns with\\nthat name.  The original note was wrong anyway for the two-parent case -\\nthe second parent prevents the marking as independent when the first\\nparent's column is dropped.\\n\\n\\n\\n> > C2 - Sub-commands where using them with a partitioned table will\\n> automatically propagate to child partitions; ONLY prevents propagation; new\\n> partitions inherit the parent's new setting; and child partitions can be\\n> set to different values than the parent.\\n>\\n> The documentation of this group is inconsistent.\\n>\\n> DROP CONSTRAINT mentions that individual partitions can be dropped\\n> separately:\\n>\\n> +      When applied to a partitioned table, the constraint is dropped from\\n> +      all existing partitions unless <literal>ONLY</literal> is specified.\\n> +      Individual partitions may drop constraints independently of the\\n> +      partitioned table.\\n>\\n> But most of the sub commands in the C2 group leave the last sentence\\n> out, and also the C7 (ADD table_constraint)\\n>\\n\\nI didn't try and verify this dynamic or keep to it - though am on board\\nwith considering changes that do so and remain accurate.\\n\\n\\n> Also, isn't DROP CONSTRAINT on a partition limited to constraints\\n> defined on that partition? So it would be better to say \\"may drop\\n> constraints defined directly on that individual partition\\n> independently\\".\\n>\\n\\n\\"When applied to a partitioned table, dependent constraints are dropped\\nfrom ... is specified.\\" should suffice.\\nI'd be fine leaving out the entire \\"Individual partitions may drop...\\"\\nbusiness with that wording.  It implies partitions may have independent\\nconstraints which by extension may be targeted.\\n\\nFor Add Constraint - mention dependent constraints\\n\\"When applied to a partitioned table, the constraint is added to\\nthe partitioned table and dependent constraints are added to all\\npartitions.\\"\\n\\nWhich implies independent ones may exist and the logic for drop constraint\\nthen follows.\\n(We should explain what happens if a partition already has an independent\\nconstraint of the given name as that would be relevant here.)\\n\\n\\n>   CREATE TABLE parent (id int, val int) PARTITION BY RANGE (id);\\n>   ALTER TABLE parent ADD CONSTRAINT val_positive CHECK (val > 0);\\n>   CREATE TABLE child PARTITION OF parent FOR VALUES FROM (1) TO (100);\\n>   ALTER TABLE child DROP CONSTRAINT val_positive;\\n>   -- ERROR: cannot drop inherited constraint \\"val_positive\\" of relation\\n> \\"child\\"\\n>\\n> +      When a new partition is created, it generally inherits the current\\n> +      definition-level properties of the parent partitioned table.\\n>\\n> Maybe something like the following?\\n>\\n> When a new partition is created, it generally inherits structural\\n> properties of the parent partitioned table, such as column\\n> definitions, constraints, and storage settings.\\n>\\n> To be more explicit about what's inherited, and not only focus on\\n> what's not. (The commit message also says that the change describes\\n> both what's inherited and what's not inherited)\\n\\n\\nI concur with the premise but how about:\\n\\n      When a partition is created, it inherits many of the properties\\n      of the parent table.  However, properties related to ownership,\\n      schema, replica identity, row-level security configuration,\\n      per-attribute statistics targets, and per-attribute options\\n      are not inherited.\\n\\n\\"new\\" is superfluous on this page.\\n\\"definition-level\\" are the only kind of properties that exist - I'm not\\nbeing wordy thinking people might believe properties includes data.\\n\\"parent\\" suffices as well.\\nWe did all the work to identify things - use \\"however\\" instead of \\"in\\nparticular\\" to give us credit for the work.\\nEven if a property is explicitly set for the partition it isn't \\"inherited\\"\\n- the partition has its own independent value that in a rare case might\\nhappen to match the parent at the time of creation. (i.e., remove\\nautomatically and 'not inherited unless')\\nI'm not that inclined to mention the inclusion list.  The general premise\\nof assuming inherited unless told otherwise works fine here; minimal\\nfuture-proofing.\\n\\nDavid J.\\n","threadId":"19bea52b86e5169b","snippet":"Thank you for the review! On Fri, Jan 23, 2026 at 3:07 AM Zsolt Parragi <zsolt.parragi@percona.com> wrote: + When applied to a partitioned table, the constraint is altered on the + partitioned","historyId":"15682","internalDate":"1769216239000","receivedAtUtc":"2026-01-24T00:57:19.000Z","from":"\\"David G. Johnston\\" <david.g.johnston@gmail.com>"},{"id":"19bed939249f806d","messageId":"<CAKFQuwbUVLeeooQWc0TY7NJS05RexG_fOY5cz2S4H3sDGKQ_qA@mail.gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","body":"On Fri, Jan 23, 2026 at 5:57 PM David G. Johnston <\\ndavid.g.johnston@gmail.com> wrote:\\n\\n>\\n>> \\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\n>> never removes any descendant columns, but instead marks them as\\n>> independently defined rather than inherited.\\"\\n>>\\n>> This part is now undocumented, it was only mentioned in this paragraph.\\n>>\\n>\\n> True, it's left implied instead of explicitly stated.  Any column that\\n> exists on a child but not the parent is by definition \\"independently\\n> defined\\".  So if either ONLY is supplied or the rules for cascading delete\\n> are not met the result is children with independently defined columns with\\n> that name.\\n>\\n\\n\\n\\n> The original note was wrong anyway for the two-parent case - the second\\n> parent prevents the marking as independent when the first parent's column\\n> is dropped.\\n>\\n\\nDecided to test this one and I see the original wording was correct and we\\nwill need to keep a note that in the two-parent ONLY case the un-dropped\\nchildren are marked both dependent and independent.\\n\\nChange:\\n\\n     <para>\\n      For inheritance setups, a descendant column is removed only if both\\nof the\\n      following are true: this is the only parent defining the column, and\\nthe column\\n      was never independently defined in the descendant.\\n     </para>\\n\\nTo:\\n\\n\\"For inheritance setups, a descendant column is removed only if all the\\nfollowing are true: ONLY is not specified, no other parent defines the\\ncolumn, and the column is not marked as having been independent.\\nOtherwise, the descendant column is instead marked as having\\nbeen independent.\\n\\nIf we think that deserves a bit longer explanation about that/why/how a\\ncolumn can be both dependent and \\"having been independent\\" we should\\ncross-reference to a more appropriate location.  Here we just state this is\\none way that condition can materialize.\\n\\nDavid J.\\n","threadId":"19bea52b86e5169b","snippet":"On Fri, Jan 23, 2026 at 5:57 PM David G. Johnston <david.g.johnston@gmail.com> wrote: \\"A nonrecursive DROP COLUMN (ie, ALTER TABLE ONLY ... DROP COLUMN) never removes any descendant columns,","historyId":"15682","internalDate":"1769217383000","receivedAtUtc":"2026-01-24T01:16:23.000Z","from":"\\"David G. Johnston\\" <david.g.johnston@gmail.com>"}]	The discussion focuses on improving PostgreSQL documentation for ALTER TABLE behavior on partitioned tables. David G. Johnston responds to Zsolt Parragi's review feedback, addressing grammatical issues and clarifying technical wording. Key points include: correcting missing conjunctions in constraint descriptions, clarifying that partition columns and constraints are implicitly renamed without ONLY specification, and refining language about inheritance behavior. Johnston proposes removing redundant sentences and suggests more precise wording for constraint propagation. A significant correction emerges regarding DROP COLUMN behavior in multi-parent inheritance scenarios, where descendant columns can be marked as both dependent and independent. The discussion involves detailed wordsmithing to ensure accurate technical documentation while maintaining clarity about partition inheritance rules and constraint handling.\n\n讨论集中在改进PostgreSQL分区表ALTER TABLE行为的文档。David G. Johnston回应Zsolt Parragi的审查反馈，解决语法问题并澄清技术措辞。关键点包括：纠正约束描述中缺失的连词，澄清分区列和约束在没有ONLY规范时隐式重命名，以及完善继承行为的语言表述。Johnston提议删除冗余句子并建议更精确的约束传播措辞。关于多父继承场景中DROP COLUMN行为出现重要修正，其中后代列可以同时标记为依赖和独立。讨论涉及详细的措辞修改，以确保准确的技术文档同时保持分区继承规则和约束处理的清晰性。	2026-01-24 01:16:23+00	\N
15	19bec7b069713c1b	ON CONFLICT DO SELECT (take 3)	["andreas@proxel.se","dean.a.rasheed@gmail.com","jian.universality@gmail.com","marko@joh.to","v@viktorh.net"]	[{"id":"19bedccbb83544ef","messageId":"<CACJufxH0sycCGgmSjG=SxvdwmL26T+Jf=ZrTEtQaMZTEbVWiVg@mail.gmail.com>","subject":"Re: ON CONFLICT DO SELECT (take 3)","body":"On Thu, Jan 22, 2026 at 4:05 AM Viktor Holmberg <v@viktorh.net> wrote:\\n>\\n> There are some white spaces in v19.\\n>\\n> Sorry, what do you mean \\"white spaces"? Is it a problem?\\n\\nyou can use ``git diff --check`` to find out these white spaces.\\nThe attached file should be able to fix these issues.\\n\\n+-- DO SELECT FOR UPDATE requires UPDATE rights, should fail for non-novel\\n+INSERT INTO document VALUES (33, (SELECT cid from category WHERE\\ncname = 'science fiction'), 1, 'regress_rls_bob', 'another sci-fi')\\n+    ON CONFLICT (did) DO SELECT FOR UPDATE RETURNING did, dauthor, dtitle;\\n+ERROR:  new row violates row-level security policy for table \\"document\\"\\n\\nThe above comment is wrong. If i place\\n\\nINSERT INTO document VALUES (33, (SELECT cid from category WHERE cname\\n= 'science fiction'), 1, 'regress_rls_bob', 'another sci-fi')\\nON CONFLICT (did) DO NOTHING;\\n\\nbefore the above tests, it will still fail, it will fail on SELECT\\npolicy, p1_select_novels.\\nwe can remove the above tests or rephrase the comment.\\n\\n+CREATE POLICY p3_update_novels ON document FOR UPDATE\\n+  USING (cid = (SELECT cid from category WHERE cname = 'novel') AND dlevel = 1)\\n+  WITH CHECK (dauthor = current_user);\\n\\nMy understanding of the change in get_row_security_policies is that, ON CONFLICT\\nDO SELECT FOR UPDATE, the UPDATE WITH CHECK policy clause is never evaluated.\\nFor testing purposes, we could change  the above\\n+WITH CHECK (dauthor = current_user);\\nto\\n+WITH CHECK (dauthor = current_user AND false);\\n\\nThis leads to the next issue in ExecOnConflictSelect->ExecWithCheckOptions.\\n+ if (resultRelInfo->ri_WithCheckOptions != NIL)\\n+ {\\n+ /*\\n+ * Check target's existing tuple against SELECT-applicable USING\\n+ * security barrier quals (if any), enforced here as RLS checks/WCOs.\\n+ *\\n+ * The rewriter creates SELECT RLS checks/WCOs for SELECT security\\n+ * quals, and stores them as WCOs of \\"kind\\" WCO_RLS_CONFLICT_CHECK. If\\n+ * FOR UPDATE/SHARE was specified, UPDATE rights are required on the\\n+ * target table, and the rewriter also adds UPDATE RLS checks/WCOs for\\n+ * UPDATE security quals, using WCOs of the same kind, so this check\\n+ * enforces them too.\\n+ */\\n+ ExecWithCheckOptions(WCO_RLS_CONFLICT_CHECK, resultRelInfo,\\n+ existing,\\n+ mtstate->ps.state);\\n+ }\\nthe comment I am not sure I fully understand, especially the last sentence.\\n\\nMy understanding is that\\nFor ON CONFLICT DO SELECT FOR UPDATE, both the SELECT USING and UPDATE USING\\nclauses are evaluated.  If either evaluates to false, the row is not silently\\nignored; instead, an error is raised.\\nUPDATE CHECK clause was never evaluated.\\n\\nMaybe we need to rephrase the above comments.\\n\\n>\\n> it's time to squash the patchset into one, IMHO.\\n> you can also begin to write the draft commit message, explain what this is all\\n> about.\\n>\\n> Yes, done.\\n>\\n> ExecOnConflictSelect\\n> if (lockStrength == LCS_NONE)\\n> {\\n> /* Evem if the tuple is deleted, it must still be physically present */\\n> Assert(table_tuple_fetch_row_version(relation, conflictTid,\\n> SnapshotAny, existing));\\n> }\\n> this is wrong, i think.\\n> buildtype=release, the Assert macro will always be true,\\n> the whole Assert may be optimized out,\\n> and later code would have trouble using (TupleTableSlot *existing).\\n>\\n> Yes, you're right. Nice catch. Fixed.\\n>\\n\\nit still have problem with release branch,\\nsee https://cirrus-ci.com/task/5061396800471040?logs=gcc_warning#L454\\n\\nI intended to change it as\\n```\\n    if (lockStrength == LCS_NONE)\\n    {\\n        if (!table_tuple_fetch_row_version(relation,\\n                                           conflictTid,\\n                                           SnapshotAny,\\n                                           existing))\\n            elog(ERROR, \\"failed to fetch conflicting tuple for ON CONFLICT\\");\\n    }\\n```\\n\\n     * For ON CONFLICT .. UPDATE we just need the inner tlist to point to the\\n     * excluded expression's tlist. (Similar to the SubqueryScan we don't want\\n     * to reuse OUTER, it's used for RETURNING in some modify table cases,\\n     * although not INSERT .. CONFLICT).\\nthe above comments in set_deparse_plan need apply to ON CONFLICT DO SELECT\\n\\n\\ntypedef enum WCOKind, WCOKind\\nWCO_RLS_CONFLICT_CHECK,        /* RLS ON CONFLICT DO UPDATE USING policy */\\nthe comments need to be adjusted.\\n\\nThe discussion link should be these three.\\nDiscussion: https://postgr.es/m/5fca222d-62ae-4a2f-9fcb-0eca56277094@Spark\\nDiscussion: https://postgr.es/m/2b5db2e6-8ece-44d0-9890-f256fdca9f7e@proxel.se\\nDiscussion: https://postgr.es/m/d631b406-13b7-433e-8c0b-c6040c4b4663@Spark\\n\\nSince there have been some discussions about the author, we can also mention\\nauthors in the commit message.\\n","threadId":"19bec7b069713c1b","snippet":"On Thu, Jan 22, 2026 at 4:05 AM Viktor Holmberg <v@viktorh.net> wrote: > > There are some white spaces in v19. > > Sorry, what do you mean \\"white spaces"? Is it a problem? you","historyId":"15683","internalDate":"1769221129000","receivedAtUtc":"2026-01-24T02:18:49.000Z","from":"jian he <jian.universality@gmail.com>"}]	Jian He provides feedback on v19 of the ON CONFLICT DO SELECT patch, identifying several issues. He notes whitespace problems detectable with `git diff --check` and provides a fix. A key concern is incorrect test comments regarding row-level security policies - the test failure relates to SELECT policy p1_select_novels rather than UPDATE rights as suggested. He proposes removing or rephrasing these tests. He suggests modifying the UPDATE WITH CHECK policy to `WITH CHECK (dauthor = current_user AND false)` for better testing, noting that UPDATE WITH CHECK clauses are never evaluated in ON CONFLICT DO SELECT FOR UPDATE scenarios. Additional issues include unclear comments in ExecOnConflictSelect->ExecWithCheckOptions, problems with Assert macro optimization in release builds, and needed adjustments to WCOKind comments. He recommends updating discussion links and mentioning authors in the commit message.\n\n贾恒对ON CONFLICT DO SELECT补丁的v19版本提供反馈，识别出几个问题。他指出可通过`git diff --check`检测的空白字符问题并提供修复。一个关键问题是关于行级安全策略的错误测试注释——测试失败与SELECT策略p1_select_novels相关，而非建议的UPDATE权限。他建议移除或重新表述这些测试。他建议将UPDATE WITH CHECK策略修改为`WITH CHECK (dauthor = current_user AND false)`以便更好地测试，注意到在ON CONFLICT DO SELECT FOR UPDATE场景中UPDATE WITH CHECK子句从不被评估。其他问题包括ExecOnConflictSelect->ExecWithCheckOptions中不清楚的注释、发布版本中Assert宏优化问题，以及需要调整WCOKind注释。他建议更新讨论链接并在提交消息中提及作者。	2026-01-24 02:18:49+00	\N
15	19be6bab3032bd29	Remove PG_MMAP_FLAGS	["ashutosh.bapat.oss@gmail.com","michael@paquier.xyz","peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19bede56dbea9902","messageId":"<aXQydVFtu3LTAdqG@paquier.xyz>","subject":"Re: Remove PG_MMAP_FLAGS","body":"On Fri, Jan 23, 2026 at 03:33:33PM +0530, Ashutosh Bapat wrote:\\n> I revised the patch a bit. The macro had parenthesis around the macro\\n> definition which are not required in the assignment. Removed them.\\n> Also revised the commit message a bit.\\n\\nWFM.\\n--\\nMichael\\n","threadId":"19be6bab3032bd29","snippet":"On Fri, Jan 23, 2026 at 03:33:33PM +0530, Ashutosh Bapat wrote: > I revised the patch a bit. The macro had parenthesis around the macro > definition which are not required in the assignment.","historyId":"15679","internalDate":"1769222773000","receivedAtUtc":"2026-01-24T02:46:13.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	Michael Paquier expresses approval ("WFM" - Works For Me) of Ashutosh Bapat's revised patch to remove PG_MMAP_FLAGS. The revision involved removing unnecessary parentheses around the macro definition that were not required in the assignment context, and improving the commit message. This appears to be a simple code cleanup patch that has received positive feedback from a reviewer. The discussion seems to be concluding with the patch ready for potential commit, as no further changes or concerns were raised.\n移除PG_MMAP_FLAGS的补丁获得了Michael Paquier的批准("WFM" - 适合我)。Ashutosh Bapat修订了补丁，移除了宏定义中在赋值语句中不需要的括号，并改进了提交信息。这似乎是一个简单的代码清理补丁，已经得到审核者的积极反馈。讨论似乎即将结束，补丁已准备好可能的提交，因为没有提出进一步的修改或关注点。	2026-01-24 02:46:13+00	\N
15	19bf160dd2721de6	Buffer locking is special (hints, checksums, AIO writes)	["andres@anarazel.de","boekewurm+postgres@gmail.com","exclusion@gmail.com","hlinnaka@iki.fi","li.evan.chao@gmail.com","melanieplageman@gmail.com","michael.paquier@gmail.com","noah@leadboat.com","pg@bowt.ie","reshkekirill@gmail.com","robertmhaas@gmail.com","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19bf160dd2721de6","messageId":"<90bd2cbb-49ce-4092-9f61-5ac2ab782c94@gmail.com>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hello Andres,\\n\\n16.01.2026 01:02, Tom Lane wrote:\\n> Various buildfarm animals are complaining about fcb9c977a,\\n> similarly to this from calliphoridae [1]:\\n\\nI've discovered another anomaly introduced with fcb9c977a, this time\\nrun-time:\\nfor i in `seq 300`; do\\necho \\"iteration $i\\"\\n\\necho \\"\\ncreate table t(f1 text);\\ncreate index on t using spgist(f1);\\ninsert into t select 'a' from generate_series(1, 9000) g(i);\\nvacuum analyze t;\\ninsert into t select 'b' from generate_series(1, 1000) g(i);\\ndrop table t;\\n\\" | psql >/dev/null -v ON_ERROR_STOP=1 || break;\\ndone\\n\\nfails for me as below:\\n...\\niteration 39\\nserver closed the connection unexpectedly\\n\\nCore was generated by `postgres: law regression [local] INSERT                 '.\\nProgram terminated with signal SIGABRT, Aborted.\\n#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:44\\n\\nwarning: 44     ./nptl/pthread_kill.c: Нет такого файла или каталога\\n(gdb) bt\\n#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:44\\n#1  __pthread_kill_internal (signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:78\\n#2  __GI___pthread_kill (threadid=<optimized out>, signo=signo@entry=6) at ./nptl/pthread_kill.c:89\\n#3  0x000073625aa4527e in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\\n#4  0x000073625aa288ff in __GI_abort () at ./stdlib/abort.c:79\\n#5  0x00005a479e2f685f in ExceptionalCondition (conditionName=conditionName@entry=0x5a479e403cb8 \\"entry->data.lockmode == BUFFER_LOCK_UNLOCK\\", fileName=fileName@entry=0x5a479e37a84f \\"bufmgr.c\\", lineNumber=lineNumber@entry=5908) at assert.c:65\\n#6  0x00005a479e14d87c in BufferLockConditional (buffer=<optimized out>, buf_hdr=0x73624e882b40, mode=mode@entry=BUFFER_LOCK_EXCLUSIVE) at bufmgr.c:5908\\n#7  0x00005a479e14f4d5 in ConditionalLockBuffer (buffer=buffer@entry=13500) at bufmgr.c:6474\\n#8  0x00005a479de44da9 in SpGistNewBuffer (index=index@entry=0x73625b1f6ce8) at spgutils.c:420\\n#9  0x00005a479de45397 in allocNewBuffer (index=index@entry=0x73625b1f6ce8, flags=flags@entry=3) at spgutils.c:528\\n#10 0x00005a479de456a0 in SpGistGetBuffer (index=index@entry=0x73625b1f6ce8, flags=flags@entry=3, needSpace=<optimized out>, needSpace@entry=4088, isNew=isNew@entry=0x7ffd8fa1b2a7) at spgutils.c:663\\n#11 0x00005a479de3c913 in doPickSplit (index=index@entry=0x73625b1f6ce8, state=state@entry=0x7ffd8fa1b740, current=current@entry=0x7ffd8fa1b510, parent=parent@entry=0x7ffd8fa1b530, newLeafTuple=newLeafTuple@entry=0x5a47cbd7adc8, level=level@entry=4, isNulls=false, isNew=false) at spgdoinsert.c:1046\\n#12 0x00005a479de3e542 in spgdoinsert (index=index@entry=0x73625b1f6ce8, state=state@entry=0x7ffd8fa1b740, heapPtr=heapPtr@entry=0x5a47cbe0b248, datums=datums@entry=0x7ffd8fa1b8d0, isnulls=isnulls@entry=0x7ffd8fa1b8b0) at spgdoinsert.c:2134\\n#13 0x00005a479de40137 in spginsert (index=0x73625b1f6ce8, values=0x7ffd8fa1b8d0, isnull=0x7ffd8fa1b8b0, ht_ctid=0x5a47cbe0b248, heapRel=<optimized out>, checkUnique=<optimized out>, indexUnchanged=false, indexInfo=0x5a47cbe0b0b8) at spginsert.c:206\\n#14 0x00005a479df981d8 in ExecInsertIndexTuples (resultRelInfo=resultRelInfo@entry=0x5a47cbe07120, slot=slot@entry=0x5a47cbe0b218, estate=estate@entry=0x5a47cbe06c10, update=update@entry=false, noDupErr=noDupErr@entry=false, specConflict=specConflict@entry=0x0, arbiterIndexes=0x0, onlySummarizing=false) at execIndexing.c:449\\n#15 0x00005a479dfcc6a9 in ExecInsert (context=context@entry=0x7ffd8fa1bb70, resultRelInfo=resultRelInfo@entry=0x5a47cbe07120, slot=slot@entry=0x5a47cbe0b218, canSetTag=<optimized out>, inserted_tuple=inserted_tuple@entry=0x0, insert_destrel=insert_destrel@entry=0x0) at nodeModifyTable.c:1240\\n#16 0x00005a479dfcdf67 in ExecModifyTable (pstate=0x5a47cbe06f10) at nodeModifyTable.c:4485\\n...\\n\\nBest regards,\\nAlexander","threadId":"19bf160dd2721de6","snippet":"Hello Andres, 16.01.2026 01:02, Tom Lane wrote: Various buildfarm animals are complaining about fcb9c977a, similarly to this from calliphoridae [1]: I've discovered another anomaly introduced with","historyId":"15694","internalDate":"1769281200000","receivedAtUtc":"2026-01-24T19:00:00.000Z","from":"Alexander Lakhin <exclusion@gmail.com>"},{"id":"19bf1b46a148e8a3","messageId":"<esihk6vohorlopugumy6ps6zmyh7cgkwi66trm4ocpbkqa4i2i@g5j2hvbzv4lp>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hi,\\n\\nOn 2026-01-24 21:00:00 +0200, Alexander Lakhin wrote:\\n> 16.01.2026 01:02, Tom Lane wrote:\\n> > Various buildfarm animals are complaining about fcb9c977a,\\n> > similarly to this from calliphoridae [1]:\\n>\\n> I've discovered another anomaly introduced with fcb9c977a, this time\\n> run-time:\\n\\nWith the other anomaly, you mean the spurious compiler warning or something\\nelse?\\n\\n\\n> for i in `seq 300`; do\\n> echo \\"iteration $i\\"\\n>\\n> echo \\"\\n> create table t(f1 text);\\n> create index on t using spgist(f1);\\n> insert into t select 'a' from generate_series(1, 9000) g(i);\\n> vacuum analyze t;\\n> insert into t select 'b' from generate_series(1, 1000) g(i);\\n> drop table t;\\n> \\" | psql >/dev/null -v ON_ERROR_STOP=1 || break;\\n> done\\n>\\n> fails for me as below:\\n> ...\\n> iteration 39\\n> server closed the connection unexpectedly\\n\\n\\nThanks for this report, particularly with the easy reproducer!  How did you\\nfind this?\\n\\n\\nI think this is more likely to be a spgist bug, not a bug in the patch.  From\\nwhat I can tell, spgist tries to conditionally lock a buffer that it itself\\nalready has locked exclusively - that's why the assertion is failing.\\n\\nI reproduced this locally, and could see in a bt full stack that the buffer\\nthat spgist is trying to lock conditionally, is also referenced as\\nnewInnerBuffer in doPickSplit(). So it's not an issue of bufmgr.c loosing\\ntrack of which buffers are locked with what mode.\\n\\nI haven't yet figured out why spgist ends up with a buffer it already is\\nusing.\\n\\nWe could of course just accept this case and have the conditional lock\\nacquisition fail, but I think trying to conditionally lock a buffer that you\\nalready lock is indicative of something having gone wrong.  But I'm open to\\ngoing there anyway, just to avoid causing problems with previously \\"working\\"\\ncode.\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Hi, On 2026-01-24 21:00:00 +0200, Alexander Lakhin wrote: > 16.01.2026 01:02, Tom Lane wrote: > > Various buildfarm animals are complaining about fcb9c977a, > > similarly to this from","historyId":"15694","internalDate":"1769286674000","receivedAtUtc":"2026-01-24T20:31:14.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf1d1806f27778","messageId":"<ipf7upm2ooqnx5hkrw63prrcf4tvbcg4hansufiju3hdso35wr@4opaqhl6lwm7>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hi,\\n\\nOn 2026-01-24 15:31:14 -0500, Andres Freund wrote:\\n> I think this is more likely to be a spgist bug, not a bug in the patch.  From\\n> what I can tell, spgist tries to conditionally lock a buffer that it itself\\n> already has locked exclusively - that's why the assertion is failing.\\n> \\n> I reproduced this locally, and could see in a bt full stack that the buffer\\n> that spgist is trying to lock conditionally, is also referenced as\\n> newInnerBuffer in doPickSplit(). So it's not an issue of bufmgr.c loosing\\n> track of which buffers are locked with what mode.\\n> \\n> I haven't yet figured out why spgist ends up with a buffer it already is\\n> using.\\n> \\n> We could of course just accept this case and have the conditional lock\\n> acquisition fail, but I think trying to conditionally lock a buffer that you\\n> already lock is indicative of something having gone wrong.  But I'm open to\\n> going there anyway, just to avoid causing problems with previously \\"working\\"\\n> code.\\n\\nLooking at the spgist code, and the README, I think we may need to accept the\\nuglines of silently failing when a backend tries to conditionally lock a\\nbuffer that it itself has already locked.  Even though I still don't\\nunderstand how it happens in this this specific case, that doesn't even have\\nconcurrency.\\n\\nPretty ... not great ... that spgist does stuff like extending a relation\\nwhile holding an exclusive buffer lock.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Hi, On 2026-01-24 15:31:14 -0500, Andres Freund wrote: > I think this is more likely to be a spgist bug, not a bug in the patch. From > what I can tell, spgist tries to conditionally lock a","historyId":"15698","internalDate":"1769288584000","receivedAtUtc":"2026-01-24T21:03:04.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf1d9d19ff8787","messageId":"<3472929.1769289107@sss.pgh.pa.us>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Andres Freund <andres@anarazel.de> writes:\\n> I think this is more likely to be a spgist bug, not a bug in the patch.  From\\n> what I can tell, spgist tries to conditionally lock a buffer that it itself\\n> already has locked exclusively - that's why the assertion is failing.\\n\\nI dunno.  It looks to me like the previous LWLock-based implementation\\nof ConditionalLockBuffer() had no such restriction as\\n\\n\\t/*\\n\\t * We better not already hold a lock on the buffer.\\n\\t */\\n\\tAssert(entry->data.lockmode == BUFFER_LOCK_UNLOCK);\\n\\nMaybe I'm missing something, but it looks like the old code would\\nreturn false if the buffer was already locked, whether that lock\\nwas held by our process or another one.  SPGist evidently has an\\nassumption in edge cases that that is the behavior, and I'm not\\nconvinced that it's a good idea to change it.  There may be other\\nsuch edge cases we've not tripped over yet.\\n\\n> We could of course just accept this case and have the conditional lock\\n> acquisition fail, but I think trying to conditionally lock a buffer that you\\n> already lock is indicative of something having gone wrong.\\n\\nI don't really buy this argument.  Yes, within a single function it'd\\nbe silly to lock a buffer and immediately try to lock it again, but\\nwhen you consider cases like recursive modifications of index state,\\nit's *far* from obvious that some lower recursion level might not try\\nto lock a buffer that some outer level already locked.  In the case at\\nhand I think it is probably driven by two recursion levels trying to\\nacquire free space out of the same buffer.  SPGist is expecting the\\nlower level to fail to get the lock and then go find some free space\\nelsewhere.  Yeah, we could probably re-code it to get that outcome\\nin another way, but why?\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Andres Freund <andres@anarazel.de> writes: > I think this is more likely to be a spgist bug, not a bug in the patch. From > what I can tell, spgist tries to conditionally lock a buffer that","historyId":"15743","internalDate":"1769289107000","receivedAtUtc":"2026-01-24T21:11:47.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf1e3100d8d12a","messageId":"<CAH2-WzkDSOQfthnB-LYv3dRuTW6tGiSDGfX8F5A6tuGQ_nY9HA@mail.gmail.com>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"On Sat, Jan 24, 2026 at 4:12 PM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> Andres Freund <andres@anarazel.de> writes:\\n> > We could of course just accept this case and have the conditional lock\\n> > acquisition fail, but I think trying to conditionally lock a buffer that you\\n> > already lock is indicative of something having gone wrong.\\n>\\n> I don't really buy this argument.  Yes, within a single function it'd\\n> be silly to lock a buffer and immediately try to lock it again, but\\n> when you consider cases like recursive modifications of index state,\\n> it's *far* from obvious that some lower recursion level might not try\\n> to lock a buffer that some outer level already locked.  In the case at\\n> hand I think it is probably driven by two recursion levels trying to\\n> acquire free space out of the same buffer.\\n\\nEven nbtree has to deal with this. Also in the context of free space\\nmanagement. See the comments in _bt_allocbuf, particularly the ones\\nwhere we explicitly describe a common scenario where we conditionally\\nlock a buffer that our own caller/backend already has a lock on.\\n\\nI actually agree with Andres' general sentiment about this kind of\\ncoding pattern; it also seems sloppy to me. But it's hard to see how\\nwe could do better in places such as _bt_allocbuf. At least within the\\nconfines of the current FSM design.\\n\\n-- \\nPeter Geoghegan\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"On Sat, Jan 24, 2026 at 4:12 PM Tom Lane <tgl@sss.pgh.pa.us> wrote: > Andres Freund <andres@anarazel.de> writes: > > We could of course just accept this case and have the","historyId":"15825","internalDate":"1769289708000","receivedAtUtc":"2026-01-24T21:21:48.000Z","from":"Peter Geoghegan <pg@bowt.ie>"},{"id":"19bf23f4f8e08dd2","messageId":"<cf7prit6zlr64ekyf7ev4x2jxporxplcjnoq6sao3nbrpawtj7@65mndedqeqm2>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Hi,\\n\\nOn 2026-01-24 16:11:47 -0500, Tom Lane wrote:\\n> Andres Freund <andres@anarazel.de> writes:\\n> > I think this is more likely to be a spgist bug, not a bug in the patch.  From\\n> > what I can tell, spgist tries to conditionally lock a buffer that it itself\\n> > already has locked exclusively - that's why the assertion is failing.\\n> \\n> I dunno.  It looks to me like the previous LWLock-based implementation\\n> of ConditionalLockBuffer() had no such restriction as\\n> \\n> \\t/*\\n> \\t * We better not already hold a lock on the buffer.\\n> \\t */\\n> \\tAssert(entry->data.lockmode == BUFFER_LOCK_UNLOCK);\\n> \\n> Maybe I'm missing something, but it looks like the old code would\\n> return false if the buffer was already locked, whether that lock\\n> was held by our process or another one.\\n\\nYea. I added that assert when (I think) Melanie complained that the new code\\nwouldn't detect repeated acquisitions or release of the same content lock as\\nnicely as before.  I guess I went a bit overboard and also added the assertion\\nto ConditionalLockBuffer().\\n\\nI'll go and move it into the branch where we actually got the lock, that seems\\nworth continuing to do.\\n\\n\\n> > We could of course just accept this case and have the conditional lock\\n> > acquisition fail, but I think trying to conditionally lock a buffer that you\\n> > already lock is indicative of something having gone wrong.\\n> \\n> I don't really buy this argument.  Yes, within a single function it'd\\n> be silly to lock a buffer and immediately try to lock it again, but\\n> when you consider cases like recursive modifications of index state,\\n> it's *far* from obvious that some lower recursion level might not try\\n> to lock a buffer that some outer level already locked.\\n\\nYea, there's probably something too that. But I'm not entirely convinced -\\nconsider what happens with an index on a temporary table: A higher level think\\nit got a buffer with space, but then a lower level uses up that space...\\n\\n\\n> In the case at hand I think it is probably driven by two recursion levels\\n> trying to acquire free space out of the same buffer.  SPGist is expecting\\n> the lower level to fail to get the lock and then go find some free space\\n> elsewhere.  Yeah, we could probably re-code it to get that outcome in\\n> another way, but why?\\n\\nRegardless of the assertion, it still feels like there may be something off\\nhere. Why is the page marked as empty in the FSM, despite actually not being\\nempty?\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Hi, On 2026-01-24 16:11:47 -0500, Tom Lane wrote: > Andres Freund <andres@anarazel.de> writes: > > I think this is more likely to be a spgist bug, not a bug in the patch. From > >","historyId":"16085","internalDate":"1769295780000","receivedAtUtc":"2026-01-24T23:03:00.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf2a5afd993ce8","messageId":"<3496575.1769302476@sss.pgh.pa.us>","subject":"Re: Buffer locking is special (hints, checksums, AIO writes)","body":"Andres Freund <andres@anarazel.de> writes:\\n> On 2026-01-24 16:11:47 -0500, Tom Lane wrote:\\n>> In the case at hand I think it is probably driven by two recursion levels\\n>> trying to acquire free space out of the same buffer.  SPGist is expecting\\n>> the lower level to fail to get the lock and then go find some free space\\n>> elsewhere.  Yeah, we could probably re-code it to get that outcome in\\n>> another way, but why?\\n\\n> Regardless of the assertion, it still feels like there may be something off\\n> here. Why is the page marked as empty in the FSM, despite actually not being\\n> empty?\\n\\nWho said anything about its being empty?  There's X amount of space\\nused on the page now, the outer level is preparing to add a tuple\\nof size Y, the inner level is looking for a place to put a tuple\\nof size Z.  As long as X+Y+Z <= 8K, there's no free-space-related\\nreason the page wouldn't work for this.  We could actually try to\\nmake it work, but that seems fragile to me: the outer level would\\nhave to be prepared for the possibility that the page changes\\nunder it despite holding exclusive lock.  I think it's reasonable\\non complexity grounds to insist that the inner recursion level\\ngo play someplace else.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf160dd2721de6","snippet":"Andres Freund <andres@anarazel.de> writes: > On 2026-01-24 16:11:47 -0500, Tom Lane wrote: >> In the case at hand I think it is probably driven by two recursion levels >> trying to","historyId":"16365","internalDate":"1769302476000","receivedAtUtc":"2026-01-25T00:54:36.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	A PostgreSQL patch (fcb9c977a) introduced runtime crashes in SPGist operations. Alexander Lakhin reported a reproducible crash during index insertions involving a buffer locking assertion failure. The crash occurs when SPGist attempts to conditionally lock a buffer that is already exclusively locked by the same process. Andres Freund initially suspected a SPGist bug but later acknowledged the issue may require accepting conditional lock failures for already-locked buffers. Tom Lane argued that the previous LWLock implementation allowed this behavior and that recursive index modifications legitimately need this pattern. Peter Geoghegan noted similar patterns exist in btree's free space management. The discussion centers on whether to remove the assertion or redesign the locking logic, with consensus leaning toward allowing conditional locks to fail when buffers are already locked by the same backend.\n\n一个PostgreSQL补丁(fcb9c977a)在SPGist操作中引入了运行时崩溃。Alexander Lakhin报告了在涉及缓冲区锁断言失败的索引插入过程中出现可重现的崩溃。当SPGist尝试条件性锁定一个已被同一进程独占锁定的缓冲区时发生崩溃。Andres Freund最初怀疑是SPGist的错误，但后来承认该问题可能需要接受对已锁定缓冲区的条件锁失败。Tom Lane认为之前的LWLock实现允许这种行为，递归索引修改合理地需要这种模式。Peter Geoghegan指出btree的空闲空间管理中存在类似模式。讨论围绕是否移除断言或重新设计锁定逻辑展开，共识倾向于允许当缓冲区已被同一后端锁定时条件锁失败。	2026-01-25 00:54:36+00	\N
15	19be79057d59089e	[PATCH] Align verify_heapam.c error message offset with test expectations	["khoaduynguyen@gmail.com","zengman@halodbtech.com"]	[{"id":"19bee91d8a6c9fb3","messageId":"<tencent_556F0A9A3E4C0D1E2E20B32F@qq.com>","subject":"Re: [PATCH] Align verify_heapam.c error message offset with test expectations","body":"> Both patches look great to me.\\n\\nHi,\\n\\nI truly appreciate your approval, along with your thorough review and valuable insights. \\nThat said, I don't plan to make further revisions to Patch 1 at this stage—and I tend to think that Patch 2 might just be sufficient on its own. \\nOf course, this will ultimately depend on the committers.\\nThanks again!\\n\\n--\\nRegards,\\nMan Zeng\\nwww.openhalo.org","threadId":"19be79057d59089e","snippet":"> Both patches look great to me. Hi, I truly appreciate your approval, along with your thorough review and valuable insights. That said, I don't plan to make further revisions to Patch 1 at this","historyId":"15680","internalDate":"1769234051000","receivedAtUtc":"2026-01-24T05:54:11.000Z","from":"zengman <zengman@halodbtech.com>"}]	Man Zeng responds to feedback on his patch to align verify_heapam.c error message offsets with test expectations. He expresses appreciation for the thorough review and approval of both patches. However, he indicates he doesn't plan to make further revisions to Patch 1 and suggests that Patch 2 alone might be sufficient. He acknowledges that the final decision will depend on the committers. The discussion appears to be in a concluding phase with positive feedback received.\nMan Zeng回应了关于对齐verify_heapam.c错误消息偏移量与测试期望的补丁的反馈。他对彻底的审查和两个补丁的批准表示感谢。然而，他表示不打算对补丁1进行进一步修订，并建议仅补丁2可能就足够了。他承认最终决定将取决于提交者。讨论似乎已进入收尾阶段，收到了积极的反馈。	2026-01-24 05:54:11+00	\N
15	19bed39e57f8cfa7	libpq: Bump protocol version to version 3.2 at least until the first/second beta	["andres@anarazel.de","hlinnaka@iki.fi","jacob.champion@enterprisedb.com","postgres@jeltef.nl","robertmhaas@gmail.com"]	[{"id":"19bef7c346ac806a","messageId":"<CAGECzQTtBa6u2-dxv83g_-7ssop-Ds5-DFibrUin+RfDOtsJFg@mail.gmail.com>","subject":"Re: libpq: Bump protocol version to version 3.2 at least until the first/second beta","body":"On Sat, 24 Jan 2026 at 00:38, Jacob Champion\\n<jacob.champion@enterprisedb.com> wrote:\\n> WDYT?\\n\\nOverall, I think the changes and the split look fine. And I'd be happy\\nwith having it committed as is.\\n\\nA few thoughts on the docs:\\n1. I like the version table split. I think it might be better to do\\nthe same for protocol extensions too. Primarily because I think the\\ntiny empty cell at the start of each row looks weird (see screenshot),\\nbut also just for consistency.\\n2. In my v5 I created a dedicated section header for protocol\\nextensions instead of including it in the extension. I think that's\\nslightly nicer, primarily so you can link to that section from the\\nStartupMessage docs (including the introductory paragraph), instead of\\nhaving to link to the table.\\n3. In the table in my v5 I use \\"extension name\\" as a column instead of\\n\\"parameter name\\" so I did not have to include the \\"_pq_.\\" prefix. I'm\\ngoing a bit back and forth between which I like better.\\n4. I think mentioning the \\"_pq_.\\" prefix in the paragraph above the\\nextension table would be good. Otherwise once we get more extensions\\nyou only learn about it once you get to the reserved extensions\\nsection.\\n\\nA few thoughts on the implementation:\\n1. If you like the randomization I did in my v5-0003, but don't want\\nto commit it yet. Then I think it would be good to change the reserved\\nprotocol extension to rename to _pq_.test_protocol_negotiation_0000.\\nSo that if we commit it later we don't have both\\n_pq_.test_protocol_negotiation and _pq_.test_protocol_negotiation_XXXX\\nreserved, but only have the one with a suffix reserved.\\n2. It might be nice to also error duplicate keys in NegotiateProtocolVersion.\\n","threadId":"19bed39e57f8cfa7","snippet":"On Sat, 24 Jan 2026 at 00:38, Jacob Champion <jacob.champion@enterprisedb.com> wrote: > WDYT? Overall, I think the changes and the split look fine. And I'd be happy with having it","historyId":"15685","internalDate":"1769249427000","receivedAtUtc":"2026-01-24T10:10:27.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"}]	Jelte Fennema-Nio provides feedback on Jacob Champion's proposal to bump the libpq protocol version to 3.2. He approves the overall changes and documentation split, suggesting it's ready for commit. For documentation improvements, he recommends creating a consistent table format for protocol extensions, adding a dedicated section header for extensions, considering "extension name" vs "parameter name" as column headers, and mentioning the "_pq_." prefix earlier in documentation. On implementation, he suggests renaming the reserved protocol extension to include a suffix for future compatibility and adding error handling for duplicate keys in NegotiateProtocolVersion.\nJelte Fennema-Nio对Jacob Champion提议将libpq协议版本升级到3.2版本提供了反馈。他总体上赞同这些变更和文档拆分，认为可以提交。在文档改进方面，他建议为协议扩展创建一致的表格格式，为扩展添加专门的章节标题，考虑使用"扩展名称"而非"参数名称"作为列标题，并在文档中更早地提及"_pq_."前缀。在实现方面，他建议重命名保留的协议扩展以包含后缀以确保未来兼容性，并在NegotiateProtocolVersion中添加重复键的错误处理。	2026-01-24 10:10:27+00	\N
15	19beed7dde2b545a	proposal: plpgsql - FOREACH t IN JSON ARRAY expr	["pavel.stehule@gmail.com"]	[{"id":"19beed7dde2b545a","messageId":"<CAFj8pRB858EmA2xqaWQMUs_bYmLNZY8eBS2zP+wrg0vyT97gDA@mail.gmail.com>","subject":"proposal: plpgsql - FOREACH t IN JSON ARRAY expr","body":"Hi,\\n\\nlast year I did a performance audit of some applications and I found a new\\nrelatively common pattern - iteration over jsonb arrays. Because PL/pgSQL\\ndoesn't support this iteration directly, they used some combinations of\\njsonb_array_elements function and FOR IN SELECT.\\n\\nThe overhead of this can be relatively high, and I think we can support\\nFOREACH json(b) arrays without some high cost.\\n\\nMy idea is a support of syntax\\n\\nFOREACH target IN JSON ARRAY expression LOOP .. END LOOP\\n\\ntarget can be a scalar variable of any type - we can use cast rules used in\\nJSON_TABLE\\n\\nWhat do you think about this proposal?\\n\\nRegards\\n\\nPavel\\n","threadId":"19beed7dde2b545a","snippet":"Hi, last year I did a performance audit of some applications and I found a new relatively common pattern - iteration over jsonb arrays. Because PL/pgSQL doesn't support this iteration directly,","historyId":"15689","internalDate":"1769238636000","receivedAtUtc":"2026-01-24T07:10:36.000Z","from":"Pavel Stehule <pavel.stehule@gmail.com>"},{"id":"19befbe438bd85a3","messageId":"<CAFj8pRDKi0m==eAnE0q3Dfjbe=0kY2N9qGhduhJTUr7zOJDn9A@mail.gmail.com>","subject":"Re: proposal: plpgsql - FOREACH t IN JSON ARRAY expr","body":"so 24. 1. 2026 v 8:10 odesílatel Pavel Stehule <pavel.stehule@gmail.com>\\nnapsal:\\n\\n> Hi,\\n>\\n> last year I did a performance audit of some applications and I found a new\\n> relatively common pattern - iteration over jsonb arrays. Because PL/pgSQL\\n> doesn't support this iteration directly, they used some combinations of\\n> jsonb_array_elements function and FOR IN SELECT.\\n>\\n> The overhead of this can be relatively high, and I think we can support\\n> FOREACH json(b) arrays without some high cost.\\n>\\n> My idea is a support of syntax\\n>\\n> FOREACH target IN JSON ARRAY expression LOOP .. END LOOP\\n>\\n\\nI did some simple test\\n\\nCREATE OR REPLACE FUNCTION public.randoma(integer)\\n RETURNS integer[]\\n LANGUAGE sql\\nAS $function$\\nselect array_agg(random()*10000) from generate_series(1,$1)\\n$function$\\n\\nCREATE OR REPLACE FUNCTION public.suma(integer[])\\n RETURNS integer\\n LANGUAGE plpgsql\\n IMMUTABLE\\nAS $function$\\ndeclare s int default 0;\\n f int;\\nbegin\\n  foreach f in array $1 loop s := s + f; end loop;\\n  return s;\\nend;\\n$function$\\n\\nCREATE OR REPLACE FUNCTION public.sumj(jsonb)\\n RETURNS integer\\n LANGUAGE plpgsql\\n IMMUTABLE\\nAS $function$\\ndeclare s int default 0;\\n f int;\\nbegin\\n  for f in select v from jsonb_array_elements($1) g(v) loop s := s +\\nf::int; end loop;\\n  return s;\\nend;\\n$function$\\n\\n(2026-01-24 12:20:07) postgres=# do $$\\ndeclare a int[] = randoma(10000);\\nbegin\\n  for i in 1..1000 loop\\n    perform suma(a);\\n  end loop;\\nend;\\n$$;\\nDO\\nTime: 2705,881 ms (00:02,706)\\n(2026-01-24 12:20:11) postgres=# do $$\\ndeclare a jsonb = array_to_json(randoma(10000));\\nbegin\\n  for i in 1..1000 loop\\n    perform sumj(a);\\n  end loop;\\nend;\\n$$;\\nDO\\nTime: 25809,319 ms (00:25,809)\\n\\nFOREACH is +/- 10 times faster\\n\\n\\n\\n\\n\\n\\n>\\n> target can be a scalar variable of any type - we can use cast rules used\\n> in JSON_TABLE\\n>\\n> What do you think about this proposal?\\n>\\n> Regards\\n>\\n> Pavel\\n>\\n","threadId":"19beed7dde2b545a","snippet":"so 24. 1. 2026 v 8:10 odesílatel Pavel Stehule <pavel.stehule@gmail.com> napsal: Hi, last year I did a performance audit of some applications and I found a new relatively common pattern -","historyId":"15689","internalDate":"1769253735000","receivedAtUtc":"2026-01-24T11:22:15.000Z","from":"Pavel Stehule <pavel.stehule@gmail.com>"}]	Pavel Stehule proposes adding native support for iterating over JSON arrays in PL/pgSQL through a new FOREACH syntax. Currently, developers must use combinations of jsonb_array_elements function with FOR IN SELECT loops, which creates significant performance overhead. The proposed syntax would be "FOREACH target IN JSON ARRAY expression LOOP .. END LOOP" where the target variable can be any type using JSON_TABLE cast rules. Performance testing demonstrates the current workaround is approximately 10 times slower than native array iteration - processing 10,000 elements 1,000 times took 25.8 seconds for JSON arrays versus 2.7 seconds for regular arrays. This proposal aims to provide efficient native JSON array iteration without high implementation costs.\n\nPavel Stehule 提议在 PL/pgSQL 中添加对 JSON 数组迭代的原生支持，通过新的 FOREACH 语法实现。目前，开发者必须使用 jsonb_array_elements 函数与 FOR IN SELECT 循环的组合，这会产生显著的性能开销。提议的语法是 "FOREACH target IN JSON ARRAY expression LOOP .. END LOOP"，其中目标变量可以是任何类型，使用 JSON_TABLE 转换规则。性能测试表明当前的替代方案比原生数组迭代慢约 10 倍——处理 10,000 个元素 1,000 次，JSON 数组需要 25.8 秒，而常规数组仅需 2.7 秒。该提议旨在提供高效的原生 JSON 数组迭代，而不需要高实现成本。	2026-01-24 11:22:15+00	\N
15	19bf07c83663338a	unclear OAuth error message	["alvherre@kurilemu.de","jacob.champion@enterprisedb.com"]	[{"id":"19bf07c83663338a","messageId":"<202601241015.y5uvxd7oxnfs@alvherre.pgsql>","subject":"unclear OAuth error message","body":"Hello,\\n\\nWhile updating the translation, I noticed this code\\n\\n    /*\\n     * Log any authentication results even if the token isn't authorized; it\\n     * might be useful for auditing or troubleshooting.\\n     */\\n    if (ret->authn_id)\\n        set_authn_id(port, ret->authn_id);\\n\\n    if (!ret->authorized)\\n    {\\n        ereport(LOG,\\n                errmsg(\\"OAuth bearer authentication failed for user \\\\\\"%s\\\\\\"\\",\\n                       port->user_name),\\n                errdetail_log(\\"Validator failed to authorize the provided token.\\"));\\n\\n        status = false;\\n        goto cleanup;\\n    }\\n\\nI'm not sure I understand the errdetail() part of it.  At first it made\\nme wonder if it was about a user-supplied module that had an internal\\nfailure preventing it from deciding whether the user was authorized or\\nnot (which would have been something like \\"Validator failed while ...\\").\\nBut the code suggests that the module worked fine and made the\\ndetermination not to authorize the user.  If that's so, then why do we\\nhave the errdetail at all?  Can't we just get rid of it and let the\\nerrmsg stand on its own merit?\\n\\nThere is one more case for this exact errmsg to be given:\\n\\n    /* Make sure the validator authenticated the user. */\\n    if (ret->authn_id == NULL || ret->authn_id[0] == '\\\\0')\\n    {\\n        ereport(LOG,\\n                errmsg(\\"OAuth bearer authentication failed for user \\\\\\"%s\\\\\\"\\",\\n                       port->user_name),\\n                errdetail_log(\\"Validator provided no identity.\\"));\\n\\nHere it seems the validator did indeed have an internal problem of some\\nsort, because while it did declare that the user was authorized, it did\\nnot provide what we were expecting from it.  Should in this case the\\nerrmsg() be different?\\n\\n(Actually, there's also auth_failed() giving the same message.)\\n\\n-- \\nÁlvaro Herrera         PostgreSQL Developer  —  https://www.EnterpriseDB.com/\\n\\"The saddest aspect of life right now is that science gathers knowledge faster\\n than society gathers wisdom.\\"  (Isaac Asimov)\\n\\n\\n","threadId":"19bf07c83663338a","snippet":"Hello, While updating the translation, I noticed this code /* * Log any authentication results even if the token isn't authorized; it * might be useful for auditing or troubleshooting. */ if (ret-","historyId":"15691","internalDate":"1769266228000","receivedAtUtc":"2026-01-24T14:50:28.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"}]	Álvaro Herrera raises concerns about unclear OAuth error messaging in PostgreSQL's authentication code. He questions whether the errdetail_log message "Validator failed to authorize the provided token" is appropriate when the OAuth validator successfully determined that a user should not be authorized, suggesting the detail message implies validator failure rather than proper authorization denial. He also notes a separate case where the same main error message is used when the validator fails to provide required identity information, asking if different error messages should distinguish between validator operational failure versus proper authorization denial. The issue involves improving error message clarity for OAuth authentication debugging and auditing purposes.\n\n阿尔瓦罗·埃雷拉对PostgreSQL身份验证代码中不清楚的OAuth错误消息表达了担忧。他质疑当OAuth验证器成功确定用户不应被授权时，errdetail_log消息"验证器未能授权提供的令牌"是否合适，认为详细消息暗示验证器失败而不是正确的授权拒绝。他还注意到当验证器未能提供所需身份信息时使用相同主错误消息的另一种情况，询问是否应使用不同的错误消息来区分验证器操作失败与正确的授权拒绝。该问题涉及改进OAuth身份验证调试和审计目的的错误消息清晰度。	2026-01-24 14:50:28+00	\N
15	19bef57ec77f7749	Converting README documentation to Markdown	["alvherre@kurilemu.de","daniel@yesql.se","peter@eisentraut.org","robertmhaas@gmail.com","zhjwpku@gmail.com"]	[{"id":"19bef57ec77f7749","messageId":"<202601240907.ccskdsdc5smx@alvherre.pgsql>","subject":"Re: Converting README documentation to Markdown","body":"On 2024-Sep-10, Robert Haas wrote:\\n\\n> On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <daniel@yesql.se> wrote:\\n> > Since there doesn't seem to be much interest in going all the way to Markdown,\\n> \\n> Just for the record, I suspect going to Markdown is actually the right\\n> thing to do.\\n\\nI had occasion to go look at our doxygen this morning, whose box is as\\nof a couple of days ago running Debian Trixie, and realized that it is\\nnow showing the README.md files in the documentation hierarchy -- for\\nexample,\\nhttps://doxygen.postgresql.org/md_src_2backend_2storage_2aio_2README.html\\nThe plain README files don't get this treatment.\\n\\nI don't know if it was already working in the previous version, or it is\\nonly that I happened to notice it now. (*)\\n\\nAnyway, I wonder if this fact would give more fuel to the idea of making\\nour README files gain a .md extension.\\n\\n\\n(*) Now that I look closer, this might be very old actually, because\\nBookworm had doxygen 1.9.4 and trixie has 1.9.8 -- very little\\ndifference there.  I guess I only noticed this now because we now have\\nREADME.me and the aio/README.md file.\\n\\n-- \\nÁlvaro Herrera        Breisgau, Deutschland  —  https://www.EnterpriseDB.com/\\n\\"La vida es para el que se aventura\\"\\n\\n\\n","threadId":"19bef57ec77f7749","snippet":"On 2024-Sep-10, Robert Haas wrote: > On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <daniel@yesql.se> wrote: > > Since there doesn't seem to be much interest in going all the way","historyId":"15690","internalDate":"1769247054000","receivedAtUtc":"2026-01-24T09:30:54.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>"},{"id":"19bf0a606cf2b161","messageId":"<CAEG8a3Kehi9=eNdCjYizEJp3+Y7ssa7R6tFfuP8-rpDmYsjz3g@mail.gmail.com>","subject":"Re: Converting README documentation to Markdown","body":"On Sat, Jan 24, 2026 at 5:31 PM Álvaro Herrera <alvherre@kurilemu.de> wrote:\\n>\\n> On 2024-Sep-10, Robert Haas wrote:\\n>\\n> > On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <daniel@yesql.se> wrote:\\n> > > Since there doesn't seem to be much interest in going all the way to Markdown,\\n> >\\n> > Just for the record, I suspect going to Markdown is actually the right\\n> > thing to do.\\n>\\n> I had occasion to go look at our doxygen this morning, whose box is as\\n> of a couple of days ago running Debian Trixie, and realized that it is\\n> now showing the README.md files in the documentation hierarchy -- for\\n> example,\\n> https://doxygen.postgresql.org/md_src_2backend_2storage_2aio_2README.html\\n> The plain README files don't get this treatment.\\n>\\n> I don't know if it was already working in the previous version, or it is\\n> only that I happened to notice it now. (*)\\n>\\n> Anyway, I wonder if this fact would give more fuel to the idea of making\\n> our README files gain a .md extension.\\n\\nGitHub also provides nice rendering for markdown files, see\\n\\nhttps://github.com/postgres/postgres/blob/master/src/backend/storage/aio/README.md\\n\\n>\\n>\\n> (*) Now that I look closer, this might be very old actually, because\\n> Bookworm had doxygen 1.9.4 and trixie has 1.9.8 -- very little\\n> difference there.  I guess I only noticed this now because we now have\\n> README.me and the aio/README.md file.\\n>\\n> --\\n> Álvaro Herrera        Breisgau, Deutschland  —  https://www.EnterpriseDB.com/\\n> \\"La vida es para el que se aventura\\"\\n>\\n>\\n\\n\\n-- \\nRegards\\nJunwang Zhao\\n\\n\\n","threadId":"19bef57ec77f7749","snippet":"On Sat, Jan 24, 2026 at 5:31 PM Álvaro Herrera <alvherre@kurilemu.de> wrote: > > On 2024-Sep-10, Robert Haas wrote: > > > On Tue, Sep 10, 2024 at 8:51 AM Daniel Gustafsson <","historyId":"15690","internalDate":"1769268947000","receivedAtUtc":"2026-01-24T15:35:47.000Z","from":"Junwang Zhao <zhjwpku@gmail.com>"}]	PostgreSQL developers are discussing converting README files to Markdown format. Álvaro Herrera discovered that Doxygen documentation now properly renders README.md files in the documentation hierarchy, while plain README files lack this treatment. This observation provides additional motivation for adding .md extensions to README files. Robert Haas previously expressed support for converting to Markdown, though Daniel Gustafsson noted limited interest in full conversion. Junwang Zhao highlighted that GitHub also provides enhanced rendering for Markdown files, referencing the existing aio/README.md as an example. The discussion centers on whether improved documentation rendering justifies converting existing README files to Markdown format, with technical evidence supporting the change.\n\nPostgreSQL开发者正在讨论将README文件转换为Markdown格式。Álvaro Herrera发现Doxygen文档现在能正确渲染README.md文件到文档层次结构中，而普通README文件缺乏这种处理。这一发现为给README文件添加.md扩展名提供了额外的动机。Robert Haas此前表示支持转换为Markdown，尽管Daniel Gustafsson指出对完全转换的兴趣有限。Junwang Zhao强调GitHub也为Markdown文件提供增强渲染，并引用现有的aio/README.md作为例子。讨论的核心是改进的文档渲染是否证明将现有README文件转换为Markdown格式的合理性，技术证据支持这一变更。	2026-01-24 15:35:47+00	\N
15	19bebb16779ae05d	Time to drop RADIUS support?	["alvherre@kurilemu.de","jacob.champion@enterprisedb.com","mbanck@gmx.net","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19bf24a30d7acf52","messageId":"<CA+hUKGKXHBCptORqu2jZf5o0Gw45Q7YMW9wKmrXYDm35uQStoA@mail.gmail.com>","subject":"Re: Time to drop RADIUS support?","body":"On Sat, Jan 24, 2026 at 6:50 AM Jacob Champion\\n<jacob.champion@enterprisedb.com> wrote:\\n> On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> > > I don't think removing it entirely from all back branches is a good\\n> > > idea, without first making sure that there are no users.\\n> >\\n> > Agreed, we can't pull it from the back branches.  But I'm in favor of\\n> > pulling it from HEAD if we document how to use PAM-based RADIUS\\n> > instead.  I agree with Thomas' argument that the cost-benefit ratio\\n> > of fixing our implementation would be poor.\\n>\\n> +1.\\n\\nGreat, it sounds like we have a plan.  I think the wiki might be a\\ngood place for that documentation.  The details are likely to change,\\nand I wouldn't want to have to maintain that information in-tree, so I\\ncreated some PAM how-to documentation at\\nhttps://wiki.postgresql.org/wiki/RADIUS after testing on Debian and\\nFreeBSD.  We could point to that from the 19 release notes and in the\\ndeprecation notice added to the documentation for 14-18, calling it\\n\\"community-maintained guidance on migration to supported\\nconfigurations\\".  Do we need to keep any trace of this in the 19 docs,\\nand if so, where?  A new tombstone section?\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"On Sat, Jan 24, 2026 at 6:50 AM Jacob Champion <jacob.champion@enterprisedb.com> wrote: > On Fri, Jan 23, 2026 at 8:30 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > > > I don't","historyId":"16168","internalDate":"1769296459000","receivedAtUtc":"2026-01-24T23:14:19.000Z","from":"Thomas Munro <thomas.munro@gmail.com>"},{"id":"19bf2ad083eb2b4f","messageId":"<3497908.1769302964@sss.pgh.pa.us>","subject":"Re: Time to drop RADIUS support?","body":"Thomas Munro <thomas.munro@gmail.com> writes:\\n> Great, it sounds like we have a plan.  I think the wiki might be a\\n> good place for that documentation.  The details are likely to change,\\n> and I wouldn't want to have to maintain that information in-tree, so I\\n> created some PAM how-to documentation at\\n> https://wiki.postgresql.org/wiki/RADIUS after testing on Debian and\\n> FreeBSD.\\n\\nOk ...\\n\\n> We could point to that from the 19 release notes and in the\\n> deprecation notice added to the documentation for 14-18, calling it\\n> \\"community-maintained guidance on migration to supported\\n> configurations\\".  Do we need to keep any trace of this in the 19 docs,\\n> and if so, where?  A new tombstone section?\\n\\nI think we don't want\\nhttps://www.postgresql.org/docs/current/auth-radius.html\\nto become 404, so I'd advocate keeping a short section with that\\nSGML ID that says we no longer support RADIUS directly and\\ngives a pointer to the wiki page.  It probably doesn't belong\\nexactly where it is today in the TOC, though, but shoved off\\nin a corner somewhere.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebb16779ae05d","snippet":"Thomas Munro <thomas.munro@gmail.com> writes: > Great, it sounds like we have a plan. I think the wiki might be a > good place for that documentation. The details are likely to change, >","historyId":"16452","internalDate":"1769302964000","receivedAtUtc":"2026-01-25T01:02:44.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	The PostgreSQL team has reached consensus to remove direct RADIUS authentication support from HEAD (version 19) while keeping it in back branches. Thomas Munro created community-maintained PAM-based RADIUS migration documentation on the PostgreSQL wiki after testing on Debian and FreeBSD. The plan includes pointing to this wiki documentation from v19 release notes and adding deprecation notices to v14-18 documentation. Tom Lane suggests maintaining a short tombstone section in the current documentation location to prevent 404 errors, redirecting users to the wiki page rather than completely removing the auth-radius.html page.\n\nPostgreSQL团队已达成共识，将从HEAD（版本19）中移除直接RADIUS身份验证支持，但在后续分支中保留。Thomas Munro在Debian和FreeBSD上测试后，在PostgreSQL wiki上创建了社区维护的基于PAM的RADIUS迁移文档。计划包括在v19发布说明中指向此wiki文档，并在v14-18文档中添加弃用通知。Tom Lane建议在当前文档位置保留一个简短的墓碑章节，以防止404错误，将用户重定向到wiki页面，而不是完全删除auth-radius.html页面。	2026-01-25 01:02:44+00	\N
15	19bf100b2caf0fc6	Add SQL/JSON ON MISMATCH clause to JSON_VALUE	["florents.tselai@gmail.com"]	[{"id":"19bf100b2caf0fc6","messageId":"<CA+v5N42Kn65HauYbZJ=bAVHjzdp=wCg64dd+WzRmtu=Uu1z+Ow@mail.gmail.com>","subject":"Add SQL/JSON ON MISMATCH clause to JSON_VALUE","body":"Hello hackers,\\n\\nHere's a patch that attempts to $subject.\\n\\nMy original motivation was to implement this for JSON_TABLE,\\nbut I realized it would be better to start with a smaller scope\\nby targeting the basic query functions first.\\n\\nCurrently this v1 passes the tests I've put for JSON_VALUE.\\n\\nI've had trouble making JSON_QUERY work too,\\nso I suspect that although my tests pass,\\nthere may be something I'm missing in the executor side of things.\\nWhile I troubleshoot that it'd be nice to get some feedback for this\\nversion.\\n\\nRegards,\\nFlo\\n","threadId":"19bf100b2caf0fc6","snippet":"Hello hackers, Here's a patch that attempts to $subject. My original motivation was to implement this for JSON_TABLE, but I realized it would be better to start with a smaller scope by targeting","historyId":"15692","internalDate":"1769274862000","receivedAtUtc":"2026-01-24T17:14:22.000Z","from":"Florents Tselai <florents.tselai@gmail.com>"},{"id":"19bf2b95b68358ea","messageId":"<CA+v5N40MaAQQOxucapnW9kVxyHgt8qVmrt4vxv_2=DRxQ+y+AA@mail.gmail.com>","subject":"Re: Add SQL/JSON ON MISMATCH clause to JSON_VALUE","body":">\\n> I've had trouble making JSON_QUERY work too,\\n> so I suspect that although my tests pass,\\n> there may be something I'm missing in the executor side of things.\\n>\\n\\n\\"For those curious, I found the issue: in ExecEvalJsonExprPath, I\\n had misplaced the check for jsexpr->on_mismatch.\\nI wasn't setting jsestate->escontext.details_wanted = true early enough.\\n Without this, the soft error context wasn't capturing the specific SQL\\nerror code needed to identify the mismatch.\\n\\nAttaching a v2 that implements ON MISMATCH for JSON_QUERY and JSON_TABLE\\ntoo.\\n\\nThat said, the semantics of ON ERROR / MISMATCH / EMPTY are complex.\\nI expect someone with access to and detailed knowledge of the standard\\nmight be able to poke holes in certain edge cases, particularly regarding\\nprecedence.\\n","threadId":"19bf100b2caf0fc6","snippet":"I've had trouble making JSON_QUERY work too, so I suspect that although my tests pass, there may be something I'm missing in the executor side of things. \\"For those curious, I found the","historyId":"16507","internalDate":"1769303739000","receivedAtUtc":"2026-01-25T01:15:39.000Z","from":"Florents Tselai <florents.tselai@gmail.com>"}]	Florents Tselai proposes adding the SQL/JSON ON MISMATCH clause to JSON_VALUE, starting with a smaller scope before implementing it for JSON_TABLE. The initial v1 patch passes tests for JSON_VALUE but encounters issues with JSON_QUERY due to executor-side problems. The author identifies the root cause: incorrect placement of the on_mismatch check in ExecEvalJsonExprPath and failure to set jsestate->escontext.details_wanted early enough, preventing proper soft error context capture. A v2 patch extends ON MISMATCH support to JSON_QUERY and JSON_TABLE. However, the author acknowledges that ON ERROR/MISMATCH/EMPTY semantics are complex and expects experts familiar with the standard may identify edge cases, particularly regarding precedence handling.\n\nFlorents Tselai 提议为 JSON_VALUE 添加 SQL/JSON ON MISMATCH 子句，在为 JSON_TABLE 实现之前先从较小的范围开始。初始 v1 补丁通过了 JSON_VALUE 的测试，但由于执行器端问题在 JSON_QUERY 上遇到困难。作者识别出根本原因：在 ExecEvalJsonExprPath 中错误放置了 on_mismatch 检查，并且未能及早设置 jsestate->escontext.details_wanted，导致软错误上下文无法正确捕获。v2 补丁将 ON MISMATCH 支持扩展到 JSON_QUERY 和 JSON_TABLE。然而，作者承认 ON ERROR/MISMATCH/EMPTY 语义复杂，预期熟悉标准的专家可能会发现边缘情况，特别是在优先级处理方面。	2026-01-25 01:15:39+00	\N
15	19be4bfe79e845a8	Add WALRCV_CONNECTING state to walreceiver	["li.evan.chao@gmail.com","michael@paquier.xyz","noah@leadboat.com","rahilasyed90@gmail.com","xunengzhou@gmail.com"]	[{"id":"19bf2c2c4c355b67","messageId":"<aXVxSXBMKN1XrqxB@paquier.xyz>","subject":"Re: Add WALRCV_CONNECTING state to walreceiver","body":"On Fri, Jan 23, 2026 at 04:47:43PM +0800, Xuneng Zhou wrote:\\n> I'll post the patches and possibly start a new thread for discussion.\\n\\nThanks for all that.  I'd suggest posting the startup proposal into an\\nentirely new thread for clarity.\\n--\\nMichael\\n","threadId":"19be4bfe79e845a8","snippet":"On Fri, Jan 23, 2026 at 04:47:43PM +0800, Xuneng Zhou wrote: > I'll post the patches and possibly start a new thread for discussion. Thanks for all that. I'd suggest posting the startup","historyId":"16593","internalDate":"1769304393000","receivedAtUtc":"2026-01-25T01:26:33.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	Michael Paquier responded to Xuneng Zhou's proposal to add a WALRCV_CONNECTING state to the walreceiver functionality in PostgreSQL. Zhou had indicated plans to post patches and potentially start a new discussion thread. Paquier acknowledged this plan and specifically recommended that Zhou create an entirely new thread for the startup proposal to ensure clarity in the discussion. The brief exchange suggests this is part of a larger ongoing discussion about walreceiver state management, with the conversation transitioning toward a more formal patch submission and review process.\n\nMichael Paquier回应了Xuneng Zhou关于在PostgreSQL的walreceiver功能中添加WALRCV_CONNECTING状态的提案。Zhou表示计划发布补丁并可能开启新的讨论线程。Paquier确认了这个计划，并特别建议Zhou为启动提案创建一个全新的线程以确保讨论的清晰性。这个简短的交流表明这是关于walreceiver状态管理的更大讨论的一部分，对话正在转向更正式的补丁提交和审查过程。	2026-01-25 01:26:33+00	\N
15	19bf4bf6b943af32	[PATCH] Add monitoring guidance to replication slot documentation	["tvvraghavan@gmail.com"]	[{"id":"19bf4bf6b943af32","messageId":"<CADFU1-1O_xNZQHZMXsNDk0zX3Wd3KKaFpGN2+-3OLpmK6+qH8A@mail.gmail.com>","subject":"[PATCH] Add monitoring guidance to replication slot documentation","body":"Hello PostgreSQL developers,\\n\\nI'm submitting a documentation improvement for Section 26.2.6 (Replication\\nSlots) based on my experience as a database architect managing PostgreSQL\\nhigh-availability environments.\\n\\n# Problem\\n\\nThe current documentation warns that replication slots \\"can cause the\\nserver to retain so many WAL segments that they fill up the space allocated\\nfor \\"pg_wal\\" and mentions \\"max_slot_wal_keep_size\\" as a mitigation.\\nHowever, it doesn't provide guidance on what DBAs should monitor to detect\\nthis condition before it becomes critical.\\n\\nIn production environments, the database engineers need to know what\\nmetrics to watch, not just how to limit the problem after the fact.\\n\\n# Solution\\n\\nThis patch adds specific monitoring recommendations immediately after the\\nwarning, including:\\n\\n- Disk space monitoring for pg_wal directory\\n- Replication lag metrics from pg_stat_replication (write_lag, flush_lag,\\nreplay_lag)\\n- Slot status checks from pg_replication_slots (active flag, restart_lsn)\\n\\nThis gives the database engineers actionable information they can use to\\nset up proactive monitoring and alerting.\\n\\n# Background\\n\\nFrom my production experience managing EFM clusters with streaming\\nreplication, the most common cause of WAL accumulation is inactive standbys\\nthat prevent\\nWAL cleanup. The combination of monitoring restart_lsn in\\npg_replication_slots along with the active flag provides early warning when\\na slot is preventing cleanup, before disk space becomes critical.\\n\\nI've seen this scenario multiple times in enterprise deployments:\\n- Standby server goes offline for maintenance or network issues\\n- Replication slot remains active but standby not connected\\n- Primary keeps WAL segments needed by the slot\\n- pg_wal fills up over hours or days\\n- Primary eventually fails when out of disk space\\n\\nThe monitoring guidance in this patch would help the database engineers catch\\nthis early.\\n\\n# Patch Details\\n\\nThe patch is attached and has also been pushed to my GitHub fork:\\nhttps://github.com/mastercloudarchitect/postgres/tree/docs/improve-replication-slot-monitoring\\n\\nI'm happy to revise based on feedback. If the community thinks additional\\nmonitoring recommendations would be helpful (e.g., alerting thresholds,\\nintegration with monitoring tools), I can add those as well.\\n\\nThanks for considering this improvement!\\n\\nBest regards,\\nVenkat Venkatakrishnan\\nDatabase Architect\\n","threadId":"19bf4bf6b943af32","snippet":"Hello PostgreSQL developers, I'm submitting a documentation improvement for Section 26.2.6 (Replication Slots) based on my experience as a database architect managing PostgreSQL high-availability","historyId":"17278","internalDate":"1769311030000","receivedAtUtc":"2026-01-25T03:17:10.000Z","from":"Venkat Venkatakrishnan <tvvraghavan@gmail.com>"}]	Venkat Venkatakrishnan proposes a documentation patch for PostgreSQL's replication slots section (26.2.6) to add monitoring guidance. The current documentation warns about WAL accumulation filling pg_wal space and mentions max_slot_wal_keep_size as mitigation, but lacks proactive monitoring recommendations. The patch adds specific monitoring advice including disk space monitoring for pg_wal directory, replication lag metrics from pg_stat_replication, and slot status checks from pg_replication_slots. Based on production experience with EFM clusters, Venkat explains that inactive standbys commonly cause WAL accumulation when slots remain active but standbys disconnect, leading to potential primary failures. The patch aims to help database administrators detect this condition early through monitoring restart_lsn and active flags before disk space becomes critical.\nVenkat Venkatakrishnan 提议为 PostgreSQL 复制槽文档章节 (26.2.6) 添加监控指导的补丁。当前文档警告 WAL 累积会填满 pg_wal 空间，并提及 max_slot_wal_keep_size 作为缓解措施，但缺乏主动监控建议。该补丁添加了具体的监控建议，包括 pg_wal 目录磁盘空间监控、pg_stat_replication 的复制延迟指标以及 pg_replication_slots 的槽状态检查。基于 EFM 集群的生产经验，Venkat 解释说当槽保持活跃但备机断开连接时，非活跃备机通常会导致 WAL 累积，可能导致主机故障。该补丁旨在帮助数据库管理员通过监控 restart_lsn 和活跃标志在磁盘空间变得关键之前早期检测此状况。	2026-01-25 03:17:10+00	\N
15	19bf3bd174625cfe	pg_stat_statements: add missing tests for nesting_level	["exclusion@gmail.com","michael@paquier.xyz","samimseih@gmail.com"]	[{"id":"19bf3bd174625cfe","messageId":"<82dd02bb-4e0f-40ad-a60b-baa1763ff0bd@gmail.com>","subject":"Re: pg_stat_statements: add missing tests for nesting_level","body":"Hello Michael and Sami,\\n\\n21.01.2026 02:41, Michael Paquier wrote:\\n> On Tue, Jan 20, 2026 at 06:08:14PM -0600, Sami Imseih wrote:\\n>> While looking at pg_stat_statements nesting_level, I realized that there\\n>> are missing nesting_level tests for pgss_planner and pgss_ExecutorFinish.\\n>> That is, if you remove nesting_level++ and nesting_level-- in those 2 hooks,\\n>> the tests will still succeed.\\n>>\\n>> For pgss_planner the nesting_level updates missing tests are the ones\\n>> when track_planning is enabled.\\n>>\\n>> Attached is a quick patch to add coverage.\\n> Confirmed these two deficiencies, nice catch.  If one does the same\\n> removal of the nesting level calculation in other code paths like\\n> pgss_ExecutorRun(), one get complaints.  Will see to get this addition\\n> done.\\n\\nTwo buildfarm animals [1], [2] say that that addition is incompatible with\\nthe CLOBBER_CACHE_ALWAYS mode:\\nnot ok 5     - level_tracking                          52571 ms\\n\\ndiff -U3 /home/buildfarm/avocet/buildroot/HEAD/pgsql.build/contrib/pg_stat_statements/expected/level_tracking.out /home/buildfarm/avocet/buildroot/HEAD/pgsql.build/contrib/pg_stat_statements/results/level_tracking.out\\n--- /home/buildfarm/avocet/buildroot/HEAD/pgsql.build/contrib/pg_stat_statements/expected/level_tracking.out 2026-01-22 01:59:12.213054121 +0100\\n+++ /home/buildfarm/avocet/buildroot/HEAD/pgsql.build/contrib/pg_stat_statements/results/level_tracking.out 2026-01-22 05:24:17.363666155 +0100\\n@@ -1560,7 +1560,7 @@\\n  toplevel | calls | rows | plans | query\\n ----------+-------+------+-------+--------------------------------------------------------------------\\n  t        |     2 |    2 |     2 | SELECT PLUS_THREE($1)\\n- f        |     2 |    2 |     2 | SELECT i + 3 LIMIT 1\\n+ f        |     2 |    2 |     2 | SELECT i + $2 LIMIT $3\\n  t        |     1 |    1 |     0 | SELECT pg_stat_statements_reset() IS NOT NULL AS t\\n  t        |     0 |    0 |     1 | SELECT toplevel, calls, rows, plans, query FROM pg_stat_statements+\\n           |       |      |       |   ORDER BY query COLLATE \\"C\\"\\n\\nI can reproduce this locally with no extra tricks. Could you please adjust\\nthe test for this mode?\\n\\n[1] https://buildfarm.postgresql.org/cgi-bin/show_log.pl?nm=avocet&dt=2026-01-22%2000%3A58%3A36\\n[2] https://buildfarm.postgresql.org/cgi-bin/show_log.pl?nm=trilobite&dt=2026-01-24%2023%3A10%3A13\\n\\nBest regards,\\nAlexander","threadId":"19bf3bd174625cfe","snippet":"Hello Michael and Sami, 21.01.2026 02:41, Michael Paquier wrote: On Tue, Jan 20, 2026 at 06:08:14PM -0600, Sami Imseih wrote: While looking at pg_stat_statements nesting_level, I realized that there","historyId":"16819","internalDate":"1769320800000","receivedAtUtc":"2026-01-25T06:00:00.000Z","from":"Alexander Lakhin <exclusion@gmail.com>"},{"id":"19bf41a15403aa7a","messageId":"<aXXJIorDJDdxReF9@paquier.xyz>","subject":"Re: pg_stat_statements: add missing tests for nesting_level","body":"On Sun, Jan 25, 2026 at 08:00:00AM +0200, Alexander Lakhin wrote:\\n> I can reproduce this locally with no extra tricks. Could you please adjust\\n> the test for this mode?\\n\\nReproduced here.  That was trickier than it looks.  A trick with\\ndebug_discard_caches cannot help, because with a CLOBBER_CACHE_ALWAYS\\nbuild we would still do a GetCachedPlan() -> RevalidateCachedQuery()\\nthat goes through the post-parse analyze hook where the query would\\nstill be normalized, showing up in the output anyway.\\n\\nSo I have come up with a plan B.  If we do a DISCARD PLANS before the\\n*first* function call, we can force the test to revalidate the cached\\nquery without caring about CLOBBER_CACHE_ALWAYS, meaning that we would\\nalways store a normalized version of the inner query.  The point of\\nthe test is to check after the nesting level calculation in the\\nplanner hook, and the test is still able to check that correctly.  If\\nI remove the nesting_level bits from the code while the DISCARD is\\naround, the entry is stored as a top level entry incorrectly, but it\\nshould be stored as toplevel=false.  I'll go apply the attached\\nshortly, after some more checks..\\n--\\nMichael\\n","threadId":"19bf3bd174625cfe","snippet":"On Sun, Jan 25, 2026 at 08:00:00AM +0200, Alexander Lakhin wrote: > I can reproduce this locally with no extra tricks. Could you please adjust > the test for this mode? Reproduced here. That was","historyId":"17044","internalDate":"1769326882000","receivedAtUtc":"2026-01-25T07:41:22.000Z","from":"Michael Paquier <michael@paquier.xyz>"}]	A patch was proposed to add missing test coverage for nesting_level functionality in pg_stat_statements, specifically for pgss_planner and pgss_ExecutorFinish hooks when track_planning is enabled. Alexander Lakhin identified that the new tests fail under CLOBBER_CACHE_ALWAYS mode due to query normalization differences, where parameter placeholders ($2, $3) appear instead of literal values (3, 1) in the expected output. Michael Paquier reproduced the issue and developed a solution using DISCARD PLANS before the first function call to force query revalidation, ensuring normalized queries are consistently stored regardless of CLOBBER_CACHE_ALWAYS mode while maintaining the test's ability to verify correct nesting level calculation in the planner hook.\n\n提出了一个补丁来为pg_stat_statements中的nesting_level功能添加缺失的测试覆盖，特别是针对启用track_planning时的pgss_planner和pgss_ExecutorFinish钩子。Alexander Lakhin发现新测试在CLOBBER_CACHE_ALWAYS模式下失败，这是由于查询规范化差异导致的，期望输出中出现参数占位符($2, $3)而不是字面值(3, 1)。Michael Paquier重现了这个问题并开发了一个解决方案，在第一次函数调用前使用DISCARD PLANS来强制查询重新验证，确保无论CLOBBER_CACHE_ALWAYS模式如何都能一致地存储规范化查询，同时保持测试验证计划器钩子中正确嵌套级别计算的能力。	2026-01-25 07:41:22+00	\N
15	19bf35809663774d	Fix a reference error for window functions: In the function 'find_window_functions', the deduplication logic should be removed	["dgrowleyml@gmail.com","mza117jc@gmail.com","tndrwang@gmail.com"]	[{"id":"19bf35809663774d","messageId":"<CAErYLFAuxmW0UVdgrz7iiuNrxGQnFK_OP9hBD5CUzRgjrVrz=Q@mail.gmail.com>","subject":"Fix a reference error for window functions: In the function 'find_window_functions', the deduplication logic should be removed","body":"The deduplication logic won't cause an error when the result of this\\nfunction is only used in `select_active_windows`.\\nBut when the result is used in `optimize_window_clauses`, it will cause the\\n`winref` field of a certain window function to not be modified in the new\\nwindow.\\n","threadId":"19bf35809663774d","snippet":"The deduplication logic won't cause an error when the result of this function is only used in `select_active_windows`. But when the result is used in `optimize_window_clauses`, it will cause the `","historyId":"16748","internalDate":"1769314167000","receivedAtUtc":"2026-01-25T04:09:27.000Z","from":"Meng Zhang <mza117jc@gmail.com>"},{"id":"19bf3f8c7b81a505","messageId":"<CAApHDvoW8LZuiGK+_cyAR7q2kgoEeZfjNwm6wK2KcpvTGbcRgQ@mail.gmail.com>","subject":"Re: Fix a reference error for window functions: In the function 'find_window_functions', the deduplication logic should be removed","body":"On Sun, 25 Jan 2026 at 17:09, Meng Zhang <mza117jc@gmail.com> wrote:\\n> The deduplication logic won't cause an error when the result of this function is only used in `select_active_windows`.\\n> But when the result is used in `optimize_window_clauses`, it will cause the `winref` field of a certain window function to not be modified in the new window.\\n\\nThanks for the report. I'll have a look.\\n\\nDavid\\n\\n\\n","threadId":"19bf35809663774d","snippet":"On Sun, 25 Jan 2026 at 17:09, Meng Zhang <mza117jc@gmail.com> wrote: > The deduplication logic won't cause an error when the result of this function is only used in `select_active_windows`","historyId":"16951","internalDate":"1769324703000","receivedAtUtc":"2026-01-25T07:05:03.000Z","from":"David Rowley <dgrowleyml@gmail.com>"},{"id":"19bf407bba96ba15","messageId":"<CAHewXNkvTpofYp747vQaxvJdWiH+00vkvkd7MhP1fvdvDEvkfQ@mail.gmail.com>","subject":"Re: Fix a reference error for window functions: In the function 'find_window_functions', the deduplication logic should be removed","body":"Hi，all\\n\\nDavid Rowley <dgrowleyml@gmail.com> 于2026年1月25日周日 15:05写道：\\n>\\n> On Sun, 25 Jan 2026 at 17:09, Meng Zhang <mza117jc@gmail.com> wrote:\\n> > The deduplication logic won't cause an error when the result of this function is only used in `select_active_windows`.\\n> > But when the result is used in `optimize_window_clauses`, it will cause the `winref` field of a certain window function to not be modified in the new window.\\n>\\n> Thanks for the report. I'll have a look.\\n>\\n> David\\n>\\n>\\nI did some analysis, and I found this issue was introduced by this\\ncommit ed1a88d:\\nAllow window functions to adjust their frameOptions\\n\\nIn optimize_window_clauses(), the list wc->winref = 2 was set to NIL,\\nso \\"window 2\\" would not be in the activewindow lists.\\nWe only have one windowagg node, in ExecEndWindowAgg(), when we\\nprocess the second \\"ROW_NUMBER() OVER window2\\"\\nwhich its winref was still 2 because in\\nfind_window_functions_walker(), it was skipped due to duplicates.\\n\\nThe attached patch seems workable. But I have one question.  If we\\nimplement the attached patch, would it introduce redundant\\ncomputation?\\nMaybe optimize_window_clauses() would optimize the repeated\\ncomputation. I don't understand this much.\\n\\n-- \\nThanks,\\nTender Wang\\n\\n\\n","threadId":"19bf35809663774d","snippet":"Hi，all David Rowley <dgrowleyml@gmail.com> 于2026年1月25日周日 15:05写道： > > On Sun, 25 Jan 2026 at 17:09, Meng Zhang <mza117jc@gmail.com> wrote: > > The deduplication logic won't","historyId":"16998","internalDate":"1769325648000","receivedAtUtc":"2026-01-25T07:20:48.000Z","from":"Tender Wang <tndrwang@gmail.com>"},{"id":"19bf4a6a2407a1ec","messageId":"<CAApHDvpOXK6G2304mSzs9Hb110_U7SyYmoT0p9AucrEgZv5tJw@mail.gmail.com>","subject":"Re: Fix a reference error for window functions: In the function 'find_window_functions', the deduplication logic should be removed","body":"On Sun, 25 Jan 2026 at 20:05, David Rowley <dgrowleyml@gmail.com> wrote:\\n>\\n> On Sun, 25 Jan 2026 at 17:09, Meng Zhang <mza117jc@gmail.com> wrote:\\n> > The deduplication logic won't cause an error when the result of this function is only used in `select_active_windows`.\\n> > But when the result is used in `optimize_window_clauses`, it will cause the `winref` field of a certain window function to not be modified in the new window.\\n>\\n> Thanks for the report. I'll have a look.\\n\\nI initially didn't think your patch was correct as it was getting rid\\nof the deduplication logic, but after looking a bit deeper, the\\ndeduplication logic no longer works. I assume it did work when Tom\\nwrote the comment in 2016 (51c0f63e4), but in 2017 Andres changed the\\nexpression evaluation code for projections (b8d7f053c). The expression\\nevaluation code goes through the targetlist and will find the\\nWindowFuncs again, all 3 of them, in this case, and since the\\ndeduplication code didn't put them all in the WindowFuncLists lists,\\none still has the unmodified winref because optimize_window_clauses()\\nonly operates on the non-duplicate WindowFuncs.\\n\\nThe problem now is if we just delete the code as your patch does, then\\nthe costing code will newly include costs for any duplicate\\nWindowFuncs, and that could result in the dreaded plan changes in the\\nbackbranches problem. Yes, really we should be including these extra\\ncosts as we *do* evaluate the WindowFuncs separately, so in master, I\\nthink what you have is fine. We just probably will need to do\\nsomething to maintain the costs in the backbranches.\\n\\nI came up with the attached for that. I did write the list_uniquify()\\nbefore I realised your fix is ok for master. That function might be\\nmisplaced just in the backbranches, and it might be better to just\\nforeach and if (!list_member()) directly in optimize_window_clauses()\\nto get rid of the duplicates. That's probably safer too.\\n\\nI'll park the attached patch here for a bit to see if anyone else has\\nany thoughts.\\n\\nDavid\\n","threadId":"19bf35809663774d","snippet":"On Sun, 25 Jan 2026 at 20:05, David Rowley <dgrowleyml@gmail.com> wrote: > > On Sun, 25 Jan 2026 at 17:09, Meng Zhang <mza117jc@gmail.com> wrote: > > The deduplication logic won","historyId":"17143","internalDate":"1769336097000","receivedAtUtc":"2026-01-25T10:14:57.000Z","from":"David Rowley <dgrowleyml@gmail.com>"}]	Meng Zhang reported a reference error in PostgreSQL's window function handling where deduplication logic in `find_window_functions` causes `winref` fields to remain unmodified in `optimize_window_clauses`. Tender Wang analyzed the issue, tracing it to commit ed1a88d which allowed window functions to adjust frameOptions. The problem occurs when window references are set to NIL, causing certain window functions to be skipped during processing due to duplicate handling. David Rowley confirmed the bug exists because deduplication logic broke after Andres' 2017 expression evaluation changes (b8d7f053c). While removing deduplication fixes the issue in master, it could affect query costing and cause plan changes in backbranches. David proposed a patch using `list_uniquify()` for backbranches but suggests direct duplicate removal in `optimize_window_clauses` might be safer.\n\n张孟报告了PostgreSQL窗口函数处理中的引用错误，其中`find_window_functions`中的去重逻辑导致`optimize_window_clauses`中的`winref`字段保持未修改状态。Tender Wang分析了该问题，将其追溯到允许窗口函数调整frameOptions的提交ed1a88d。当窗口引用被设置为NIL时出现问题，导致某些窗口函数由于重复处理而被跳过。David Rowley确认该错误存在，因为去重逻辑在Andres 2017年表达式评估更改(b8d7f053c)后失效。虽然在主分支中移除去重可以修复问题，但可能影响查询成本计算并在后续分支中引起计划变更。David提出了在后续分支中使用`list_uniquify()`的补丁，但建议在`optimize_window_clauses`中直接移除重复项可能更安全。	2026-01-25 10:14:57+00	\N
15	19be99a6948cab2b	Extended Statistics set/restore/clear functions.	["corey.huinker@gmail.com","li.evan.chao@gmail.com","michael@paquier.xyz","tndrwang@gmail.com","zhjwpku@gmail.com"]	[{"id":"19bf09de6bf73015","messageId":"<CAEG8a3+6ibpVjnGiw6AWcM4roMYoge=aOuw1JP7RV5Wv+q4xvA@mail.gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","body":"On Fri, Jan 23, 2026 at 2:46 PM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>>\\n>> How about the multirange range case in extended_statistics_update()\\n>> for the mcv/expression path?\\n>\\n>\\n> Added.\\n>\\n>>\\n>> import_expressions() also complains about a statatt_set_slot() with\\n>> histograms.\\n>\\n>\\n> Unsure what you mean here.\\n>\\n>>\\n>> These ones are less consistent in style, the error hints should be the\\n>> errmsg, and there are some s/statitisics/statistics/.  The errhint\\n>> should be a full sentence, so I guess that you mean to switch both\\n>> fields in such cases.\\n>\\n>\\n> The 0003 patch of this set addresses this.\\n>\\n>>\\n>> s/the the/the/, I think this one's mine.  :D\\n>\\n>\\n> 0002\\n>\\n>>\\n>>\\n>> While the documentation shows one example with n_distinct,\\n>> dependencies and exprs, I'd guess that we should push forward with\\n>> something similar regarding most_common_val, most_common_val_nulls,\\n>> most_common_freqs, most_common_base_freqs.  It looks particularly\\n>> important to expand this part, the relationship they have between each\\n>> pther, their expected input format (?), and what they map to in the\\n>> catalogs.  If one is specified, all four of them are required, for\\n>> example, but that's not the only thing I imagine should keep a track\\n>> of.  This data is more complex than the single stats fields.\\n>\\n>\\n> I think some of this may have been addressed in this patchset.\\n>\\n> I've left these patches un-squashed to help differentiate what changes address which problems. They'll likely be re-squashed once those issues are addressed.\\n>\\n> The most interesting here is the change I did to statatt_get_type() to get it to work for MCV/expression multiranges. Mostly, the problem arose from the fact that MCVlist will have multirange as a part of the exported tuple text array, so there is a legit need to parse the input of a multirange's text reprepresentation, whereas with attribute stats we only ever need to parse the input of the multirange's element, a plain old range. The fix, as you may see highlights how statatt_get_type() is doing two things (resolving typ* info for an attribute or expression, and fetching the basetype and basetype's ltopr and eqopr) and maybe the basetype/operator stuff should be moved to its own function.\\n>\\n> Another possible solution is to change the two refactor the examine_attribute() functions (one in analyze.c, one in extended_stats.c) unifying them where possible, and allowing the unified function to still generate a VacAttrStats even if the attstattarget is 0. That's a heavier lift, and I left things as they are now to demonstrate the issue at hand.\\n>\\n> Rebased as well.\\n>\\n\\nv30-0003-normalize-error-messages.patch introduced a typo:\\n\\n%s/incorect/incorrect\\n\\n-- \\nRegards\\nJunwang Zhao\\n\\n\\n","threadId":"19be99a6948cab2b","snippet":"On Fri, Jan 23, 2026 at 2:46 PM Corey Huinker <corey.huinker@gmail.com> wrote: >> >> How about the multirange range case in extended_statistics_update() >> for the mcv/","historyId":"15681","internalDate":"1769268414000","receivedAtUtc":"2026-01-24T15:26:54.000Z","from":"Junwang Zhao <zhjwpku@gmail.com>"},{"id":"19bf2c1375128ab4","messageId":"<aXVw4LGO4fWunn4n@paquier.xyz>","subject":"Re: Extended Statistics set/restore/clear functions.","body":"On Fri, Jan 23, 2026 at 01:45:38AM -0500, Corey Huinker wrote:\\n> I think some of this may have been addressed in this patchset.\\n> \\n> I've left these patches un-squashed to help differentiate what changes\\n> address which problems. They'll likely be re-squashed once those issues are\\n> addressed.\\n\\nNo problem here for the moment.\\n\\n> The most interesting here is the change I did to statatt_get_type() to get\\n> it to work for MCV/expression multiranges. Mostly, the problem arose from\\n> the fact that MCVlist will have multirange as a part of the exported tuple\\n> text array, so there is a legit need to parse the input of a multirange's\\n> text reprepresentation, whereas with attribute stats we only ever need to\\n> parse the input of the multirange's element, a plain old range. The fix, as\\n> you may see highlights how statatt_get_type() is doing two things\\n> (resolving typ* info for an attribute or expression, and fetching the\\n> basetype and basetype's ltopr and eqopr) and maybe the basetype/operator\\n> stuff should be moved to its own function.\\n> \\n> Another possible solution is to change the two refactor the\\n> examine_attribute() functions (one in analyze.c, one in extended_stats.c)\\n> unifying them where possible, and allowing the unified function to still\\n> generate a VacAttrStats even if the attstattarget is 0. That's a heavier\\n> lift, and I left things as they are now to demonstrate the issue at hand.\\n\\nYes, we are entering into some complexity territory here that needs a\\nvery careful lookup, and I am not sure yet if your suggestion of\\ninput arguments is the best thing to do.\\n\\nI have been thinking about how to move this patch forward, and I think\\nthat we should split things a bit more the logic (aka my usual\\ndivide-and-conquer strategy) for the restore function, because we\\nshould make sure that each part is sound before merging, and that's\\nalso a risk reduction if we need to revert one part or the other:\\n1) One patch for ndistinct.\\n2) One patch for dependencies.\\n3) One patch for MVC.\\n4) Dump/restore.\\n\\nThe \\"exprs\\" input argument is required by all the three others, meaning\\nthat it needs to stand in the first bits of the patch.  The order of\\nndistinct and dependencies does not matter, let's just do these based\\non the order of the input arguments.  Dump/restore could be already\\nintegrated even if we have only 1) and 2) restore integrated in the\\ntree.  It also seems like the \\"exprs\\" argument should stand on top of\\nall the others, as well, so it would make more sense to have it after\\n\\"inherited\\" in extended_stats_argnum?\\n\\nThere are two reasons behind this set of thoughts:\\n1) The regression tests are bloated.  We rely currently on one single\\nextended stats object that holds all the types of stats (MCV,\\ndependencies, ndistinct), meaning that for some of the valid cases we\\nneed to cary all the types in the input of restore function.  It's \\nalso a bit true in terms of the invalid cases.  One thing that I would\\nrecommend to do here is create two simpler extstat objects for each\\nstxkind (one with expression, one without expression).  You should\\nstill require the \\"global\\" extstat object that includes all the\\nstxkind, which counts for the expression import path, of course.\\n2) Each stxkind has its own set of paths in terms of input and\\nvalidation.  ndistinct and dependencies are much easier to handle as\\nthey have their own input function, hence they're better handled\\nfirst.\\n--\\nMichael\\n","threadId":"19be99a6948cab2b","snippet":"On Fri, Jan 23, 2026 at 01:45:38AM -0500, Corey Huinker wrote: > I think some of this may have been addressed in this patchset. > > I've left these patches un-squashed to help","historyId":"16549","internalDate":"1769304288000","receivedAtUtc":"2026-01-25T01:24:48.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19bf2f359a363e4f","messageId":"<CADkLM=f4+3_HrXSAaEic5VGGd-fOjS4jGnr1WGJYrL7vf3ZJnw@mail.gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","body":">\\n>\\n> Yes, we are entering into some complexity territory here that needs a\\n> very careful lookup, and I am not sure yet if your suggestion of\\n> input arguments is the best thing to do.\\n>\\n\\nWith that in mind, I'm going to move forward with a local static version of\\nstatatt_get_type() which avoids the typecache stuff altogether. Whatever\\nremains there will be instructive for how we keep/lose/modify the real\\nstatatt_get_type().\\n\\n\\n>\\n> I have been thinking about how to move this patch forward, and I think\\n> that we should split things a bit more the logic (aka my usual\\n> divide-and-conquer strategy) for the restore function, because we\\n> should make sure that each part is sound before merging, and that's\\n> also a risk reduction if we need to revert one part or the other:\\n> 1) One patch for ndistinct.\\n> 2) One patch for dependencies.\\n> 3) One patch for MVC.\\n>\\n\\nAll three of these are possible, though the tests of trying to set one of\\nthe three types on a stat object incapable of holding it won't be add-able\\nuntil the next type of stats are settlable.\\n\\nExpressions would be a 4th patch, and honestly it's the lion's share of the\\ncode.\\n\\n\\n\\n> 4) Dump/restore.\\n>\\n> The \\"exprs\\" input argument is required by all the three others, meaning\\n> that it needs to stand in the first bits of the patch.  The order of\\n> ndistinct and dependencies does not matter, let's just do these based\\n> on the order of the input arguments.  Dump/restore could be already\\n> integrated even if we have only 1) and 2) restore integrated in the\\n> tree.  It also seems like the \\"exprs\\" argument should stand on top of\\n> all the others, as well, so it would make more sense to have it after\\n> \\"inherited\\" in extended_stats_argnum?\\n>\\n\\nI think I went with the order they appeared in pg_stats_ext, with exprs\\ntacked on the end. I'm a bit confused why the argument order matters given\\nthat the only user exposure is the kwargs-like interface.\\n\\n\\n>\\n> There are two reasons behind this set of thoughts:\\n> 1) The regression tests are bloated.  We rely currently on one single\\n> extended stats object that holds all the types of stats (MCV,\\n> dependencies, ndistinct), meaning that for some of the valid cases we\\n> need to cary all the types in the input of restore function.  It's\\n> also a bit true in terms of the invalid cases.  One thing that I would\\n> recommend to do here is create two simpler extstat objects for each\\n> stxkind (one with expression, one without expression).  You should\\n> still require the \\"global\\" extstat object that includes all the\\n> stxkind, which counts for the expression import path, of course.\\n>\\n\\nWe can definitely lean on the one-stat-only objects more now that we have\\nthem.\\n","threadId":"19be99a6948cab2b","snippet":"Yes, we are entering into some complexity territory here that needs a very careful lookup, and I am not sure yet if your suggestion of input arguments is the best thing to do. With that in mind, I'","historyId":"16652","internalDate":"1769307570000","receivedAtUtc":"2026-01-25T02:19:30.000Z","from":"Corey Huinker <corey.huinker@gmail.com>"},{"id":"19bf3025b4a1e261","messageId":"<aXWBhkru03FnrfIW@paquier.xyz>","subject":"Re: Extended Statistics set/restore/clear functions.","body":"On Sat, Jan 24, 2026 at 09:19:30PM -0500, Corey Huinker wrote:\\n> Expressions would be a 4th patch, and honestly it's the lion's share of the\\n> code.\\n\\nI was under the impression that this was a strong dependency.  If that\\ncan be split out of the rest, well better for us then.\\n\\n> I think I went with the order they appeared in pg_stats_ext, with exprs\\n> tacked on the end. I'm a bit confused why the argument order matters given\\n> that the only user exposure is the kwargs-like interface.\\n\\nOkay, as you feel is better.\\n--\\nMichael\\n","threadId":"19be99a6948cab2b","snippet":"On Sat, Jan 24, 2026 at 09:19:30PM -0500, Corey Huinker wrote: > Expressions would be a 4th patch, and honestly it's the lion's share of the > code. I was under the impression that this","historyId":"16699","internalDate":"1769308550000","receivedAtUtc":"2026-01-25T02:35:50.000Z","from":"Michael Paquier <michael@paquier.xyz>"},{"id":"19bf4ab96aab52ee","messageId":"<CADkLM=c7DY3Jv6ef0n_MGUJ1FyTMUoT697LbkST05nraVGNHYg@mail.gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","body":"On Sat, Jan 24, 2026 at 9:35 PM Michael Paquier <michael@paquier.xyz> wrote:\\n\\n> On Sat, Jan 24, 2026 at 09:19:30PM -0500, Corey Huinker wrote:\\n> > Expressions would be a 4th patch, and honestly it's the lion's share of\\n> the\\n> > code.\\n>\\n> I was under the impression that this was a strong dependency.  If that\\n> can be split out of the rest, well better for us then.\\n\\n\\nOk, here's my attempt at splitting things out:\\n\\n0001 - Add attribute stats test for multiranges\\n0002 - Basic restore functionality ndistinct\\n0003 - add dependencies\\n0004 - add mcv\\n0005 - add expressions\\n0006 - Add in the before/after diff test on a stats object (in theory this\\ncould be added after 0002)\\n0007 - add SGML\\n0008 - restore MAINTAIN test (in theory this could be merged into 0002)\\n0009 - pg_dump\\n","threadId":"19be99a6948cab2b","snippet":"On Sat, Jan 24, 2026 at 9:35 PM Michael Paquier <michael@paquier.xyz> wrote: On Sat, Jan 24, 2026 at 09:19:30PM -0500, Corey Huinker wrote: > Expressions would be a 4th patch, and honestly","historyId":"17181","internalDate":"1769336413000","receivedAtUtc":"2026-01-25T10:20:13.000Z","from":"Corey Huinker <corey.huinker@gmail.com>"}]	The discussion centers on extended statistics functions for PostgreSQL, particularly the restore functionality. Junwang Zhao reports a typo in v30-0003 patch ("incorect" should be "incorrect"). Michael Paquier suggests splitting the complex patch into smaller, manageable pieces using a divide-and-conquer approach: separate patches for ndistinct, dependencies, MCV, and expressions, followed by dump/restore functionality. He recommends creating simpler extended statistics objects for testing rather than relying on one comprehensive object. Corey Huinker agrees to implement a local static version of statatt_get_type() to avoid complexity issues and proposes a 9-patch structure. The main technical challenge involves handling multirange text representation parsing for MCV/expression statistics, where the export format differs from attribute statistics. The team aims to ensure each component is sound before integration to reduce reversion risks.\n讨论围绕PostgreSQL的扩展统计函数，特别是恢复功能。Junwang Zhao报告了v30-0003补丁中的拼写错误（"incorect"应为"incorrect"）。Michael Paquier建议采用分而治之的方法将复杂补丁拆分为更易管理的小块：为ndistinct、dependencies、MCV和表达式分别创建补丁，然后是转储/恢复功能。他建议创建更简单的扩展统计对象进行测试，而不是依赖一个综合对象。Corey Huinker同意实现statatt_get_type()的本地静态版本以避免复杂性问题，并提出了9个补丁的结构。主要技术挑战涉及处理MCV/表达式统计的多范围文本表示解析，其中导出格式与属性统计不同。团队旨在确保每个组件在集成前都是健全的，以降低回滚风险。	2026-01-25 10:20:13+00	\N
15	19bebbb1bd6c2d07	Proposal: Adding compression of temporary files	["fjanus@redhat.com","lakshmigcdac@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bf5044c321b096","messageId":"<CAFjYY+J+TN-Ovi=ToGG4CcJweY_a6Hb6xL67fMESqKpT=FXuJQ@mail.gmail.com>","subject":"Re: Proposal: Adding compression of temporary files","body":"Fixed spacing in the patch.\\n\\n    -Filip-\\n\\n\\npá 23. 1. 2026 v 17:40 odesílatel Filip Janus <fjanus@redhat.com> napsal:\\n\\n> Hi all,\\n> Thanks for the feedback and the provided patch.\\n> I've addressed your findings and proposals. Lakshmi's documentation patch\\n> was incorporated.\\n>\\n>     -Filip-\\n>\\n>\\n> st 21. 1. 2026 v 7:30 odesílatel lakshmi <lakshmigcdac@gmail.com> napsal:\\n>\\n>> HI all,\\n>> While testing the temp file compression patch,noticed that the new\\n>> temp_file_compression GUC isn't documented yet.I put together a small docs\\n>> patch to add a short description and clarify that the effect of compression\\n>> depends on the workload(for example ,hash join spills may not show visible\\n>> size reduction due to fixed_size chunks).\\n>>\\n>> patch is attached.Happy to adjust the wording if needed.\\n>> thanks,\\n>> lakshmi\\n>>\\n>> On Tue, Jan 20, 2026 at 4:21 PM lakshmi <lakshmigcdac@gmail.com> wrote:\\n>>\\n>>> Hi Filip,\\n>>>\\n>>> I tested both patches on current master using git am -3 .They apply\\n>>> cleanly,build fine,and the temp_file _compression GUC works as expected.\\n>>> Query results are unchanged.\\n>>>\\n>>> For hash join spill test,temp files were created as expected,but the\\n>>> logged size were same for no,lz4,and pglz,which seems consistent with\\n>>> fixed-size fileset chunking.It might be helpful to briefly note this in the\\n>>> documentation to avoid confusion.\\n>>>\\n>>> Thanks for working on this .\\n>>> best regards,\\n>>> lakshmi\\n>>>\\n>>> On Tue, Jan 20, 2026 at 4:10 AM Zsolt Parragi <zsolt.parragi@percona.com>\\n>>> wrote:\\n>>>\\n>>>> Hello!\\n>>>>\\n>>>> I tried to review the code. It compiled, the test suite passed.\\n>>>>\\n>>>> I noticed two typos:\\n>>>>\\n>>>> buffile.c:77 - \\"Disaled\\"\\n>>>> buffile.c:133 - \\"mathods\\"\\n>>>>\\n>>>> And a few other small findings:\\n>>>>\\n>>>> buffile.h:35 and buffile.c:63 - same constants defined first as an\\n>>>> Enum and then as #defines - code builds properly without the defines.\\n>>>>\\n>>>> buffile.c:121 - compress_tempfile is defined, set to false at :167,\\n>>>> but never used otherwise\\n>>>>\\n>>>> guc_tables.c:470 - the comment says that pglz isn't supported yet, but\\n>>>> we have a value for it, and I see support for it in the code\\n>>>>\\n>>>> buffile.c:659: (and at other places) if USE_LZ4 is undefined, the\\n>>>> codepath doesn't do anything. I think these ifdefs should follow how\\n>>>> other compression code works, such as wal compression where there's an\\n>>>> #else path with elog(ERROR, ...)\\n>>>> Similarly, maybe there should be an explicit TEMP_NONE_COMPRESSION\\n>>>> branch that does nothing, and the default branch should be an error?\\n>>>>\\n>>>> buffile.c:265: If seek isn't supported/limited, shouldn't there be at\\n>>>> least an assertion about it in BufFileSeek? And tell isn't mentioned,\\n>>>> but it seems to me that tell also doesn't work properly.\\n>>>>\\n>>>\\n","threadId":"19bebbb1bd6c2d07","snippet":"Fixed spacing in the patch. -Filip- pá 23. 1. 2026 v 17:40 odesílatel Filip Janus <fjanus@redhat.com> napsal: Hi all, Thanks for the feedback and the provided patch. I've addressed your","historyId":"17347","internalDate":"1769342225000","receivedAtUtc":"2026-01-25T11:57:05.000Z","from":"Filip Janus <fjanus@redhat.com>"}]	Filip Janus has submitted an updated patch for PostgreSQL temporary file compression, addressing feedback from reviewers. The patch incorporates documentation improvements from Lakshmi, who noted that the new temp_file_compression GUC wasn't documented and suggested clarifying that compression effectiveness depends on workload characteristics. Zsolt Parragi provided detailed code review feedback, identifying typos ("Disaled", "mathods"), redundant constant definitions, unused variables, and structural issues with ifdef handling for compression methods. Key concerns include proper error handling for unsupported compression types, seek/tell functionality limitations with compressed files, and inconsistent comments about pglz support. The patch appears to build and pass tests, with hash join spill testing showing expected behavior where compression may not reduce logged file sizes due to fixed-size chunking.\n\nFilip Janus 提交了PostgreSQL临时文件压缩的更新补丁，解决了审查者的反馈意见。该补丁整合了Lakshmi的文档改进，她指出新的temp_file_compression GUC缺少文档，并建议说明压缩效果取决于工作负载特性。Zsolt Parragi提供了详细的代码审查反馈，发现了拼写错误（"Disaled"，"mathods"）、重复的常量定义、未使用的变量以及压缩方法ifdef处理的结构性问题。主要关注点包括不支持的压缩类型的正确错误处理、压缩文件的seek/tell功能限制以及pglz支持的不一致注释。补丁似乎能够构建并通过测试，哈希连接溢出测试显示预期行为，即由于固定大小分块，压缩可能不会减少记录的文件大小。	2026-01-25 11:57:05+00	\N
15	19bf506ae1e4b94e	[BUG] [PATCH] pg_basebackup produces wrong incremental files after relation truncation in segmented tables	["andrew@dunslane.net","exclusion@gmail.com","oatkachenko@gmail.com","robertmhaas@gmail.com","stanislav.bashkyrtsev@elsci.io","sulamul@gmail.com"]	[{"id":"19bf506ae1e4b94e","messageId":"<274e0a1a-d7d2-4bc8-8b56-dd09f285715e@gmail.com>","subject":"Re: [BUG] [PATCH] pg_basebackup produces wrong incremental files after relation truncation in segmented tables","body":"Hello Robert,\\n\\n19.01.2026 19:42, Robert Haas wrote:\\n> On Fri, Jan 16, 2026 at 7:10 AM Oleg Tkachenko <oatkachenko@gmail.com> wrote:\\n>> As you suggested, I've updated the test so that it produces small files consistently across platforms.\\n>> On one specific platform (with segment size = 6 blocks), it still exercises the relevant code path.\\n>> And I've also applied the style changes you mentioned.\\n> Thanks. I have committed the fix and back-patched to v17. I made some\\n> style changes to your test, especially rewriting comments, but the\\n> substance of it is unchanged.\\n\\nAs Windows animal fairywren shows at [1],  the test\\n011_incremental_backup_truncation_block, added by ecd275718, hit Windows\\nlimitation to the path length:\\n126/281 postgresql:pg_combinebackup / pg_combinebackup/011_incremental_backup_truncation_block ERROR            96.71s   (exit status 255 or signal 127 SIGinvalid)\\n\\nlog/011_incremental_backup_truncation_block_primary.log contains:\\n...\\n2026-01-20 02:11:14.760 UTC [7480:2] [unknown] LOG:  connection authenticated: user=\\"pgrunner\\" method=trust (C:/tools/xmsys64/home/pgrunner/bf/root/REL_18_STABLE/pgsql.build/testrun/pg_combinebackup/011_incremental_backup_truncation_block/data/t_011_incremental_backup_truncation_block_primary_data/pgdata/pg_hba.conf:117)\\n...\\n2026-01-20 02:11:23.506 UTC [1252:3] LOG:  checkpoint starting: immediate force wait\\n2026-01-20 02:11:23.580 UTC [1252:4] LOG:  checkpoint complete: wrote 5 buffers (3.9%), wrote 1 SLRU buffers; 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.074 s; sync files=0, longest=0.000 s, average=0.000 s; distance=32768 kB, estimate=32768 kB; lsn=0/4000080, redo lsn=0/4000028\\n2026-01-20 02:11:23.974 UTC [8968:2] ERROR:  could not rename file \\"pg_wal/summaries/temp.summary\\" to \\"pg_wal/summaries/00000001000000000100002800000000010CAA50.summary\\": No such file or directory\\n        1 file(s) copied.\\n2026-01-20 02:11:33.645 UTC [7968:14] 011_incremental_backup_truncation_block.pl WARNING:  still waiting for WAL summarization through 0/4000028 after 10 seconds\\n2026-01-20 02:11:33.645 UTC [7968:15] 011_incremental_backup_truncation_block.pl DETAIL:  Summarization has reached 0/1000000 on disk and 0/10CAA50 in memory.\\n\\nThat is, the target filename for the rename operation is:\\nC:/tools/xmsys64/home/pgrunner/bf/root/REL_18_STABLE/pgsql.build/testrun/pg_combinebackup/011_incremental_backup_truncation_block/data/t_011_incremental_backup_truncation_block_primary_data/pgdata/pg_wal/summaries/00000001000000000100002800000000010CAA50.summary\\n\\nI can reproduce this locally with the source tree located at\\n/c/src/postgresql12345678901234567890123456789012345678901.\\nNot reproduced with HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\FileSystem\\\\LongPathsEnabled set to 1.\\n\\nNote that the test passes at the master branch ([2]) because \\"master\\" is\\nshorter than \\"REL_18_STABLE\\" by 7 chars.\\n\\nSee also [3].\\n\\n[1] https://buildfarm.postgresql.org/cgi-bin/show_log.pl?nm=fairywren&dt=2026-01-20%2001%3A26%3A02\\n[2] https://buildfarm.postgresql.org/cgi-bin/show_stage_log.pl?nm=fairywren&dt=2026-01-24%2010%3A03%3A10&stg=misc-check\\n[3] https://www.postgresql.org/message-id/666ac55b-3400-fb2c-2cea-0281bf36a53c%40dunslane.net\\n\\nBest regards,\\nAlexander\\n\\n\\n","threadId":"19bf506ae1e4b94e","snippet":"Hello Robert, 19.01.2026 19:42, Robert Haas wrote: > On Fri, Jan 16, 2026 at 7:10 AM Oleg Tkachenko <oatkachenko@gmail.com> wrote: >> As you suggested, I've updated the test so that","historyId":"17387","internalDate":"1769342400000","receivedAtUtc":"2026-01-25T12:00:00.000Z","from":"Alexander Lakhin <exclusion@gmail.com>"}]	Alexander Lakhin reports that the recently committed test 011_incremental_backup_truncation_block (commit ecd275718) is failing on Windows buildfarm animal fairywren due to Windows path length limitations. The test failure occurs because the generated file path exceeds Windows' maximum path length when the PostgreSQL source tree is located in a deep directory structure. The target filename for WAL summary operations becomes too long, causing "could not rename file" errors. Lakhin demonstrates that the issue can be reproduced locally with long source paths and notes that the test passes on the master branch because "master" is 7 characters shorter than "REL_18_STABLE". The problem specifically affects the pg_combinebackup test suite and suggests a need for shorter test names or path handling adjustments for Windows compatibility.\n\nAlexander Lakhin报告最近提交的测试011_incremental_backup_truncation_block（提交ecd275718）在Windows构建农场动物fairywren上因Windows路径长度限制而失败。当PostgreSQL源代码树位于深层目录结构中时，生成的文件路径超过了Windows的最大路径长度，导致测试失败。WAL摘要操作的目标文件名变得过长，引起"无法重命名文件"错误。Lakhin演示该问题可以通过长源路径在本地重现，并注意到测试在主分支上通过，因为"master"比"REL_18_STABLE"短7个字符。该问题特别影响pg_combinebackup测试套件，建议需要更短的测试名称或Windows兼容性的路径处理调整。	2026-01-25 12:00:00+00	\N
15	19bf538c2efd504e	RFC: adding pytest as a supported test framework	["aleksander@tigerdata.com","andres@anarazel.de","byavuz81@gmail.com","daniel@yesql.se","jacob.champion@enterprisedb.com","peter@eisentraut.org","postgres@jeltef.nl","robertmhaas@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19bf538c2efd504e","messageId":"<DFXOP22NFAEV.3T0VD64AW2C1H@jeltef.nl>","subject":"Re: RFC: adding pytest as a supported test framework","body":"On Mon Jan 19, 2026 at 12:34 PM CET, Aleksander Alekseev wrote:\\n> Hi,\\n>\\n>> v10 attached to resolve merge conflicts.\\n>\\n> I tested and reviewed patches 0001 .. 0003 on Linux x64. All in all\\n> the code is in a pretty good shape except for several TODOs:\\n>\\n> ```\\n>                 # TODO: proper quoting\\n>                 v = v.replace(\\"\\\\\\\\\\", \\"\\\\\\\\\\\\\\\\\\")\\n>                 v = v.replace(\\"'\\", \\"\\\\\\\\'\\")\\n>                 v = \\"'{}'\\".format(v)\\n> ```\\n\\nThanks for the review. Attached is v11. I addressed this TODO by\\nimplementing the full quoting logic.\\n\\n> and:\\n>\\n> ```\\n>             # TODO: rather than using callback(), consider explicitly signaling\\n>             # the fn() implementation to stop early if we get an exception.\\n>             # Otherwise we'll hang until the end of the timeout.\\n>             self._thread = threading.Thread(target=_bg)\\n>             self.callback(self._join)\\n> ```\\n\\nI moved the whole local_server fixture and the test that it adds into\\npatch 0004, i.e. the first WIP patch by Jacob. I don't think this\\nfunctionality (nor the test it added) needs to be part of the initial\\nmerge.\\n\\n> ```\\n>         # XXX interacts poorly with testwrap's boilerplate diagnostics\\n>         # self.print(\\"TAP version 13\\")\\n> ```\\n\\nRemoved this and changed the comment on the TAP class to specify that\\nwe're implementing TAP 12 instead (which requires no version line). TAP 13 doesn't seem to contain features that we currently need.\\n\\n> I haven't looked at 0004 and 0005.\\n\\nMakes sense. I mostly kept those patches as part of the patchset to make\\nsure I did not break Jacob's usecase with all my changes to the test\\nsuite. They were more meant as: \\"I did not touch these patches, nor are\\nthey ready to merge, but it's possible to do stuff like this too\\".\\n","threadId":"19bf538c2efd504e","snippet":"On Mon Jan 19, 2026 at 12:34 PM CET, Aleksander Alekseev wrote: > Hi, > >> v10 attached to resolve merge conflicts. > > I tested and reviewed patches 0001 .. 0003 on Linux x64. All in","historyId":"17624","internalDate":"1769345675000","receivedAtUtc":"2026-01-25T12:54:35.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"}]	The PostgreSQL development team is discussing adding pytest as a supported test framework. In the latest update (v11), Jelte Fennema-Nio addressed reviewer feedback from Aleksander Alekseev, who tested patches 0001-0003 on Linux x64. Key improvements include implementing proper string quoting logic to replace a TODO placeholder, moving the local_server fixture and associated test to patch 0004 (marked as work-in-progress), and switching from TAP 13 to TAP 12 implementation by removing the version line requirement. The reviewer noted the code is in good shape overall. Patches 0004-0005 remain as proof-of-concept work by Jacob Champion, demonstrating extended functionality but not intended for the initial merge.\nPostgreSQL开发团队正在讨论将pytest添加为支持的测试框架。在最新的更新(v11)中，Jelte Fennema-Nio回应了Aleksander Alekseev的审查反馈，后者在Linux x64上测试了补丁0001-0003。主要改进包括实现适当的字符串引用逻辑以替换TODO占位符，将local_server固件和相关测试移至补丁0004(标记为正在进行的工作)，以及通过删除版本行要求从TAP 13切换到TAP 12实现。审查者指出代码整体状况良好。补丁0004-0005仍作为Jacob Champion的概念验证工作，展示扩展功能但不打算用于初始合并。	2026-01-25 12:54:35+00	\N
15	19bf53bc38e6ee10	Cleaning up PREPARE query strings?	["rjuju123@gmail.com","samimseih@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19bf53bc38e6ee10","messageId":"<aXYTOw_1GXq0oMaq@jrouhaud>","subject":"Re: Cleaning up PREPARE query strings?","body":"Hi,\\n\\nOn Mon, Jan 19, 2026 at 12:43:53AM -0600, Sami Imseih wrote:\\n>\\n> However, the error reporting does break with the patch. Notice with the patch\\n> the cursor for the error reporting shifts incorrectly. This is due to the fact\\n> rawstmt->stmt_location/length are no longer representative of the original\\n> qurey text.\\n>\\n> ## unpatched\\n> ```\\n> postgres=# SELECT 1    \\\\; PREPARE stmt AS SELECT nonexistent_column\\n> FROM users\\\\; SELECT 2;\\n>  ?column?\\n> ----------\\n>         1\\n> (1 row)\\n>\\n> ERROR:  relation \\"users\\" does not exist\\n> LINE 1: ... ; PREPARE stmt AS SELECT nonexistent_column FROM users; SEL...\\n>\\n>                                        ^\\n> ```\\n>\\n> ## patched\\n> ```\\n> postgres=# SELECT 1    \\\\; PREPARE stmt AS SELECT nonexistent_column\\n> FROM users\\\\; SELECT 2;\\n>  ?column?\\n> ----------\\n>         1\\n> (1 row)\\n>\\n> ERROR:  relation \\"users\\" does not exist\\n> LINE 1: ...LECT 1    ; PREPARE stmt AS SELECT nonexistent_column FROM u...\\n>\\n>                                    ^\\n> ```\\n\\nThis was already reported by Tom Lane on his first message, although his\\ncomplaint was about execution time error reporting while this is during\\nparse-analysis.  However, I think that the exact same approach can be used to\\nfixed both, either updating the position of every single element (which no one\\nwants) or teaching the executor (and evidently the planstate) about a new\\n\\"query offset\\" so that parser_errposition and executor_errposition report the\\ncorrect location.  I'm still waiting on whether the latter would be acceptable\\nor not before implementing it.  Note that I wasn't able to hit the execution\\ntime error so at least with parse-analysis time error I could at least have\\nsome regression tests, so thanks a lot!\\n\\nIn the meantime, the cfbot shows that a rebase is needed, so v3 attached.\\n","threadId":"19bf53bc38e6ee10","snippet":"Hi, On Mon, Jan 19, 2026 at 12:43:53AM -0600, Sami Imseih wrote: > > However, the error reporting does break with the patch. Notice with the patch > the cursor for the error reporting shifts","historyId":"17684","internalDate":"1769345851000","receivedAtUtc":"2026-01-25T12:57:31.000Z","from":"Julien Rouhaud <rjuju123@gmail.com>"}]	The discussion focuses on a patch that cleans up PREPARE query strings but introduces error reporting issues. Sami Imseih identified that the patch breaks cursor positioning in error messages because rawstmt->stmt_location/length no longer accurately represent the original query text. When errors occur, the cursor points to incorrect locations in the cleaned-up text rather than the original query. Julien Rouhaud acknowledges this issue was previously reported by Tom Lane for execution-time errors, and the same problem now affects parse-analysis errors. Rouhaud proposes two potential solutions: updating positions of every element (undesirable) or implementing a "query offset" mechanism for parser_errposition and executor_errposition to report correct locations. A rebase (v3) has been provided while awaiting feedback on the preferred approach. The core challenge is maintaining accurate error location reporting while cleaning up query strings.\n该讨论集中在一个清理PREPARE查询字符串的补丁上，但该补丁引入了错误报告问题。Sami Imseih发现补丁破坏了错误消息中的光标定位，因为rawstmt->stmt_location/length不再准确代表原始查询文本。当发生错误时，光标指向清理后文本中的错误位置而非原始查询。Julien Rouhaud承认这个问题之前被Tom Lane报告过用于执行时错误，现在同样的问题影响了解析分析错误。Rouhaud提出两个潜在解决方案：更新每个元素的位置（不理想）或为parser_errposition和executor_errposition实现"查询偏移"机制以报告正确位置。在等待首选方法的反馈时提供了重新基准版本（v3）。核心挑战是在清理查询字符串的同时保持准确的错误位置报告。	2026-01-25 12:57:31+00	\N
15	19bec801a96f066e	unnecessary executor overheads around seqscans	["amit.kapila16@gmail.com","amitlangote09@gmail.com","andres@anarazel.de","dgrowleyml@gmail.com","robertmhaas@gmail.com"]	[{"id":"19beeaa8f697ec9b","messageId":"<CA+HiwqEUDeBaydqYOq4uK6Rz9PBpOagfZqQevD71=JZrmgE3CQ@mail.gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> Hi,\\n>\\n> In [1] I was looking at the profile of a seqscan with a where clause that\\n> doesn't match any of the many rows.  I was a bit saddened by where we were\\n> spending time.\\n>\\n>\\n> - The fetching of variables, as well as the null check of scandesc, in\\n>   SeqNext() is repeated in every loop iteration of ExecScanExtended, despite\\n>   that obviously not being required after the first iteration\\n>\\n>   We could perhaps address this by moving the check to the callers of\\n>   ExecScanExtended() or by extending ExecScanExtended to have an explicit\\n>   beginscan callback that it calls after.\\n>\\n>   Or perhaps we could just make it so that the entire if (scandesc == NULL)\\n>   branch isn't needed?\\n\\nKind of like ExecProcNodeFirst(), what if we replace the variant\\nselection in ExecInitSeqScan() with just:\\n\\n    scanstate->ss.ps.ExecProcNode = ExecSeqScanFirst;\\n\\nExecSeqScanFirst() would:\\n\\n- do the table_beginscan() call that's currently inside the if\\n(scandesc == NULL) block in SeqNext()\\n\\n- select and install the appropriate ExecSeqScan variant based on\\nqual/projection/EPQ\\n\\n- call that variant to fetch and return the first tuple.\\n\\nThen we can just remove the if (scandesc == NULL) block from SeqNext() entirely.\\n\\n> - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n>   show up noticeably and in every loop iteration, despite afaict never being reachable\\n>\\n>   It's not obvious to me that this should\\n>   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n>      change in the middle of a scan? That would require a wrapper around\\n>      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n>   b) not just be an assertion?\\n\\nHaven't thought about this.\\n\\n> - The TupIsNull(slot) check in ExecScanExtended() is redundant with the return\\n>   value of table_scan_getnextslot(), but the compiler doesn't grok that.\\n>\\n>   We can use a pg_assume() in table_scan_getnextslot() to make the compiler\\n>   understand.\\n\\nSomething like this?\\n\\n    result = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\n    pg_assume(result == !TupIsNull(slot));\\n    return result;\\n\\nI assume this relies on table_scan_getnextslot() being inlined into\\nExecScanExtended()?\\n\\n> - We repeatedly store the table oid in the slot, table_scan_getnextslot() and\\n>   then again in ExecStoreBufferHeapTuple(). This shows up in the profile.\\n>\\n>   I wish we had made the slot a property of the scan, that way the scan could\\n>   assume the slot already has the oid set...\\n\\nI've noticed this when working on my batching patch. I set\\ntts_tableOid when creating the slots used in the batch themselves, so\\nthe per-tuple assignment isn't needed.\\n\\n> - heap_getnextslot() calls ExecStoreBufferHeapTuple() and then returns\\n>   true. That prevents the sibiling call optimization.\\n>\\n>   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n>   current return value. Alternatively we should consider just moving it to\\n>   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n>   only ones that should use it anyway.\\n\\nMakes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\nlike the simpler option, unless I misunderstood.\\n\\n-- \\nThanks, Amit Langote\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote: > > Hi, > > In [1] I was looking at the profile of a seqscan with a where clause that > doesn't","historyId":"15684","internalDate":"1769235682000","receivedAtUtc":"2026-01-24T06:21:22.000Z","from":"Amit Langote <amitlangote09@gmail.com>"},{"id":"19beeb7f3964deec","messageId":"<CAApHDvrL7Q41B=gv+3wc8+AJGKZugGegUbBo8FPQ+3+NGTPb+w@mail.gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","body":"On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote:\\n> On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n> >   Or perhaps we could just make it so that the entire if (scandesc == NULL)\\n> >   branch isn't needed?\\n>\\n> Kind of like ExecProcNodeFirst(), what if we replace the variant\\n> selection in ExecInitSeqScan() with just:\\n\\nI imagined moving it to ExecInitSeqScan() and just avoid doing it when\\nwe're doing EXPLAIN or we're doing a parallel scan. Something like the\\nattached, which is giving me a 4% speedup selecting from a million row\\ntable with a single int column running a seqscan query with a WHERE\\nclause matching no rows.\\n\\n> >   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n> >   current return value. Alternatively we should consider just moving it to\\n> >   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n> >   only ones that should use it anyway.\\n>\\n> Makes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\n> like the simpler option, unless I misunderstood.\\n\\nIt's probably too late to change it now, but wouldn't it have been\\nbetter if scan_getnextslot had been coded to return the TupleTableSlot\\nrather than bool? That way you could get the sibling call in\\nExecStoreBufferHeapTuple() and in SeqNext().\\n\\nI also noticed my compiler does not inline SeqNext(). Adding a\\npg_attribute_always_inline results in it getting inlined and gives a\\nsmall speedup.\\n\\nDavid\\n","threadId":"19bec801a96f066e","snippet":"On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote: > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote: > > Or perhaps we could just","historyId":"15684","internalDate":"1769236568000","receivedAtUtc":"2026-01-24T06:36:08.000Z","from":"David Rowley <dgrowleyml@gmail.com>"},{"id":"19bef6ce0f625bef","messageId":"<CAA4eK1LQ2ynGNg=3DHrKXBaU9G7WFh-+Mkef4COhUd0_a0KusA@mail.gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","body":"On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n>   show up noticeably and in every loop iteration, despite afaict never being reachable\\n>\\n>   It's not obvious to me that this should\\n>   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n>      change in the middle of a scan? That would require a wrapper around\\n>      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n>   b) not just be an assertion?\\n>\\n\\nIIRC, the main reason for having this precautionary check in the API\\nis to ensure that during logical decoding we never access the table AM\\nor\\nheap APIs directly when scanning catalog tables. This restriction\\nexists because we only check for concurrent aborts inside the\\nsystable_* APIs.\\n\\nIn practice, the core code should never hit this precautionary check,\\nso it could likely be converted into an assert. The reason it may not\\nhave been an assert originally is to give an ERROR if an output plugin\\nincorrectly invokes these APIs during decoding to access catalogs as\\nnoted in docs [1] (Note that access to user catalog tables or regular\\nsystem catalog tables in the output plugins has to be done via the\\nsystable_* scan APIs only. Access via the heap_* scan APIs will error\\nout.).\\n\\nI'll think some more about it.\\n\\n[1] - https://www.postgresql.org/docs/devel/logicaldecoding-output-plugin-writing.html\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote: > > - The checkXidAlive checks that have been added to table_scan_getnextslot() > show up noticeably and in","historyId":"15684","internalDate":"1769248424000","receivedAtUtc":"2026-01-24T09:53:44.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>"},{"id":"19bf0a18b129f97b","messageId":"<tlpltqm5jjwj7mp66dtebwwhppe4ri36vdypux2zoczrc2i3mp@dhv4v4nikyfg>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn 2026-01-24 15:23:44 +0530, Amit Kapila wrote:\\n> On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote:\\n> >\\n> > - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n> >   show up noticeably and in every loop iteration, despite afaict never being reachable\\n> >\\n> >   It's not obvious to me that this should\\n> >   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n> >      change in the middle of a scan? That would require a wrapper around\\n> >      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n> >   b) not just be an assertion?\\n> >\\n> \\n> IIRC, the main reason for having this precautionary check in the API\\n> is to ensure that during logical decoding we never access the table AM\\n> or\\n> heap APIs directly when scanning catalog tables. This restriction\\n> exists because we only check for concurrent aborts inside the\\n> systable_* APIs.\\n\\nI know why the check exists - but why does it have to be in\\ntable_scan_getnextslot(), which is executed very frequently, rather than\\ntable_beginscan*(), which is executed much less frequently.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-24 15:23:44 +0530, Amit Kapila wrote: > On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote: > > > > - The checkXidAlive checks that have been","historyId":"15684","internalDate":"1769268661000","receivedAtUtc":"2026-01-24T15:31:01.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf0a64f7cd0f93","messageId":"<yk5rybusljgxmsrm2xh2se77lbzq7cz6avxuwa4xjq7flh2dic@4wfcvplykhoj>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn 2026-01-24 19:36:08 +1300, David Rowley wrote:\\n> On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote:\\n> > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n> > >   Or perhaps we could just make it so that the entire if (scandesc == NULL)\\n> > >   branch isn't needed?\\n> >\\n> > Kind of like ExecProcNodeFirst(), what if we replace the variant\\n> > selection in ExecInitSeqScan() with just:\\n> \\n> I imagined moving it to ExecInitSeqScan() and just avoid doing it when\\n> we're doing EXPLAIN or we're doing a parallel scan. Something like the\\n> attached, which is giving me a 4% speedup selecting from a million row\\n> table with a single int column running a seqscan query with a WHERE\\n> clause matching no rows.\\n\\nYes, i think that'd be better. Nice!\\n\\n\\n> > >   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n> > >   current return value. Alternatively we should consider just moving it to\\n> > >   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n> > >   only ones that should use it anyway.\\n> >\\n> > Makes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\n> > like the simpler option, unless I misunderstood.\\n> \\n> It's probably too late to change it now, but wouldn't it have been\\n> better if scan_getnextslot had been coded to return the TupleTableSlot\\n> rather than bool? That way you could get the sibling call in\\n> ExecStoreBufferHeapTuple() and in SeqNext().\\n\\nTupIsNull() is actually more expensive than a bool return value, because it\\nneeds a memory fetch to complete... Except of course if we end up doing both.\\n\\nSeqNext() shouldn't need a sibling call because it ought to be inlined. But:\\n\\n> I also noticed my compiler does not inline SeqNext(). Adding a\\n> pg_attribute_always_inline results in it getting inlined and gives a\\n> small speedup.\\n\\nOh,m that's not good. I think we really had assumed that it would with the 18\\nchanges around this. It does here, but that's probably because I use -O3.\\n\\n\\n> diff --git a/src/backend/executor/nodeSeqscan.c b/src/backend/executor/nodeSeqscan.c\\n> index b8119face43..87420e60dc9 100644\\n> --- a/src/backend/executor/nodeSeqscan.c\\n> +++ b/src/backend/executor/nodeSeqscan.c\\n> @@ -63,17 +63,6 @@ SeqNext(SeqScanState *node)\\n>  \\tdirection = estate->es_direction;\\n>  \\tslot = node->ss.ss_ScanTupleSlot;\\n>  \\n> -\\tif (scandesc == NULL)\\n> -\\t{\\n> -\\t\\t/*\\n> -\\t\\t * We reach here if the scan is not parallel, or if we're serially\\n> -\\t\\t * executing a scan that was planned to be parallel.\\n> -\\t\\t */\\n> -\\t\\tscandesc = table_beginscan(node->ss.ss_currentRelation,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t   estate->es_snapshot,\\n> -\\t\\t\\t\\t\\t\\t\\t\\t   0, NULL);\\n> -\\t\\tnode->ss.ss_currentScanDesc = scandesc;\\n> -\\t}\\n\\nWhat about the \\"if we're serially executing a scan that was planned to be\\nparallel.\\" part? I frankly don't really know what precisely was referencing...\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-24 19:36:08 +1300, David Rowley wrote: > On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote: > > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <","historyId":"15684","internalDate":"1769268979000","receivedAtUtc":"2026-01-24T15:36:19.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf0b8b37b6875d","messageId":"<pxzibbqejp4vdjc3zqtjdzkfgxohn32lwnngyddnwe5ydbajkj@rw5jb54mrjvt>","subject":"Re: unnecessary executor overheads around seqscans","body":"Hi,\\n\\nOn 2026-01-24 15:21:22 +0900, Amit Langote wrote:\\n> On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\n> > - The TupIsNull(slot) check in ExecScanExtended() is redundant with the return\\n> >   value of table_scan_getnextslot(), but the compiler doesn't grok that.\\n> >\\n> >   We can use a pg_assume() in table_scan_getnextslot() to make the compiler\\n> >   understand.\\n> \\n> Something like this?\\n> \\n>     result = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\n>     pg_assume(result == !TupIsNull(slot));\\n>     return result;\\n\\nYep, that seems to clue at least gcc into understanding the situation. I only\\ntried two pg_assume(!found || !TupIsNull(slot)), but yours should probably\\nalso work.\\n\\n\\n> I assume this relies on table_scan_getnextslot() being inlined into\\n> ExecScanExtended()?\\n\\nYes. But I think that that's a good bet, given that it's an inline function\\nand only used once in nodeSeqscan.c.\\n\\n\\n> > - heap_getnextslot() calls ExecStoreBufferHeapTuple() and then returns\\n> >   true. That prevents the sibiling call optimization.\\n> >\\n> >   We should change ExecStoreBufferHeapTuple() to return true. Nobody uses the\\n> >   current return value. Alternatively we should consider just moving it to\\n> >   somewhere heapam.c/heapam_handler.c can see the implementations, they're the\\n> >   only ones that should use it anyway.\\n> \\n> Makes sense. Changing ExecStoreBufferHeapTuple() to return true seems\\n> like the simpler option, unless I misunderstood.\\n\\nYea. There's probably more to be gained by the other approach, but it's also\\nsomewhat painful due to some functionality being private to execTuples.c right\\nnow.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-24 15:21:22 +0900, Amit Langote wrote: > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote: > > - The TupIsNull(slot) check in ExecScanExtended() is","historyId":"15684","internalDate":"1769270181000","receivedAtUtc":"2026-01-24T15:56:21.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf550622c9b6dc","messageId":"<CAApHDvriDesugxt4oi4ePp-kvHpMojpYXk46AFhXFO-b6uH-8w@mail.gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","body":"On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote:\\n> On 2026-01-24 19:36:08 +1300, David Rowley wrote:\\n> > diff --git a/src/backend/executor/nodeSeqscan.c b/src/backend/executor/nodeSeqscan.c\\n> > index b8119face43..87420e60dc9 100644\\n> > --- a/src/backend/executor/nodeSeqscan.c\\n> > +++ b/src/backend/executor/nodeSeqscan.c\\n> > @@ -63,17 +63,6 @@ SeqNext(SeqScanState *node)\\n> >       direction = estate->es_direction;\\n> >       slot = node->ss.ss_ScanTupleSlot;\\n> >\\n> > -     if (scandesc == NULL)\\n> > -     {\\n> > -             /*\\n> > -              * We reach here if the scan is not parallel, or if we're serially\\n> > -              * executing a scan that was planned to be parallel.\\n> > -              */\\n> > -             scandesc = table_beginscan(node->ss.ss_currentRelation,\\n> > -                                                                estate->es_snapshot,\\n> > -                                                                0, NULL);\\n> > -             node->ss.ss_currentScanDesc = scandesc;\\n> > -     }\\n>\\n> What about the \\"if we're serially executing a scan that was planned to be\\n> parallel.\\" part? I frankly don't really know what precisely was referencing...\\n\\nI think that comment is wrong and that maybe it worked that way at\\nsome point when Parallel Seq Scan was in development, but it doesn't\\nseem to work that way today, and does not appear to have when Parallel\\nSeq Scan was committed. It's pretty easy to see that code isn't\\ntriggered just by setting max_parallel_workers to 0 and running query\\nwhich triggers a Parallel Seq Scan. I think that's what \\"serially\\nexecuting a scan that was planned to be parallel\\" means, right? The\\ndebug_parallel_query = on case uses a non-parallel Seq scan.\\n\\nOne user-visible side effect of initialising the TableScanDesc during\\nplan initialisation rather than on the first row is that the stats\\nwill record the Seq Scan even if it's never executed in the plan.\\nCurrently what we do there is somewhat inconsistent as with a Parallel\\nSeq Scan we'll count the seq scan stat if the Gather node is executed,\\nregardless of if the Seq Scan node gets executed: ExecGather ->\\nExecInitParallelPlan -> ExecParallelInitializeDSM ->\\nExecSeqScanInitializeDSM -> table_beginscan_parallel. But with a\\nnon-parallel Seq Scan, the scan will be tracked after fetching the\\nfirst row.\\n\\nAdded Robert to see if he remembers about the comment or can shed some\\nlight on it.\\n\\nDavid\\n\\n\\n","threadId":"19bec801a96f066e","snippet":"On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote: > On 2026-01-24 19:36:08 +1300, David Rowley wrote: > > diff --git a/src/backend/executor/nodeSeqscan.cb/src/","historyId":"17765","internalDate":"1769347220000","receivedAtUtc":"2026-01-25T13:20:20.000Z","from":"David Rowley <dgrowleyml@gmail.com>"}]	Andres Freund identified several performance overheads in PostgreSQL's sequential scan executor. The main issues include: repeated variable fetching and null checks in SeqNext() during every loop iteration, expensive checkXidAlive checks in table_scan_getnextslot() that are rarely reachable, redundant TupIsNull(slot) checks that compilers don't optimize, repeated table OID storage in slots, and suboptimal function call patterns preventing sibling call optimization in heap_getnextslot(). Amit Langote proposed using an ExecSeqScanFirst() approach similar to ExecProcNodeFirst() to eliminate the scandesc null check overhead. David Rowley implemented a patch moving the scan initialization to ExecInitSeqScan(), achieving a 4% performance improvement and suggesting pg_attribute_always_inline for SeqNext(). Amit Kapila explained that checkXidAlive exists for logical decoding safety but agreed it could potentially be moved to beginscan or converted to an assertion. Discussion continues on optimizing return values and addressing a comment about parallel scan execution that may be outdated.\nAndres Freund 识别出PostgreSQL顺序扫描执行器中的几个性能开销。主要问题包括：SeqNext()在每次循环迭代中重复获取变量和空值检查，table_scan_getnextslot()中昂贵但很少触发的checkXidAlive检查，编译器无法优化的冗余TupIsNull(slot)检查，在插槽中重复存储表OID，以及heap_getnextslot()中阻止同级调用优化的次优函数调用模式。Amit Langote提议使用类似ExecProcNodeFirst()的ExecSeqScanFirst()方法来消除scandesc空值检查开销。David Rowley实现了一个补丁，将扫描初始化移到ExecInitSeqScan()，获得4%性能提升，并建议对SeqNext()使用pg_attribute_always_inline。Amit Kapila解释checkXidAlive的存在是为了逻辑解码安全，但同意可能将其移到beginscan或转换为断言。关于优化返回值和处理一个可能过时的并行扫描执行注释的讨论仍在继续。	2026-01-25 13:20:20+00	\N
15	19bf595565890d2e	RFC: Allow EXPLAIN to Output Page Fault Information	["andres@anarazel.de","bruce@momjian.us","postgres@jeltef.nl","rjuju123@gmail.com","tgl@sss.pgh.pa.us","torikoshia@oss.nttdata.com"]	[{"id":"19bf595565890d2e","messageId":"<DFXQUHHKZN5U.2IAL4TGTP32IG@jeltef.nl>","subject":"Re: RFC: Allow EXPLAIN to Output Page Fault Information","body":"On Tue Oct 28, 2025 at 9:43 AM CET, torikoshia wrote:\\n> Rebased the patch again.\\n\\nI took another look at this patch because I think it would be really\\nuseful to have. Below is my review:\\n\\n1.\\n\\n\\t\\tExplainPropertyInteger(\\"Storage I/O Read\\", NULL,\\n\\t\\t\\t\\t\\t\\t\\t   usage->inblock, es);\\n\\t\\tExplainPropertyInteger(\\"Storage I/O Read\\", NULL,\\n\\t\\t\\t\\t\\t\\t\\t   usage->outblock, es);\\n\\n The second one is a copy paste error and should say Storage I/O Write\\n instead of read.\\n\\n2. I think the comment on pgStorageIOUsageParallel could be a bit\\n  clearer on how it works, because it's different than how we\\n  accumulate most others explain numbers. Something like:\\n\\n  Accumulates the I/O usage send by parallel workers to the main\\n  process. This does not contain the I/O from the main backend process\\n  itself because the kernel tracks that instead of us.\\n\\n3. I'm not sure if I like the \\"times\\" suffix either, because it doesn't\\n  mean that did that many reads. It probably read a bunch of blocks in\\n  one go. Maybe just put the number without a suffix.\\n\\n4. I think it would be good to use the string \\"Storage I/O\\" in the docs,\\n  so that it's easily findable for people that try to figure out how it\\n  works.\\n\\n5. I think this debug statement can be removed:\\n\\t\\tereport(DEBUG1,\\n\\t\\t\\t\\t(errmsg(\\"Parallel worker's storage I/O times: inblock:%ld outblock:%ld\\",\\n\\t\\t\\t\\t\\t\\tstorageiousage->inblock, storageiousage->outblock)));\\n\\n6. The prepare exacute planning calculation is missing a\\n  StorageIOUsageDiff call, so it will report the number since process\\n  start.\\n\\n7. I think it would be good for GetStorageIOUsage to stil initialize the\\n  struct values even if pgaio workers are enabled. Let's just set them\\n  to 0 in that case.\\n\\n8. Now that worker is the default io_method the new explain fields are never\\n  present in the explain tests anymore. So explain_1.out is\\n  unnecessary and can be removed. That obviously also means that\\n  there's no coverage for this feature at all in the tests currently,\\n  which is clearly a problem. So I think it would be good to add some\\n  actual tests for the feature using some other io_method in a Perl TAP\\n  test.\\n\\n9. The added docs about the kernel not being built with the correct\\n  options seems a bit too much detail. I'd say remove that sentence.\\n  And maybe shorten th\\n\\n10. nit: There's \\"Also, When...\\" in the docs, when should be lower case\\n   there.\\n\\n\\nAttached is your original patch plus a fixup patch that address:\\n1, 2, 3, 5, 6 and 7.\\n","threadId":"19bf595565890d2e","snippet":"On Tue Oct 28, 2025 at 9:43 AM CET, torikoshia wrote: > Rebased the patch again. I took another look at this patch because I think it would be really useful to have. Below is my review: 1.","historyId":"17820","internalDate":"1769351742000","receivedAtUtc":"2026-01-25T14:35:42.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"}]	Jelte Fennema-Nio provides a detailed review of torikoshia's rebased patch for adding page fault information to EXPLAIN output. The review identifies ten issues including: a copy-paste error labeling storage I/O write as read, unclear comments in pgStorageIOUsageParallel, questionable "times" suffix usage, missing StorageIOUsageDiff call in prepared statement planning, lack of test coverage since worker became default io_method, and documentation issues. Fennema-Nio finds the feature useful and provides a fixup patch addressing six of the identified problems. Key remaining issues include removing unnecessary test files, adding proper test coverage using alternative io_method in Perl TAP tests, and simplifying documentation by removing overly detailed kernel configuration information.\n\nJelte Fennema-Nio对torikoshia重新提交的为EXPLAIN输出添加页面错误信息的补丁进行了详细审查。审查发现了十个问题，包括：将存储I/O写操作错误标记为读操作的复制粘贴错误、pgStorageIOUsageParallel中注释不清晰、"times"后缀使用存疑、预处理语句规划中缺少StorageIOUsageDiff调用、由于worker成为默认io_method导致测试覆盖不足，以及文档问题。Fennema-Nio认为该功能很有用，并提供了修复补丁解决其中六个问题。剩余关键问题包括删除不必要的测试文件、使用替代io_method在Perl TAP测试中添加适当的测试覆盖，以及通过删除过于详细的内核配置信息来简化文档。	2026-01-25 14:35:42+00	\N
15	19be4da9486dc0d1	Adding REPACK [concurrently]	["ah@cybertec.at","alvherre@alvh.no-ip.org","mihailnikalayeu@gmail.com","rob@xzilla.net"]	[{"id":"19bf5fef08f80ad1","messageId":"<CADzfLwUEH5+LjCN+6kRfSsXwuou8rKXyVV42Wi-O_TG0360Kug@mail.gmail.com>","subject":"Re: Adding REPACK [concurrently]","body":"Hello, Antonin!\\n\\nPART 1:\\n\\nI started rebasing the MVCC-safe version on top of the multi-snapshot\\nversion and realized it becomes complex.\\nBut, what's really bad about MVCC-unsafety is the ability to access\\n*incorrect* data and break some logic (or even constraints).\\n\\nIf we may *prevent* such data access with some kind of error (which is\\ngoing to be very infrequent) - I don't see any sense to achieve true\\nMVCC-safety.\\n\\nI remembered a way it works with indcheckxmin for indexes. And made\\nsomething similar for pg_class: it records the rewriting transaction XID\\nand causes the executor to raise an error if a transaction with an older\\nsnapshot attempts to access the rewritten relation.\\n\\nFor the normal case - check is never executed, no performance regression\\nhere. Also, the flag is automatically cleared by VACUUM once the\\ntransaction ID is frozen.\\n\\nIt also \\"fixes\\" ALTER TABLE, not only REPACK concurrently.\\n\\nAttached patch contains more details (some in the commit message).\\n\\nPART 2:\\n\\nI have continued working with stress tests. This time I added your WIP\\npatch to fix the LR\\\\CLOG race.\\n\\nI made the following configs:\\n1) just REPACK CONCURRENTLY - ok\\n2) + relcheckxmin (see PART1) - ok\\n3) + worker - ok\\n4) + multiple snapshots - broken in multiple ways.\\n\\nYou may see example of run here -\\nhttps://cirrus-ci.com/build/6359048020295680\\n\\nSome examples:\\n\\n1)  'pgbench: error: client 11 script 0 aborted in command 20 query 0:\\nERROR:  could not read blocks 0..0 in file \\"base/5/16414\\": read only 0 of\\n8192 bytes\\n2) at /home/postgres/postgres/contrib/amcheck/t/008_repack_concurrently.pl\\nline 51.\\n[15:36:37.204] #                   'pgbench: error: client 5 script 0\\naborted in command 28 query 0: ERROR:  division by zero\\n3)    'pgbench: error: client 12 script 0 aborted in command 6 query 0:\\nERROR:  cache lookup failed for relation 17400\\n","threadId":"19be4da9486dc0d1","snippet":"Hello, Antonin! PART 1: I started rebasing the MVCC-safe version on top of the multi-snapshot version and realized it becomes complex. But, what's really bad about MVCC-unsafety is the ability to","historyId":"17892","internalDate":"1769358660000","receivedAtUtc":"2026-01-25T16:31:00.000Z","from":"Mihail Nikalayeu <mihailnikalayeu@gmail.com>"}]	Mihail reports on work rebasing MVCC-safe REPACK CONCURRENTLY on top of multi-snapshot version, finding it complex. He proposes an alternative approach using a mechanism similar to indcheckxmin for indexes, recording rewriting transaction XID in pg_class to prevent access by older snapshots with error instead of achieving true MVCC-safety. This approach avoids performance regression in normal cases and automatically clears via VACUUM when transaction ID is frozen. The solution also fixes ALTER TABLE issues beyond REPACK. Stress testing shows success with basic REPACK CONCURRENTLY and relcheckxmin additions, but multiple snapshots configuration fails with various errors including file read failures, division by zero, and cache lookup failures for relations.\n\nMihail报告了在多快照版本基础上重新构建MVCC安全REPACK CONCURRENTLY的工作，发现其复杂性。他提出了一种替代方法，使用类似于索引indcheckxmin的机制，在pg_class中记录重写事务XID，通过错误阻止旧快照访问，而非实现真正的MVCC安全。该方法在正常情况下避免性能回归，并在事务ID被冻结时通过VACUUM自动清除。该解决方案还修复了REPACK之外的ALTER TABLE问题。压力测试显示基本REPACK CONCURRENTLY和relcheckxmin添加成功，但多快照配置失败，出现各种错误，包括文件读取失败、除零错误和关系缓存查找失败。	2026-01-25 16:31:00+00	\N
15	19bf3e96d60a9129	[PATCH] Replace COUNT(NULL) with '0'::bigint	["dgrowleyml@gmail.com","tgl@sss.pgh.pa.us","zhjwpku@gmail.com"]	[{"id":"19bf3e96d60a9129","messageId":"<CAEG8a3K1OZJm2k2W9ijasqQr3qkM2Ggy2LfB0ZP+cwLhEYzbeQ@mail.gmail.com>","subject":"[PATCH] Replace COUNT(NULL) with '0'::bigint","body":"Hi,\\n\\nIn [1], David Rowley noted that COUNT(NULL) can be replaced\\nwith '0'::bigint. The change should be straightforward, and I came\\nup with the attached patch to implement it.\\n\\n[1] https://www.postgresql.org/message-id/CAApHDvrde9DUpQ3DhPd3ia9tchVmhZqewfzxSYWmYFWVj%3DLPpg%40mail.gmail.com\\n\\n-- \\nRegards\\nJunwang Zhao\\n","threadId":"19bf3e96d60a9129","snippet":"Hi, In [1], David Rowley noted that COUNT(NULL) can be replaced with '0'::bigint. The change should be straightforward, and I came up with the attached patch to implement it. [1] https://www.","historyId":"16886","internalDate":"1769323695000","receivedAtUtc":"2026-01-25T06:48:15.000Z","from":"Junwang Zhao <zhjwpku@gmail.com>"},{"id":"19bf512fb70b1401","messageId":"<CAApHDvoaX-GGpt=KCWhGkgT=e_cYuVyLciZsGYZs3Rk+kv0S5w@mail.gmail.com>","subject":"Re: [PATCH] Replace COUNT(NULL) with '0'::bigint","body":"On Sun, 25 Jan 2026 at 19:48, Junwang Zhao <zhjwpku@gmail.com> wrote:\\n> In [1], David Rowley noted that COUNT(NULL) can be replaced\\n> with '0'::bigint. The change should be straightforward, and I came\\n> up with the attached patch to implement it.\\n>\\n> [1] https://www.postgresql.org/message-id/CAApHDvrde9DUpQ3DhPd3ia9tchVmhZqewfzxSYWmYFWVj%3DLPpg%40mail.gmail.com\\n\\nComing up with the code to do this wasn't the problem. I already\\nposted it in the patch in [2]. The reason I didn't commit that part is\\nsimply that I don't think anyone would ever write COUNT(NULL) in a\\nquery. My opinion has not changed since I wrote [3]. The main reason I\\neven mentioned COUNT(NULL) is because I wanted the API to support\\nreplacing the Aggref with some other Node type, and that was the only\\nexample I could think of to test to ensure it worked. I had hoped that\\nsomeone might come up with some ideas to do that which might be more\\napplicable in the real world, rather than regurgitate ideas I'd\\nthought of but didn't think were useful.\\n\\nDo you really feel like this is useful to anyone? or did you just\\nwrite the patch because you can?\\n\\nCorey did mention in [4] that he is in favour, so maybe it's just me\\nwho thinks it's useless... Perhaps someone else wants to commit it.\\n\\nDavid\\n\\n[2] https://postgr.es/m/CAApHDvppFVDdjpYrs%3DpwgCnp-jv-tneQyfu8rWM8ymHcuJOJYw%40mail.gmail.com\\n[3] https://postgr.es/m/CAApHDvppFVDdjpYrs%3DpwgCnp-jv-tneQyfu8rWM8ymHcuJOJYw%40mail.gmail.com\\n[4] https://postgr.es/m/CADkLM%3De2Rb%2Bs3TV3LgYx8O1z2Cs%2BX2FSoafd6%3DUzpPD7hiocfw%40mail.gmail.com\\n\\n\\n","threadId":"19bf3e96d60a9129","snippet":"On Sun, 25 Jan 2026 at 19:48, Junwang Zhao <zhjwpku@gmail.com> wrote: > In [1], David Rowley noted that COUNT(NULL) can be replaced > with '0'::bigint. The change should be","historyId":"17465","internalDate":"1769343197000","receivedAtUtc":"2026-01-25T12:13:17.000Z","from":"David Rowley <dgrowleyml@gmail.com>"},{"id":"19bf52f9bee877e1","messageId":"<CAEG8a3+5T75R6MrsA7Wkt0Nv5045uo44pgZ6krZpRKkYBq0epw@mail.gmail.com>","subject":"Re: [PATCH] Replace COUNT(NULL) with '0'::bigint","body":"On Sun, Jan 25, 2026 at 8:13 PM David Rowley <dgrowleyml@gmail.com> wrote:\\n>\\n> On Sun, 25 Jan 2026 at 19:48, Junwang Zhao <zhjwpku@gmail.com> wrote:\\n> > In [1], David Rowley noted that COUNT(NULL) can be replaced\\n> > with '0'::bigint. The change should be straightforward, and I came\\n> > up with the attached patch to implement it.\\n> >\\n> > [1] https://www.postgresql.org/message-id/CAApHDvrde9DUpQ3DhPd3ia9tchVmhZqewfzxSYWmYFWVj%3DLPpg%40mail.gmail.com\\n>\\n> Coming up with the code to do this wasn't the problem. I already\\n> posted it in the patch in [2].\\n\\nAh, I didn't check the v2 details carefully.\\n\\n> The reason I didn't commit that part is\\n> simply that I don't think anyone would ever write COUNT(NULL) in a\\n> query. My opinion has not changed since I wrote [3]. The main reason I\\n> even mentioned COUNT(NULL) is because I wanted the API to support\\n> replacing the Aggref with some other Node type, and that was the only\\n> example I could think of to test to ensure it worked. I had hoped that\\n> someone might come up with some ideas to do that which might be more\\n> applicable in the real world, rather than regurgitate ideas I'd\\n> thought of but didn't think were useful.\\n>\\n> Do you really feel like this is useful to anyone? or did you just\\n> write the patch because you can?\\n\\nI did this because of Corey's comment \\"There is nothing faster than nothing\\"\\nand your note \\"Which is leaving the door open for more aggressive\\noptimisations that someone might want to do, e.g. the mentioned\\nCOUNT(NULL) replaced with '0'::bigint.\\"\\n\\nI wasn't following that context and only saw this thread recently,\\nso I may have misunderstood the point of the comment.\\n\\nI agree that people are more likely to write COUNT(1) than\\nCOUNT(NULL), so I'm fine with leaving COUNT(NULL) as is.\\n\\n>\\n> Corey did mention in [4] that he is in favour, so maybe it's just me\\n> who thinks it's useless... Perhaps someone else wants to commit it.\\n>\\n> David\\n>\\n> [2] https://postgr.es/m/CAApHDvppFVDdjpYrs%3DpwgCnp-jv-tneQyfu8rWM8ymHcuJOJYw%40mail.gmail.com\\n> [3] https://postgr.es/m/CAApHDvppFVDdjpYrs%3DpwgCnp-jv-tneQyfu8rWM8ymHcuJOJYw%40mail.gmail.com\\n> [4] https://postgr.es/m/CADkLM%3De2Rb%2Bs3TV3LgYx8O1z2Cs%2BX2FSoafd6%3DUzpPD7hiocfw%40mail.gmail.com\\n\\n\\n\\n-- \\nRegards\\nJunwang Zhao\\n\\n\\n","threadId":"19bf3e96d60a9129","snippet":"On Sun, Jan 25, 2026 at 8:13 PM David Rowley <dgrowleyml@gmail.com> wrote: > > On Sun, 25 Jan 2026 at 19:48, Junwang Zhao <zhjwpku@gmail.com> wrote: > > In [1], David Rowley","historyId":"17572","internalDate":"1769345073000","receivedAtUtc":"2026-01-25T12:44:33.000Z","from":"Junwang Zhao <zhjwpku@gmail.com>"},{"id":"19bf60b2a79b83b4","messageId":"<3600427.1769359466@sss.pgh.pa.us>","subject":"Re: [PATCH] Replace COUNT(NULL) with '0'::bigint","body":"David Rowley <dgrowleyml@gmail.com> writes:\\n> On Sun, 25 Jan 2026 at 19:48, Junwang Zhao <zhjwpku@gmail.com> wrote:\\n>> In [1], David Rowley noted that COUNT(NULL) can be replaced\\n>> with '0'::bigint. The change should be straightforward, and I came\\n>> up with the attached patch to implement it.\\n\\n> Coming up with the code to do this wasn't the problem. I already\\n> posted it in the patch in [2]. The reason I didn't commit that part is\\n> simply that I don't think anyone would ever write COUNT(NULL) in a\\n> query.\\n\\nYeah, I agree that this should be so rare as to not be worth expending\\nplanner cycles to check for, not to mention future code maintenance\\ncosts.  The other special cases we optimize COUNT() for are common\\nreal-world usages, but not this.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf3e96d60a9129","snippet":"David Rowley <dgrowleyml@gmail.com> writes: > On Sun, 25 Jan 2026 at 19:48, Junwang Zhao <zhjwpku@gmail.com> wrote: >> In [1], David Rowley noted that COUNT(NULL) can be replaced","historyId":"17941","internalDate":"1769359466000","receivedAtUtc":"2026-01-25T16:44:26.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	Junwang Zhao proposed a patch to replace COUNT(NULL) with '0'::bigint based on David Rowley's earlier suggestion. David responded that while he had already posted similar code, he didn't commit it because COUNT(NULL) is extremely unlikely to be used in real-world queries. He questioned whether this optimization is useful to anyone or just an academic exercise. Junwang acknowledged he may have misunderstood the context and agreed that COUNT(1) is more common than COUNT(NULL). Tom Lane concurred that such rare usage doesn't justify the planner overhead and maintenance costs, noting that other COUNT() optimizations target common real-world patterns. The consensus appears to be against implementing this optimization.\n\n赵俊旺基于David Rowley早期建议，提议将COUNT(NULL)替换为'0'::bigint的补丁。David回应称虽然他已发布过类似代码，但未提交是因为COUNT(NULL)在实际查询中极不可能使用。他质疑这种优化是否对任何人有用，还是仅仅是学术练习。赵俊旺承认可能误解了上下文，并同意COUNT(1)比COUNT(NULL)更常见。Tom Lane赞同这种罕见用法不值得计划器开销和维护成本，指出其他COUNT()优化针对的是常见的实际使用模式。共识似乎反对实施此优化。	2026-01-25 16:44:26+00	\N
15	19bebeb32c2a6da1	alignas (C11)	["peter@eisentraut.org","tgl@sss.pgh.pa.us"]	[{"id":"19bf4b884bfe56c3","messageId":"<862bad1f-b94e-403d-b730-8af435f3cf58@eisentraut.org>","subject":"Re: alignas (C11)","body":"On 23.01.26 23:18, Tom Lane wrote:\\n> Peter Eisentraut <peter@eisentraut.org> writes:\\n>> On 23.01.26 18:33, Tom Lane wrote:\\n>>> Not sure what to do about that, but I do read it as indicating that we\\n>>> cannot put any faith in the compiler to honor such large alignment\\n>>> demands.\\n> >> I think we could work around it like this:\\n> >>       #if defined(__cplusplus) && defined(__GNUC__) && __GNUC__ <= 6\\n>>       #define alignas(a) __attribute__((aligned(a)))\\n>>       #endif\\n> > Hmm, yeah, their bug #70066 shows clearly that the __attribute__\\n> spelling should work.  But I think we'd better make the cutoff be\\n> version 9 not version 6, because that same bug is quite clear\\n> about when they fixed it.  The lack of complaints from the buildfarm\\n> may just indicate a lack of animals running the intermediate versions.\\n\\nOk, done that way.\\n\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"On 23.01.26 23:18, Tom Lane wrote: > Peter Eisentraut <peter@eisentraut.org> writes: >> On 23.01.26 18:33, Tom Lane wrote: >>> Not sure what to do about that, but I do read it","historyId":"17238","internalDate":"1769337278000","receivedAtUtc":"2026-01-25T10:34:38.000Z","from":"Peter Eisentraut <peter@eisentraut.org>"},{"id":"19bf62629cdd2692","messageId":"<3635041.1769361243@sss.pgh.pa.us>","subject":"Re: alignas (C11)","body":"Peter Eisentraut <peter@eisentraut.org> writes:\\n> On 23.01.26 23:18, Tom Lane wrote:\\n>> Hmm, yeah, their bug #70066 shows clearly that the __attribute__\\n>> spelling should work.  But I think we'd better make the cutoff be\\n>> version 9 not version 6, because that same bug is quite clear\\n>> about when they fixed it.  The lack of complaints from the buildfarm\\n>> may just indicate a lack of animals running the intermediate versions.\\n\\n> Ok, done that way.\\n\\nSigh ... that did not work.  Various BF animals are now blowing up in\\nsrc/backend/jit/llvm because this macro definition breaks some usages\\nof alignas() in LLVM header files.\\n\\nMaybe we could #define alignas this way for the two exposed usages\\nand then #undef afterwards?\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bebeb32c2a6da1","snippet":"Peter Eisentraut <peter@eisentraut.org> writes: > On 23.01.26 23:18, Tom Lane wrote: >> Hmm, yeah, their bug #70066 shows clearly that the __attribute__ >> spelling should work.","historyId":"18148","internalDate":"1769361243000","receivedAtUtc":"2026-01-25T17:14:03.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"}]	The discussion centers on fixing a compiler compatibility issue with the C11 alignas keyword in PostgreSQL. Peter Eisentraut and Tom Lane are addressing a problem where older GCC versions (particularly version 6) don't properly support alignas with large alignment values. They initially agreed on a workaround using __attribute__((aligned(a))) as a macro replacement, with Tom suggesting to extend the version cutoff to GCC 9 based on bug report #70066 evidence. However, after Peter implemented this solution, Tom reports that the fix caused new problems - various buildfarm animals are failing in the LLVM JIT backend because the macro definition conflicts with alignas() usage in LLVM header files. Tom now proposes a more targeted approach: defining the alignas macro only for the specific problematic usages and then immediately undefining it afterward.\n讨论的重点是修复PostgreSQL中C11 alignas关键字的编译器兼容性问题。Peter Eisentraut和Tom Lane正在解决旧版GCC（特别是第6版）不能正确支持大对齐值alignas的问题。他们最初同意使用__attribute__((aligned(a)))作为宏替换的解决方案，Tom根据错误报告#70066的证据建议将版本截止点扩展到GCC 9。然而，在Peter实施此解决方案后，Tom报告该修复引起了新问题——各种构建农场动物在LLVM JIT后端失败，因为宏定义与LLVM头文件中的alignas()使用冲突。Tom现在提出了一个更有针对性的方法：仅为特定的问题用法定义alignas宏，然后立即取消定义。	2026-01-25 17:14:03+00	\N
15	19be5000123f9d5e	Optional skipping of unchanged relations during ANALYZE?	["dgrowleyml@gmail.com","ilya.evdokimov@tantorlabs.com","myon@debian.org","rob@xzilla.net","robertmhaas@gmail.com","samimseih@gmail.com","vasukianand0119@gmail.com"]	[{"id":"19bf1f07cc94d47a","messageId":"<CAJSLCQ3Z9cM2eZNa4aOnLmLyiZmSDrZH2xQm1RfT4PdKWo0ZLg@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"On Fri, Jan 23, 2026 at 9:31 PM Sami Imseih <samimseih@gmail.com> wrote:\\n>\\n> Thanks for the detailed summary!\\n>\\n> It is important to point out that this feature is trying to do 2 distinct\\n> things in 1 command. run analyze under when either one of these conditions\\n> is true:\\n>\\n> 1/ Table has not been analyzed yet.\\n> 2/ Table has been modified.\\n>\\n\\nMaybe this is all an aside, but I don't think that was the vision for\\nwhat the OP was trying to do with his patch, in that sense he was\\napproaching it from a different angle, and I've been reading this\\nthread trying to decide if people are just talking past each other.\\nBut after thinking about it some more, I think the above might be the\\nmore useful mental model for the discussion.\\n\\n> > Thanks a lot for the detailed feedback — this has been very helpful.Answering to all mails in one.\\n> >\\n> > A few clarifications on intent and scope, and how this relates to the points raised:\\n> >\\n> > Autovacuum overlap\\n> > I agree there is some conceptual overlap with autovacuum's analyze decision logic.\\n> > The intent here is not to replace or duplicate autovacuum heuristics, but to reduce\\n>\\n> Yes, I agree with this.\\n>\\n> > I agree that n_mod_since_analyze == 0 is a very simple condition\\n> > and not "smart" in the general sense. That is intentional for now.\\n> > This option is not trying to answer when statistics should be refreshed optimally,\\n> > but only to skip relations that are known to be unchanged since the last analyze.\\n> > If even a single tuple is modified, SMART ANALYZE will still re-run, preserving\\n> > conservative behavior.\\n>\\n> Yes, this is my concern. Why would I want to analyze if 1 row or a negligible\\n> amount of rows are modified? I understand that this feature is trying to\\n> keep the decision making very simple, but I think it's too simple to actually\\n> be helpful in addressing the wasted effort of an ANALYZE command.\\n>\\n> > Tables never analyzed\\n> > As Christoph and Ilia pointed out earlier, skipping tables that were never analyzed would be incorrect.\\n> > The current logic explicitly avoids that by requiring last_analyze or last_autoanalyze to be present\\n> > before skipping. Tables without prior statistics are always analyzed.\\n>\\n> I agree with this, but I think it's more than just tables that have\\n> not been analyzed.\\n> What if a new column is added after the last (auto)analyze. Would we not want to\\n> trigger an analyze in that case?\\n>\\n\\nWell, I don't know that we are \\"triggering\\" anything, but this is\\ndefinitely a case where we have \\"missing stats\\".\\n\\n> > Relation to vacuumdb --missing-stats-only\\n> > I agree this is related but slightly different in intent. --missing-stats-only\\n> > answers \\"does this table have any statistics at all?\\", while SMART ANALYZE\\n> > answers \\"has this table changed since the last statistics collection?\\". Both seem\\n> > useful, but they target different use cases. I see SMART ANALYZE primarily\\n> > as a performance optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n>\\n> SMART ANALYZE is trying to answer 2 questions \\"which table does not\\n> have any statistics at all\\"\\n> and \\"has this table changed since the last statistics collection?\\", right?\\n>\\n> So, maybe they need to be 2 separate options.\\n>\\n> > Although as sami said this SMART is not smart enough as it should be ,\\n> > I will change name accordingly in the further patches\\n>\\n> Yup, I am not too fond of SMART in the name. Also, then name itself\\n> is vague. SKIP_LOCKED and BUFFER_USAGE_LIMIT on the other\\n> hand tell you exactly what they[re used for.\\n>\\n\\nSo, tossing out a new proposal here, which is to offer ANALYZE with 2\\nnew options... MISSING_STATS and MODIFIED_STATS.\\n\\nWhen MISSING_STATS is passed, we attempt to analyze only tables that\\nhave missing stats, essentially implementing a version of\\n--missing-stats-only but for the ANALYZE command. In successive runs,\\nthis should reduce towards a no-op, although we need to decide what to\\ndo about system tables, which, iirc --missing-stats-only always\\nassumes to be true, but this version probably doesn't want to assume\\nthat.\\n\\nWhen MODIFIED_STATS is passed, we would instead only analyze tables\\nwhere some threshold of rows has been modified. I feel like the most\\nobvious choice for this calculation would be based on a formula like\\n\\"analyze threshold = analyze base threshold + analyze scale factor *\\nnumber of tuples\\". Astute observers will note that this is the same\\nthreshold used by autoanalyze, which means if you had the same\\ndefaults you are just doing the work manually that autoanalyze would\\neventually get around to doing (which seems potentially useful on its\\nown). But also if these were based on gucs, the OP could modify those\\ngucs to achieve their desired behavior, ie.\\nset analyze_base_threshold=1; set analyze_scale_factor=0; analyze\\n(modified_stats);  // this should analyze anything with 1 modified row\\nGranted, I don't like that it is both more wordy than the original\\nidea, and that we would need to add new gucs, but this would be pretty\\nflexible.\\n\\n\\nRobert Treat\\nhttps://xzilla.net\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"On Fri, Jan 23, 2026 at 9:31 PM Sami Imseih <samimseih@gmail.com> wrote: > > Thanks for the detailed summary! > > It is important to point out that this feature is trying to do 2","historyId":"15957","internalDate":"1769290598000","receivedAtUtc":"2026-01-24T21:36:38.000Z","from":"Robert Treat <rob@xzilla.net>"},{"id":"19bf6124df4abf8c","messageId":"<CAA5RZ0uBRmE5k6Q=8PkrttDVwgDh9r=fN0TTHsU48sb_E7KfMw@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":"> > > Relation to vacuumdb --missing-stats-only\\n> > > I agree this is related but slightly different in intent. --missing-stats-only\\n> > > answers \\"does this table have any statistics at all?\\", while SMART ANALYZE\\n> > > answers \\"has this table changed since the last statistics collection?\\". Both seem\\n> > > useful, but they target different use cases. I see SMART ANALYZE primarily\\n> > > as a performance optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n> >\\n> > SMART ANALYZE is trying to answer 2 questions \\"which table does not\\n> > have any statistics at all\\"\\n> > and \\"has this table changed since the last statistics collection?\\", right?\\n> >\\n> > So, maybe they need to be 2 separate options.\\n> >\\n> > > Although as sami said this SMART is not smart enough as it should be ,\\n> > > I will change name accordingly in the further patches\\n> >\\n> > Yup, I am not too fond of SMART in the name. Also, then name itself\\n> > is vague. SKIP_LOCKED and BUFFER_USAGE_LIMIT on the other\\n> > hand tell you exactly what they[re used for.\\n> >\\n>\\n> So, tossing out a new proposal here, which is to offer ANALYZE with 2\\n> new options... MISSING_STATS and MODIFIED_STATS.\\n\\nYes, that is what I am thinking as well.\\n\\n> When MISSING_STATS is passed, we attempt to analyze only tables that\\n> have missing stats, essentially implementing a version of\\n> --missing-stats-only but for the ANALYZE command. In successive runs,\\n> this should reduce towards a no-op, although we need to decide what to\\n> do about system tables, which, iirc --missing-stats-only always\\n> assumes to be true, but this version probably doesn't want to assume\\n> that.\\n\\nFrom a quick test, I don't see system tables being treated different\\n\\n```\\npostgres=# select max(last_analyze), max(last_autoanalyze) from\\npg_stat_all_tables where relname = 'pg_class';\\n max | max\\n-----+-----\\n     |\\n(1 row)\\n\\npostgres=# delete from pg_statistic;\\nDELETE 417\\npostgres=# \\\\! vacuumdb --analyze-only --missing-stats-only postgres\\nvacuumdb: vacuuming database \\"postgres\\"\\npostgres=# select max(last_analyze), max(last_autoanalyze) from\\npg_stat_all_tables where relname = 'pg_class';\\n              max              | max\\n-------------------------------+-----\\n 2026-01-25 16:31:42.839329+00 |\\n(1 row)\\n\\npostgres=# \\\\! vacuumdb --analyze-only --missing-stats-only postgres\\nvacuumdb: vacuuming database \\"postgres\\"\\npostgres=#\\npostgres=# select max(last_analyze), max(last_autoanalyze) from\\npg_stat_all_tables where relname = 'pg_class';\\n              max              | max\\n-------------------------------+-----\\n 2026-01-25 16:31:42.839329+00 |\\n(1 row)\\n```\\n\\nTables that remain empty, will always be analyzed since they will\\nalways have \\"missing stats\\".\\nFor example pg_sequence, if a sequence is never created. The same\\napplies for normal\\nuser tables.\\n\\n> When MODIFIED_STATS is passed, we would instead only analyze tables\\n> where some threshold of rows has been modified. I feel like the most\\n> obvious choice for this calculation would be based on a formula like\\n> \\"analyze threshold = analyze base threshold + analyze scale factor *\\n> number of tuples\\". Astute observers will note that this is the same\\n> threshold used by autoanalyze, which means if you had the same\\n> defaults you are just doing the work manually that autoanalyze would\\n> eventually get around to doing (which seems potentially useful on its\\n> own).\\n\\nYes, we would want to use the same calculation as autoanalyze.\\n\\n> But also if these were based on gucs, the OP could modify those\\n> gucs to achieve their desired behavior, ie.\\n> set analyze_base_threshold=1; set analyze_scale_factor=0; analyze\\n> (modified_stats);  // this should analyze anything with 1 modified row\\n> Granted, I don't like that it is both more wordy than the original\\n> idea, and that we would need to add new gucs, but this would be pretty\\n> flexible.\\n\\nWe can either allow the threshold and scale_factor be an argument to\\nthe option; but I do really think the GUC approach is much better.\\n\\nNot in scope, but I can even see vacuum_threshold and vacuum_scale_factor\\n to allow us to control VACUUM the same way.\\n\\nOverall, this becomes very handy for scripting of manual ANALYZE\\nand VACUUM.\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":"> > > Relation to vacuumdb --missing-stats-only > > > I agree this is related but slightly different in intent. --missing-stats-only > > > answers \\"does this table have any","historyId":"18025","internalDate":"1769359929000","receivedAtUtc":"2026-01-25T16:52:09.000Z","from":"Sami Imseih <samimseih@gmail.com>"},{"id":"19bf62f1c42f74ed","messageId":"<CAA5RZ0t=fGScwGL9=_HJzXf3808-U4zqne+qAob6R2PYcj-9YA@mail.gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","body":">> I agree with this, but I think it's more than just tables that have\\n>> not been analyzed.\\n>> What if a new column is added after the last (auto)analyze. Would we not want to\\n>> trigger an analyze in that case?\\n>>\\n\\n> Well, I don't know that we are \\"triggering\\" anything, but this is\\n> definitely a case where we have \\"missing stats\\".\\n\\n> When MISSING_STATS is passed, we attempt to analyze only tables that\\n> have missing stats, essentially implementing a version of\\n> --missing-stats-only\\n\\nI also want to do add that the benefit of implementing a --missing-stats\\nfo ANALYZE is that the timestamps in pg_stat_all_tables are cleared on\\ncrash recovery, but pg_statistic is obviously persistent. So it is\\nbetter to look directly there as --missing-stats-only does for vacuumdb.\\n\\nunfortunately, this is not the case for n_mod_since_analyze, because that\\ndoes not survive. There is discussion about improving this situation\\nhowever [0].\\n\\n\\n[0] https://www.postgresql.org/message-id/20240607033806.6gwgolihss72cj6r@awork3.anarazel.de\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n","threadId":"19be5000123f9d5e","snippet":">> I agree with this, but I think it's more than just tables that have >> not been analyzed. >> What if a new column is added after the last (auto)analyze. Would we not want to","historyId":"18191","internalDate":"1769361819000","receivedAtUtc":"2026-01-25T17:23:39.000Z","from":"Sami Imseih <samimseih@gmail.com>"}]	The discussion centers on a proposed PostgreSQL feature for selectively running ANALYZE operations. The original "SMART ANALYZE" proposal would skip relations unchanged since last analysis using n_mod_since_analyze == 0, but reviewers find this approach too simplistic. Key concerns include analyzing tables after minimal modifications (even single row changes) and handling edge cases like new columns added after last analysis. Robert Treat proposes splitting functionality into two separate options: MISSING_STATS (for tables without any statistics, similar to vacuumdb --missing-stats-only) and MODIFIED_STATS (using autoanalyze threshold calculations). Sami Imseih supports this direction, suggesting GUC-based threshold configuration for flexibility. Additional considerations include handling system tables, empty tables that always appear to have missing stats, and the fact that pg_statistic persists through crashes while pg_stat_all_tables timestamps don't. The discussion reflects ongoing refinement toward a more nuanced approach than the original binary skip/analyze decision.\n\n讨论围绕PostgreSQL的一个建议功能展开，用于有选择地运行ANALYZE操作。原始的"SMART ANALYZE"提案使用n_mod_since_analyze == 0来跳过自上次分析以来未更改的关系，但审阅者认为这种方法过于简单。主要关切包括在最小修改（甚至单行更改）后分析表，以及处理边缘情况如在上次分析后添加新列。Robert Treat提议将功能拆分为两个独立选项：MISSING_STATS（用于没有任何统计信息的表，类似于vacuumdb --missing-stats-only）和MODIFIED_STATS（使用自动分析阈值计算）。Sami Imseih支持这个方向，建议基于GUC的阈值配置以增加灵活性。其他考虑包括处理系统表、始终显示缺少统计信息的空表，以及pg_statistic在崩溃后持续存在而pg_stat_all_tables时间戳不会的事实。讨论反映了从原始的二进制跳过/分析决策向更细致方法的持续改进。	2026-01-25 17:23:39+00	\N
15	19bf673fa3fcca59	Issues with ON CONFLICT UPDATE and REINDEX CONCURRENTLY	["alvherre@kurilemu.de","exclusion@gmail.com","michael@paquier.xyz","mihailnikalayeu@gmail.com","noah@leadboat.com"]	[{"id":"19bf673fa3fcca59","messageId":"<CADzfLwWZjWqeX6fF5=iKq_PJiw7G+k01CBu5xB8X_Z+nN1gqqA@mail.gmail.com>","subject":"Re: Issues with ON CONFLICT UPDATE and REINDEX CONCURRENTLY","body":"Hello, Álvaro!\\n\\nFixes are in attachment. I think the comment message and comments are good\\nenough to explain the changes.\\n\\nAlso, the second commit adds syscache for pg_inherites. I am not very\\nconfident with it, but it feels correct to me.\\n\\nAnother approach - put information about parents into - I can rebuild the\\npatch that way.\\nAlso, for the first commit it is possible to create a batched version of\\nget_partition_ancestors (with the same snapshot for multiple indexes).\\n\\nBest regards,\\nMikhail.\\n","threadId":"19bf673fa3fcca59","snippet":"Hello, Álvaro! Fixes are in attachment. I think the comment message and comments are good enough to explain the changes. Also, the second commit adds syscache for pg_inherites. I am not very confident","historyId":"18288","internalDate":"1769366340000","receivedAtUtc":"2026-01-25T18:39:00.000Z","from":"Mihail Nikalayeu <mihailnikalayeu@gmail.com>"}]	Mikhail Nikalayeu responds to Álvaro with attached fixes for issues related to ON CONFLICT UPDATE and REINDEX CONCURRENTLY operations. The proposed solution includes two commits: the first addresses the core problem with appropriate comment explanations, while the second adds a syscache for pg_inherits to improve performance. Mikhail expresses some uncertainty about the syscache implementation but believes it's the correct approach. He suggests alternative approaches, including storing parent information differently or creating a batched version of get_partition_ancestors that uses the same snapshot for multiple indexes to optimize performance further.\n\nMikhail Nikalayeu 回复 Álvaro，提供了修复 ON CONFLICT UPDATE 和 REINDEX CONCURRENTLY 操作相关问题的补丁。建议的解决方案包含两个提交：第一个解决核心问题并提供适当的注释说明，第二个为 pg_inherits 添加系统缓存以提高性能。Mikhail 对系统缓存实现表示一些不确定性，但认为这是正确的方法。他建议了替代方案，包括以不同方式存储父级信息，或创建 get_partition_ancestors 的批处理版本，为多个索引使用相同快照以进一步优化性能。	2026-01-25 18:39:00+00	\N
15	19bf52df62072cb8	Make copyObject work in C++	["andres@anarazel.de","peter@eisentraut.org","postgres@jeltef.nl","thomas.munro@gmail.com"]	[{"id":"19bf52df62072cb8","messageId":"<DFXOG2P1QMS8.3L7MCAL0E6MVJ@jeltef.nl>","subject":"Re: Make copyObject work in C++","body":"On Tue Jan 20, 2026 at 5:28 PM CET, Peter Eisentraut wrote:\\n> I have split your first patch further.  For a start, I left out the > PG_MODULE_MAGIC*-related changes and disabled the module under MSVC. > This has been committed.  I plan to let the buildfarm run with it for a > day or two and then add in the basic MSVC support.\\n\\nTo hopefully make your life a bit easier. Here's a rebased version that\\nenables the MSVC support again, with an updated commit message.\\n","threadId":"19bf52df62072cb8","snippet":"On Tue Jan 20, 2026 at 5:28 PM CET, Peter Eisentraut wrote: > I have split your first patch further. For a start, I left out the > PG_MODULE_MAGIC*-related changes and disabled the module under","historyId":"17512","internalDate":"1769344971000","receivedAtUtc":"2026-01-25T12:42:51.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"},{"id":"19bf610937a4e905","messageId":"<ztktlrqatfj4roqhdjurccb3b4mf5hrycybfrzwupt4xmbwjt4@alrtyxhz5sns>","subject":"Re: Make copyObject work in C++","body":"Hi,\\n\\nOn 2026-01-25 13:42:51 +0100, Jelte Fennema-Nio wrote:\\n> This reverts to using positional initializers in PG_MODULE_MAGIC_DATA so\\n> that its possible to write C++ extensions in standard C++11. Sadly that\\n> means that using designated initializers in C++20 is still not allowed\\n> in PG_MODULE_MAGIC_EXT because mixing designated an positional\\n> initializers is a C only feature. This restriction for C++ extensions is\\n> now documented and tested.\\n\\nI'm pretty sceptical this is the right direction. We were going for designated\\ninitializers for a reason, namely that we expect more arguments to be added\\nover time and perhaps eventually also to remove some. And this will just lead\\nto that being harder because we have to worry about C++ extensions.\\n\\n\\nBut I'm also confused as to why it's needed - there's nomixing of designated\\nand non-designated initializers that I can see? If you use\\nPG_MODULE_MAGIC_EXT(.name = \\"whatnot\\"), it evaluates down to\\n\\nextern __attribute__((visibility(\\"default\\"))) const Pg_magic_struct *Pg_magic_func(void); const Pg_magic_struct * Pg_magic_func(void) { static const Pg_magic_struct Pg_magic_data = { .len = sizeof(Pg_magic_struct), .abi_fields = { 190000 / 100, 100, 32, 64, true, \\"PostgreSQL\\", }, .name=\\"whatnot\\"}; return &Pg_magic_data; } extern int no_such_variable;\\n\\nAnd indeed, contra to what you reported upthread, I can't get clang to report\\na warning about that.  I do obviously see warnings about the wrong order if I\\npass the arguments in the wrong order, but that's a lot less problematic. And\\nomitted args don't trigger warnings, as you noted.\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf52df62072cb8","snippet":"Hi, On 2026-01-25 13:42:51 +0100, Jelte Fennema-Nio wrote: > This reverts to using positional initializers in PG_MODULE_MAGIC_DATA so > that its possible to write C++ extensions in standard C++11","historyId":"17978","internalDate":"1769359828000","receivedAtUtc":"2026-01-25T16:50:28.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf64994bc479fb","messageId":"<DFXV193BOBQ8.1BY2PK8YRJ9O1@jeltef.nl>","subject":"Re: Make copyObject work in C++","body":"On Sun Jan 25, 2026 at 5:50 PM CET, Andres Freund wrote:\\n> I'm pretty sceptical this is the right direction. The only other option I can think of is not supporting C++ extension on\\nMSVC unless they are compiled with C++20 (or later). I don't\\nparticularly care about Windows C++ extensions myself, so I personally\\nwould be fine with that choice. It seems a bit harsh, though.\\n\\n> We were going for designated\\n> initializers for a reason, namely that we expect more arguments to be added\\n> over time and perhaps eventually also to remove some. And this will just lead\\n> to that being harder because we have to worry about C++ extensions.\\n\\nAdding new arguments (aka fields) should cause no problems. Assuming\\nwe'd add them at the end of the Pg_magic_struct definition. Removing\\nones seems like even for C you'd need different PG_MODULE_MAGIC_EXT\\ninvocations depending on PG_VERSION_NUM. I don't see how using\\npositional args would make that harder.\\n\\n> But I'm also confused as to why it's needed - there's nomixing of designated\\n> and non-designated initializers that I can see? If you use\\n> PG_MODULE_MAGIC_EXT(.name = \\"whatnot\\"), it evaluates down to\\n>\\n> extern __attribute__((visibility(\\"default\\"))) const Pg_magic_struct *Pg_magic_func(void); const Pg_magic_struct * Pg_magic_func(void) { static const Pg_magic_struct Pg_magic_data = { .len = sizeof(Pg_magic_struct), .abi_fields = { 190000 / 100, 100, 32, 64, true, \\"PostgreSQL\\", }, .name=\\"whatnot\\"}; return &Pg_magic_data; } extern int no_such_variable;\\n>\\n> And indeed, contra to what you reported upthread, I can't get clang to report\\n> a warning about that.  I do obviously see warnings about the wrong order if I\\n> pass the arguments in the wrong order, but that's a lot less problematic. And\\n> omitted args don't trigger warnings, as you noted.\\n\\nIt sounds like I wasn't clear enough what the problem was. The main\\nproblem currently is that MSVC C++ fails to compile a cpp file\\ncontaining PG_MODULE_MAGIC (or PG_MODULE_MAGIC_EXT) unless you use /std:c++20.\\n\\nAfaict it would have been possible to do so before 9324c8c580 (aka\\nanything before PG18), but since that commit you need /std:c++20. The\\nfact that we haven't heard anyone complain so far, might be an indication\\nthat not many people (or maybe anyone) is using C++ extensions on Windows.\\n\\nThe only way to make PG_MODULE_MAGIC work on MSVC pre-C++20 is to\\npartially revert 9324c8c580, and use positional arguments in the\\ndefinition of PG_MODULE_MAGIC_DATA again. Like I've done in v7-0001.\\n\\nFor C extensions v7-0001 has no downsides. However, after applying\\nv7-0001, C++ extensions that use PG_MODULE_MAGIC_EXT with designated\\nparameters will get the following warning on at least clang 18 on my\\nmachine:\\n\\nmeson setup --prefix ~/.pgenv/pgsql-master --debug build --reconfigure -Dc_args='-fno-omit-frame-pointer' -Dcassert=true\\nmeson test -C build --suite setup --suite test_cplusplusext\\n\\n[2202/2268] Compiling C++ object src/test/modules/test_cplusplusext/test_cplusplusext.so.p/test_cplusplusext.cpp.o\\n../src/test/modules/test_cplusplusext/test_cplusplusext.cpp:23:21: warning: mixture of designated and non-designated initializers in the same initializer list is a C99 extension [-Wc99-designator]\\n  23 | PG_MODULE_MAGIC_EXT(.name=\\"test_cplusplusext\\",.version= \\"1.2\\");\\n     |                     ^~~~~~~~~~~~~~~~~~~~~~~~~\\n../src/include/fmgr.h:548:24: note: expanded from macro 'PG_MODULE_MAGIC_EXT'\\n 548 |                 PG_MODULE_MAGIC_DATA(__VA_ARGS__); \\\\\\n     |                                      ^~~~~~~~~~~\\n../src/include/fmgr.h:509:2: note: expanded from macro 'PG_MODULE_MAGIC_DATA'\\n 509 |         __VA_ARGS__ \\\\\\n     |         ^~~~~~~~~~~\\n../src/test/modules/test_cplusplusext/test_cplusplusext.cpp:23:1: note: first non-designated initializer is here\\n  23 | PG_MODULE_MAGIC_EXT(.name=\\"test_cplusplusext\\",.version= \\"1.2\\");\\n     | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n../src/include/fmgr.h:548:3: note: expanded from macro 'PG_MODULE_MAGIC_EXT'\\n 548 |                 PG_MODULE_MAGIC_DATA(__VA_ARGS__); \\\\\\n     |                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n../src/include/fmgr.h:507:2: note: expanded from macro 'PG_MODULE_MAGIC_DATA'\\n 507 |         sizeof(Pg_magic_struct), \\\\\\n     |         ^~~~~~~~~~~~~~~~~~~~~~~\\n\\nNote that you need to use meson test, not meson install, otherwise\\ntest_cplusplusext.cpp won't get compiled.\\n\\nSo to be clear, yes right now there's no mixing of designated and\\nnon-designated initializers. But after applying v7-0001 there would be\\nwhen you use something like this:\\nPG_MODULE_MAGIC_EXT(.name=\\"test_cplusplusext\\",.version= \\"1.2\\");\\n\\n\\nAnd while the C standard allows mixing designated and non-designated\\ninitializerss, the C++ standard (even C++20) does not.\\n\\n\\n","threadId":"19bf52df62072cb8","snippet":"On Sun Jan 25, 2026 at 5:50 PM CET, Andres Freund wrote: > I'm pretty sceptical this is the right direction. The only other option I can think of is not supporting C++ extension on MSVC unless","historyId":"18242","internalDate":"1769363557000","receivedAtUtc":"2026-01-25T17:52:37.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"},{"id":"19bf6c3dc182f41f","messageId":"<2h2n2gyw2f4ucicbl3drtdkjt2wzf6b2r4wqm7xwks6vpx5j7n@imymv4hkz5jz>","subject":"Re: Make copyObject work in C++","body":"Hi,\\n\\nOn 2026-01-25 18:52:37 +0100, Jelte Fennema-Nio wrote:\\n> On Sun Jan 25, 2026 at 5:50 PM CET, Andres Freund wrote:\\n> > We were going for designated\\n> > initializers for a reason, namely that we expect more arguments to be added\\n> > over time and perhaps eventually also to remove some. And this will just lead\\n> > to that being harder because we have to worry about C++ extensions.\\n> \\n> Adding new arguments (aka fields) should cause no problems. Assuming\\n> we'd add them at the end of the Pg_magic_struct definition. Removing\\n> ones seems like even for C you'd need different PG_MODULE_MAGIC_EXT\\n> invocations depending on PG_VERSION_NUM. I don't see how using\\n> positional args would make that harder.\\n\\nNamed args make that easier in two ways: First, only extensions using the\\nto-be-removed option will fail. Second, removal of options reliably generates\\nerrors, rather than bogusly use one field for another, just because the types\\nare compatible.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n","threadId":"19bf52df62072cb8","snippet":"Hi, On 2026-01-25 18:52:37 +0100, Jelte Fennema-Nio wrote: > On Sun Jan 25, 2026 at 5:50 PM CET, Andres Freund wrote: > > We were going for designated > > initializers for a reason,","historyId":"18358","internalDate":"1769371572000","receivedAtUtc":"2026-01-25T20:06:12.000Z","from":"Andres Freund <andres@anarazel.de>"}]	The discussion centers on making PostgreSQL's PG_MODULE_MAGIC work with C++ extensions on MSVC. Peter Eisentraut committed an initial patch but disabled MSVC support temporarily. Jelte Fennema-Nio proposed reverting to positional initializers in PG_MODULE_MAGIC_DATA to enable C++11 compatibility on MSVC, since designated initializers require C++20. However, this approach causes compiler warnings when mixing designated and non-designated initializers in PG_MODULE_MAGIC_EXT calls. Andres Freund expressed skepticism about reverting to positional initializers, arguing that designated initializers were chosen to facilitate future field additions and removals. He noted that named arguments provide better error handling and only break extensions actually using removed options, rather than causing silent field misassignment. The core tension is between maintaining C++11 compatibility on MSVC versus preserving the maintainability benefits of designated initializers for future PostgreSQL development.\n讨论的焦点是让PostgreSQL的PG_MODULE_MAGIC在MSVC上支持C++扩展。Peter Eisentraut提交了初始补丁但暂时禁用了MSVC支持。Jelte Fennema-Nio提议在PG_MODULE_MAGIC_DATA中恢复使用位置初始化器以实现MSVC上的C++11兼容性，因为指定初始化器需要C++20。然而，这种方法在PG_MODULE_MAGIC_EXT调用中混合指定和非指定初始化器时会导致编译器警告。Andres Freund对恢复位置初始化器表示怀疑，认为选择指定初始化器是为了便于未来字段的添加和删除。他指出命名参数提供更好的错误处理，只会破坏实际使用已删除选项的扩展，而不是导致静默的字段错误分配。核心冲突在于维持MSVC上的C++11兼容性与保持指定初始化器对未来PostgreSQL开发的可维护性优势之间。	2026-01-25 20:06:12+00	\N
15	19bf12489bc2e8dc	ABI Compliance Checker GSoC Project	["andres@anarazel.de","andrew@dunslane.net","david@justatheory.com","dean.a.rasheed@gmail.com","mankiratsingh1315@gmail.com","tgl@sss.pgh.pa.us"]	[{"id":"19bf12489bc2e8dc","messageId":"<3451994.1769277248@sss.pgh.pa.us>","subject":"Re: ABI Compliance Checker GSoC Project","body":"As per the discussion at [1], our ABI checks would be more helpful if\\nwe include a --headers-dir option in the abidw call, along the lines\\nof the attached patch.  As things stand, changes in structs that\\nare intentionally abstract outside their defining module will\\nnonetheless be reported as ABI breaks, so that the tool completely\\nmisses the point of the abstraction.  But pointing it to the\\ninstalled headers tree alongside the binary seems to be enough to\\nfix that.  I can confirm Andres' observation that the attached is\\nenough to change the currently-reported breakage to mention just\\nthe globally-accessible struct.\\n\\nSome notes:\\n\\n1. It's kind of annoying not to fold this into the abidw_flags_list\\noption, but I don't see a good way to do that given that the headers\\npath is branch-dependent.\\n\\n2. When installing this change into an active BF member, you'd better\\nblow away the abicheck.$animal cache tree, else you'll have a mess\\nfrom cached trees not having been analyzed with the same options.\\n(I experimented and indeed got some very strange ABI-diff complaints\\nwhen I hadn't done that.)\\n\\n3. The same would likely apply to any change in abidw_flags_list.\\nIs it worth trying to automate that somehow, perhaps by recording\\nthe flags used to build an abicheck cache file?\\n\\n\\t\\t\\tregards, tom lane\\n\\n[1] https://www.postgresql.org/message-id/flat/3256998.1769270320%40sss.pgh.pa.us#67ee3d4a9ebfc915dd6fa2cfecdcbedb\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"As per the discussion at [1], our ABI checks would be more helpful if we include a --headers-dir option in the abidw call, along the lines of the attached patch. As things stand, changes in structs","historyId":"15693","internalDate":"1769277248000","receivedAtUtc":"2026-01-24T17:54:08.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf1e1aea4a5902","messageId":"<2CEFC7F6-4D97-4078-97AB-AEF8CAE287A2@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 12:54, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n\\n> 2. When installing this change into an active BF member, you'd better\\n> blow away the abicheck.$animal cache tree, else you'll have a mess\\n> from cached trees not having been analyzed with the same options.\\n> (I experimented and indeed got some very strange ABI-diff complaints\\n> when I hadn't done that.)\\n\\nI've applied this change to baza, and after a couple false starts, it seems to be sending OKs. I did have to delete every directory except for `pgmirror.git`.\\n\\nD\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 12:54, Tom Lane <tgl@sss.pgh.pa.us> wrote: > 2. When installing this change into an active BF member, you'd better > blow away the abicheck.$animal cache tree, else","historyId":"15780","internalDate":"1769289632000","receivedAtUtc":"2026-01-24T21:20:32.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf1e4e55742fb6","messageId":"<3473943.1769289856@sss.pgh.pa.us>","subject":"Re: ABI Compliance Checker GSoC Project","body":"\\"David E. Wheeler\\" <david@justatheory.com> writes:\\n> I've applied this change to baza, and after a couple false starts, it seems to be sending OKs. I did have to delete every directory except for `pgmirror.git`.\\n\\nSome of baza's recent failures indicate out-of-disk-space.\\nYou might have to clear some additional space on that machine.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"\\"David E. Wheeler\\" <david@justatheory.com> writes: > I've applied this change to baza, and after a couple false starts, it seems to be sending OKs. I did have to delete every","historyId":"15871","internalDate":"1769289856000","receivedAtUtc":"2026-01-24T21:24:16.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf1e963d73f90e","messageId":"<139BC930-34CD-42F0-9848-53659529B04E@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 16:24, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n\\n> Some of baza's recent failures indicate out-of-disk-space.\\n> You might have to clear some additional space on that machine.\\n\\nYeah I have a script that runs ahead of the daily cron job that clear space, but forgot to run it before I manually started a run about an hour ago. Killed that run, cleared space, and started another run.\\n\\nD\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 16:24, Tom Lane <tgl@sss.pgh.pa.us> wrote: > Some of baza's recent failures indicate out-of-disk-space. > You might have to clear some additional space on that","historyId":"15912","internalDate":"1769290140000","receivedAtUtc":"2026-01-24T21:29:00.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf245ccf69fb62","messageId":"<9EB6EE0F-72D6-4F74-A479-F13A15BCE551@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 16:29, David E. Wheeler <david@justatheory.com> wrote:\\n\\n> Yeah I have a script that runs ahead of the daily cron job that clear space, but forgot to run it before I manually started a run about an hour ago. Killed that run, cleared space, and started another run.\\n\\nAre ABI failures like this[0] expected?\\n\\nD\\n\\n[0]: https://buildfarm.postgresql.org/cgi-bin/show_stage_log.pl?nm=baza&dt=2026-01-24%2022%3A06%3A20&stg=abi-compliance-check\\n\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 16:29, David E. Wheeler <david@justatheory.com> wrote: > Yeah I have a script that runs ahead of the daily cron job that clear space, but forgot to run it before I manually","historyId":"16127","internalDate":"1769296194000","receivedAtUtc":"2026-01-24T23:09:54.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf25e793c57986","messageId":"<c2lzkkxeyrvucxyl4uf2d6v5l56esymzs3hujc64pdhg2er6j2@xnxpbj6gqcpi>","subject":"Re: ABI Compliance Checker GSoC Project","body":"Hi,\\n\\nOn 2026-01-24 18:09:54 -0500, David E. Wheeler wrote:\\n> Are ABI failures like this[0] expected?\\n\\ncommit b4307ae2e54 (HEAD, upstream/master, upstream/HEAD, master)\\nAuthor: Dean Rasheed <dean.a.rasheed@gmail.com>\\nDate:   2026-01-24 11:30:48 +0000\\n\\n    Fix trigger transition table capture for MERGE in CTE queries.\\n...\\n\\n    This requires changing the TransitionCaptureState structure, replacing\\n    \\"tcs_private\\" with 3 separate pointers to AfterTriggersTableData\\n    structures, one for each of INSERT, UPDATE, and DELETE. Nominally,\\n    this is an ABI break to a public structure in commands/trigger.h.\\n    However, since this is a private field pointing to an opaque data\\n    structure, the only way to create a valid TransitionCaptureState is by\\n    calling MakeTransitionCaptureState(), and no extensions appear to be\\n    doing that anyway, so it seems safe for back-patching.\\n...\\n\\n\\nIn [1] Dean said he's expects to have to push an amendment to\\n.abi-compliance-history soon. But then the discussion got a bit derailed\\nbecause one of the complaints being reported is bogus, as the struct is only\\ndefined in a .c file.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n[1] https://postgr.es/m/CAEZATCX3obg5BP3g36LFDhsZgG9BYPN3qQusz_F-K%3D-yOoPJCw%40mail.gmail.com\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"Hi, On 2026-01-24 18:09:54 -0500, David E. Wheeler wrote: > Are ABI failures like this[0] expected? commit b4307ae2e54 (HEAD, upstream/master, upstream/HEAD, master) Author: Dean Rasheed <dean.a.","historyId":"16225","internalDate":"1769297822000","receivedAtUtc":"2026-01-24T23:37:02.000Z","from":"Andres Freund <andres@anarazel.de>"},{"id":"19bf26995350fd3b","messageId":"<5AF06D5F-D954-4ECA-8184-98F387265E25@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 24, 2026, at 18:37, Andres Freund <andres@anarazel.de> wrote:\\n\\n> In [1] Dean said he's expects to have to push an amendment to\\n> .abi-compliance-history soon. But then the discussion got a bit derailed\\n> because one of the complaints being reported is bogus, as the struct is only\\n> defined in a .c file.\\n\\nCool, hopefully we're back on track then.\\n\\nD\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 24, 2026, at 18:37, Andres Freund <andres@anarazel.de> wrote: > In [1] Dean said he's expects to have to push an amendment to > .abi-compliance-history soon. But then the","historyId":"16276","internalDate":"1769298541000","receivedAtUtc":"2026-01-24T23:49:01.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf2a7909ab5636","messageId":"<3497234.1769302612@sss.pgh.pa.us>","subject":"Re: ABI Compliance Checker GSoC Project","body":"\\"David E. Wheeler\\" <david@justatheory.com> writes:\\n> On Jan 24, 2026, at 18:37, Andres Freund <andres@anarazel.de> wrote:\\n>> In [1] Dean said he's expects to have to push an amendment to\\n>> .abi-compliance-history soon. But then the discussion got a bit derailed\\n>> because one of the complaints being reported is bogus, as the struct is only\\n>> defined in a .c file.\\n\\n> Cool, hopefully we're back on track then.\\n\\nBut the report you pointed to is complaining about both structs,\\nwhich I'd not expect to happen if you installed that patch I\\nproposed.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"\\"David E. Wheeler\\" <david@justatheory.com> writes: > On Jan 24, 2026, at 18:37, Andres Freund <andres@anarazel.de> wrote: >> In [1] Dean said he's expects to have to","historyId":"16410","internalDate":"1769302612000","receivedAtUtc":"2026-01-25T00:56:52.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf49bc8cf59f79","messageId":"<CAEZATCW+acBq6rV6vQ+9Pr+NyjaGaiS9Kg3twzDY8vQXQ_xTtA@mail.gmail.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Sun, 25 Jan 2026 at 00:57, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n>\\n> \\"David E. Wheeler\\" <david@justatheory.com> writes:\\n> > On Jan 24, 2026, at 18:37, Andres Freund <andres@anarazel.de> wrote:\\n> >> In [1] Dean said he's expects to have to push an amendment to\\n> >> .abi-compliance-history soon. But then the discussion got a bit derailed\\n> >> because one of the complaints being reported is bogus, as the struct is only\\n> >> defined in a .c file.\\n>\\n> > Cool, hopefully we're back on track then.\\n>\\n> But the report you pointed to is complaining about both structs,\\n> which I'd not expect to happen if you installed that patch I\\n> proposed.\\n>\\n\\nYes, the most recent check on baza [1] is still incorrectly\\ncomplaining about both structs.\\n\\nI have prepared a patch for .abi-compliance-history, but I'll hold off\\non pushing it.\\n\\nRegards,\\nDean\\n\\n[1] https://buildfarm.postgresql.org/cgi-bin/show_log.pl?nm=baza&dt=2026-01-25%2003%3A22%3A35\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Sun, 25 Jan 2026 at 00:57, Tom Lane <tgl@sss.pgh.pa.us> wrote: > > \\"David E. Wheeler\\" <david@justatheory.com> writes: > > On Jan 24, 2026, at 18:37, Andres Freund","historyId":"17092","internalDate":"1769335385000","receivedAtUtc":"2026-01-25T10:03:05.000Z","from":"Dean Rasheed <dean.a.rasheed@gmail.com>"},{"id":"19bf6dc1c4bc0f71","messageId":"<A94C850D-05B6-4DA0-BCCC-E2745519D7A6@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 25, 2026, at 05:03, Dean Rasheed <dean.a.rasheed@gmail.com> wrote:\\n\\n> Yes, the most recent check on baza [1] is still incorrectly\\n> complaining about both structs.\\n> \\n> I have prepared a patch for .abi-compliance-history, but I'll hold off\\n> on pushing it.\\n\\nOkay, off-list Andres suggested that perhaps --headers-dir wasn't implying --drop-private-types on my system. Turns out bookworm packages libabigail 2.2; the Abigail maintainers changed that behavior[0] in v2.8[1]. Adding it explicitly on baza results in this output:\\n\\n```\\nLeaf changes summary: 1 artifact changed\\nChanged leaf types summary: 1 leaf type changed\\nRemoved/Changed/Added functions summary: 0 Removed, 0 Changed, 0 Added function (3 filtered out)\\nRemoved/Changed/Added variables summary: 0 Removed, 0 Changed, 0 Added variable\\n\\n'struct TransitionCaptureState' changed:\\n  type size changed from 24 to 40 (in bytes)\\n  2 data member insertions:\\n    'AfterTriggersTableData* tcs_update_private', at offset 24 (in bytes)\\n    'AfterTriggersTableData* tcs_delete_private', at offset 32 (in bytes)\\n```\\n\\nWhich seems more correct. I've made a PR[2] to always pass --drop-private-types as well as  --headers-dir, which seems to be compatible with the existing code[3].\\n\\nOne downside, though: the above is still considered an ABI compliance failure:\\n\\n```\\nbaza:REL_17_STABLE [19:21:24] ABICompCheck :: doing comparison against baseline 0f69beddea113dd1d6c5b6f6d82df577ef3c21f2\\nbaza:REL_17_STABLE [19:21:57] ABICompCheck :: ABI difference found for postgres.abi\\nBranch: REL_17_STABLE\\nStage abi-compliance-check failed with status 1\\n```\\n\\nI tried adding --exported-interfaces-only but got the same result. Anyone got other ideas?\\n\\nBest,\\n\\nDavid\\n\\n  [0]: https://sourceware.org/git/?p=libabigail.git;a=commit;h=577a81fa83d215d9bd87aaf7baaae0c47bce4757\\n  [1]: https://sourceware.org/git/?p=libabigail.git;a=blob;f=ChangeLog;h=0f5d805c901f9eb6f52d37c3bb4e72a85fdcc6c6;hb=HEAD#l364\\n  [2]: https://github.com/PGBuildFarm/client-code/pull/41\\n  [3]: https://sourceware.org/git/?p=libabigail.git;a=blob;f=tools/abidw.cc;h=ebffb8fd4e14d90ac8d650da93513526d1bda2be;hb=577a81fa83d215d9bd87aaf7baaae0c47bce4757#l316\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 25, 2026, at 05:03, Dean Rasheed <dean.a.rasheed@gmail.com> wrote: > Yes, the most recent check on baza [1] is still incorrectly > complaining about both structs. > > I have","historyId":"18409","internalDate":"1769373154000","receivedAtUtc":"2026-01-25T20:32:34.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf6e63bf6f616d","messageId":"<99677B1A-C557-4757-B4C9-510DE0C48198@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 25, 2026, at 15:32, David E. Wheeler <david@justatheory.com> wrote:\\n\\n> I tried adding --exported-interfaces-only but got the same result. Anyone got other ideas?\\n\\nEr, or is this expected prior to you patching .abi-compliance-history?\\n\\nD\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 25, 2026, at 15:32, David E. Wheeler <david@justatheory.com> wrote: > I tried adding --exported-interfaces-only but got the same result. Anyone got other ideas? Er, or is this expected","historyId":"18461","internalDate":"1769373819000","receivedAtUtc":"2026-01-25T20:43:39.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"},{"id":"19bf6ea583984153","messageId":"<14745.1769374096@sss.pgh.pa.us>","subject":"Re: ABI Compliance Checker GSoC Project","body":"\\"David E. Wheeler\\" <david@justatheory.com> writes:\\n> On Jan 25, 2026, at 15:32, David E. Wheeler <david@justatheory.com> wrote:\\n>> I tried adding --exported-interfaces-only but got the same result. Anyone got other ideas?\\n\\n> Er, or is this expected prior to you patching .abi-compliance-history?\\n\\nYeah, exactly.  The point here is we want the complaint about\\nTransitionCaptureState but not the one about AfterTriggersTableData.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"\\"David E. Wheeler\\" <david@justatheory.com> writes: > On Jan 25, 2026, at 15:32, David E. Wheeler <david@justatheory.com> wrote: >> I tried adding --exported-interfaces-","historyId":"18501","internalDate":"1769374096000","receivedAtUtc":"2026-01-25T20:48:16.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>"},{"id":"19bf6f67f48436b3","messageId":"<50446D85-8623-43E3-84F6-A157C8BDC61F@justatheory.com>","subject":"Re: ABI Compliance Checker GSoC Project","body":"On Jan 25, 2026, at 15:48, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n\\n> Yeah, exactly.  The point here is we want the complaint about\\n> TransitionCaptureState but not the one about AfterTriggersTableData.\\n\\nOkay, great. Hopefully it'll start passing again once Dean pushes the .abi-compliance-history patch.\\n\\nD\\n\\n","threadId":"19bf12489bc2e8dc","snippet":"On Jan 25, 2026, at 15:48, Tom Lane <tgl@sss.pgh.pa.us> wrote: > Yeah, exactly. The point here is we want the complaint about > TransitionCaptureState but not the one about","historyId":"18559","internalDate":"1769374883000","receivedAtUtc":"2026-01-25T21:01:23.000Z","from":"\\"David E. Wheeler\\" <david@justatheory.com>"}]	Tom Lane proposed a patch to improve ABI compliance checking by adding a --headers-dir option to the abidw call. This change addresses false positives where intentionally abstract structs are incorrectly reported as ABI breaks. The patch helps the tool focus on globally-accessible structures rather than internal implementation details. David Wheeler applied the changes to the baza buildfarm member, encountering initial disk space issues that were resolved. However, ABI failures persisted due to Dean Rasheed's recent commit that modified the TransitionCaptureState structure for MERGE trigger transition table fixes. Wheeler discovered that older libabigail versions require explicitly passing --drop-private-types alongside --headers-dir. The discussion clarified that current ABI complaints about TransitionCaptureState are expected and legitimate, while complaints about AfterTriggersTableData should be filtered out. Dean prepared a patch for .abi-compliance-history to address the legitimate ABI change but is holding off on pushing it until the tooling improvements are fully deployed.\n\n汤姆·莱恩提出了一个补丁，通过在abidw调用中添加--headers-dir选项来改进ABI兼容性检查。这个更改解决了误报问题，即故意抽象的结构体被错误地报告为ABI破坏。该补丁帮助工具专注于全局可访问的结构体，而不是内部实现细节。大卫·惠勒将更改应用到baza构建农场成员，遇到了最初的磁盘空间问题但已解决。然而，由于迪恩·拉希德最近提交的修改TransitionCaptureState结构体以修复MERGE触发器过渡表的代码，ABI失败仍然存在。惠勒发现较旧的libabigail版本需要在--headers-dir的同时显式传递--drop-private-types。讨论澄清了当前关于TransitionCaptureState的ABI投诉是预期的和合理的，而关于AfterTriggersTableData的投诉应该被过滤掉。迪恩准备了一个.abi-compliance-history的补丁来处理合理的ABI更改，但在工具改进完全部署之前暂缓推送。	2026-01-25 21:01:23+00	\N
15	19bf74018d8e45c9	Add GoAway protocol message for graceful but fast server shutdown/switchover	["davecramer@gmail.com","hlinnaka@iki.fi","jacob.champion@enterprisedb.com","me@jeltef.nl","postgres@jeltef.nl"]	[{"id":"19bf74018d8e45c9","messageId":"<DFY0RHAZTTXJ.15AD95RE6A5N5@jeltef.nl>","subject":"Re: Add GoAway protocol message for graceful but fast server shutdown/switchover","body":"On Thu Jan 8, 2026 at 10:15 AM CET, Jelte Fennema-Nio wrote:\\n> After pushback on another threadabout introducing additional minor\\n> protocol versions[1], I've decided to change this patch to use a\\n> protocol extension instead of a minor version bump.\\n\\nTurns out there were still some leftovers from using a version bump in\\nthe libpq_pipeline tests. Removed those too now.\\n","threadId":"19bf74018d8e45c9","snippet":"On Thu Jan 8, 2026 at 10:15 AM CET, Jelte Fennema-Nio wrote: > After pushback on another threadabout introducing additional minor > protocol versions[1], I've decided to change this patch to","historyId":"18609","internalDate":"1769379718000","receivedAtUtc":"2026-01-25T22:21:58.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"}]	Jelte Fennema-Nio has updated their patch for adding a GoAway protocol message to PostgreSQL, which enables graceful but fast server shutdown and switchover capabilities. Following community feedback that opposed introducing additional minor protocol versions, the author pivoted from using a version bump approach to implementing this feature as a protocol extension instead. The latest update addresses remaining artifacts from the previous version-based implementation, specifically removing leftover references in the libpq_pipeline tests that were still using the old version bump methodology. This change maintains the core functionality while conforming to community preferences for protocol extension mechanisms over versioning changes.\n\nJelte Fennema-Nio已更新其为PostgreSQL添加GoAway协议消息的补丁，该功能可实现优雅但快速的服务器关闭和切换。在社区反对引入额外次要协议版本的反馈后，作者从使用版本升级方法转向将此功能实现为协议扩展。最新更新解决了先前基于版本实现的剩余痕迹，特别是删除了libpq_pipeline测试中仍在使用旧版本升级方法的遗留引用。此更改保持了核心功能，同时符合社区对协议扩展机制而非版本控制更改的偏好。	2026-01-25 22:21:58+00	\N
15	19bf78601a3003b0	Safer hash table initialization macro	["bertranddrouvot.pg@gmail.com","postgres@jeltef.nl","thomas.munro@gmail.com"]	[{"id":"19bf78601a3003b0","messageId":"<DFY2DVPSXAZX.1BAGDNB27D0F2@jeltef.nl>","subject":"Re: Safer hash table initialization macro","body":"On Wed Jan 14, 2026 at 9:46 AM CET, Jelte Fennema-Nio wrote:\\n> Changed wording and changed to NOTE.\\n\\nAttached is v7 which is rebased and changed the hash_create calls\\nintroduced by 282b1cde9de.\\n","threadId":"19bf78601a3003b0","snippet":"On Wed Jan 14, 2026 at 9:46 AM CET, Jelte Fennema-Nio wrote: > Changed wording and changed to NOTE. Attached is v7 which is rebased and changed the hash_create calls introduced by 282b1cde9de.","historyId":"18679","internalDate":"1769384295000","receivedAtUtc":"2026-01-25T23:38:15.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>"}]	Jelte Fennema-Nio has submitted version 7 of a patch for safer hash table initialization macros. This revision is rebased and incorporates changes to hash_create calls that were introduced by commit 282b1cde9de. The patch appears to address wording improvements and includes a NOTE directive as previously requested. The submission follows earlier feedback and represents an iterative refinement of the proposed hash table initialization safety improvements. No specific technical details about the macro changes or safety enhancements are provided in this brief update message.\n\nJelte Fennema-Nio 提交了用于更安全的哈希表初始化宏的第7版补丁。此修订版本已重新基于最新代码，并合并了对由提交 282b1cde9de 引入的 hash_create 调用的更改。该补丁似乎解决了措辞改进问题，并包含了之前请求的 NOTE 指令。此次提交遵循了早期反馈，代表了对提议的哈希表初始化安全改进的迭代完善。此简短更新消息中未提供关于宏更改或安全增强的具体技术细节。	2026-01-25 23:38:15+00	\N
22	19bea7defb8a17b6	Proposal: Conflict log history table for Logical Replication	["amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","sawada.mshk@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19bfd6d86b9791d6","threadId":"19bea7defb8a17b6","snippet":"Hi Dilip. Some comments for the first 2 patches: ////////// v24-00001 ////////// 1. + /* + * Conflict log tables are managed by the system to record logical + * replication conflicts. We do not allow","historyId":"24696","internalDate":"1769483334000","receivedAtUtc":"2026-01-27T03:08:54.000Z","from":"Peter Smith <smithpb2250@gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","messageId":"<CAHut+PuaqNDfDu_3xkZR4OYxw-B7ew_WjpLXCBvMcSBJz2K6Xg@mail.gmail.com>","body":"Hi Dilip.\\n\\nSome comments for the first 2 patches:\\n\\n//////////\\nv24-00001\\n//////////\\n\\n1.\\n+ /*\\n+ * Conflict log tables are managed by the system to record logical\\n+ * replication conflicts.  We do not allow locking rows in CONFLICT\\n+ * relations.\\n+ */\\n+ if (IsConflictNamespace(RelationGetNamespace(rel)))\\n+ ereport(ERROR,\\n+ (errcode(ERRCODE_WRONG_OBJECT_TYPE),\\n+ errmsg(\\"cannot lock rows in CONFLICT relation \\\\\\"%s\\\\\\"\\",\\n+ RelationGetRelationName(rel))));\\n\\nAFAIK, this \\"CONFLICT relation\\" terminology is not used anywhere else.\\n\\nWhy not just call it what it is:\\n\\ne.g.\\ncannot lock rows in conflict log table \\\\\\"%s\\\\\\"\\n\\n~\\n\\nOTOH, if you were attempting to future-proof the message for different\\nkinds of relations in the 'pg_conflict' namespace, I still felt it\\nmight be better to refer to 'pg_conflict' instead of CONFLICT:\\n\\ne.g.\\ncannot lock rows in 'pg_conflict' relation \\\\\\"%s\\\\\\"\\n\\n//////////\\nv24-0002\\n//////////\\n\\n1.\\n+static char *build_index_value_desc(EState *estate, Relation localrel,\\n+ TupleTableSlot *slot, Oid indexoid);\\n\\nDeclared twice?\\n\\n======\\nKind Regards,\\nPeter Smith.\\nFujitsu Australia.\\n\\n\\n"},{"id":"19bfd968203432ef","threadId":"19bea7defb8a17b6","snippet":"On Tue, Jan 27, 2026 at 8:39 AM Peter Smith <smithpb2250@gmail.com> wrote: > > Hi Dilip. > > Some comments for the first 2 patches: > > ////////// > v24-00001 > //////////","historyId":"24959","internalDate":"1769486023000","receivedAtUtc":"2026-01-27T03:53:43.000Z","from":"Dilip Kumar <dilipbalaut@gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","messageId":"<CAFiTN-uqNN9S_hRuda_th5MEpywa15g+XO00yM6tNJ-spGRRJw@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 8:39 AM Peter Smith <smithpb2250@gmail.com> wrote:\\n>\\n> Hi Dilip.\\n>\\n> Some comments for the first 2 patches:\\n>\\n> //////////\\n> v24-00001\\n> //////////\\n>\\n> 1.\\n> + /*\\n> + * Conflict log tables are managed by the system to record logical\\n> + * replication conflicts.  We do not allow locking rows in CONFLICT\\n> + * relations.\\n> + */\\n> + if (IsConflictNamespace(RelationGetNamespace(rel)))\\n> + ereport(ERROR,\\n> + (errcode(ERRCODE_WRONG_OBJECT_TYPE),\\n> + errmsg(\\"cannot lock rows in CONFLICT relation \\\\\\"%s\\\\\\"\\",\\n> + RelationGetRelationName(rel))));\\n>\\n> AFAIK, this \\"CONFLICT relation\\" terminology is not used anywhere else.\\n>\\n> Why not just call it what it is:\\n>\\n> e.g.\\n> cannot lock rows in conflict log table \\\\\\"%s\\\\\\"\\n>\\n> ~\\n>\\n> OTOH, if you were attempting to future-proof the message for different\\n> kinds of relations in the 'pg_conflict' namespace, I still felt it\\n> might be better to refer to 'pg_conflict' instead of CONFLICT:\\n>\\n> e.g.\\n> cannot lock rows in 'pg_conflict' relation \\\\\\"%s\\\\\\"\\n\\nI prefer conflict log tables for consistency with other places.\\n\\n> //////////\\n> v24-0002\\n> //////////\\n>\\n> 1.\\n> +static char *build_index_value_desc(EState *estate, Relation localrel,\\n> + TupleTableSlot *slot, Oid indexoid);\\n>\\n> Declared twice?\\n\\nRemoved duplicate.\\n\\nAlso fixed all pending doc comments.\\n\\n\\n\\n-- \\nRegards,\\nDilip Kumar\\nGoogle\\n"}]	Peter Smith reviewed the first two patches of Dilip Kumar's conflict log history table proposal for logical replication. He identified terminology inconsistency in error messages, suggesting "conflict log table" instead of "CONFLICT relation" for consistency, or alternatively using "pg_conflict relation" for future-proofing. He also caught a duplicate function declaration for build_index_value_desc in v24-0002. Dilip responded positively, agreeing to use "conflict log tables" for consistency and confirming removal of the duplicate declaration. He also indicated that all pending documentation comments have been addressed. The discussion shows ongoing refinement of the patch set based on code review feedback.\n逻辑复制冲突日志历史表提案的讨论中，Peter Smith审查了Dilip Kumar的前两个补丁。他指出错误消息中术语不一致的问题，建议使用"conflict log table"而不是"CONFLICT relation"以保持一致性，或者使用"pg_conflict relation"以备未来扩展。他还发现v24-0002中build_index_value_desc函数重复声明的问题。Dilip积极回应，同意为保持一致性而使用"conflict log tables"，并确认删除了重复声明。他还表示已修复所有待处理的文档注释。讨论显示基于代码审查反馈的补丁集持续改进。	2026-01-27 03:53:43+00	\N
22	19be897af3bbca01	Newly created replication slot may be invalidated by checkpoint	["aekorotkov@gmail.com","amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","houzj.fnst@fujitsu.com","kuroda.hayato@fujitsu.com","li.evan.chao@gmail.com","mengjuan.cmj@alibaba-inc.com","michael@paquier.xyz","sawada.mshk@gmail.com","tomas@vondra.me","v.davydov@postgrespro.ru","vignesh21@gmail.com"]	[{"id":"19bf841fe5fbd443","threadId":"19be897af3bbca01","snippet":"On Friday, January 23, 2026 5:06 PM Amit Kapila <amit.kapila16@gmail.com> wrote: > > On Fri, Jan 23, 2026 at 7:33 AM Zhijie Hou (Fujitsu) <houzj.fnst@fujitsu.com> > wrote: >","historyId":"22986","internalDate":"1769396616000","receivedAtUtc":"2026-01-26T03:03:36.000Z","from":"\\"Zhijie Hou (Fujitsu)\\" <houzj.fnst@fujitsu.com>","subject":"RE: Newly created replication slot may be invalidated by checkpoint","messageId":"<TY4PR01MB169076CE653659F8F8BC984729493A@TY4PR01MB16907.jpnprd01.prod.outlook.com>","body":"On Friday, January 23, 2026 5:06 PM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n> \\n> On Fri, Jan 23, 2026 at 7:33 AM Zhijie Hou (Fujitsu) <houzj.fnst@fujitsu.com>\\n> wrote:\\n> >\\n> > This patch cannot be applied cleanly on backbranches, I can prepare\\n> > patches for those once the main patch is stable.\\n> >\\n> \\n> Some comments:\\n> 1.\\n> + /*\\n> + * Determine the minimum non-removable LSN by comparing the redo\\n> + pointer\\n> + * with the minimum slot LSN.\\n> + */\\n> + min_safe_lsn = GetRedoRecPtr();\\n> + slot_min_lsn = XLogGetReplicationSlotMinimumLSN();\\n> \\n> Can we expand these comments a bit to state why we need both RedoRecPtr\\n> and slot's minimum LSN?\\n\\nAdded some comments for this.\\n\\n> \\n> 2.\\n> +# Verify that while syncing a slot to the standby server, if the WAL\\n> +before the # remote restart_lsn is at risk of being removed by a\\n> +checkpoint, the slot # cannot be synced. Otherwise, even if the slot\\n> +syncing succeeds, it may be # immediately invalidated by the checkpoint.\\n> +my $primary = $node;\\n> \\n> This comment atop the testcase is not very clear. Because, it is testing that\\n> the slot is synced and is not invalidated. How about:\\n> \\"Verify that the synchronized slots won't be invalidated immediately after\\n> synchronization in the presence of a concurrent checkpoint.\\"?\\n\\nThanks, I have changed to use the suggested version.\\n\\n> \\n> 3.\\n> +# Increase the log_min_messages setting to DEBUG2 on both the standby\\n> +and # primary to debug test failures, if any.\\n> +my $connstr_1 = $primary->connstr;\\n> \\n> Do we need this DEBUG2? I don't think we should add too many DEBUG2\\n> tests as it increases Log volume.\\n\\nRemoved.\\n\\nHere are the V4 patches for both HEAD and back branches.\\n\\nBest Regards,\\nHou zj\\n\\n"},{"id":"19bf8cd293731139","threadId":"19be897af3bbca01","snippet":"Dear Hou, Thanks for updating the patch. I ran tests and reproducer [1] for all versions. Confirmed the issue happened before the patch and fixed after applying them. One difference between master and","historyId":"22986","internalDate":"1769405737000","receivedAtUtc":"2026-01-26T05:35:37.000Z","from":"\\"Hayato Kuroda (Fujitsu)\\" <kuroda.hayato@fujitsu.com>","subject":"RE: Newly created replication slot may be invalidated by checkpoint","messageId":"<TY7PR01MB14554C9C81D84F9D25B1D7F51F593A@TY7PR01MB14554.jpnprd01.prod.outlook.com>","body":"Dear Hou,\\n\\nThanks for updating the patch. I ran tests and reproducer [1] for all versions.\\nConfirmed the issue happened before the patch and fixed after applying them.\\n\\nOne difference between master and others is that pg_sync_replication_slots()\\non HEAD is not returned. Because the behavior was changed by 0d2d4a0, not\\nrelated with the fix.\\n\\nI feel these patches are enough good shape.\\n\\n[1]: https://www.postgresql.org/message-id/TY7PR01MB14554DBE84290130EB421DD28F596A%40TY7PR01MB14554.jpnprd01.prod.outlook.com\\n\\nBest regards,\\nHayato Kuroda\\nFUJITSU LIMITED\\n\\n"},{"id":"19bf9a9cd762e11b","threadId":"19be897af3bbca01","snippet":"> On Jan 26, 2026, at 13:35, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > Dear Hou, > > Thanks for updating the patch. I ran tests and reproducer [1] for all","historyId":"22986","internalDate":"1769420159000","receivedAtUtc":"2026-01-26T09:35:59.000Z","from":"Chao Li <li.evan.chao@gmail.com>","subject":"Re: Newly created replication slot may be invalidated by checkpoint","messageId":"<5073F4B4-35FB-4BC1-AB07-22C7498884C4@gmail.com>","body":"\\n\\n> On Jan 26, 2026, at 13:35, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> \\n> Dear Hou,\\n> \\n> Thanks for updating the patch. I ran tests and reproducer [1] for all versions.\\n> Confirmed the issue happened before the patch and fixed after applying them.\\n> \\n> One difference between master and others is that pg_sync_replication_slots()\\n> on HEAD is not returned. Because the behavior was changed by 0d2d4a0, not\\n> related with the fix.\\n> \\n> I feel these patches are enough good shape.\\n> \\n> [1]: https://www.postgresql.org/message-id/TY7PR01MB14554DBE84290130EB421DD28F596A%40TY7PR01MB14554.jpnprd01.prod.outlook.com\\n> \\n> Best regards,\\n> Hayato Kuroda\\n> FUJITSU LIMITED\\n> \\n\\nYeah, I agree v4 is solid. I have a few nitpicks:\\n\\n1 - commit message\\n```\\nWAL reservation and checkpoints, this creates a race conditions where\\n```\\n\\nTypo: a race conditions => a race condition\\n\\n2 - commit message\\n```\\nbefore the the slotsync updates the restart_lsn. This is because in slotsync\\n```\\n\\nTypo: the the => the\\n\\n3 - slotsync.c\\n```\\n+\\t * This can happen because the initial restart_lsn received from the\\n+\\t * remote server can precede redo pointer. Therefore, when selecting the\\n```\\n\\nI think we need to add \\"the\\" before \\"redo pointer\\": the remote server can precede the redo pointer.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n"}]	This discussion focuses on a race condition bug where newly created replication slots can be immediately invalidated by checkpoints. The issue occurs when slot synchronization happens concurrently with checkpoint operations. Zhijie Hou addressed Amit Kapila's review feedback by adding clearer comments explaining the need for both RedoRecPtr and slot minimum LSN, improving test case comments, and removing unnecessary DEBUG2 logging. Hayato Kuroda confirmed that the V4 patches successfully fixed the issue across all PostgreSQL versions and that test reproducers validate the solution. Chao Li endorsed the patches as solid but suggested minor cosmetic fixes including typo corrections in commit messages and improving code comments. The patches are now considered ready for final implementation with only minor editorial adjustments needed.\n这个讨论重点关注一个竞态条件缺陷，即新创建的复制槽可能会立即被检查点操作无效化。该问题发生在槽同步与检查点操作并发执行时。侯志杰根据Amit Kapila的审查反馈，添加了更清晰的注释来解释同时需要RedoRecPtr和槽最小LSN的原因，改进了测试用例注释，并移除了不必要的DEBUG2日志记录。黑田早人确认V4补丁成功修复了所有PostgreSQL版本的问题，测试重现器验证了解决方案。李超认为补丁很稳定，但建议进行轻微的修饰性修改，包括修正提交信息中的拼写错误和改进代码注释。补丁现在被认为可以最终实现，只需要进行轻微的编辑调整。	2026-01-26 09:35:59+00	\N
22	19bfaa2fe006e548	Exit walsender before confirming remote flush in logical replication	["a.silitskiy@postgrespro.ru","aekorotkov@gmail.com","amit.kapila16@gmail.com","andres@anarazel.de","dilipbalaut@gmail.com","horikyota.ntt@gmail.com","htamfids@gmail.com","kuroda.hayato@fujitsu.com","masao.fujii@gmail.com","michael@paquier.xyz","osumi.takamichi@fujitsu.com","peter.eisentraut@enterprisedb.com","sawada.mshk@gmail.com","smithpb2250@gmail.com","v.davydov@postgrespro.ru"]	[{"id":"19bfaa2fe006e548","threadId":"19bfaa2fe006e548","snippet":"On Thu, Jan 22, 2026 at 12:11 AM Andrey Silitskiy <a.silitskiy@postgrespro.ru> wrote: > > Dear Vitaliy, > Thanks for reproducing the error. > > The problem occurred during a test","historyId":"23035","internalDate":"1769436519000","receivedAtUtc":"2026-01-26T14:08:39.000Z","from":"Fujii Masao <masao.fujii@gmail.com>","subject":"Re: Exit walsender before confirming remote flush in logical replication","messageId":"<CAHGQGwGotoS0VeMDdK6ezkhvdQpWZ5oJvO3QKJKEV6Pc+rZ_9A@mail.gmail.com>","body":"On Thu, Jan 22, 2026 at 12:11 AM Andrey Silitskiy\\n<a.silitskiy@postgrespro.ru> wrote:\\n>\\n> Dear Vitaliy,\\n> Thanks for reproducing the error.\\n>\\n> The problem occurred during a test case with a full output buffer after\\n> adding ereport about the termination of walsender process in immediate mode.\\n> ereport sends message by default if replica is interested in this logging\\n> level(WARNING level fit this description). And since the output buffer was\\n> already full, the message could not be sent and the process could not exit.\\n>\\n> Changed the logging level to LOG_SERVER_ONLY to exclude sending a message\\n> to the replica during immediate shutdown.\\n\\nYou changed the log level used by ereport() in WalSndDoneImmediate() to\\nLOG_SERVER_ONLY, but proc_exit() can still emit messages at other levels.\\nThat could result in attempts to send additional messages to the standby.\\nTo avoid this, should whereToSendOutput be reset, as is done\\nin WalSndShutdown()?\\n\\n\\n> In my environment, this error was not reproduced due to the fact that\\n> buffers did not have time to fill up because pg_ctl stop was called\\n> immediately after data was inserted and the buffers did not have time to\\n> fill up and ereport did not hang.\\n>\\n> I added a wait for sent_lsn from pg_stat_replication to stop advancing\\n> in the test before server shutdown to give walsender time to fill output\\n> buffers.\\n\\nThanks for addressing the issue and updating the patch!\\n\\n\\nThere seems also an alternative way to implement immediate shutdown of\\nwalsenders: if wal_sender_shutdown_mode is set to immediate, the postmaster\\ncould send SIGTERM to walsenders, just as it does to backends. In that case,\\nwalsenders would exit without waiting for WAL replication, and the shutdown\\nsequence could proceed normally. With this approach, WalSndDoneImmediate()\\nwould no longer be needed. I'm still unsure which approach is better....\\n\\nOne issue with the SIGTERM-based approach is that walsenders call\\nereport(FATAL) on exit and may try to send the error message to the standby.\\nIf the send buffer is full, the walsender could block in ereport(). This would\\nneed to be addressed if we go that route.\\n\\nBTW, this issue can also occur when terminating a walsender via\\npg_terminate_backend() (for maintenance, etc.). If that is considered\\nproblematic on its own, it might be better handled as a separate patch first.\\n\\n\\nRegarding the GUC name, wal_sender_shutdown seems simple and sufficient to me.\\nThis isn't a blocker, so I'm fine with the current name for now and\\nrevisiting it later if needed.\\n\\n\\nOn the documentation, there's at least one reference to shutdown behavior\\nin high-availability.sgml. Since this patch changes walsender shutdown behavior,\\nthat section should be updated as well.\\n\\n\\n+        In <literal>immediate</literal> mode, the walsender will exit\\nwithout waiting\\n+        for data replication to the receiver. This may break data\\nconsistency between\\n+        sender and receiver after shutdown, which can be especially\\nimportant in\\n+        case of physical replication and switch-over.\\n\\nIt seems clearer to clarify the benefit of wait_flush in relation to\\nswitchovers, rather than focusing only risks. For example:\\n\\n----------------------\\nSpecifies how a walsender process terminates after receiving a shutdown\\nrequest. Valid values are wait_flush and immediate. The default is wait_flush.\\nThis setting can be configured per walsender.\\n\\nIn wait_flush mode, the walsender waits until all WAL data has been flushed on\\nthe receiver before exiting. This helps keep the sender and receiver in sync\\nafter shutdown, which is especially important for physical replication\\nswitchovers. However, it can delay server shutdown.\\n\\nIn immediate mode, the walsender exits without waiting for WAL data to be\\nreplicated to the receiver. This can reduce shutdown time when flushing\\nWAL data to the receiver would take a long time, for example on high-latency\\nnetworks or when the subscriber's apply worker is blocked waiting for locks\\nin logical replication.\\n----------------------\\n\\n\\nThere's no strict rule for the ordering of parameter descriptions, but it seems\\nmore intuitive to place wal_sender_shutdown_mode immediately after\\nwal_sender_timeout, rather than after track_commit_timestamp,\\nsince the former two are more closely related. If we do that,\\npostgresql.conf.sample should be updated accordingly.\\n\\n\\n+#wal_sender_shutdown_mode = wait_flush  # walsender termination mode after\\n+                                # receival of shutdown request\\n\\nIn postgresql.conf.sample, enum GUCs typically list their valid values in\\nthe comment. It would be good to do the same for wal_sender_shutdown_mode.\\n\\n\\nAt the top of walsender.c, there are comments describing walsender behavior,\\nincluding shutdown handling. Since this patch changes shutdown behavior,\\nthose comments should be updated.\\n\\n\\n+typedef enum\\n+{\\n+ WALSND_SHUTDOWN_MODE_WAIT_FLUSH = 0,\\n+ WALSND_SHUTDOWN_MODE_IMMEDIATE\\n+} WalSndShutdownMode;\\n\\nWalSndShutdownMode should be added into src/tools/pgindent/typedefs.list\\nfor pgindent.\\n\\n\\n+ * NB: This should only be called when immediate shutdown of walsender\\n+ * was requested and shutdown signal has been received from postmaster.\\n\\nThe comment on WalSndDoneImmediate() says it is only called after a shutdown\\nsignal from the postmaster, but it can also be called when the checkpointer\\nsignals walsenders to move to the stopping state (got_STOPPING = true),\\nwhich may happen earlier. So this comment seems to need to be updated.\\nOr, if this comment is true, WalSndDoneImmediate() should not be called under\\ngot_STOPPING=true.\\n\\n\\n+ proc_exit(0);\\n+ abort();\\n+}\\n\\nabort() call at the end of WalSndDoneImmediate() does not seem necessary.\\nPlease see the discussion [1].\\n\\nRegards,\\n\\n[1] https://postgr.es/m/CAHGQGwHPX1yoixq+YB5rF4zL90TMmSEa3FpHURtqW3Jc5+=oSA@mail.gmail.com\\n\\nRegards,\\n\\n-- \\nFujii Masao\\n\\n\\n"}]	Fujii Masao reviews a patch addressing walsender immediate shutdown issues. Andrey Silitskiy had fixed a problem where ereport messages during shutdown caused hangs when output buffers were full, by changing log levels to LOG_SERVER_ONLY. Fujii raises concerns about proc_exit() still potentially emitting messages and suggests resetting whereToSendOutput. He proposes an alternative SIGTERM-based approach but notes similar blocking issues. The review covers extensive feedback on documentation improvements, GUC parameter placement, code comments needing updates, and removing unnecessary abort() calls. Key issues include handling full buffers during shutdown and ensuring proper termination without blocking on message sends to standbys.\n\n藤井正雄审查了一个解决walsender立即关闭问题的补丁。Andrey Silitskiy修复了一个问题：关闭过程中ereport消息在输出缓冲区满时导致挂起，通过将日志级别改为LOG_SERVER_ONLY解决。藤井担心proc_exit()仍可能发出消息，建议重置whereToSendOutput。他提出基于SIGTERM的替代方案，但指出类似的阻塞问题。审查涵盖了大量反馈，包括文档改进、GUC参数放置、代码注释更新需求，以及移除不必要的abort()调用。关键问题包括处理关闭期间的缓冲区满问题，确保正确终止而不在向备库发送消息时阻塞。	2026-01-26 14:08:39+00	\N
22	19bec801a96f066e	unnecessary executor overheads around seqscans	["amit.kapila16@gmail.com","amitlangote09@gmail.com","andres@anarazel.de","dgrowleyml@gmail.com","hlinnaka@iki.fi","robertmhaas@gmail.com"]	{"{\\"id\\":\\"19bf550622c9b6dc\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote: > On 2026-01-24 19:36:08 +1300, David Rowley wrote: > > diff --git a/src/backend/executor/nodeSeqscan.cb/src/\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769347220000\\",\\"receivedAtUtc\\":\\"2026-01-25T13:20:20.000Z\\",\\"from\\":\\"David Rowley <dgrowleyml@gmail.com>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<CAApHDvriDesugxt4oi4ePp-kvHpMojpYXk46AFhXFO-b6uH-8w@mail.gmail.com>\\",\\"body\\":\\"On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote:\\\\n> On 2026-01-24 19:36:08 +1300, David Rowley wrote:\\\\n> > diff --git a/src/backend/executor/nodeSeqscan.c b/src/backend/executor/nodeSeqscan.c\\\\n> > index b8119face43..87420e60dc9 100644\\\\n> > --- a/src/backend/executor/nodeSeqscan.c\\\\n> > +++ b/src/backend/executor/nodeSeqscan.c\\\\n> > @@ -63,17 +63,6 @@ SeqNext(SeqScanState *node)\\\\n> >       direction = estate->es_direction;\\\\n> >       slot = node->ss.ss_ScanTupleSlot;\\\\n> >\\\\n> > -     if (scandesc == NULL)\\\\n> > -     {\\\\n> > -             /*\\\\n> > -              * We reach here if the scan is not parallel, or if we're serially\\\\n> > -              * executing a scan that was planned to be parallel.\\\\n> > -              */\\\\n> > -             scandesc = table_beginscan(node->ss.ss_currentRelation,\\\\n> > -                                                                estate->es_snapshot,\\\\n> > -                                                                0, NULL);\\\\n> > -             node->ss.ss_currentScanDesc = scandesc;\\\\n> > -     }\\\\n>\\\\n> What about the \\\\\\"if we're serially executing a scan that was planned to be\\\\n> parallel.\\\\\\" part? I frankly don't really know what precisely was referencing...\\\\n\\\\nI think that comment is wrong and that maybe it worked that way at\\\\nsome point when Parallel Seq Scan was in development, but it doesn't\\\\nseem to work that way today, and does not appear to have when Parallel\\\\nSeq Scan was committed. It's pretty easy to see that code isn't\\\\ntriggered just by setting max_parallel_workers to 0 and running query\\\\nwhich triggers a Parallel Seq Scan. I think that's what \\\\\\"serially\\\\nexecuting a scan that was planned to be parallel\\\\\\" means, right? The\\\\ndebug_parallel_query = on case uses a non-parallel Seq scan.\\\\n\\\\nOne user-visible side effect of initialising the TableScanDesc during\\\\nplan initialisation rather than on the first row is that the stats\\\\nwill record the Seq Scan even if it's never executed in the plan.\\\\nCurrently what we do there is somewhat inconsistent as with a Parallel\\\\nSeq Scan we'll count the seq scan stat if the Gather node is executed,\\\\nregardless of if the Seq Scan node gets executed: ExecGather ->\\\\nExecInitParallelPlan -> ExecParallelInitializeDSM ->\\\\nExecSeqScanInitializeDSM -> table_beginscan_parallel. But with a\\\\nnon-parallel Seq Scan, the scan will be tracked after fetching the\\\\nfirst row.\\\\n\\\\nAdded Robert to see if he remembers about the comment or can shed some\\\\nlight on it.\\\\n\\\\nDavid\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bf7eef96516a76\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote: > On 2026-01-24 19:36:08 +1300, David Rowley wrote: > > I also noticed my compiler does not inline SeqNext().\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769391170000\\",\\"receivedAtUtc\\":\\"2026-01-26T01:32:50.000Z\\",\\"from\\":\\"David Rowley <dgrowleyml@gmail.com>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<CAApHDvpc7ab5pTrfHtJo1FBVruCvUBq22FvrJvNwc1nau80WBg@mail.gmail.com>\\",\\"body\\":\\"On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote:\\\\n> On 2026-01-24 19:36:08 +1300, David Rowley wrote:\\\\n> > I also noticed my compiler does not inline SeqNext(). Adding a\\\\n> > pg_attribute_always_inline results in it getting inlined and gives a\\\\n> > small speedup.\\\\n>\\\\n> Oh,m that's not good. I think we really had assumed that it would with the 18\\\\n> changes around this. It does here, but that's probably because I use -O3.\\\\n\\\\nTo reduce the variables here, I've pushed a fix for that after a quick\\\\ntest showed a 3.9% speedup on a 1 million row table with a single int4\\\\ncolumn filtering out all rows. I noticed that clang also didn't inline\\\\nwith -O2. It does now.\\\\n\\\\nDavid\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bf841ce5aff55b\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote: > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote: > > We can use a pg_assume()\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769396599000\\",\\"receivedAtUtc\\":\\"2026-01-26T03:03:19.000Z\\",\\"from\\":\\"David Rowley <dgrowleyml@gmail.com>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<CAApHDvpJ=HAnfCqywhduqYHWabXeKJKfKSCVA-+v84DTbUxO8Q@mail.gmail.com>\\",\\"body\\":\\"On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote:\\\\n> On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\\\n> >   We can use a pg_assume() in table_scan_getnextslot() to make the compiler\\\\n> >   understand.\\\\n>\\\\n> Something like this?\\\\n>\\\\n>     result = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\\\n>     pg_assume(result == !TupIsNull(slot));\\\\n>     return result;\\\\n>\\\\n> I assume this relies on table_scan_getnextslot() being inlined into\\\\n> ExecScanExtended()?\\\\n\\\\nI looked at the objdump of this, and it does seem to get rid of the extra check.\\\\n\\\\nI did:\\\\n\\\\ncd src/backend/executor\\\\ngcc -Wall -Wmissing-prototypes -Wpointer-arith\\\\n-Wdeclaration-after-statement -Werror=vla -Wendif-labels\\\\n-Wmissing-format-attribute -Wimplicit-fallthrough=3\\\\n-Wcast-function-type -Wshadow=compatible-local -Wformat-security\\\\n-Wmissing-variable-declarations -fno-strict-aliasing -fwrapv\\\\n-fexcess-precision=standard -Wno-format-truncation\\\\n-Wno-stringop-truncation -O2 -I../../../src/include -D_GNU_SOURCE -g\\\\n-c nodeSeqscan.c\\\\nobjdump -d -M intel -S nodeSeqscan.o > nodeSeqscan_pg_assume.s\\\\n\\\\nLooking at ExecSeqScanWithQual, I see:\\\\n\\\\nmaster:\\\\nreturn sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\\\n 22c: 48 8b 07              mov    rax,QWORD PTR [rdi]\\\\n 22f: 4c 89 f2              mov    rdx,r14\\\\n 232: 44 89 fe              mov    esi,r15d\\\\n 235: 48 8b 80 40 01 00 00 mov    rax,QWORD PTR [rax+0x140]\\\\n 23c: ff 50 28              call   QWORD PTR [rax+0x28]\\\\nif (table_scan_getnextslot(scandesc, direction, slot))\\\\n 23f: 84 c0                test   al,al <-- *** this test and the\\\\nsubsequent jump equal are removed\\\\n 241: 74 6d                je     2b0 <ExecSeqScanWithQual+0x100>\\\\nif (TupIsNull(slot))\\\\n 243: 41 f6 46 04 02        test   BYTE PTR [r14+0x4],0x2\\\\n 248: 75 69                jne    2b3 <ExecSeqScanWithQual+0x103>\\\\n 24a: 48 8b 45 28          mov    rax,QWORD PTR [rbp+0x28]\\\\n\\\\nAnd with your pg_assume added:\\\\nresult = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\\\n 22c: 48 8b 07              mov    rax,QWORD PTR [rdi]\\\\n 22f: 4c 89 f2              mov    rdx,r14\\\\n 232: 44 89 fe              mov    esi,r15d\\\\n 235: 48 8b 80 40 01 00 00 mov    rax,QWORD PTR [rax+0x140]\\\\n 23c: ff 50 28              call   QWORD PTR [rax+0x28]\\\\npg_assume(result == !TupIsNull(slot));\\\\n 23f: 41 f6 46 04 02        test   BYTE PTR [r14+0x4],0x2\\\\n 244: 75 62                jne    2a8 <ExecSeqScanWithQual+0xf8>\\\\n 246: 48 8b 45 28          mov    rax,QWORD PTR [rbp+0x28]\\\\n\\\\nI didn't test the performance.\\\\n\\\\nDavid\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bf946139f5ceef\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On Mon, Jan 26, 2026 at 12:03 PM David Rowley <dgrowleyml@gmail.com> wrote: > On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote: > > On Sat, Jan 24, 2026\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769413651000\\",\\"receivedAtUtc\\":\\"2026-01-26T07:47:31.000Z\\",\\"from\\":\\"Amit Langote <amitlangote09@gmail.com>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<CA+HiwqGVzd43bSiQ+g=7RESM=8kZsZQUCZiVz_fzzNH3N1zX0A@mail.gmail.com>\\",\\"body\\":\\"On Mon, Jan 26, 2026 at 12:03 PM David Rowley <dgrowleyml@gmail.com> wrote:\\\\n> On Sat, 24 Jan 2026 at 19:21, Amit Langote <amitlangote09@gmail.com> wrote:\\\\n> > On Sat, Jan 24, 2026 at 5:16 AM Andres Freund <andres@anarazel.de> wrote:\\\\n> > >   We can use a pg_assume() in table_scan_getnextslot() to make the compiler\\\\n> > >   understand.\\\\n> >\\\\n> > Something like this?\\\\n> >\\\\n> >     result = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\\\n> >     pg_assume(result == !TupIsNull(slot));\\\\n> >     return result;\\\\n> >\\\\n> > I assume this relies on table_scan_getnextslot() being inlined into\\\\n> > ExecScanExtended()?\\\\n>\\\\n> I looked at the objdump of this, and it does seem to get rid of the extra check.\\\\n>\\\\n> I did:\\\\n>\\\\n> cd src/backend/executor\\\\n> gcc -Wall -Wmissing-prototypes -Wpointer-arith\\\\n> -Wdeclaration-after-statement -Werror=vla -Wendif-labels\\\\n> -Wmissing-format-attribute -Wimplicit-fallthrough=3\\\\n> -Wcast-function-type -Wshadow=compatible-local -Wformat-security\\\\n> -Wmissing-variable-declarations -fno-strict-aliasing -fwrapv\\\\n> -fexcess-precision=standard -Wno-format-truncation\\\\n> -Wno-stringop-truncation -O2 -I../../../src/include -D_GNU_SOURCE -g\\\\n> -c nodeSeqscan.c\\\\n> objdump -d -M intel -S nodeSeqscan.o > nodeSeqscan_pg_assume.s\\\\n>\\\\n> Looking at ExecSeqScanWithQual, I see:\\\\n>\\\\n> master:\\\\n> return sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\\\n>  22c: 48 8b 07              mov    rax,QWORD PTR [rdi]\\\\n>  22f: 4c 89 f2              mov    rdx,r14\\\\n>  232: 44 89 fe              mov    esi,r15d\\\\n>  235: 48 8b 80 40 01 00 00 mov    rax,QWORD PTR [rax+0x140]\\\\n>  23c: ff 50 28              call   QWORD PTR [rax+0x28]\\\\n> if (table_scan_getnextslot(scandesc, direction, slot))\\\\n>  23f: 84 c0                test   al,al <-- *** this test and the\\\\n> subsequent jump equal are removed\\\\n>  241: 74 6d                je     2b0 <ExecSeqScanWithQual+0x100>\\\\n> if (TupIsNull(slot))\\\\n>  243: 41 f6 46 04 02        test   BYTE PTR [r14+0x4],0x2\\\\n>  248: 75 69                jne    2b3 <ExecSeqScanWithQual+0x103>\\\\n>  24a: 48 8b 45 28          mov    rax,QWORD PTR [rbp+0x28]\\\\n>\\\\n> And with your pg_assume added:\\\\n> result = sscan->rs_rd->rd_tableam->scan_getnextslot(sscan, direction, slot);\\\\n>  22c: 48 8b 07              mov    rax,QWORD PTR [rdi]\\\\n>  22f: 4c 89 f2              mov    rdx,r14\\\\n>  232: 44 89 fe              mov    esi,r15d\\\\n>  235: 48 8b 80 40 01 00 00 mov    rax,QWORD PTR [rax+0x140]\\\\n>  23c: ff 50 28              call   QWORD PTR [rax+0x28]\\\\n> pg_assume(result == !TupIsNull(slot));\\\\n>  23f: 41 f6 46 04 02        test   BYTE PTR [r14+0x4],0x2\\\\n>  244: 75 62                jne    2a8 <ExecSeqScanWithQual+0xf8>\\\\n>  246: 48 8b 45 28          mov    rax,QWORD PTR [rbp+0x28]\\\\n>\\\\n> I didn't test the performance.\\\\n\\\\nThanks for sharing that.\\\\n\\\\nI tried my patch over your committed SeqNext inlining patch and ran\\\\nthe following benchmark but didn't notice in material difference:\\\\n\\\\nCREATE TABLE t (a int);\\\\nINSERT INTO t SELECT generate_series(1, 1000000);\\\\nANALYZE t;\\\\nSET max_parallel_workers_per_gather = 0;\\\\nSELECT * FROM t WHERE a = -1;\\\\n\\\\nPerhaps not too surprising given it's just eliminating a couple of\\\\ninstructions per row that the branch predictor probably handles well\\\\nanyway? Still seems worth having for code hygiene if nothing else.\\\\n\\\\nSame result (no diff in perf) when I apply it over your patch to move\\\\nthe scandesc == NULL check.\\\\n\\\\n-- \\\\nThanks, Amit Langote\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bfa2afdf5a8d89\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On Sat, Jan 24, 2026 at 9:01 PM Andres Freund <andres@anarazel.de> wrote: > > On 2026-01-24 15:23:44 +0530, Amit Kapila wrote: > > On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769428656000\\",\\"receivedAtUtc\\":\\"2026-01-26T11:57:36.000Z\\",\\"from\\":\\"Amit Kapila <amit.kapila16@gmail.com>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<CAA4eK1K1aUYLR3EunwAMNkA4cEzSNng+kwZUA-1DKp572H3-9A@mail.gmail.com>\\",\\"body\\":\\"On Sat, Jan 24, 2026 at 9:01 PM Andres Freund <andres@anarazel.de> wrote:\\\\n>\\\\n> On 2026-01-24 15:23:44 +0530, Amit Kapila wrote:\\\\n> > On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote:\\\\n> > >\\\\n> > > - The checkXidAlive checks that have been added to table_scan_getnextslot()\\\\n> > >   show up noticeably and in every loop iteration, despite afaict never being reachable\\\\n> > >\\\\n> > >   It's not obvious to me that this should\\\\n> > >   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\\\n> > >      change in the middle of a scan? That would require a wrapper around\\\\n> > >      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\\\n> > >   b) not just be an assertion?\\\\n> > >\\\\n> >\\\\n> > IIRC, the main reason for having this precautionary check in the API\\\\n> > is to ensure that during logical decoding we never access the table AM\\\\n> > or\\\\n> > heap APIs directly when scanning catalog tables. This restriction\\\\n> > exists because we only check for concurrent aborts inside the\\\\n> > systable_* APIs.\\\\n>\\\\n> I know why the check exists - but why does it have to be in\\\\n> table_scan_getnextslot(), which is executed very frequently, rather than\\\\n> table_beginscan*(), which is executed much less frequently.\\\\n>\\\\n\\\\nI thought about this point and couldn't think of any reason why this\\\\ncheck can't be in table_beginscan*(). I think your idea of having a\\\\nwrapper around scan_begin() to handle this check is a good one.\\\\n\\\\n-- \\\\nWith Regards,\\\\nAmit Kapila.\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bfae739ae7d19f\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On 23/01/2026 22:16, Andres Freund wrote: > Hi, > > In [1] I was looking at the profile of a seqscan with a where clause that > doesn't match any of the many rows. I was a bit saddened\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769440996000\\",\\"receivedAtUtc\\":\\"2026-01-26T15:23:16.000Z\\",\\"from\\":\\"Heikki Linnakangas <hlinnaka@iki.fi>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<2c266fc0-8cd0-41c3-bd28-a874c422d158@iki.fi>\\",\\"body\\":\\"On 23/01/2026 22:16, Andres Freund wrote:\\\\n> Hi,\\\\n> > In [1] I was looking at the profile of a seqscan with a where clause that\\\\n> doesn't match any of the many rows.  I was a bit saddened by where we were\\\\n> spending time.\\\\n> > > - The fetching of variables, as well as the null check of scandesc, in\\\\n>    SeqNext() is repeated in every loop iteration of ExecScanExtended, despite\\\\n>    that obviously not being required after the first iteration\\\\n> >    We could perhaps address this by moving the check to the callers of\\\\n>    ExecScanExtended() or by extending ExecScanExtended to have an explicit\\\\n>    beginscan callback that it calls after.\\\\n\\\\nFor context, we're talking about this in SeqNext:\\\\n\\\\n> \\\\t/*\\\\n> \\\\t * get information from the estate and scan state\\\\n> \\\\t */\\\\n> \\\\tscandesc = node->ss.ss_currentScanDesc;\\\\n> \\\\testate = node->ss.ps.state;\\\\n> \\\\tdirection = estate->es_direction;\\\\n> \\\\tslot = node->ss.ss_ScanTupleSlot;\\\\n\\\\nHmm. I guess the compiler doesn't know that the variables don't change between calls, so it has to fetch them on every iteration. Passing them through a 'const' pointer might give it clue, but I'm not sure how to shoehorn that here.\\\\n\\\\nPerhaps we should turn the ExecScanExtended() function inside out. Instead of passing SeqNext as a callback to ExecScanExtended(), we would have a function like this (for illustration purposes only, doesn't compile):\\\\n\\\\n> /* ----------------------------------------------------------------\\\\n>  *\\\\t\\\\tExecSeqNextInline\\\\n>  *\\\\n>  *\\\\t\\\\tThis is a workhorse for ExecSeqScan. It's inlined into\\\\n>  *\\\\t\\\\tspecialized implementations for cases where epqstate, qual,\\\\n>  *\\\\t\\\\tprojInfo are NULL or not.\\\\n>  * ----------------------------------------------------------------\\\\n>  */\\\\n> static pg_attribute_always_inline TupleTableSlot *\\\\n> ExecSeqScanInline(SeqScanState *node,\\\\n> \\\\t\\\\t\\\\t\\\\t  EPQState *epqstate,\\\\n> \\\\t\\\\t\\\\t\\\\t  ExprState *qual,\\\\n> \\\\t\\\\t\\\\t\\\\t  ProjectionInfo *projInfo)\\\\n> {\\\\n> \\\\t/*\\\\n> \\\\t * get information from the estate and scan state\\\\n> \\\\t */\\\\n> \\\\tscandesc = node->ss.ss_currentScanDesc;\\\\n> \\\\testate = node->ss.ps.state;\\\\n> \\\\tdirection = estate->es_direction;\\\\n> \\\\tslot = node->ss.ss_ScanTupleSlot;\\\\n> > \\\\tif (scandesc == NULL)\\\\n> \\\\t{\\\\n> \\\\t\\\\t/*\\\\n> \\\\t\\\\t * We reach here if the scan is not parallel, or if we're serially\\\\n> \\\\t\\\\t * executing a scan that was planned to be parallel.\\\\n> \\\\t\\\\t */\\\\n> \\\\t\\\\tscandesc = table_beginscan(node->ss.ss_currentRelation,\\\\n> \\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t   estate->es_snapshot,\\\\n> \\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t   0, NULL);\\\\n> \\\\t\\\\tnode->ss.ss_currentScanDesc = scandesc;\\\\n> \\\\t}\\\\n> > \\\\tfor (;;)\\\\n> \\\\t{\\\\n> \\\\t\\\\t/* do ExecScanFetch(), except for the call to SeqScanNext */\\\\n> \\\\t\\\\tslot = ExecScanFetchEPQ(...);\\\\n> > \\\\t\\\\t/*\\\\n> \\\\t\\\\t * get the row next tuple from the table\\\\n> \\\\t\\\\t */\\\\n> \\\\t\\\\tif (slot == NULL)\\\\n> \\\\t\\\\t\\\\tslot = table_scan_getnextslot(scandesc, direction, slot);\\\\n> > \\\\t\\\\tif (slot == NULL)\\\\n> \\\\t\\\\t\\\\tbreak;\\\\n> > \\\\t\\\\t/*\\\\n> \\\\t\\\\t * Does it pass the quals? (This does the parts of ExecScanExtended()\\\\n> \\\\t\\\\t * after the ExecScanFetch() call)\\\\n> \\\\t\\\\t */\\\\n> \\\\t\\\\tslot = ExecScanProjectAndFilter(&node->ss, slot, qual, projInfo);\\\\n> \\\\t\\\\tif (slot)\\\\n> \\\\t\\\\t\\\\treturn slot;\\\\n> \\\\t}\\\\n> \\\\treturn NULL;\\\\n> }\\\\n\\\\n- Heikki\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bfb4e706da6645\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On 2026-01-26 14:32:50 +1300, David Rowley wrote: > On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote: > > On 2026-01-24 19:36:08 +1300, David Rowley wrote: >\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769447768000\\",\\"receivedAtUtc\\":\\"2026-01-26T17:16:08.000Z\\",\\"from\\":\\"Andres Freund <andres@anarazel.de>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<nn62scnhjr3ihmzinhtcltzvixm5ep6gttia4u6emznzkkc3ib@iglpwqgtwjir>\\",\\"body\\":\\"On 2026-01-26 14:32:50 +1300, David Rowley wrote:\\\\n> On Sun, 25 Jan 2026 at 04:36, Andres Freund <andres@anarazel.de> wrote:\\\\n> > On 2026-01-24 19:36:08 +1300, David Rowley wrote:\\\\n> > > I also noticed my compiler does not inline SeqNext(). Adding a\\\\n> > > pg_attribute_always_inline results in it getting inlined and gives a\\\\n> > > small speedup.\\\\n> >\\\\n> > Oh,m that's not good. I think we really had assumed that it would with the 18\\\\n> > changes around this. It does here, but that's probably because I use -O3.\\\\n> \\\\n> To reduce the variables here, I've pushed a fix for that after a quick\\\\n> test showed a 3.9% speedup on a 1 million row table with a single int4\\\\n> column filtering out all rows. I noticed that clang also didn't inline\\\\n> with -O2. It does now.\\\\n\\\\nThanks!\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bfb7e994d4bf24\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"Hi, On 2026-01-26 16:47:31 +0900, Amit Langote wrote: > I tried my patch over your committed SeqNext inlining patch and ran > the following benchmark but didn't notice in material difference:\\",\\"historyId\\":\\"23000\\",\\"internalDate\\":\\"1769450925000\\",\\"receivedAtUtc\\":\\"2026-01-26T18:08:45.000Z\\",\\"from\\":\\"Andres Freund <andres@anarazel.de>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<ia64rgzcqwtmmgimovwiaj7qbzk3s2hvwto2i3obcv7u6sjhue@a5zvxu7y7e57>\\",\\"body\\":\\"Hi,\\\\n\\\\nOn 2026-01-26 16:47:31 +0900, Amit Langote wrote:\\\\n> I tried my patch over your committed SeqNext inlining patch and ran\\\\n> the following benchmark but didn't notice in material difference:\\\\n> \\\\n> CREATE TABLE t (a int);\\\\n> INSERT INTO t SELECT generate_series(1, 1000000);\\\\n> ANALYZE t;\\\\n\\\\nBecause the table isn't frozen, visibility checks will probably add enough\\\\nper-row overhead to make any per-row micro-optimization harder to see.  On my\\\\nsomewhat older workstation freezing is a 17% improvement.\\\\n\\\\n\\\\n> SET max_parallel_workers_per_gather = 0;\\\\n> SELECT * FROM t WHERE a = -1;\\\\n> \\\\n> Perhaps not too surprising given it's just eliminating a couple of\\\\n> instructions per row that the branch predictor probably handles well\\\\n> anyway? Still seems worth having for code hygiene if nothing else.\\\\n> \\\\n> Same result (no diff in perf) when I apply it over your patch to move\\\\n> the scandesc == NULL check.\\\\n\\\\nFWIW, on my cascade lake workstation it's a, surprisingly large, 3.5%, after\\\\nfreezing. Without freezing there maybe still is a difference, but it's very\\\\nclose to the noise floor.\\\\n\\\\nGreetings,\\\\n\\\\nAndres Freund\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bfca0caec460c1\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"Hi, On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote: > On 23/01/2026 22:16, Andres Freund wrote: > > Hi, > > > > In [1] I was looking at the profile of a seqscan with a\\",\\"historyId\\":\\"24083\\",\\"internalDate\\":\\"1769469944000\\",\\"receivedAtUtc\\":\\"2026-01-26T23:25:44.000Z\\",\\"from\\":\\"Andres Freund <andres@anarazel.de>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<qugnsw6pkl3ab4ttke3b2kwiq3kur46xegx5omuvv6z3vwcznh@562ojlz2oqia>\\",\\"body\\":\\"Hi,\\\\n\\\\nOn 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote:\\\\n> On 23/01/2026 22:16, Andres Freund wrote:\\\\n> > Hi,\\\\n> >\\\\n> > In [1] I was looking at the profile of a seqscan with a where clause that\\\\n> > doesn't match any of the many rows.  I was a bit saddened by where we were\\\\n> > spending time.\\\\n> >\\\\n> >\\\\n> > - The fetching of variables, as well as the null check of scandesc, in\\\\n> >    SeqNext() is repeated in every loop iteration of ExecScanExtended, despite\\\\n> >    that obviously not being required after the first iteration\\\\n> >\\\\n> >    We could perhaps address this by moving the check to the callers of\\\\n> >    ExecScanExtended() or by extending ExecScanExtended to have an explicit\\\\n> >    beginscan callback that it calls after.\\\\n>\\\\n> For context, we're talking about this in SeqNext:\\\\n>\\\\n> > \\\\t/*\\\\n> > \\\\t * get information from the estate and scan state\\\\n> > \\\\t */\\\\n> > \\\\tscandesc = node->ss.ss_currentScanDesc;\\\\n> > \\\\testate = node->ss.ps.state;\\\\n> > \\\\tdirection = estate->es_direction;\\\\n> > \\\\tslot = node->ss.ss_ScanTupleSlot;\\\\n>\\\\n> Hmm. I guess the compiler doesn't know that the variables don't change\\\\n> between calls, so it has to fetch them on every iteration. Passing them\\\\n> through a 'const' pointer might give it clue, but I'm not sure how to\\\\n> shoehorn that here.\\\\n\\\\nMy understanding is that compilers very rarely utilize const on pointers for\\\\noptimization. The problem is that just because the current pointer is const\\\\ndoesn't mean there aren't other *non-const* pointers. And since there are a\\\\nlot of external function calls involved here, there's no way the compiler\\\\ncould provide that that isn't the case :(.\\\\n\\\\n\\\\n> Perhaps we should turn the ExecScanExtended() function inside out. Instead\\\\n> of passing SeqNext as a callback to ExecScanExtended(), we would have a\\\\n> function like this (for illustration purposes only, doesn't compile):\\\\n\\\\nThat would be one approach, would require structural changes in a fair number\\\\nof places though :/.\\\\n\\\\nA slightly simpler approach could be for ExecScanExtended to pass in these\\\\nparameters as arguments to the callbacks. For things like estate, direction\\\\nand scanslot, that makes plenty sense. It's a bit more problematic for the\\\\nscan descriptor, due to the \\\\\\"lazy start\\\\\\" we have in a few places.\\\\n\\\\nI very briefly prototyped that (relying on the fact that all callers cast to\\\\nthe callback type and that passing unused arguments just works even if the\\\\nfunction definition doesn't expect them), and that seems to do the trick.\\\\n\\\\nWhat shows up more visibly afterwards is that we set ExecScanExtended() sets\\\\necontext->ecxt_scantuple in every iteration, despite that not changing in\\\\nalmost all cases (I think for FDWs it could, fdwhandler.sgml just says that\\\\nthe scanslot \\\\\\"should\\\\\\" be used).\\\\n\\\\nGreetings,\\\\n\\\\nAndres Freund\\\\n\\\\n\\\\n\\"}","{\\"id\\":\\"19bfd51ff0aaaec7\\",\\"threadId\\":\\"19bec801a96f066e\\",\\"snippet\\":\\"On Tue, Jan 27, 2026 at 3:08 AM Andres Freund <andres@anarazel.de> wrote: > > Hi, > > On 2026-01-26 16:47:31 +0900, Amit Langote wrote: > > I tried my patch over your committed\\",\\"historyId\\":\\"24510\\",\\"internalDate\\":\\"1769481540000\\",\\"receivedAtUtc\\":\\"2026-01-27T02:39:00.000Z\\",\\"from\\":\\"Amit Langote <amitlangote09@gmail.com>\\",\\"subject\\":\\"Re: unnecessary executor overheads around seqscans\\",\\"messageId\\":\\"<CA+HiwqE9g2tb96hgrNH81Q5PeK3YnwT7nrmVCnRWJVjFpKAtEA@mail.gmail.com>\\",\\"body\\":\\"On Tue, Jan 27, 2026 at 3:08 AM Andres Freund <andres@anarazel.de> wrote:\\\\n>\\\\n> Hi,\\\\n>\\\\n> On 2026-01-26 16:47:31 +0900, Amit Langote wrote:\\\\n> > I tried my patch over your committed SeqNext inlining patch and ran\\\\n> > the following benchmark but didn't notice in material difference:\\\\n> >\\\\n> > CREATE TABLE t (a int);\\\\n> > INSERT INTO t SELECT generate_series(1, 1000000);\\\\n> > ANALYZE t;\\\\n>\\\\n> Because the table isn't frozen, visibility checks will probably add enough\\\\n> per-row overhead to make any per-row micro-optimization harder to see.  On my\\\\n> somewhat older workstation freezing is a 17% improvement.\\\\n>\\\\n> > SET max_parallel_workers_per_gather = 0;\\\\n> > SELECT * FROM t WHERE a = -1;\\\\n> >\\\\n> > Perhaps not too surprising given it's just eliminating a couple of\\\\n> > instructions per row that the branch predictor probably handles well\\\\n> > anyway? Still seems worth having for code hygiene if nothing else.\\\\n> >\\\\n> > Same result (no diff in perf) when I apply it over your patch to move\\\\n> > the scandesc == NULL check.\\\\n>\\\\n> FWIW, on my cascade lake workstation it's a, surprisingly large, 3.5%, after\\\\n> freezing. Without freezing there maybe still is a difference, but it's very\\\\n> close to the noise floor.\\\\n\\\\nI did freeze but still don't see a measurable difference.  Though, I\\\\ntested on a VM, so the noise floor is probably higher than on your\\\\nbare metal workstation.  I'll try later on bare metal.\\\\n\\\\n-- \\\\nThanks, Amit Langote\\\\n\\\\n\\\\n\\"}"}	\N	\N	\N
22	19be5000123f9d5e	Optional skipping of unchanged relations during ANALYZE?	["dgrowleyml@gmail.com","ilya.evdokimov@tantorlabs.com","myon@debian.org","rob@xzilla.net","robertmhaas@gmail.com","samimseih@gmail.com","vasukianand0119@gmail.com"]	[{"id":"19bf6124df4abf8c","threadId":"19be5000123f9d5e","snippet":"> > > Relation to vacuumdb --missing-stats-only > > > I agree this is related but slightly different in intent. --missing-stats-only > > > answers "does this table have any","historyId":"22981","internalDate":"1769359929000","receivedAtUtc":"2026-01-25T16:52:09.000Z","from":"Sami Imseih <samimseih@gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","messageId":"<CAA5RZ0uBRmE5k6Q=8PkrttDVwgDh9r=fN0TTHsU48sb_E7KfMw@mail.gmail.com>","body":"> > > Relation to vacuumdb --missing-stats-only\\n> > > I agree this is related but slightly different in intent. --missing-stats-only\\n> > > answers "does this table have any statistics at all?", while SMART ANALYZE\\n> > > answers "has this table changed since the last statistics collection?". Both seem\\n> > > useful, but they target different use cases. I see SMART ANALYZE primarily\\n> > > as a performance optimization for repeated manual ANALYZE runs on mostly-static schemas.\\n> >\\n> > SMART ANALYZE is trying to answer 2 questions \\"which table does not\\n> > have any statistics at all\\"\\n> > and \\"has this table changed since the last statistics collection?", right?\\n> >\\n> > So, maybe they need to be 2 separate options.\\n> >\\n> > > Although as sami said this SMART is not smart enough as it should be ,\\n> > > I will change name accordingly in the further patches\\n> >\\n> > Yup, I am not too fond of SMART in the name. Also, then name itself\\n> > is vague. SKIP_LOCKED and BUFFER_USAGE_LIMIT on the other\\n> > hand tell you exactly what they[re used for.\\n> >\\n>\\n> So, tossing out a new proposal here, which is to offer ANALYZE with 2\\n> new options... MISSING_STATS and MODIFIED_STATS.\\n\\nYes, that is what I am thinking as well.\\n\\n> When MISSING_STATS is passed, we attempt to analyze only tables that\\n> have missing stats, essentially implementing a version of\\n> --missing-stats-only but for the ANALYZE command. In successive runs,\\n> this should reduce towards a no-op, although we need to decide what to\\n> do about system tables, which, iirc --missing-stats-only always\\n> assumes to be true, but this version probably doesn't want to assume\\n> that.\\n\\nFrom a quick test, I don't see system tables being treated different\\n\\n```\\npostgres=# select max(last_analyze), max(last_autoanalyze) from\\npg_stat_all_tables where relname = 'pg_class';\\n max | max\\n-----+-----\\n     |\\n(1 row)\\n\\npostgres=# delete from pg_statistic;\\nDELETE 417\\npostgres=# \\\\! vacuumdb --analyze-only --missing-stats-only postgres\\nvacuumdb: vacuuming database \\"postgres\\"\\npostgres=# select max(last_analyze), max(last_autoanalyze) from\\npg_stat_all_tables where relname = 'pg_class';\\n              max              | max\\n-------------------------------+-----\\n 2026-01-25 16:31:42.839329+00 |\\n(1 row)\\n\\npostgres=# \\\\! vacuumdb --analyze-only --missing-stats-only postgres\\nvacuumdb: vacuuming database \\"postgres\\"\\npostgres=#\\npostgres=# select max(last_analyze), max(last_autoanalyze) from\\npg_stat_all_tables where relname = 'pg_class';\\n              max              | max\\n-------------------------------+-----\\n 2026-01-25 16:31:42.839329+00 |\\n(1 row)\\n```\\n\\nTables that remain empty, will always be analyzed since they will\\nalways have \\"missing stats\\".\\nFor example pg_sequence, if a sequence is never created. The same\\napplies for normal\\nuser tables.\\n\\n> When MODIFIED_STATS is passed, we would instead only analyze tables\\n> where some threshold of rows has been modified. I feel like the most\\n> obvious choice for this calculation would be based on a formula like\\n> \\"analyze threshold = analyze base threshold + analyze scale factor *\\n> number of tuples\\". Astute observers will note that this is the same\\n> threshold used by autoanalyze, which means if you had the same\\n> defaults you are just doing the work manually that autoanalyze would\\n> eventually get around to doing (which seems potentially useful on its\\n> own).\\n\\nYes, we would want to use the same calculation as autoanalyze.\\n\\n> But also if these were based on gucs, the OP could modify those\\n> gucs to achieve their desired behavior, ie.\\n> set analyze_base_threshold=1; set analyze_scale_factor=0; analyze\\n> (modified_stats);  // this should analyze anything with 1 modified row\\n> Granted, I don't like that it is both more wordy than the original\\n> idea, and that we would need to add new gucs, but this would be pretty\\n> flexible.\\n\\nWe can either allow the threshold and scale_factor be an argument to\\nthe option; but I do really think the GUC approach is much better.\\n\\nNot in scope, but I can even see vacuum_threshold and vacuum_scale_factor\\nto allow us to control VACUUM the same way.\\n\\nOverall, this becomes very handy for scripting of manual ANALYZE\\nand VACUUM.\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n"},{"id":"19bf62f1c42f74ed","threadId":"19be5000123f9d5e","snippet":">> I agree with this, but I think it's more than just tables that have >> not been analyzed. >> What if a new column is added after the last (auto)analyze. Would we not want to","historyId":"22981","internalDate":"1769361819000","receivedAtUtc":"2026-01-25T17:23:39.000Z","from":"Sami Imseih <samimseih@gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","messageId":"<CAA5RZ0t=fGScwGL9=_HJzXf3808-U4zqne+qAob6R2PYcj-9YA@mail.gmail.com>","body":">> I agree with this, but I think it's more than just tables that have\\n>> not been analyzed.\\n>> What if a new column is added after the last (auto)analyze. Would we not want to\\n>> trigger an analyze in that case?\\n>>\\n\\n> Well, I don't know that we are \\"triggering\\" anything, but this is\\n> definitely a case where we have \\"missing stats\\".\\n\\n> When MISSING_STATS is passed, we attempt to analyze only tables that\\n> have missing stats, essentially implementing a version of\\n> --missing-stats-only\\n\\nI also want to do add that the benefit of implementing a --missing-stats\\nfo ANALYZE is that the timestamps in pg_stat_all_tables are cleared on\\ncrash recovery, but pg_statistic is obviously persistent. So it is\\nbetter to look directly there as --missing-stats-only does for vacuumdb.\\n\\nunfortunately, this is not the case for n_mod_since_analyze, because that\\ndoes not survive. There is discussion about improving this situation\\nhowever [0].\\n\\n\\n[0] https://www.postgresql.org/message-id/20240607033806.6gwgolihss72cj6r@awork3.anarazel.de\\n\\n--\\nSami Imseih\\nAmazon Web Services (AWS)\\n\\n\\n"},{"id":"19bfddcf3a4c09d2","threadId":"19be5000123f9d5e","snippet":">Maybe this is all an aside, but I don't think that was the vision for >what the OP was trying to do with his patch, in that sense he was >approaching it from a different angle, and I'","historyId":"25077","internalDate":"1769490669000","receivedAtUtc":"2026-01-27T05:11:09.000Z","from":"VASUKI M <vasukianand0119@gmail.com>","subject":"Re: Optional skipping of unchanged relations during ANALYZE?","messageId":"<CAE2r8H5+kdis5JZxte_i7f1X8AVyUedh_PW1Kc5iOHaFV9=7Qw@mail.gmail.com>","body":">Maybe this is all an aside, but I don't think that was the vision for\\n>what the OP was trying to do with his patch, in that sense he was\\n>approaching it from a different angle, and I've been reading this\\n>thread trying to decide if people are just talking past each other.\\n>But after thinking about it some more, I think the above might be the\\n>more useful mental model for the discussion.\\n\\nHi Robert,\\n\\nThanks for taking the time to step back and summarize the discussion —\\nthat's very helpful.\\n\\nI agree that part of the thread drifted toward broader questions about\\nwhen ANALYZE should run optimally, whereas my original\\nintent was narrower: providing a simple, explicit way to skip work that is\\nknown to be unnecessary when running ANALYZE\\nacross many relations. I appreciate you calling out that distinction.\\n\\nAlso, just a small note: I'm a she, not a he :)\\n\\ncoming to other mails:\\n\\nThanks everyone, this discussion has been extremely helpful.\\n\\nI agree with the framing that has emerged here: there are really two\\nseparate questions involved:\\n\\n1) Which relations are missing statistics entirely?\\n2) Which relations have statistics, but may need them refreshed due to\\n   modifications?\\n\\nMy original SMART ANALYZE prototype was trying to approximate both with\\na very simple rule, but I agree that this makes the option vague and\\nharder to reason about, especially once cases like new columns, crash\\nrecovery, extended statistics, and persistence are considered.\\n\\nThe idea of introducing explicit options such as ANALYZE (MISSING_STATS)\\nand ANALYZE (MODIFIED_STATS) feels like a much cleaner direction.\\nIn particular, starting with MISSING_STATS as a SQL-level equivalent of\\nvacuumdb --missing-stats-only seems like a well-scoped and low-risk\\nfirst step.\\n\\nI also agree that relying solely on pg_stat counters (e.g.\\nn_mod_since_analyze) has limitations due to their non-persistence across\\ncrashes, which further supports handling "missing stats" separately\\nvia catalog inspection.\\n\\nI'm happy to pivot in this direction and focus first on a clear,\\nwell-defined MISSING_STATS option for ANALYZE, and then revisit\\nMODIFIED_STATS (possibly reusing autoanalyze-style thresholds) as a\\nfollow-up, once there is agreement on the semantics.\\n\\nThanks again for the thoughtful feedback — it's been very educational.\\n\\n\\nBest regards,\\nVasuki M\\nC-DAC,Chennai.\\n"}]	The discussion centers around evolving SMART ANALYZE into more specific ANALYZE options. The original proposal for SMART ANALYZE was attempting to answer two questions: "which tables lack statistics?" and "which tables changed since last statistics collection?" However, reviewers found the name vague and suggested splitting this into two separate options: MISSING_STATS and MODIFIED_STATS. MISSING_STATS would act as a SQL equivalent to vacuumdb's --missing-stats-only, checking for tables without statistics by examining the pg_statistic catalog. MODIFIED_STATS would analyze tables based on modification thresholds, potentially reusing autoanalyze's calculation formula. Key advantages include better persistence than pg_stat counters (which are cleared on crash recovery) and improved scriptability for manual ANALYZE operations. The original patch author agrees with this direction and plans to focus first on implementing MISSING_STATS as a well-scoped initial step before addressing MODIFIED_STATS in follow-up work.\n\n讨论围绕将SMART ANALYZE发展为更具体的ANALYZE选项展开。最初的SMART ANALYZE提案试图回答两个问题："哪些表缺少统计信息？"和"哪些表自上次统计信息收集以来发生了变化？"然而，审查者认为该名称模糊，建议将其分为两个独立选项：MISSING_STATS和MODIFIED_STATS。MISSING_STATS将作为vacuumdb的--missing-stats-only的SQL等效项，通过检查pg_statistic目录来查找没有统计信息的表。MODIFIED_STATS将基于修改阈值分析表，可能重用自动分析的计算公式。主要优势包括比pg_stat计数器更好的持久性（在崩溃恢复时被清除）以及改进手动ANALYZE操作的脚本能力。原始补丁作者同意这个方向，计划首先专注于实现MISSING_STATS作为一个范围明确的初始步骤，然后在后续工作中解决MODIFIED_STATS。	2026-01-27 05:11:09+00	\N
22	19be67781ef21b94	AIX support	["andres@anarazel.de","hlinnaka@iki.fi","peter@eisentraut.org","postgres-ibm-aix@wwpdl.vnet.ibm.com","sriram.rk@in.ibm.com","tgl@sss.pgh.pa.us","tristan@partin.io"]	[{"id":"19bfa413868f8630","threadId":"19be67781ef21b94","snippet":"On 23.01.26 17:11, Srirama Kucherlapati wrote: > Hi Peter, > > > It's ok to split changes into multiple patches, and then recommend > which parts you want >> reviewed first.","historyId":"22984","internalDate":"1769430124000","receivedAtUtc":"2026-01-26T12:22:04.000Z","from":"Peter Eisentraut <peter@eisentraut.org>","subject":"Re: AIX support","messageId":"<f6c4e700-73b9-47e7-bf0b-ccb2b7020739@eisentraut.org>","body":"On 23.01.26 17:11, Srirama Kucherlapati wrote:\\n> Hi Peter,\\n> >  > It's ok to split changes into multiple patches, and then recommend > which parts you want\\n>> reviewed first.  But we need to see at least a rough outline of the\\n>  > complete plan before spending significant effort on reviewing the pieces.\\n> Please find attached patches.\\n>      Meson changes    - 0001-Support-for-AIX-pg19-meson.2.diff\\n>      Complete changes - 0001-Support-for-AIX.pg19.v11.patch\\n> > We have updated couple of changes in the full patch wrt to your previous\\n> comments as well. Also, we are working to get the stats for the s_lock.h wrt\\n> TAS. Will submit in a different thread.\\n\\nOk, that patch set looks pretty reasonable now.\\n\\nCan you confirm that this is the complete patch set required for AIX support?\\n\\nWhat version of AIX are you testing with?\\n\\nWhat compilers are you testing with?\\n\\n\\n\\n"},{"id":"19bfad1ecf88b16c","threadId":"19be67781ef21b94","snippet":"> Ok, that patch set looks pretty reasonable now. Thank you, Peter, for taking the time to review the patches. I really appreciate your feedback, and it's great to hear your positive assessment.","historyId":"22984","internalDate":"1769439589000","receivedAtUtc":"2026-01-26T14:59:49.000Z","from":"Srirama Kucherlapati <sriram.rk@in.ibm.com>","subject":"RE: AIX support","messageId":"<SJ4PPFB817783261A2C27D455D0A0706A83DB93A@SJ4PPFB81778326.namprd15.prod.outlook.com>","body":"\\n> Ok, that patch set looks pretty reasonable now.\\n\\nThank you, Peter, for taking the time to review the patches. I really appreciate your feedback, and it's great to hear your positive assessment.\\n\\n> Can you confirm that this is the complete patch set required for AIX support?\\nYes, the complete patch attached in the previous mail has all the changes for AIX support.\\n    Complete changes - 0001-Support-for-AIX.pg19.v11.patch\\n\\n> What version of AIX are you testing with?\\nWe are testing on an AIX 73F node.\\n    oslevel - 7300-03-01-2520\\n\\n> What compilers are you testing with?\\nWe are compiling the source with gcc.\\n    gcc-12 (GCC) 12.3.0\\n\\n\\n\\nWarm regards,\\n\\nSriram.\\n\\n"},{"id":"19bfaf7630155b09","threadId":"19be67781ef21b94","snippet":"Hi, From what I can tell the meson patch *AGAIN* is missing mkldexport.sh. Also, you seem to reference the script as files('port/aix/mkldexport.sh'), but that that's not a path that makes","historyId":"22984","internalDate":"1769442062000","receivedAtUtc":"2026-01-26T15:41:02.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: AIX support","messageId":"<lx56bdyuajddthcksde62fze7k2oiy3pfczbsuu6ppngcvud7j@cjgb2zem42li>","body":"Hi,\\n\\nFrom what I can tell the meson patch *AGAIN* is missing mkldexport.sh. Also,\\nyou seem to reference the script as files('port/aix/mkldexport.sh'), but that\\nthat's not a path that makes sense for our source code structure (nor where\\nthe \\"complete\\" patch adds it).\\n\\nYou really need to actually start testing your patches.\\n\\n\\nDoesn't the meson patch also require the changes to src/tools/gen_export.pl?\\n\\n\\nOn 2026-01-23 16:11:25 +0000, Srirama Kucherlapati wrote:\\n> diff --git a/meson.build b/meson.build\\n> index 6e7ddd74683..17ad9c6ca32 100644\\n> --- a/meson.build\\n> +++ b/meson.build\\n> @@ -198,6 +198,8 @@ endif\\n>  # that purpose.\\n>  portname = host_system\\n>\\n> +dep_static_lib = declare_dependency()\\n\\nAdd a comment saying something like\\n\\n# In some configurations we don't want to install static libraries. For those\\n# dep_static_lib can be set to disabler() below.\\n\\n\\nThe introduction of dep_static_lib should be broken out into its own patch.\\n\\n\\n\\n> +  # This flag is required to make sure the user spefic float.h is\\n> +  # picked instead of the system float.h header file, which doesnot\\n> +  # have definition like float8, etc\\n> +  cflags += '-D_H_FLOAT'\\n\\nI don't understand this one - how does defining _H_FLOAT lead to a different\\nheader being picked? Also, float8 is defined in c.h, so it hardly could be\\ninfluenced by a system float.h header?\\n\\nOur float.h header is only included as \\"utils/float.h\\", so it really shouldn't\\nbe confused with a system header?\\n\\n\\n> @@ -1765,10 +1793,49 @@ endforeach\\n>  # as long, char, short, or int.  Note that we intentionally do not consider\\n>  # any types wider than 64 bits, as allowing MAXIMUM_ALIGNOF to exceed 8\\n>  # would be too much of a penalty for disk and memory space.\\n> -alignof_double = cdata.get('ALIGNOF_DOUBLE')\\n> -if cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>') > alignof_double\\n> -  error('alignment of int64_t is greater than the alignment of double')\\n> -endif\\n> +if host_system != 'aix'\\n> +  alignof_double = cdata.get('ALIGNOF_DOUBLE')\\n> +  if cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>') > alignof_double\\n> +       error('alignment of int64_t is greater than the alignment of double')\\n> +  endif\\n> +else\\n> +  # The AIX 'power' alignment rules apply the natural alignment of the \\"first\\n> +  # member\\" if it is of a floating-point data type (or is an aggregate whose\\n> +  # recursively \\"first\\" member or element is such a type). The alignment\\n> +  # associated with these types for subsequent members use an alignment value\\n> +  # where the floating-point data type is considered to have 4-byte alignment.\\n> +  # More info\\n> +  # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=99557\\n> +  #\\n> +  # The double is aligned to 4-bytes on AIX in aggregates. But to maintain\\n> +  # alignement across platforms the max alignment of long should be considered.\\n\\nHow are these \\"AIX 'power' alignment rules\\" for float not just completely\\nbroken?\\n\\nI assume this means that 4 byte aligned floats work just fine, but have\\ndegraded peformance?\\n\\nIs there documentation about this that isn't an already fixed bug report in gcc?\\n\\n\\nMaybe I'm confused, but doesn't this power alignment rule mean that the\\ncc.alignment('double') will always return 8? That computation won't apply the\\n\\"subsequent member\\" rule, and therefore will have an alignment of 8. Which in\\nturn seems to make this entire change pointless?\\n\\n\\n> +  # Get the alignment values\\n> +  ac_cv_alignof_long    = cc.alignment('long', args: test_c_args, prefix: '#include <stdint.h>')\\n> +  ac_cv_alignof_double  = cc.alignment('double', args: test_c_args, prefix: '#include <stdint.h>')\\n> +  ac_cv_alignof_int64_t = cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>')\\n\\nI've previously complained about these av_cv_ variable names. This isn't\\nautoconf. What is this doing here?\\n\\nWhy do we need a platform specific alignment determination for long, int64?\\n\\n\\n> +  message('Alignment of long    : @0@'.format(ac_cv_alignof_long))\\n> +  message('Alignment of double  : @0@'.format(ac_cv_alignof_double))\\n> +  message('Alignment of int64_t : @0@'.format(ac_cv_alignof_int64_t))\\n\\nThese are already going to be output by cc.alignment, this is just redundant,\\nno?\\n\\n\\n> +  # Start with long\\n> +  alignof_double = ac_cv_alignof_long\\n> +  message('MAX ALIGN ac_cv_alignof_long')\\n> +\\n> +  # Compare with double\\n> +  if alignof_double < ac_cv_alignof_double\\n> +    alignof_double = ac_cv_alignof_double\\n> +    message('MAX ALIGN ac_cv_alignof_double')\\n> +  endif\\n> +\\n> +  # Compare with int64_t\\n> +  if alignof_double < ac_cv_alignof_int64_t\\n> +    alignof_double = ac_cv_alignof_int64_t\\n> +    message('MAX ALIGN ac_cv_alignof_int64_t')\\n> +  endif\\n> +endif\\n> +message('MAX ALIGN OF DOUBLE : @0@'.format(alignof_double))\\n\\nThis is a lot of output for something that's just computing a maximum of three\\nvariables.\\n\\n\\n\\n> diff --git a/src/backend/meson.build b/src/backend/meson.build\\n> index b831a541652..4838f245ab3 100644\\n> --- a/src/backend/meson.build\\n> +++ b/src/backend/meson.build\\n> @@ -125,6 +125,24 @@ if host_system == 'windows'\\n>      '--FILEDESC', 'PostgreSQL Server',])\\n>  endif\\n>\\n> +if host_system == 'aix'\\n> +  # The '.' argument leads mkldexport.sh to emit \\"#! .\\", which refers to the\\n> +  # main executable, allowing extension libraries to resolve their undefined\\n> +  # symbols to symbols in the postgres binary.\\n> +  postgres_imp = custom_target('postgres.imp',\\n> +    command: [files('port/aix/mkldexport.sh'), '@INPUT@', '.'],\\n> +    input: postgres_lib,\\n> +    output: 'postgres.imp',\\n> +    capture: true,\\n> +    install: true,\\n> +    install_dir: dir_lib,\\n> +    build_by_default: false,\\n> +  )\\n> +  backend_link_args += '-Wl,-bE:@0@'.format(postgres_imp.full_path())\\n> +  backend_link_depends += postgres_imp\\n> +endif\\n\\nThis should be moved next to the msvc specific block (the one about\\npostgres_def) and should use an elif.\\n\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19bfb69daa749a95","threadId":"19be67781ef21b94","snippet":"Peter Eisentraut <peter@eisentraut.org> writes: > Ok, that patch set looks pretty reasonable now. > Can you confirm that this is the complete patch set required for AIX > support? >","historyId":"22984","internalDate":"1769449537000","receivedAtUtc":"2026-01-26T17:45:37.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: AIX support","messageId":"<190704.1769449537@sss.pgh.pa.us>","body":"Peter Eisentraut <peter@eisentraut.org> writes:\\n> Ok, that patch set looks pretty reasonable now.\\n> Can you confirm that this is the complete patch set required for AIX \\n> support?\\n> What version of AIX are you testing with?\\n> What compilers are you testing with?\\n\\nI tried to build HEAD with 0001-Support-for-AIX.pg19.v11.patch\\non the GCC compile farm (cfarm119.cfarm.net, which is running\\nAIX 7.3); I used gcc 13.3.0.  I observed the following problems:\\n\\n* The patch's changes to configure do not match those to configure.ac.\\nI used configure as-patched, so I don't know if it'd work after\\nre-running autoconf.\\n\\n* In my tree, mkldexport.sh was created without execute permissions,\\ncausing a build failure.  I see that the patch says\\n\\tnew file mode 100755\\nso this is arguably the fault of the rather hoary version of\\npatch(1) that cfarm119 has.  I mention it mainly to remind the\\neventual committer to make sure mkldexport.sh is committed with\\nthe correct permissions.\\n\\n* I got this:\\n\\nIn file included from ../../../../src/include/postgres.h:48,\\n                 from pgstat_slru.c:18:\\npgstat_slru.c:60:11: warning: no previous prototype for 'pgstat_count_slru_truncate64' [-Wmissing-prototypes]\\n   60 | CppConcat(pgstat_count_slru_,stat)(int slru_idx)        \\\\\\n      |           ^~~~~~~~~~~~~~~~~~\\n../../../../src/include/c.h:429:41: note: in definition of macro 'CppConcat'\\n  429 | #define CppConcat(x, y)                 x##y\\n      |                                         ^\\npgstat_slru.c:84:1: note: in expansion of macro 'PGSTAT_COUNT_SLRU'\\n   84 | PGSTAT_COUNT_SLRU(truncate)\\n      | ^~~~~~~~~~~~~~~~~\\n\\nand then\\n\\nld: 0711-317 ERROR: Undefined symbol: .pgstat_count_slru_truncate\\n\\nOn investigation, this is happening because <unistd.h> has\\n\\n\\t#define   truncate        truncate64\\n\\nwhich causes \\"PGSTAT_COUNT_SLRU(truncate)\\" to expand as\\n\\"pgstat_count_slru_truncate64\\", which is not the name declared in\\npgstat.h.  An even more unfortunate result is that the \\"truncate\\"\\nfield in PgStat_SLRUStats might actually be named \\"truncate64\\",\\ndepending on whether <unistd.h> was read before pgstat.h.\\n\\nI got around that by partially reverting eccba079c2ea:\\n\\ndiff --git a/src/backend/utils/activity/pgstat_slru.c b/src/backend/utils/activity/pgstat_slru.c\\nindex 2190f388eae..4d8ad3f20fc 100644\\n--- a/src/backend/utils/activity/pgstat_slru.c\\n+++ b/src/backend/utils/activity/pgstat_slru.c\\n@@ -81,7 +81,11 @@ PGSTAT_COUNT_SLRU(blocks_written)\\n PGSTAT_COUNT_SLRU(flush)\\n \\n /* pgstat_count_slru_truncate */\\n-PGSTAT_COUNT_SLRU(truncate)\\n+void\\n+pgstat_count_slru_truncate(int slru_idx)\\n+{\\n+       get_slru_entry(slru_idx)->truncate += 1;\\n+}\\n\\nI didn't have to make any other changes, so it seems that we are\\ncurrently consistent about always reading <unistd.h> first, but this\\nseems terribly fragile.  We probably need some more-invasive answer,\\nlike changing both the function and field name to \\"trunc\\" or something\\nlike that.\\n\\n* I also got some warnings:\\n\\nauth.c: In function 'auth_peer':\\nauth.c:1877:13: warning: implicit declaration of function 'getpeereid' [-Wimplicit-function-declaration]\\n 1877 |         if (getpeereid(port->sock, &uid, &gid) != 0)\\n\\npg_locale_libc.c: In function 'wchar2char':\\npg_locale_libc.c:1243:26: warning: implicit declaration of function 'wcstombs_l'; did you mean 'wcstombs'? [-Wimplicit-function-declaration]\\n 1243 |                 result = wcstombs_l(to, from, tolen, loc);\\n\\nfe-connect.c: In function 'PQconnectPoll':\\nfe-connect.c:3598:45: warning: implicit declaration of function 'getpeereid'; did you mean 'getpwuid'? [-Wimplicit-function-declaration]\\n 3598 |                                         if (getpeereid(conn->sock, &uid, &gid) != 0)\\n\\nThese did not break the build (so the functions do exist...) but\\nthey need to be fixed.\\n\\nAfter all that I was able to get through \\"make\\" and \\"make install\\",\\nbut testing failed immediately:\\n\\nbash-5.3$ initdb\\nexec(): 0509-036 Cannot load program initdb because of the following errors:\\n        0509-022 Cannot load module /home/tgl/testversion/lib/libpq.a(libpq.so.5).\\n        0509-150   Dependent module libgcc_s.a(shr.o) could not be loaded.\\n        0509-022 Cannot load module libgcc_s.a(shr.o).\\n        0509-026 System error: A file or directory in the path name does not exist.\\n\\nSo there's something wrong with the make rules for using libpq.so.\\nI do not know anything about AIX, so I can't debug this.\\n\\nI was unable to test the meson patches, because meson isn't installed\\non this machine.\\n\\nI haven't actually read the patch, so don't take this as an\\nendorsement of the changes otherwise.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"}]	The discussion centers on PostgreSQL patches for AIX support submitted by Srirama Kucherlapati. Peter Eisentraut initially found the patch set "pretty reasonable" and requested confirmation about completeness, AIX version (7.3), and compiler (gcc-12). However, Andres Freund identified critical issues in the Meson patches: missing mkldexport.sh file, incorrect file paths, unclear float alignment logic with _H_FLOAT flag, redundant variable naming conventions, and structural problems. Tom Lane tested the patches on AIX 7.3 with gcc 13.3.0 and encountered multiple build failures: configure/configure.ac mismatches, permission issues with mkldexport.sh, symbol naming conflicts caused by AIX's truncate/truncate64 macro redefinition affecting PGSTAT_COUNT_SLRU, missing function prototypes for getpeereid and wcstombs_l, and runtime library loading failures preventing initdb execution. The patches require substantial fixes before acceptance.\n\n该讨论围绕Srirama Kucherlapati提交的PostgreSQL AIX支持补丁展开。Peter Eisentraut最初认为补丁集"相当合理"，并要求确认完整性、AIX版本(7.3)和编译器(gcc-12)。然而，Andres Freund发现了Meson补丁中的关键问题：缺失mkldexport.sh文件、错误的文件路径、_H_FLOAT标志的float对齐逻辑不清晰、冗余的变量命名约定和结构问题。Tom Lane在AIX 7.3上使用gcc 13.3.0测试补丁，遇到了多个构建失败：configure/configure.ac不匹配、mkldexport.sh权限问题、AIX的truncate/truncate64宏重定义导致的符号命名冲突影响PGSTAT_COUNT_SLRU、getpeereid和wcstombs_l缺失函数原型，以及阻止initdb执行的运行时库加载失败。这些补丁在被接受之前需要大量修复。	2026-01-26 17:45:37+00	\N
22	19bea52b86e5169b	docs: clarify ALTER TABLE behavior on partitioned tables	["amit.kapila16@gmail.com","david.g.johnston@gmail.com","li.evan.chao@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19bf88444f8415c0","threadId":"19bea52b86e5169b","snippet":"> On Jan 24, 2026, at 08:57, David G. Johnston <david.g.johnston@gmail.com> wrote: > > Thank you for the review! > > On Fri, Jan 23, 2026 at 3:07 AM Zsolt Parragi <zsolt.parragi","historyId":"22991","internalDate":"1769400927000","receivedAtUtc":"2026-01-26T04:15:27.000Z","from":"Chao Li <li.evan.chao@gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<C3E25893-E862-4EA4-825C-BEB5CE3B62C2@gmail.com>","body":"\\n\\n> On Jan 24, 2026, at 08:57, David G. Johnston <david.g.johnston@gmail.com> wrote:\\n> \\n> Thank you for the review!\\n> \\n> On Fri, Jan 23, 2026 at 3:07 AM Zsolt Parragi <zsolt.parragi@percona.com> wrote:\\n> + When applied to a partitioned table, the constraint is altered on the\\n> + partitioned table definition is implicitly applied to all partitions.\\n> \\n> an \\"and\\" is missing here (definition and is)\\n> \\n> Correct.  But I'd go with:\\n> \\n> ...the constraint is altered on the partitioned table and implicitly applied to all partitions.\\n> \\n\\nFixed with David's version.\\n\\n> +      When applied to a partitioned table, partition columns constraints\\n> +      are implicitly renamed and specifying <literal>ONLY</literal>\\n> is not allowed.\\n> +     </para>\\n> \\n> \\"partition columns constraints\\" - that seems like a strange/unclear\\n> wording to me. maybe \\", the partition's column constraints are ... \\" ?\\n> \\n> This is just wrong - only is not permitted for either columns or constraints.  Only cannot be implicit if cascading is allowed.\\n> The unclear wording noted is just missing an \\"and\\" - of the three things that can be renamed (relation name, column name, constraint name) only these two apply.\\n> \\"the partition columns and constraints...\\"\\n> \\n>      <para>\\n>       When applied to a partitioned table, partition columns and constraints\\n>       are implicitly renamed.\\n>       Specifying <literal>ONLY</literal> is not allowed, and this command\\n>       cannot be used on individual partitions.\\n>      </para>\\n>      <para>\\n>       For inheritance setups, index-based constraints are always considered\\n>       independent.  ~~Dependent columns and constraints are implicitly renamed\\n>       and specifying <literal>ONLY</literal> is not allowed.~~\\n>      </para>\\n> \\n> The last sentence is redundant with the notes though, I'd remove it as noted above:\\n> \\n>    <para>\\n>     For inheritance setups, the behavior described for partitioned tables applies\\n>     only to the dependent column(s) on the descendant table(s).  It is always\\n>     allowed to target a descendant table with column altering commands on independent\\n>     columns.\\n>    </para>\\n> \\n> But that note should have \\"dependent constraints\\" added to it.\\n> \\n\\nI added the missing "and". And updated the "for inheritance" paragraph as suggested.\\n\\nBut for \\"Specifying <literal>ONLY</literal> is not allowed, and this command, cannot be used on individual partitions.", that doesn't seem correct. See my test:\\n```\\nevantest=# create table root (i int, j int) partition by list(i);\\nCREATE TABLE\\nevantest=# create table p1 partition of root for values in (1);\\nCREATE TABLE\\nevantest=# alter table p1 rename to pp1; <== Rename a partition is allowed.\\nALTER TABLE\\nevantest=# alter table only pp1 rename to p1; <== ONLY can be used, but just no effect\\nALTER TABLE\\n```\\n\\n> +     <para>\\n> +      When applied to a partitioned table <literal>ONLY</literal> is implicit,\\n> +      these forms must be applied separately to the partitioned table and/or to\\n> +      individual partitions.\\n> +     </para>\\n> \\n> \\"When applied to a partitioned table, <literal>ONLY</literal> is\\n> implicit and ...\\"  (at multiple places, this is an example)\\n> \\n> I've grown unfond of my suggested wording here during reviews too.  But because it's too wordy and a bit redundant.\\n> \\n> \\"When applied to a partitioned table ONLY is implicit, however, this command can be used on individual partitions.\\"\\n> \\n> has a better symmetry with:\\n> \\n> Specifying <literal>ONLY</literal> is not allowed, and this command cannot be used on individual partitions.\\n> \\n> \\n> \\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\n> never removes any descendant columns, but instead marks them as\\n> independently defined rather than inherited.\\"\\n> \\n> This part is now undocumented, it was only mentioned in this paragraph.\\n> \\n> True, it's left implied instead of explicitly stated.  Any column that exists on a child but not the parent is by definition \\"independently defined\\".  So if either ONLY is supplied or the rules for cascading delete are not met the result is children with independently defined columns with that name.  The original note was wrong anyway for the two-parent case - the second parent prevents the marking as independent when the first parent's column is dropped.\\n> \\n> \\n> > C2 - Sub-commands where using them with a partitioned table will automatically propagate to child partitions; ONLY prevents propagation; new partitions inherit the parent's new setting; and child partitions can be set to different values than the parent.\\n> \\n> The documentation of this group is inconsistent.\\n> \\n> DROP CONSTRAINT mentions that individual partitions can be dropped separately:\\n> \\n> +      When applied to a partitioned table, the constraint is dropped from\\n> +      all existing partitions unless <literal>ONLY</literal> is specified.\\n> +      Individual partitions may drop constraints independently of the\\n> +      partitioned table.\\n> \\n> But most of the sub commands in the C2 group leave the last sentence\\n> out, and also the C7 (ADD table_constraint)\\n> \\n> I didn't try and verify this dynamic or keep to it - though am on board with considering changes that do so and remain accurate.\\n> \\n> \\n> Also, isn't DROP CONSTRAINT on a partition limited to constraints\\n> defined on that partition? So it would be better to say \\"may drop\\n> constraints defined directly on that individual partition\\n> independently\\".\\n> \\n> \\"When applied to a partitioned table, dependent constraints are dropped from ... is specified.\\" should suffice.\\n> I'd be fine leaving out the entire \\"Individual partitions may drop...\\" business with that wording.  It implies partitions may have independent constraints which by extension may be targeted.  \\n> \\n> For Add Constraint - mention dependent constraints\\n> \\"When applied to a partitioned table, the constraint is added to the partitioned table and dependent constraints are added to all partitions.\\"\\n> \\n> Which implies independent ones may exist and the logic for drop constraint then follows.\\n> (We should explain what happens if a partition already has an independent constraint of the given name as that would be relevant here.)\\n> \\n> \\n>   CREATE TABLE parent (id int, val int) PARTITION BY RANGE (id);\\n>   ALTER TABLE parent ADD CONSTRAINT val_positive CHECK (val > 0);\\n>   CREATE TABLE child PARTITION OF parent FOR VALUES FROM (1) TO (100);\\n>   ALTER TABLE child DROP CONSTRAINT val_positive;\\n>   -- ERROR: cannot drop inherited constraint \\"val_positive\\" of relation \\"child\\"\\n\\nThis is true. I updated the paragraph for DROP CONSTRAINT as:\\n```\\n     <para>\\n      When applied to a partitioned table, the constraint is dropped from\\n      all existing partitions unless <literal>ONLY</literal> is specified.\\n      Dropping an inherited constaint from an individual partition is not allowed.\\n     </para>\\n```\\n\\n> \\n> +      When a new partition is created, it generally inherits the current\\n> +      definition-level properties of the parent partitioned table.\\n> \\n> Maybe something like the following?\\n> \\n> When a new partition is created, it generally inherits structural\\n> properties of the parent partitioned table, such as column\\n> definitions, constraints, and storage settings.\\n> \\n> To be more explicit about what's inherited, and not only focus on\\n> what's not. (The commit message also says that the change describes\\n> both what's inherited and what's not inherited)\\n> \\n> I concur with the premise but how about:\\n> \\n>       When a partition is created, it inherits many of the properties\\n>       of the parent table.  However, properties related to ownership,\\n>       schema, replica identity, row-level security configuration,\\n>       per-attribute statistics targets, and per-attribute options\\n>       are not inherited.\\n> \\n> \\"new\\" is superfluous on this page.\\n> \\"definition-level\\" are the only kind of properties that exist - I'm not being wordy thinking people might believe properties includes data.\\n> \\"parent\\" suffices as well.\\n> We did all the work to identify things - use \\"however\\" instead of \\"in particular\\" to give us credit for the work.\\n> Even if a property is explicitly set for the partition it isn't \\"inherited\\" - the partition has its own independent value that in a rare case might happen to match the parent at the time of creation. (i.e., remove automatically and 'not inherited unless')\\n> I'm not that inclined to mention the inclusion list.  The general premise of assuming inherited unless told otherwise works fine here; minimal future-proofing.\\n> \\n\\nI'm also not included to mention the inclusion list. My other patch [1] is changing replica identity to be inherited. Go forward, the inclusion list should shrink.\\n\\nSo updated with David's version.\\n\\nPFA v7.\\n\\n[1] https://postgr.es/m/CAEoWx2nJ71hy8R614HQr7vQhkBReO9AANPODPg0aSQs74eOdLQ@mail.gmail.com\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n\\n"},{"id":"19bf8851374678c3","threadId":"19bea52b86e5169b","snippet":"> On Jan 24, 2026, at 09:16, David G. Johnston <david.g.johnston@gmail.com> wrote: > > > On Fri, Jan 23, 2026 at 5:57 PM David G. Johnston <david.g.johnston@gmail.com> wrote:","historyId":"22991","internalDate":"1769400984000","receivedAtUtc":"2026-01-26T04:16:24.000Z","from":"Chao Li <li.evan.chao@gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<4ADB3A71-86B2-46FA-AC27-E5BA4E3FF1A1@gmail.com>","body":"\\n\\n> On Jan 24, 2026, at 09:16, David G. Johnston <david.g.johnston@gmail.com> wrote:\\n> \\n> \\n> On Fri, Jan 23, 2026 at 5:57 PM David G. Johnston <david.g.johnston@gmail.com> wrote:\\n> \\n> \\"A nonrecursive DROP COLUMN (i.e., ALTER TABLE ONLY ... DROP COLUMN)\\n> never removes any descendant columns, but instead marks them as\\n> independently defined rather than inherited.\\"\\n> \\n> This part is now undocumented, it was only mentioned in this paragraph.\\n> \\n> True, it's left implied instead of explicitly stated.  Any column that exists on a child but not the parent is by definition \\"independently defined\\".  So if either ONLY is supplied or the rules for cascading delete are not met the result is children with independently defined columns with that name.\\n> \\n>  The original note was wrong anyway for the two-parent case - the second parent prevents the marking as independent when the first parent's column is dropped.\\n> \\n> Decided to test this one and I see the original wording was correct and we will need to keep a note that in the two-parent ONLY case the un-dropped children are marked both dependent and independent.\\n> \\n> Change:\\n> \\n>      <para>\\n>       For inheritance setups, a descendant column is removed only if both of the\\n>       following are true: this is the only parent defining the column, and the column\\n>       was never independently defined in the descendant.\\n>      </para>\\n> \\n> To:\\n> \\n> \\"For inheritance setups, a descendant column is removed only if all the following are true: ONLY is not specified, no other parent defines the column, and the column is not marked as having been independent.  Otherwise, the descendant column is instead marked as having been independent.\\n> \\n> If we think that deserves a bit longer explanation about that/why/how a column can be both dependent and \\"having been independent\\" we should cross-reference to a more appropriate location.  Here we just state this is one way that condition can materialize.\\n> \\n> David J.\\n> \\n\\nThanks a lot for the test. Included in v7.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n"},{"id":"19bf896ba713925c","threadId":"19bea52b86e5169b","snippet":"On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote: > <para> > When applied to a partitioned table, partition columns and constraints > are implicitly renamed.","historyId":"22991","internalDate":"1769402175000","receivedAtUtc":"2026-01-26T04:36:15.000Z","from":"\\"David G. Johnston\\" <david.g.johnston@gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<CAKFQuwa9OEJ_sygQi3fNKxzQz7M6V7-zu=4fL0rquXCjudUoyw@mail.gmail.com>","body":"On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote:\\n\\n>\\n> >      <para>\\n> >       When applied to a partitioned table, partition columns and\\n> constraints\\n> >       are implicitly renamed.\\n> >       Specifying <literal>ONLY</literal> is not allowed, and this command\\n> >       cannot be used on individual partitions.\\n> >      </para>\\n>\\n> But for \\"Specifying <literal>ONLY</literal> is not allowed, and this\\n> command, cannot be used on individual partitions.", that doesn't seem\\n> correct. See my test:\\n> ```\\n> evantest=# create table root (i int, j int) partition by list(i);\\n> CREATE TABLE\\n> evantest=# create table p1 partition of root for values in (1);\\n> CREATE TABLE\\n> evantest=# alter table p1 rename to pp1; <== Rename a partition is allowed.\\n> ALTER TABLE\\n> evantest=# alter table only pp1 rename to p1; <== ONLY can be used, but\\n> just no effect\\n> ALTER TABLE\\n> ```\\n>\\n\\nI was mentally restricting the second sentence about ONLY to the column and\\nconstraints renaming action, which are called out by the first sentence.\\nIt makes little sense to talk about renaming the table, parent or child,\\nhere in the context of ONLY.  It goes without mention that table renaming\\nnever cascades.  Only is implied for that action, even if only should just\\nbe considered valid on a parent in any case.\\n\\nBut I'd accept a sentence like: "Table renames always only apply to the\\nnamed table." Added to that paragraph; it's a convoluted command.\\n\\nDavid J.\\n"},{"id":"19bf8b9208c3b817","threadId":"19bea52b86e5169b","snippet":"> On Jan 26, 2026, at 12:36, David G. Johnston <david.g.johnston@gmail.com> wrote: > > On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote: > > > <para","historyId":"22991","internalDate":"1769404394000","receivedAtUtc":"2026-01-26T05:13:14.000Z","from":"Chao Li <li.evan.chao@gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<D8FD5BAF-2AC0-4289-B96E-D3BD99599BE6@gmail.com>","body":"\\n\\n> On Jan 26, 2026, at 12:36, David G. Johnston <david.g.johnston@gmail.com> wrote:\\n> \\n> On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote:\\n> \\n> >      <para>\\n> >       When applied to a partitioned table, partition columns and constraints\\n> >       are implicitly renamed.\\n> >       Specifying <literal>ONLY</literal> is not allowed, and this command\\n> >       cannot be used on individual partitions.\\n> >      </para>\\n> \\n> But for \\"Specifying <literal>ONLY</literal> is not allowed, and this command, cannot be used on individual partitions.", that doesn't seem correct. See my test:\\n> ```\\n> evantest=# create table root (i int, j int) partition by list(i);\\n> CREATE TABLE\\n> evantest=# create table p1 partition of root for values in (1);\\n> CREATE TABLE\\n> evantest=# alter table p1 rename to pp1; <== Rename a partition is allowed.\\n> ALTER TABLE\\n> evantest=# alter table only pp1 rename to p1; <== ONLY can be used, but just no effect\\n> ALTER TABLE\\n> ```\\n> \\n> I was mentally restricting the second sentence about ONLY to the column and constraints renaming action, which are called out by the first sentence.  It makes little sense to talk about renaming the table, parent or child, here in the context of ONLY.  It goes without mention that table renaming never cascades.  Only is implied for that action, even if only should just be considered valid on a parent in any case.\\n> \\n> But I'd accept a sentence like: "Table renames always only apply to the named table." Added to that paragraph; it's a convoluted command.\\n> \\n> David J.\\n> \\n\\nHow about this:\\n```\\n<para>\\n When applied to a partitioned table to rename columns or constraints,\\n the corresponding partition columns and constraints are renamed\\n implicitly. <literal>ONLY</literal> is not allowed, and the command\\n cannot be used on individual partitions. When the rename target is the\\n table name, only the named table is renamed.\\n</para>\\n```\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n"},{"id":"19bf8cf899130b01","threadId":"19bea52b86e5169b","snippet":"On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote: How about this: ``` <para> When applied to a partitioned table to rename columns or constraints, the corresponding","historyId":"22991","internalDate":"1769405896000","receivedAtUtc":"2026-01-26T05:38:16.000Z","from":"\\"David G. Johnston\\" <david.g.johnston@gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<CAKFQuwbXVypHH=tQEGo-PskaOjnaPwheh7m-PBw-4QDd8bJMeg@mail.gmail.com>","body":"On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote:\\n\\n>\\n> How about this:\\n> ```\\n> <para>\\n>  When applied to a partitioned table to rename columns or constraints,\\n>  the corresponding partition columns and constraints are renamed\\n>  implicitly. <literal>ONLY</literal> is not allowed, and the command\\n>  cannot be used on individual partitions. When the rename target is the\\n>  table name, only the named table is renamed.\\n> </para>\\n> ```\\n>\\n\\n…are renamed implicitly, ONLY is not allowed, and the command cannot…(and\\ndrop the mention of table renaming).\\n\\nOr:\\n\\n"When applied to a partitioned table's name only the parent is changed,\\npartitions must be renamed separately.  However, column or constraint\\nrenaming must be done on the parent without ONLY, the corresponding\\npartition columns or constraints will be renamed implicitly."\\n\\nI find the repeated use of "table" "name(d)" and "rename(d)" in one\\nsentence worth avoiding.\\n\\nDavid J.\\n"},{"id":"19bf92d872e7ec74","threadId":"19bea52b86e5169b","snippet":"> On Jan 26, 2026, at 13:38, David G. Johnston <david.g.johnston@gmail.com> wrote: > > On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote: > > How about this","historyId":"22991","internalDate":"1769412016000","receivedAtUtc":"2026-01-26T07:20:16.000Z","from":"Chao Li <li.evan.chao@gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<BA4C2371-C1E1-4E06-8719-7AED9B01EFF9@gmail.com>","body":"\\n\\n> On Jan 26, 2026, at 13:38, David G. Johnston <david.g.johnston@gmail.com> wrote:\\n> \\n> On Sunday, January 25, 2026, Chao Li <li.evan.chao@gmail.com> wrote:\\n> \\n> How about this:\\n> ```\\n> <para>\\n>  When applied to a partitioned table to rename columns or constraints,\\n>  the corresponding partition columns and constraints are renamed\\n>  implicitly. <literal>ONLY</literal> is not allowed, and the command\\n>  cannot be used on individual partitions. When the rename target is the\\n>  table name, only the named table is renamed.\\n> </para>\\n> ```\\n> \\n> …are renamed implicitly, ONLY is not allowed, and the command cannot…(and drop the mention of table renaming).\\n> \\n> Or:\\n> \\n> "When applied to a partitioned table's name only the parent is changed, partitions must be renamed separately.  However, column or constraint renaming must be done on the parent without ONLY, the corresponding partition columns or constraints will be renamed implicitly."\\n> \\n> I find the repeated use of "table" "name(d)" and "rename(d)" in one sentence worth avoiding.\\n\\nLooks good. I just did a couple of tiny tweaks:\\n\\n * Added a comma between "table's name" and "only": "when applied to a partitioned table's name, only the parent …"\\n * Replaced "however" with "in contrast".\\n\\nPFA v8.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n"},{"id":"19bfac6cb6249b1a","threadId":"19bea52b86e5169b","snippet":"There's one typo (constaint => constraint), otherwise it looks good to me.","historyId":"22991","internalDate":"1769438869000","receivedAtUtc":"2026-01-26T14:47:49.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<CAN4CZFM+vnALQBJ2n9x4njbnm_PQFKXLrPRJ1WYsOUozwz1fsQ@mail.gmail.com>","body":"There's one typo (constaint => constraint), otherwise it looks good to me.\\n\\n\\n"},{"id":"19bfc794221b8722","threadId":"19bea52b86e5169b","snippet":"> On Jan 26, 2026, at 22:47, Zsolt Parragi <zsolt.parragi@percona.com> wrote: > > There's one typo (constaint => constraint), otherwise it looks good to me. Good catch. Fixed. PFA","historyId":"24081","internalDate":"1769467316000","receivedAtUtc":"2026-01-26T22:41:56.000Z","from":"Chao Li <li.evan.chao@gmail.com>","subject":"Re: docs: clarify ALTER TABLE behavior on partitioned tables","messageId":"<C455D9E4-D63D-45D8-8395-4E8583F4B7DA@gmail.com>","body":"\\n\\n> On Jan 26, 2026, at 22:47, Zsolt Parragi <zsolt.parragi@percona.com> wrote:\\n> \\n> There's one typo (constaint => constraint), otherwise it looks good to me.\\n\\nGood catch. Fixed.\\n\\nPFA v8.\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n"}]	This discussion focuses on improving PostgreSQL documentation to clarify ALTER TABLE behavior on partitioned tables. The patch author Chao Li addresses detailed technical reviews from David Johnston and Zsolt Parragi. Key revisions include correcting grammar errors (adding missing conjunctions), clarifying constraints behavior on partitions, refining wording about ONLY clause restrictions, and distinguishing between table renaming versus column/constraint renaming behaviors. The reviewers provide detailed feedback on documentation consistency, testing edge cases like inheritance setups and two-parent scenarios, and ensuring accuracy about constraint dropping limitations on individual partitions. After multiple iterations and typo corrections, the documentation patch reaches approval status, with version 8 incorporating all suggested improvements for better clarity and technical accuracy.\n\n本次讨论聚焦于改进PostgreSQL文档，澄清ALTER TABLE在分区表上的行为。补丁作者Chao Li回应了David Johnston和Zsolt Parragi的详细技术评审。主要修订包括纠正语法错误（添加缺失的连接词）、澄清分区上的约束行为、优化关于ONLY子句限制的措辞，以及区分表重命名与列/约束重命名行为。评审者提供了关于文档一致性的详细反馈，测试继承设置和双父表场景等边缘情况，并确保关于个别分区约束删除限制的准确性。经过多次迭代和拼写错误纠正后，文档补丁获得批准，第8版整合了所有建议的改进，提高了清晰度和技术准确性。	2026-01-26 22:41:56+00	\N
22	19bfd04d9a46c4b2	Implement waiting for wal lsn replay: reloaded	["aekorotkov@gmail.com","alvherre@kurilemu.de","andres@anarazel.de","hlinnaka@iki.fi","jian.universality@gmail.com","li.evan.chao@gmail.com","michael@paquier.xyz","peter@eisentraut.org","thomas.munro@gmail.com","tomas@vondra.me","xunengzhou@gmail.com","y.sokolov@postgrespro.ru"]	[{"id":"19bfd04d9a46c4b2","threadId":"19bfd04d9a46c4b2","snippet":"Hi Alexander, Heikki spotted a misplaced wake-up call for replay waiters in PerformWalRecovery. He suggested that the WaitLSNWakeup needs to be invoked immediately after wal record is applied to avoid","historyId":"24354","internalDate":"1769476483000","receivedAtUtc":"2026-01-27T01:14:43.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>","subject":"Re: Implement waiting for wal lsn replay: reloaded","messageId":"<CABPTF7Wdq6KbvC3EhLX3Pz=ODCCPEX7qVQ+E=cokkB91an2E-A@mail.gmail.com>","body":"Hi Alexander,\\n\\nHeikki spotted a misplaced wake-up call for replay waiters in\\nPerformWalRecovery. He suggested that the WaitLSNWakeup needs to be\\ninvoked immediately after wal record is applied to avoid the potential\\nmissed wake-ups when recovery stops/pauses/promotes. It makes sense to\\nme. Please check the attached patch to fix that.\\n\\n-- \\nBest,\\nXuneng\\n"}]	Xuneng Zhou reports a bug fix identified by Heikki regarding misplaced wake-up calls for replay waiters in the WAL LSN replay implementation. The issue is in PerformWalRecovery where WaitLSNWakeup is not invoked immediately after WAL record application, potentially causing missed wake-ups when recovery stops, pauses, or promotes. Zhou agrees with Heikki's assessment and has provided a patch to correct the timing of the wake-up call. This fix addresses a critical timing issue that could affect processes waiting for specific WAL replay positions during recovery scenarios.\n\n周洵能报告了一个由Heikki发现的关于WAL LSN回放实现中重放等待器唤醒调用位置错误的bug修复。问题出现在PerformWalRecovery中，WaitLSNWakeup没有在WAL记录应用后立即调用，这可能导致在恢复停止、暂停或提升时错过唤醒。周洵能同意Heikki的评估并提供了一个补丁来修正唤醒调用的时机。这个修复解决了一个关键的时机问题，该问题可能影响在恢复场景中等待特定WAL重放位置的进程。	2026-01-27 01:14:43+00	\N
22	19be5345d4172528	Import Statistics in postgres_fdw before resorting to sampling.	["ashutosh.bapat.oss@gmail.com","corey.huinker@gmail.com","etsuro.fujita@gmail.com","jkatz@postgresql.org","michael@paquier.xyz","nathandbossart@gmail.com"]	[{"id":"19bfdfe2c948b37d","threadId":"19be5345d4172528","snippet":"On Fri, Jan 23, 2026 at 10:45 PM Corey Huinker <corey.huinker@gmail.com> wrote: >> >> >> There's an advantage if we can combine stats across multiple relations >> >","historyId":"25192","internalDate":"1769492828000","receivedAtUtc":"2026-01-27T05:47:08.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","messageId":"<CAExHW5vsQK1JVn15DYdsGAQ-qbmce_MyP7F67Ne-JpaaLRYUOg@mail.gmail.com>","body":"On Fri, Jan 23, 2026 at 10:45 PM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>>\\n>> >> There's an advantage if we can combine stats across multiple relations\\n>> >> - we don't have to sample children twice when analyzing the parent\\n>> >> without ONLY. Instead we could produce parent statistics by combining\\n>> >> statistics across children and the parent. To me this looks like\\n>> >> altogether a different beast just like partial aggregates.\\n>> >\\n>> >\\n>> > I think this patch is only ever going to get us out of 1 of the 2 samples, which isn't ideal but it is a savings.\\n>> >\\n>>\\n>> I am not suggesting to synthesize sample rows. Calculate the\\n>> statistics of the parent table from that of its children.\\n>\\n>\\n> I'm not sure we can actually do that. The functions that compute the statistics are all based off of row samples, not already computed statistics. I don't think we can synthesize a rowsample from the imported statistics, at least not accurately. If I'm misunderstanding what you're suggesting, please correct me.\\n\\nI am comparing the calculation of statistics to the calculation of\\naggregates. We have code to compute aggregates on a partitioned table\\nfrom the partial aggregates computed from the individual partitions.\\n(Even though I am mentioning the partitioned table, the technique can\\nbe used for an inheritance hierarchy.) Similarly if we could come up\\nwith a representation of partial statistics, we could get partial\\nstatistics computed for the children (and the parent in\\nnon-partitioned inheritance). Use the partial statistics to compute\\nthe statistics for the parent without the need to synthesize row\\nsamples from the children. I haven't looked at all the kinds of\\nstatistics to see whether this is feasible.\\n\\n--\\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n"}]	The discussion focuses on optimizing statistics collection for postgres_fdw by importing statistics rather than sampling. Ashutosh Bapat proposes an advanced approach similar to partial aggregates, where parent table statistics could be computed by combining statistics from child tables rather than synthesizing row samples. This would eliminate redundant sampling when analyzing parent tables without ONLY clause. Corey Huinker expresses skepticism about the feasibility, noting that current statistics functions are designed to work with row samples, not pre-computed statistics. The approach would require developing a representation of "partial statistics" and investigating whether all statistics types support this methodology. The feasibility analysis remains incomplete.\n该讨论重点关注通过导入统计信息而非采样来优化postgres_fdw的统计信息收集。Ashutosh Bapat提出了类似于部分聚合的高级方法，通过组合子表的统计信息来计算父表统计信息，而不是合成行样本。这将消除在不使用ONLY子句分析父表时的冗余采样。Corey Huinker对可行性表示怀疑，指出当前统计函数设计用于处理行样本而非预计算统计信息。该方法需要开发"部分统计信息"的表示方式，并调研所有统计类型是否支持此方法。可行性分析仍未完成。	2026-01-27 05:47:08+00	\N
24	19be5345d4172528	Import Statistics in postgres_fdw before resorting to sampling.	["ashutosh.bapat.oss@gmail.com","corey.huinker@gmail.com","etsuro.fujita@gmail.com","jkatz@postgresql.org","michael@paquier.xyz","nathandbossart@gmail.com"]	[{"id":"19bfdfe2c948b37d","threadId":"19be5345d4172528","snippet":"On Fri, Jan 23, 2026 at 10:45 PM Corey Huinker <corey.huinker@gmail.com> wrote: >> >> >> There's an advantage if we can combine stats across multiple relations >> >","historyId":"25192","internalDate":"1769492828000","receivedAtUtc":"2026-01-27T05:47:08.000Z","from":"Ashutosh Bapat <ashutosh.bapat.oss@gmail.com>","subject":"Re: Import Statistics in postgres_fdw before resorting to sampling.","messageId":"<CAExHW5vsQK1JVn15DYdsGAQ-qbmce_MyP7F67Ne-JpaaLRYUOg@mail.gmail.com>","body":"On Fri, Jan 23, 2026 at 10:45 PM Corey Huinker <corey.huinker@gmail.com> wrote:\\n>>\\n>> >> There's an advantage if we can combine stats across multiple relations\\n>> >> - we don't have to sample children twice when analyzing the parent\\n>> >> without ONLY. Instead we could produce parent statistics by combining\\n>> >> statistics across children and the parent. To me this looks like\\n>> >> altogether a different beast just like partial aggregates.\\n>> >\\n>> >\\n>> > I think this patch is only ever going to get us out of 1 of the 2 samples, which isn't ideal but it is a savings.\\n>> >\\n>>\\n>> I am not suggesting to synthesize sample rows. Calculate the\\n>> statistics of the parent table from that of its children.\\n>\\n>\\n> I'm not sure we can actually do that. The functions that compute the statistics are all based off of row samples, not already computed statistics. I don't think we can synthesize a rowsample from the imported statistics, at least not accurately. If I'm misunderstanding what you're suggesting, please correct me.\\n\\nI am comparing the calculation of statistics to the calculation of\\naggregates. We have code to compute aggregates on a partitioned table\\nfrom the partial aggregates computed from the individual partitions.\\n(Even though I am mentioning the partitioned table, the technique can\\nbe used for an inheritance hierarchy.) Similarly if we could come up\\nwith a representation of partial statistics, we could get partial\\nstatistics computed for the children (and the parent in\\nnon-partitioned inheritance). Use the partial statistics to compute\\nthe statistics for the parent without the need to synthesize row\\nsamples from the children. I haven't looked at all the kinds of\\nstatistics to see whether this is feasible.\\n\\n--\\nBest Wishes,\\nAshutosh Bapat\\n\\n\\n"}]	The discussion focuses on optimizing statistics calculation for postgres_fdw by avoiding redundant sampling. Ashutosh Bapat proposes calculating parent table statistics by combining existing children statistics, similar to how partial aggregates work in partitioned tables. This approach would eliminate the need to sample children tables twice when analyzing parent tables without ONLY clause. Corey Huinker expresses skepticism about synthesizing row samples from imported statistics, questioning the accuracy of such an approach. Bapat clarifies he's not suggesting row sample synthesis but rather developing a "partial statistics" representation that could be combined across children and parent tables in inheritance hierarchies. The feasibility depends on whether all types of statistics can support this partial computation approach.\n\n讨论集中在通过避免冗余采样来优化postgres_fdw的统计计算。Ashutosh Bapat提议通过组合现有子表统计信息来计算父表统计信息，类似于分区表中部分聚合的工作方式。这种方法可以消除在分析不带ONLY子句的父表时对子表进行两次采样的需要。Corey Huinker对从导入统计信息合成行样本表示怀疑，质疑这种方法的准确性。Bapat澄清他不是建议行样本合成，而是开发一种"部分统计"表示，可以在继承层次结构中跨子表和父表进行组合。可行性取决于所有类型的统计信息是否都能支持这种部分计算方法。	2026-01-27 05:47:08+00	\N
25	19bfff779b0f694c	pgsql: Prevent invalidation of newly synced replication slots.	["akapila@postgresql.org","amit.kapila16@gmail.com","andres@anarazel.de","greg@burd.me","robertmhaas@gmail.com","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19bfff779b0f694c","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote: > Prevent invalidation of newly synced replication slots. This commit has broken CI for me. On the \\"Windows -","historyId":"28104","internalDate":"1769525944000","receivedAtUtc":"2026-01-27T14:59:04.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmobdVhO0ckZfsBZ0wqDO4qHVCwZZx8sf=EinafvUam-dsQ@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote:\\n> Prevent invalidation of newly synced replication slots.\\n\\nThis commit has broken CI for me. On the \\"Windows - Server 2022, VS\\n2019 - Meson & ninja\\" build, the following shows up in\\n046_checkpoint_logical_slot_standby.log:\\n\\n2026-01-27 13:44:44.421 GMT startup[5172] FATAL:  could not rename\\nfile \\"backup_label\\" to \\"backup_label.old\\": Permission denied\\n\\nI imagine this is going to break CI for everybody else too, as well as cfbot.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c00026a2c7bb64","threadId":"19bfff779b0f694c","snippet":"Robert Haas <robertmhaas@gmail.com> writes: > On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote: >> Prevent invalidation of newly synced replication slots","historyId":"28185","internalDate":"1769526672000","receivedAtUtc":"2026-01-27T15:11:12.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<428236.1769526672@sss.pgh.pa.us>","body":"Robert Haas <robertmhaas@gmail.com> writes:\\n> On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote:\\n>> Prevent invalidation of newly synced replication slots.\\n\\n> This commit has broken CI for me.\\n\\nHmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\nto believe a Windows-only problem, but at least hamerkop has run\\nsince 851f664.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"},{"id":"19c0025985d49525","threadId":"19bfff779b0f694c","snippet":"I wrote: > Robert Haas <robertmhaas@gmail.com> writes: >> This commit has broken CI for me. > Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared > to believe a","historyId":"28457","internalDate":"1769528979000","receivedAtUtc":"2026-01-27T15:49:39.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<544727.1769528979@sss.pgh.pa.us>","body":"I wrote:\\n> Robert Haas <robertmhaas@gmail.com> writes:\\n>> This commit has broken CI for me.\\n\\n> Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\n> to believe a Windows-only problem, but at least hamerkop has run\\n> since 851f664.\\n\\nD'oh: hamerkop doesn't run any TAP tests, let alone ones that require\\n--enable-injection-points.  So that success proves nothing.\\n\\nOur other Windows animals (drongo, fairywren, unicorn) seem to be\\nconfigured with -Dtap_tests=enabled, but nothing about injection\\npoints, so they will also skip 046_checkpoint_logical_slot.\\nSeems like a bit of a blind spot in the buildfarm.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"},{"id":"19c0027e521e4830","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 10:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > Robert Haas <robertmhaas@gmail.com> writes: > > On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@","historyId":"28500","internalDate":"1769529118000","receivedAtUtc":"2026-01-27T15:51:58.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmoYvtJoU0eyw3XEmLLda_JV4qSJxJpVfoTtFL3uPs5+7vw@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 10:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> Robert Haas <robertmhaas@gmail.com> writes:\\n> > On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote:\\n> >> Prevent invalidation of newly synced replication slots.\\n>\\n> > This commit has broken CI for me.\\n>\\n> Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\n> to believe a Windows-only problem, but at least hamerkop has run\\n> since 851f664.\\n\\nI don't understand it, either. There's a bunch of error codes that we\\nmap to EACCES in _dosmaperr, but I don't know why any of those\\nproblems would have occurred here:\\n\\nERROR_ACCESS_DENIED, EACCES\\nERROR_CURRENT_DIRECTORY, EACCES\\nERROR_LOCK_VIOLATION, EACCES\\nERROR_SHARING_VIOLATION, EACCES\\nERROR_NETWORK_ACCESS_DENIED, EACCES\\nERROR_CANNOT_MAKE, EACCES\\nERROR_FAIL_I24, EACCES\\nERROR_DRIVE_LOCKED, EACCES\\nERROR_SEEK_ON_DEVICE, EACCES\\nERROR_NOT_LOCKED, EACCES\\nERROR_LOCK_FAILED, EACCES\\n\\n(Side note: Wouldn't it make a lot of sense to go back and kill\\n_dosmaperr in favor of display the actual Windows error code string?)\\n\\nWhat's also puzzling is that what this test is doing seems to be\\ntotally standard. 040_standby_failover_slots_sync.pl does this:\\n\\nmy $standby1 = PostgreSQL::Test::Cluster->new('standby1');\\n$standby1->init_from_backup(\\n        $primary, $backup_name,\\n        has_streaming => 1,\\n        has_restoring => 1);\\n\\nAnd 046_checkpont_logical_slot.pl does this:\\n\\nmy $standby = PostgreSQL::Test::Cluster->new('standby');\\n$standby->init_from_backup(\\n    $primary, $backup_name,\\n    has_streaming => 1,\\n    has_restoring => 1);\\n\\nSo why is 046 failing and 040 is fine? I have no idea.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c0039469215822","threadId":"19bfff779b0f694c","snippet":"Robert Haas <robertmhaas@gmail.com> writes: > What's also puzzling is that what this test is doing seems to be > totally standard. Yeah. I do notice something interesting when running","historyId":"28666","internalDate":"1769530268000","receivedAtUtc":"2026-01-27T16:11:08.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<547219.1769530268@sss.pgh.pa.us>","body":"Robert Haas <robertmhaas@gmail.com> writes:\\n> What's also puzzling is that what this test is doing seems to be\\n> totally standard.\\n\\nYeah.  I do notice something interesting when running it here:\\n046_checkpoint_logical_slot_mike.log shows that we are triggering\\nquite a few checkpoints (via pg_switch_wal()) in quick succession\\non the primary.  I wonder if that is somehow tickling a Windows\\nfilesystem restriction.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"},{"id":"19c003e82e138131","threadId":"19bfff779b0f694c","snippet":"On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote: > I imagine this is going to break CI for everybody else too, as well as cfbot. Just by the way, on that last point,","historyId":"28794","internalDate":"1769530573000","receivedAtUtc":"2026-01-27T16:16:13.000Z","from":"Thomas Munro <thomas.munro@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+hUKGJotCdMdhrwVST4xbsPzr-csDgzveNhKu4UAXEmCDJ4iA@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote:\\n> I imagine this is going to break CI for everybody else too, as well as cfbot.\\n\\nJust by the way, on that last point, we trained cfbot to watch out for\\nCI pass/fail in this account:\\n\\nhttps://github.com/postgres/postgres/commits/master/\\n\\nand then use the most recent pass as the base commit when applying\\npatches to make test branches.  So if master is broken for a while, it\\nno longer takes all the cfbot runs with it.  Mentioning just in case\\nanyone is confused by that...\\n\\nAs for what's happening... hmm, there are a few holes in the \\"shared\\nlocking\\" stuff you get with the flags we use.  For example you can't\\nunlink a directory that contains a file that has been unlinked but\\nsomeone still holds open.  Doesn't seem to be the case here.  But I\\nwonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that\\nhas already been unlinked (or renamed over) that someone still holds\\nopen, or something like that...\\n\\n\\n"},{"id":"19c003f22c3a49b7","threadId":"19bfff779b0f694c","snippet":"Hi, On 2026-01-27 10:51:58 -0500, Robert Haas wrote: > I don't understand it, either. There's a bunch of error codes that we > map to EACCES in _dosmaperr, but I don't know why any of","historyId":"28838","internalDate":"1769530651000","receivedAtUtc":"2026-01-27T16:17:31.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<o5t5teaoz3ohto3xeftdumixoqyuee4u54ysyk4lvhpp54bd2w@h6citz4to4ib>","body":"Hi,\\n\\nOn 2026-01-27 10:51:58 -0500, Robert Haas wrote:\\n> I don't understand it, either. There's a bunch of error codes that we\\n> map to EACCES in _dosmaperr, but I don't know why any of those\\n> problems would have occurred here:\\n> \\n> ERROR_ACCESS_DENIED, EACCES\\n> ERROR_CURRENT_DIRECTORY, EACCES\\n> ERROR_LOCK_VIOLATION, EACCES\\n> ERROR_SHARING_VIOLATION, EACCES\\n> ERROR_NETWORK_ACCESS_DENIED, EACCES\\n> ERROR_CANNOT_MAKE, EACCES\\n> ERROR_FAIL_I24, EACCES\\n> ERROR_DRIVE_LOCKED, EACCES\\n> ERROR_SEEK_ON_DEVICE, EACCES\\n> ERROR_NOT_LOCKED, EACCES\\n> ERROR_LOCK_FAILED, EACCES\\n> \\n> (Side note: Wouldn't it make a lot of sense to go back and kill\\n> _dosmaperr in favor of display the actual Windows error code string?)\\n\\nIt'd be great to somehow preserve the mapping to preserve the original error\\nmessage, but I don't really see how we could just give up on our mapping. We\\nrely on e.g. knowing that a read failed due to ENOENT, not\\nERROR_FILE_NOT_FOUND or whatnot.\\n\\n\\n> What's also puzzling is that what this test is doing seems to be\\n> totally standard. 040_standby_failover_slots_sync.pl does this:\\n> \\n> my $standby1 = PostgreSQL::Test::Cluster->new('standby1');\\n> $standby1->init_from_backup(\\n>         $primary, $backup_name,\\n>         has_streaming => 1,\\n>         has_restoring => 1);\\n> \\n> And 046_checkpont_logical_slot.pl does this:\\n> \\n> my $standby = PostgreSQL::Test::Cluster->new('standby');\\n> $standby->init_from_backup(\\n>     $primary, $backup_name,\\n>     has_streaming => 1,\\n>     has_restoring => 1);\\n> \\n> So why is 046 failing and 040 is fine? I have no idea.\\n\\n046 does a fair bit of stuff before the base backup is being taken, I guess?\\nBut what that concretely could be, I have no idea.\\n\\nIt'd be one thing if it failed while creating a base backup, but the fact that\\nit allows the base backup being created, but then fails during startup is just\\nplain odd.  The typical sharing violation issue seems like it'd require that\\nwe somehow are not waiting for pg_basebackup to actually have terminated?\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19c003f787cf141b","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > Robert Haas <robertmhaas@gmail.com> writes: > > What's also puzzling is that what this test is doing","historyId":"28887","internalDate":"1769530663000","receivedAtUtc":"2026-01-27T16:17:43.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmobXMhXFYM=mJ51f5PRFuj7eR9zn68Bvjndjz-k+daSotg@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> Robert Haas <robertmhaas@gmail.com> writes:\\n> > What's also puzzling is that what this test is doing seems to be\\n> > totally standard.\\n>\\n> Yeah.  I do notice something interesting when running it here:\\n> 046_checkpoint_logical_slot_mike.log shows that we are triggering\\n> quite a few checkpoints (via pg_switch_wal()) in quick succession\\n> on the primary.  I wonder if that is somehow tickling a Windows\\n> filesystem restriction.\\n\\nMaybe, but it seems unlikely to me that this would mess up the\\nstandby, since it's a totally different node. What I kind of wonder is\\nif somehow there's still a process that has backup_label open, or has\\nclosed it but not recently enough for Windows to unlock it. However, I\\ndon't see why that would affect this test case and not others.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c0051d2d756f1b","threadId":"19bfff779b0f694c","snippet":"Hi, On 2026-01-28 05:16:13 +1300, Thomas Munro wrote: > On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote: > > I imagine this is going to break CI for everybody","historyId":"29049","internalDate":"1769531876000","receivedAtUtc":"2026-01-27T16:37:56.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<jqliu25wuvlxcjybekrpvmflgaod4iytlwekjyag2q43ml76fg@tfna2hbyhw4s>","body":"Hi,\\n\\nOn 2026-01-28 05:16:13 +1300, Thomas Munro wrote:\\n> On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote:\\n> > I imagine this is going to break CI for everybody else too, as well as cfbot.\\n> \\n> Just by the way, on that last point, we trained cfbot to watch out for\\n> CI pass/fail in this account:\\n> \\n> https://github.com/postgres/postgres/commits/master/\\n> \\n> and then use the most recent pass as the base commit when applying\\n> patches to make test branches.  So if master is broken for a while, it\\n> no longer takes all the cfbot runs with it.  Mentioning just in case\\n> anyone is confused by that...\\n\\nAh. I was indeed confused by that for a bit.\\n\\n\\n> But I wonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that\\n> has already been unlinked (or renamed over) that someone still holds open,\\n> or something like that...\\n\\nI don't see a source of that that would be specific to this test though :(. We\\ndo wait for pg_basebackup to have shut down, which wrote backup.label (which\\nwas \\"manifactured\\" during streaming by basebackup.c).\\n\\n\\nPerhaps we should crank up log level in the test? No idea if it'll help, but\\nright now I don't even know where to start looking.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19c006061eecf933","threadId":"19bfff779b0f694c","snippet":"> On Jan 27, 2026, at 10:49 AM, Tom Lane <tgl@sss.pgh.pa.us> wrote: > > I wrote: >> Robert Haas <robertmhaas@gmail.com> writes: >>> This commit has broken CI for me.","historyId":"29145","internalDate":"1769532818000","receivedAtUtc":"2026-01-27T16:53:38.000Z","from":"Greg Burd <greg@burd.me>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<54F8BC8B-6F9D-4B91-8B68-AA02B7643B94@burd.me>","body":"\\n> On Jan 27, 2026, at 10:49 AM, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> \\n> I wrote:\\n>> Robert Haas <robertmhaas@gmail.com> writes:\\n>>> This commit has broken CI for me.\\n> \\n>> Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\n>> to believe a Windows-only problem, but at least hamerkop has run\\n>> since 851f664.\\n> \\n> D'oh: hamerkop doesn't run any TAP tests, let alone ones that require\\n> --enable-injection-points.  So that success proves nothing.\\n> \\n> Our other Windows animals (drongo, fairywren, unicorn) seem to be\\n> configured with -Dtap_tests=enabled, but nothing about injection\\n> points, so they will also skip 046_checkpoint_logical_slot.\\n> Seems like a bit of a blind spot in the buildfarm.\\n> \\n> regards, tom lane\\n> \\n\\n\\nI'll see if I can update unicorn today to enable injection points to add some coverage on Win11/ARM64/MSVC.  No promises that will be diagnostic at all, but it seems like a good idea.\\n\\n\\n-Dinjection_points=true\\n\\n\\n-greg\\n\\n"},{"id":"19c00709ec06c5ca","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:53 AM Greg Burd <greg@burd.me> wrote: > I'll see if I can update unicorn today to enable injection points to add some coverage on Win11/ARM64/MSVC. No promises","historyId":"29286","internalDate":"1769533883000","receivedAtUtc":"2026-01-27T17:11:23.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmoZFs8Xqf4J5fEgXiZcpH4cK0jEygB7s13riPyGKB-n17w@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:53 AM Greg Burd <greg@burd.me> wrote:\\n> I'll see if I can update unicorn today to enable injection points to add some coverage on Win11/ARM64/MSVC.  No promises that will be diagnostic at all, but it seems like a good idea.\\n> -Dinjection_points=true\\n\\nSounds good!\\n\\nThanks,\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c008d8107e63b6","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:37 AM Andres Freund <andres@anarazel.de> wrote: > > But I wonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that","historyId":"29617","internalDate":"1769535771000","receivedAtUtc":"2026-01-27T17:42:51.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmobkmUMBocv0hxKiBj_5ZoTRE=qPz7QOu7voJ_j=dWNaaA@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:37 AM Andres Freund <andres@anarazel.de> wrote:\\n> > But I wonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that\\n> > has already been unlinked (or renamed over) that someone still holds open,\\n> > or something like that...\\n>\\n> I don't see a source of that that would be specific to this test though :(. We\\n> do wait for pg_basebackup to have shut down, which wrote backup.label (which\\n> was \\"manifactured\\" during streaming by basebackup.c).\\n>\\n> Perhaps we should crank up log level in the test? No idea if it'll help, but\\n> right now I don't even know where to start looking.\\n\\nI tried sticking a pg_sleep(30) in just before starting the standby\\nnode, and that didn't help, so it doesn't seem like it's a race\\ncondition.\\n\\nHere's what the standby log file looks like with log_min_messages=DEBUG2:\\n\\n2026-01-27 17:19:25.262 GMT postmaster[4932] DEBUG:  registering\\nbackground worker \\"logical replication launcher\\"\\n2026-01-27 17:19:25.264 GMT postmaster[4932] DEBUG:  dynamic shared\\nmemory system will support 229 segments\\n2026-01-27 17:19:25.264 GMT postmaster[4932] DEBUG:  created dynamic\\nshared memory control segment 3769552926 (9176 bytes)\\n2026-01-27 17:19:25.266 GMT postmaster[4932] DEBUG:  max_safe_fds =\\n990, usable_fds = 1000, already_open = 3\\n2026-01-27 17:19:25.268 GMT postmaster[4932] LOG:  starting PostgreSQL\\n19devel on x86_64-windows, compiled by msvc-19.29.30159, 64-bit\\n2026-01-27 17:19:25.271 GMT postmaster[4932] LOG:  listening on Unix\\nsocket \\"C:/Windows/TEMP/3xesO1s4ba/.s.PGSQL.17575\\"\\n2026-01-27 17:19:25.273 GMT postmaster[4932] DEBUG:  updating PMState\\nfrom PM_INIT to PM_STARTUP\\n2026-01-27 17:19:25.273 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 57 for io worker\\n2026-01-27 17:19:25.275 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 58 for io worker\\n2026-01-27 17:19:25.277 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 59 for io worker\\n2026-01-27 17:19:25.278 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 56 for checkpointer\\n2026-01-27 17:19:25.280 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 55 for background writer\\n2026-01-27 17:19:25.281 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 89 for startup\\n2026-01-27 17:19:25.308 GMT checkpointer[6560] DEBUG:  checkpointer\\nupdated shared memory configuration values\\n2026-01-27 17:19:25.314 GMT startup[2488] LOG:  database system was\\ninterrupted; last known up at 2026-01-27 17:19:21 GMT\\n2026-01-27 17:19:25.317 GMT startup[2488] DEBUG:  removing all\\ntemporary WAL segments\\nThe system cannot find the file specified.\\n2026-01-27 17:19:25.336 GMT startup[2488] DEBUG:  could not restore\\nfile \\"00000002.history\\" from archive: child process exited with exit\\ncode 1\\n2026-01-27 17:19:25.337 GMT startup[2488] DEBUG:  backup time\\n2026-01-27 17:19:21 GMT in file \\"backup_label\\"\\n2026-01-27 17:19:25.337 GMT startup[2488] DEBUG:  backup label\\npg_basebackup base backup in file \\"backup_label\\"\\n2026-01-27 17:19:25.337 GMT startup[2488] DEBUG:  backup timeline 1 in\\nfile \\"backup_label\\"\\n2026-01-27 17:19:25.337 GMT startup[2488] LOG:  starting backup\\nrecovery with redo LSN 0/2A000028, checkpoint LSN 0/2A000080, on\\ntimeline ID 1\\nThe system cannot find the file specified.\\n2026-01-27 17:19:25.352 GMT startup[2488] DEBUG:  could not restore\\nfile \\"00000001000000000000002A\\" from archive: child process exited\\nwith exit code 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  checkpoint record is\\nat 0/2A000080\\n2026-01-27 17:19:25.353 GMT startup[2488] LOG:  entering standby mode\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  redo record is at\\n0/2A000028; shutdown false\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  next transaction ID:\\n769; next OID: 24576\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  next MultiXactId: 1;\\nnext MultiXactOffset: 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  oldest unfrozen\\ntransaction ID: 760, in database 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  oldest MultiXactId:\\n1, in database 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  commit timestamp Xid\\noldest/newest: 0/0\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  transaction ID wrap\\nlimit is 2147484407, limited by database with OID 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  MultiXactId wrap\\nlimit is 2147483648, limited by database with OID 1\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  starting up replication slots\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  xmin required by\\nslots: data 0, catalog 0\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  starting up\\nreplication origin progress state\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  didn't need to\\nunlink permanent stats file \\"pg_stat/pgstat.stat\\" - didn't exist\\n2026-01-27 17:19:38.938 GMT startup[2488] FATAL:  could not rename\\nfile \\"backup_label\\" to \\"backup_label.old\\": Permission denied\\n2026-01-27 17:19:38.983 GMT postmaster[4932] DEBUG:  releasing pm child slot 89\\n2026-01-27 17:19:38.983 GMT postmaster[4932] LOG:  startup process\\n(PID 2488) exited with exit code 1\\n2026-01-27 17:19:38.983 GMT postmaster[4932] LOG:  aborting startup\\ndue to startup process failure\\n2026-01-27 17:19:38.983 GMT postmaster[4932] DEBUG:  cleaning up\\ndynamic shared memory control segment with ID 3769552926\\n2026-01-27 17:19:38.985 GMT postmaster[4932] LOG:  database system is shut down\\n\\nUnfortunately, I don't see any clues there. The \\"The system cannot\\nfind the file specified.\\" messages look like they might be a clue, but\\nI think they are not, because they also occur in\\n040_standby_failover_slots_sync_standby1.log, and that test passes. At\\nthe point where this log file shows the FATAL error, that log file\\ncontinues thus:\\n\\n2026-01-27 17:18:36.905 GMT startup[1420] DEBUG:  resetting unlogged\\nrelations: cleanup 1 init 0\\n2026-01-27 17:18:36.906 GMT startup[1420] DEBUG:  initializing for hot standby\\n2026-01-27 17:18:36.906 GMT startup[1420] LOG:  redo starts at 0/02000028\\n2026-01-27 17:18:36.906 GMT startup[1420] DEBUG:  recovery snapshots\\nare now enabled\\n2026-01-27 17:18:36.906 GMT startup[1420] CONTEXT:  WAL redo at\\n0/02000048 for Standby/RUNNING_XACTS: nextXid 769 latestCompletedXid\\n768 oldestRunningXid 769\\n2026-01-27 17:18:36.907 GMT startup[1420] DEBUG:  end of backup record reached\\n2026-01-27 17:18:36.907 GMT startup[1420] CONTEXT:  WAL redo at\\n0/02000100 for XLOG/BACKUP_END: 0/02000028\\n2026-01-27 17:18:36.907 GMT startup[1420] DEBUG:  end of backup reached\\n\\nWhich again seems totally normal.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"}]	A recent PostgreSQL commit titled "Prevent invalidation of newly synced replication slots" has broken CI builds on Windows, specifically causing a "Permission denied" error when trying to rename the backup_label file to backup_label.old during standby startup. The error occurs in test 046_checkpoint_logical_slot_standby.log but not in similar tests like 040_standby_failover_slots_sync.pl, despite using identical initialization patterns. Buildfarm Windows machines don't show the issue because they lack injection points configuration, creating a blind spot in testing coverage. Developers are investigating potential Windows filesystem restrictions, file locking issues, or sharing violations. One buildfarm maintainer offered to enable injection points on their Windows ARM64 system to improve coverage. Despite detailed debugging including increased logging and artificial delays, the root cause remains unclear, as the backup_label renaming operation should be standard and the same code works in other test scenarios.	2026-01-27 17:42:51+00	最近一个名为"防止新同步的复制槽失效"的PostgreSQL提交破坏了Windows上的CI构建，特别是在备用服务器启动过程中尝试将backup_label文件重命名为backup_label.old时出现"权限被拒绝"错误。该错误出现在测试046_checkpoint_logical_slot_standby.log中，但在类似的测试如040_standby_failover_slots_sync.pl中没有出现，尽管使用了相同的初始化模式。构建农场的Windows机器没有显示此问题，因为它们缺少注入点配置，在测试覆盖中造成了盲点。开发人员正在调查潜在的Windows文件系统限制、文件锁定问题或共享冲突。一位构建农场维护者提出在他们的Windows ARM64系统上启用注入点以改进覆盖。尽管进行了详细调试，包括增加日志记录和人工延迟，但根本原因仍不明确，因为backup_label重命名操作应该是标准的，同样的代码在其他测试场景中能正常工作。
27	19bec801a96f066e	unnecessary executor overheads around seqscans	["amit.kapila16@gmail.com","amitlangote09@gmail.com","andres@anarazel.de","dgrowleyml@gmail.com","dilipbalaut@gmail.com","hlinnaka@iki.fi"]	[{"id":"19bfca0caec460c1","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote: > On 23/01/2026 22:16, Andres Freund wrote: > > Hi, > > > > In [1] I was looking at the profile of a seqscan with a","historyId":"24083","internalDate":"1769469944000","receivedAtUtc":"2026-01-26T23:25:44.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<qugnsw6pkl3ab4ttke3b2kwiq3kur46xegx5omuvv6z3vwcznh@562ojlz2oqia>","body":"Hi,\\n\\nOn 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote:\\n> On 23/01/2026 22:16, Andres Freund wrote:\\n> > Hi,\\n> >\\n> > In [1] I was looking at the profile of a seqscan with a where clause that\\n> > doesn't match any of the many rows.  I was a bit saddened by where we were\\n> > spending time.\\n> >\\n> >\\n> > - The fetching of variables, as well as the null check of scandesc, in\\n> >    SeqNext() is repeated in every loop iteration of ExecScanExtended, despite\\n> >    that obviously not being required after the first iteration\\n> >\\n> >    We could perhaps address this by moving the check to the callers of\\n> >    ExecScanExtended() or by extending ExecScanExtended to have an explicit\\n> >    beginscan callback that it calls after.\\n>\\n> For context, we're talking about this in SeqNext:\\n>\\n> > \\t/*\\n> > \\t * get information from the estate and scan state\\n> > \\t */\\n> > \\tscandesc = node->ss.ss_currentScanDesc;\\n> > \\testate = node->ss.ps.state;\\n> > \\tdirection = estate->es_direction;\\n> > \\tslot = node->ss.ss_ScanTupleSlot;\\n>\\n> Hmm. I guess the compiler doesn't know that the variables don't change\\n> between calls, so it has to fetch them on every iteration. Passing them\\n> through a 'const' pointer might give it clue, but I'm not sure how to\\n> shoehorn that here.\\n\\nMy understanding is that compilers very rarely utilize const on pointers for\\noptimization. The problem is that just because the current pointer is const\\ndoesn't mean there aren't other *non-const* pointers. And since there are a\\nlot of external function calls involved here, there's no way the compiler\\ncould provide that that isn't the case :(.\\n\\n\\n> Perhaps we should turn the ExecScanExtended() function inside out. Instead\\n> of passing SeqNext as a callback to ExecScanExtended(), we would have a\\n> function like this (for illustration purposes only, doesn't compile):\\n\\nThat would be one approach, would require structural changes in a fair number\\nof places though :/.\\n\\nA slightly simpler approach could be for ExecScanExtended to pass in these\\nparameters as arguments to the callbacks. For things like estate, direction\\nand scanslot, that makes plenty sense. It's a bit more problematic for the\\nscan descriptor, due to the \\"lazy start\\" we have in a few places.\\n\\nI very briefly prototyped that (relying on the fact that all callers cast to\\nthe callback type and that passing unused arguments just works even if the\\nfunction definition doesn't expect them), and that seems to do the trick.\\n\\nWhat shows up more visibly afterwards is that we set ExecScanExtended() sets\\necontext->ecxt_scantuple in every iteration, despite that not changing in\\nalmost all cases (I think for FDWs it could, fdwhandler.sgml just says that\\nthe scanslot \\"should\\" be used).\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19bfd51ff0aaaec7","threadId":"19bec801a96f066e","snippet":"On Tue, Jan 27, 2026 at 3:08 AM Andres Freund <andres@anarazel.de> wrote: > > Hi, > > On 2026-01-26 16:47:31 +0900, Amit Langote wrote: > > I tried my patch over your committed","historyId":"24510","internalDate":"1769481540000","receivedAtUtc":"2026-01-27T02:39:00.000Z","from":"Amit Langote <amitlangote09@gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<CA+HiwqE9g2tb96hgrNH81Q5PeK3YnwT7nrmVCnRWJVjFpKAtEA@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 3:08 AM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> Hi,\\n>\\n> On 2026-01-26 16:47:31 +0900, Amit Langote wrote:\\n> > I tried my patch over your committed SeqNext inlining patch and ran\\n> > the following benchmark but didn't notice in material difference:\\n> >\\n> > CREATE TABLE t (a int);\\n> > INSERT INTO t SELECT generate_series(1, 1000000);\\n> > ANALYZE t;\\n>\\n> Because the table isn't frozen, visibility checks will probably add enough\\n> per-row overhead to make any per-row micro-optimization harder to see.  On my\\n> somewhat older workstation freezing is a 17% improvement.\\n>\\n> > SET max_parallel_workers_per_gather = 0;\\n> > SELECT * FROM t WHERE a = -1;\\n> >\\n> > Perhaps not too surprising given it's just eliminating a couple of\\n> > instructions per row that the branch predictor probably handles well\\n> > anyway? Still seems worth having for code hygiene if nothing else.\\n> >\\n> > Same result (no diff in perf) when I apply it over your patch to move\\n> > the scandesc == NULL check.\\n>\\n> FWIW, on my cascade lake workstation it's a, surprisingly large, 3.5%, after\\n> freezing. Without freezing there maybe still is a difference, but it's very\\n> close to the noise floor.\\n\\nI did freeze but still don't see a measurable difference.  Though, I\\ntested on a VM, so the noise floor is probably higher than on your\\nbare metal workstation.  I'll try later on bare metal.\\n\\n-- \\nThanks, Amit Langote\\n\\n\\n"},{"id":"19bfef46958ba407","threadId":"19bec801a96f066e","snippet":"On 27/01/2026 01:25, Andres Freund wrote: > On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote: >> Perhaps we should turn the ExecScanExtended() function inside out. Instead >> of","historyId":"26762","internalDate":"1769508975000","receivedAtUtc":"2026-01-27T10:16:15.000Z","from":"Heikki Linnakangas <hlinnaka@iki.fi>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<0dc565fa-bcc0-4600-9cef-263822b08132@iki.fi>","body":"On 27/01/2026 01:25, Andres Freund wrote:\\n> On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote:\\n>> Perhaps we should turn the ExecScanExtended() function inside out. Instead\\n>> of passing SeqNext as a callback to ExecScanExtended(), we would have a\\n>> function like this (for illustration purposes only, doesn't compile):\\n> > That would be one approach, would require structural changes in a fair number\\n> of places though :/.\\n\\nExecScanExtended is only used in execScan.c and nodeSeqScan.c, so not that many places. Even replacing ExecScan() completely would be isolated to src/backend/executor.\\n\\n> A slightly simpler approach could be for ExecScanExtended to pass in these\\n> parameters as arguments to the callbacks. For things like estate, direction\\n> and scanslot, that makes plenty sense. It's a bit more problematic for the\\n> scan descriptor, due to the \\"lazy start\\" we have in a few places.\\n\\nYep, it's less flexible. We have to know beforehand which variables the function might want to avoid re-fetching, and add them all as parameters.\\n\\n> I very briefly prototyped that (relying on the fact that all callers cast to\\n> the callback type and that passing unused arguments just works even if the\\n> function definition doesn't expect them), and that seems to do the trick.\\n\\nThis can be a very hot codepath so if we can shave a few % off, I'm willing to hold my nose. But if we can do it more elegantly, even better...\\n\\n> What shows up more visibly afterwards is that we set ExecScanExtended() sets\\n> econtext->ecxt_scantuple in every iteration, despite that not changing in\\n> almost all cases (I think for FDWs it could, fdwhandler.sgml just says that\\n> the scanslot \\"should\\" be used).\\n\\nHuh, that's just a single store instruction. This really is a hot path. Or is it just that the first instruction after the function call causes some kind of a stall or data dependency, i.e. if that was removed, it'd just move to the next instruction instead?\\n\\nI wonder about the access to (econtext)->ecxt_per_tuple_memory. That never changes, but we're re-fetching that too on every iteration.\\n\\nInstrCountFiltered1() also fetches node->instrument, with a NULL check, on every iteration. Maybe keep a counter in a local variable and only call InstrCountFiltered1() when exiting the loop.\\n\\nI guess these don't show up in a profiler or you would've latched on them already..\\n\\n- Heikki\\n\\n\\n\\n"},{"id":"19bff26bc37bbc6e","threadId":"19bec801a96f066e","snippet":"On Mon, Jan 26, 2026 at 5:27 PM Amit Kapila <amit.kapila16@gmail.com> wrote: > > On Sat, Jan 24, 2026 at 9:01 PM Andres Freund <andres@anarazel.de> wrote: > > > > On 2026-","historyId":"27112","internalDate":"1769512255000","receivedAtUtc":"2026-01-27T11:10:55.000Z","from":"Dilip Kumar <dilipbalaut@gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<CAFiTN-tAo978okqS-vAt-5QFLWZRa_QfUFBdT_0-9P_ujRXnKA@mail.gmail.com>","body":"On Mon, Jan 26, 2026 at 5:27 PM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n>\\n> On Sat, Jan 24, 2026 at 9:01 PM Andres Freund <andres@anarazel.de> wrote:\\n> >\\n> > On 2026-01-24 15:23:44 +0530, Amit Kapila wrote:\\n> > > On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote:\\n> > > >\\n> > > > - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n> > > >   show up noticeably and in every loop iteration, despite afaict never being reachable\\n> > > >\\n> > > >   It's not obvious to me that this should\\n> > > >   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n> > > >      change in the middle of a scan? That would require a wrapper around\\n> > > >      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n> > > >   b) not just be an assertion?\\n> > > >\\n> > >\\n> > > IIRC, the main reason for having this precautionary check in the API\\n> > > is to ensure that during logical decoding we never access the table AM\\n> > > or\\n> > > heap APIs directly when scanning catalog tables. This restriction\\n> > > exists because we only check for concurrent aborts inside the\\n> > > systable_* APIs.\\n> >\\n> > I know why the check exists - but why does it have to be in\\n> > table_scan_getnextslot(), which is executed very frequently, rather than\\n> > table_beginscan*(), which is executed much less frequently.\\n> >\\n>\\n> I thought about this point and couldn't think of any reason why this\\n> check can't be in table_beginscan*(). I think your idea of having a\\n> wrapper around scan_begin() to handle this check is a good one.\\n\\nHere is the patch. I've used table_scan_begin_wrapper() to wrap the\\nscan_begin() callback for now. If you have a better naming preference\\nto avoid the 'wrapper' suffix, please let me know.\\n\\n-- \\nRegards,\\nDilip Kumar\\nGoogle\\n"},{"id":"19c0068c12baf979","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-27 12:16:15 +0200, Heikki Linnakangas wrote: > On 27/01/2026 01:25, Andres Freund wrote: > > On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote: > > > Perhaps we","historyId":"29239","internalDate":"1769533379000","receivedAtUtc":"2026-01-27T17:02:59.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<lp4e5zipwolqcmnxvvlpx2ylmkjgip7cvbaud55dqdydfobupx@itmbp24b4ue2>","body":"Hi,\\n\\nOn 2026-01-27 12:16:15 +0200, Heikki Linnakangas wrote:\\n> On 27/01/2026 01:25, Andres Freund wrote:\\n> > On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote:\\n> > > Perhaps we should turn the ExecScanExtended() function inside out. Instead\\n> > > of passing SeqNext as a callback to ExecScanExtended(), we would have a\\n> > > function like this (for illustration purposes only, doesn't compile):\\n> >\\n> > That would be one approach, would require structural changes in a fair number\\n> > of places though :/.\\n>\\n> ExecScanExtended is only used in execScan.c and nodeSeqScan.c, so not that\\n> many places. Even replacing ExecScan() completely would be isolated to\\n> src/backend/executor.\\n\\nI was assuming we'd not want a totally different structure for nodeSeqScan.c\\nthan for the rest. I think we really ought to use ExecScanExtended\\neverywhere. Probably not with multiple callsites (for no qual, no projection\\netc), but to get rid of the indirect function calls to \\"accessMtd\\".\\n\\n> > What shows up more visibly afterwards is that we set ExecScanExtended() sets\\n> > econtext->ecxt_scantuple in every iteration, despite that not changing in\\n> > almost all cases (I think for FDWs it could, fdwhandler.sgml just says that\\n> > the scanslot \\"should\\" be used).\\n>\\n> Huh, that's just a single store instruction. This really is a hot path. Or\\n> is it just that the first instruction after the function call causes some\\n> kind of a stall or data dependency, i.e. if that was removed, it'd just move\\n> to the next instruction instead?\\n\\nI was a bit surprised too. It might be a case of some store forwarding issue,\\nbecause very shortly afterwards we end up reading ecxt_scantuple (at the start\\nof expression evaluation). Or we're just hitting limits on the number of\\nin-flight stores.\\n\\n\\n> I wonder about the access to (econtext)->ecxt_per_tuple_memory. That never\\n> changes, but we're re-fetching that too on every iteration.\\n\\nThe load itself didn't show up crazily, but there's something related that\\ndoes show up quite prominently: ResetExprContext().  I briefly hacked upan\\ninline version of MemoryContextReset(), and that does help noticeably.\\n\\nAnother context related thing that does show up is all the switcheroo around\\nCurrentMemoryContext.\\n\\n\\n> InstrCountFiltered1() also fetches node->instrument, with a NULL check, on\\n> every iteration. Maybe keep a counter in a local variable and only call\\n> InstrCountFiltered1() when exiting the loop.\\n\\n\\n> I guess these don't show up in a profiler or you would've latched on them\\n> already..\\n\\nIt does show up, but only really after addressing the other things... There\\nare plenty more things that show up, fwiw:\\n\\n- Expression evaluation checks for NULL function args, even though we could\\n  know that they should not be NULL (this is complicated by the fact that\\n  sometimes we build \\"illegal\\" tuples, before constraint checking). That shows\\n  up surprisingly high.\\n\\n  I think if we added information about whether NOT NULL is reliable in\\n  tupledescs it could solve this.\\n\\n  While it'd allow optimizing some cases, it'd still be limited due strict\\n  function calls not being guaranteed to return NOT NULL.\\n\\n\\n- heap_getnextslot()'s calls to heapgettup_pagemode() should be inlined\\n\\n\\n- we probably should eventually inline ExecStoreBufferHeapTuple(),\\n  that way we would only need to handle the \\"buffer has changed\\" paths when\\n  heapgettup_pagemode() switches pages\\n\\n\\n- Expression evaluation has a too high startup overhead. This is partially due\\n  to it preparing to access all types of slots, which most of the time aren't\\n  needed.\\n\\n  This would be a lot easier if we didn't need to go through the indirection\\n  via ExprContext to find the right scan/outer/... slot during every\\n  evaluation. But unfortunately there are some callsites that do change the\\n  slot between executions.  Perhaps we could make it a per-expression\\n  operation to change the slot of an expression, which would update state\\n  inside the ExprState?\\n\\n\\n- The access to columns in slots is too expensive during expression\\n  evaluation. We go from the slot, via an indirect memory access, to the\\n  values array, then have to fetch the right element there. Then do the same\\n  for nulls.\\n\\n  I think to really do better we'd need to do two things:\\n\\n  - Use one NullableDatum array instead of two separate arrays for values and\\n    isnull.\\n\\n  - Store the array in place in the slot, as a flexible array member). That\\n    makes storing of per-slot-type data harder though.  We probably would need\\n    to embed the \\"common\\" part of the slot at the end of the custom part of\\n    the slot, which is more complicated...\\n\\n  That's a lot of work, I tried it before... There's a fair bit of fallout due\\n  to all the places that do stuff like forming tuples based on\\n  tts_values/tts_isnull.\\n\\n  I do wonder if it could already help to just store the offset to the values\\n  and isnull arrays inside the slot, instead of having to read pointers and\\n  then do address calculation based on those.\\n\\n\\n- The function call interface is way too expensive for simple operators\\n\\n  We need a simplified function call interface that doesn't shuffle everything\\n  through pointers...\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19c00ea54a062e51","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-27 16:40:55 +0530, Dilip Kumar wrote: > > > I know why the check exists - but why does it have to be in > > > table_scan_getnextslot(), which is executed very","historyId":"30232","internalDate":"1769541870000","receivedAtUtc":"2026-01-27T19:24:30.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<qnyy2a2rlohsq5mkehqehmdc2zzv7d3ren7hedw3hy5vup26yf@3yk4s3dtl6fn>","body":"Hi,\\n\\nOn 2026-01-27 16:40:55 +0530, Dilip Kumar wrote:\\n> > > I know why the check exists - but why does it have to be in\\n> > > table_scan_getnextslot(), which is executed very frequently, rather than\\n> > > table_beginscan*(), which is executed much less frequently.\\n> > >\\n> >\\n> > I thought about this point and couldn't think of any reason why this\\n> > check can't be in table_beginscan*(). I think your idea of having a\\n> > wrapper around scan_begin() to handle this check is a good one.\\n> \\n> Here is the patch. I've used table_scan_begin_wrapper() to wrap the\\n> scan_begin() callback for now. If you have a better naming preference\\n> to avoid the 'wrapper' suffix, please let me know.\\n\\nI'd probably just go for _internal(), _impl() or such.\\n\\n\\n\\n> diff --git a/src/backend/access/table/tableam.c b/src/backend/access/table/tableam.c\\n> index 87491796523..15a92c052d3 100644\\n> --- a/src/backend/access/table/tableam.c\\n> +++ b/src/backend/access/table/tableam.c\\n> [...]\\n> +/*\\n> + * table_scan_begin_wrapper\\n> + *\\n> + * A wrapper around the Table Access Method scan_begin callback. This handles\\n> + * centralized error checking—specifically ensuring we aren't performing\\n> + * table scan while CheckXidAlive is valid.  This state is reserved for\\n> + * specific logical decoding operations where direct relation scanning is\\n> + * prohibited.\\n> + */\\n> +TableScanDesc\\n> +table_scan_begin_wrapper(Relation rel, Snapshot snapshot, int nkeys,\\n> +\\t\\t\\t\\t\\t\\t ScanKeyData *key, ParallelTableScanDesc pscan,\\n> +\\t\\t\\t\\t\\t\\t uint32 flags)\\n> +{\\n> +\\t/*\\n> +\\t * We don't expect direct calls to this function with valid CheckXidAlive\\n> +\\t * for catalog or regular tables.  See detailed comments in xact.c where\\n> +\\t * these variables are declared.\\n> +\\t */\\n> +\\tif (unlikely(TransactionIdIsValid(CheckXidAlive) && !bsysscan))\\n> +\\t\\telog(ERROR, \\"unexpected table_scan_begin_wrapper call during logical decoding\\");\\n> +\\n> +\\treturn rel->rd_tableam->scan_begin(rel, snapshot, nkeys, key, pscan, flags);\\n> +}\\n\\nGiven that some of the callers are in inline functions in tableam.h, I would\\nimplement the wrapper there. I doubt it'll make a meaningful difference, but\\nit doesn't seem worth \\"risking\\" that.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"}]	Andres Freund identified significant executor overhead in PostgreSQL sequential scans, particularly when scanning tables with WHERE clauses that match no rows. The main issues include repeated variable fetching and null checks in SeqNext() within ExecScanExtended loops, and expensive checkXidAlive checks in table_scan_getnextslot() that execute per row despite seemingly never being reachable.\n\nHeikki Linnakangas and Andres discussed potential solutions, including restructuring ExecScanExtended to pass parameters as arguments to callbacks rather than requiring repeated fetches. Andres prototyped this approach and found it effective, though it revealed additional overhead from setting econtext->ecxt_scantuple on every iteration.\n\nDilip Kumar provided a patch moving the checkXidAlive validation from the frequently-called table_scan_getnextslot() to table_beginscan*(), implementing a wrapper around scan_begin(). Andres suggested naming improvements and recommended implementing the wrapper in tableam.h for inline functions.\n\nThe discussion expanded to identify numerous other performance bottlenecks in expression evaluation, memory context handling, slot access patterns, and function call interfaces. Amit Langote tested patches but saw mixed performance results depending on test environment.	2026-01-27 19:24:30+00	Andres Freund发现了PostgreSQL顺序扫描中的显著执行器开销，特别是在扫描带有WHERE子句但不匹配任何行的表时。主要问题包括在ExecScanExtended循环中SeqNext()重复获取变量和空值检查，以及在table_scan_getnextslot()中昂贵的checkXidAlive检查，这些检查按行执行但似乎永远不可达。\n\nHeikki Linnakangas和Andres讨论了潜在解决方案，包括重构ExecScanExtended以将参数作为参数传递给回调函数，而不是要求重复获取。Andres原型化了这种方法并发现其有效，尽管它揭示了每次迭代设置econtext->ecxt_scantuple的额外开销。\n\nDilip Kumar提供了一个补丁，将checkXidAlive验证从频繁调用的table_scan_getnextslot()移动到table_beginscan*()，在scan_begin()周围实现了一个包装器。Andres建议了命名改进，并推荐在tableam.h中为内联函数实现包装器。\n\n讨论扩展到识别表达式求值、内存上下文处理、slot访问模式和函数调用接口中的许多其他性能瓶颈。Amit Langote测试了补丁，但根据测试环境看到了不同的性能结果。
28	19be2095ebf4792a	Remaining dependency on setlocale()	["a.kozhemyakin@postgrespro.ru","li.evan.chao@gmail.com","peter@eisentraut.org","pgsql@j-davis.com","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19c00e31563d50af","threadId":"19be2095ebf4792a","snippet":"On Wed, 2026-01-21 at 11:30 -0800, Jeff Davis wrote: > It seems to be fine in master, and it was only backported to 18, so > the > attached patch is only intended for REL_18_STABLE. Committed.","historyId":"30114","internalDate":"1769541394000","receivedAtUtc":"2026-01-27T19:16:34.000Z","from":"Jeff Davis <pgsql@j-davis.com>","subject":"Re: Remaining dependency on setlocale()","messageId":"<94a8ba10943adb3cca0a3718e74a090cacdde241.camel@j-davis.com>","body":"On Wed, 2026-01-21 at 11:30 -0800, Jeff Davis wrote:\\n> It seems to be fine in master, and it was only backported to 18, so\\n> the\\n> attached patch is only intended for REL_18_STABLE.\\n\\nCommitted.\\n\\nRegards,\\n\\tJeff Davis\\n\\n\\n\\n"},{"id":"19c00fcd20541113","threadId":"19be2095ebf4792a","snippet":"On Tue, 2026-01-06 at 14:20 -0800, Jeff Davis wrote: > Looks good to me. I closed the entry for this commitfest, though there are a few loose ends: * Not sure what to do about strerror & gettext","historyId":"30328","internalDate":"1769543076000","receivedAtUtc":"2026-01-27T19:44:36.000Z","from":"Jeff Davis <pgsql@j-davis.com>","subject":"Re: Remaining dependency on setlocale()","messageId":"<cf976b924de917c762b53e0d7bcb5ded2d0b1aa3.camel@j-davis.com>","body":"On Tue, 2026-01-06 at 14:20 -0800, Jeff Davis wrote:\\n> Looks good to me.\\n\\nI closed the entry for this commitfest, though there are a few loose\\nends:\\n\\n  * Not sure what to do about strerror & gettext. One idea is to wrap\\nboth in a uselocale() everywhere. For windows, we use the special\\nsetlocale() mode. For NetBSD, I don't know if we can or should do\\nanything -- maybe just prevent changing lc_messages?\\n\\n  * pg_strcasecmp() still used many places in the backend. We should\\nconsider replacing with an ASCII variant or one that uses the database\\ncollation.\\n\\n  * A number of places still rely on isalpha(), etc., for simple\\nparsing (e.g. ltree).\\n\\nRegards,\\n\\tJeff Davis\\n\\n\\n\\n"}]	Jeff Davis has committed a patch addressing remaining setlocale() dependencies, which was backported to REL_18_STABLE only since master was already fine. The commitfest entry has been closed, but several loose ends remain unresolved. These include handling strerror and gettext functions, potentially wrapping them with uselocale() calls, though Windows would use a special setlocale() mode and NetBSD handling remains uncertain. Additionally, pg_strcasecmp() is still widely used in the backend and should be replaced with ASCII variants or database collation-aware versions. Various parsing functions like isalpha() in components such as ltree also continue relying on locale-dependent behavior that needs addressing.	2026-01-27 19:44:36+00	Jeff Davis 已提交了一个解决剩余 setlocale() 依赖的补丁，该补丁仅回移到 REL_18_STABLE，因为 master 分支已经没有问题。commitfest 条目已关闭，但仍有几个问题待解决。这些包括处理 strerror 和 gettext 函数，可能需要用 uselocale() 调用包装它们，不过 Windows 会使用特殊的 setlocale() 模式，NetBSD 的处理方式仍不确定。此外，pg_strcasecmp() 在后端中仍被广泛使用，应该替换为 ASCII 变体或数据库排序规则感知版本。各种解析函数如 ltree 等组件中的 isalpha() 也继续依赖于需要解决的区域设置相关行为。
29	19be2095ebf4792a	Remaining dependency on setlocale()	["a.kozhemyakin@postgrespro.ru","li.evan.chao@gmail.com","peter@eisentraut.org","pgsql@j-davis.com","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19c00e31563d50af","threadId":"19be2095ebf4792a","snippet":"On Wed, 2026-01-21 at 11:30 -0800, Jeff Davis wrote: > It seems to be fine in master, and it was only backported to 18, so > the > attached patch is only intended for REL_18_STABLE. Committed.","historyId":"30114","internalDate":"1769541394000","receivedAtUtc":"2026-01-27T19:16:34.000Z","from":"Jeff Davis <pgsql@j-davis.com>","subject":"Re: Remaining dependency on setlocale()","messageId":"<94a8ba10943adb3cca0a3718e74a090cacdde241.camel@j-davis.com>","body":"On Wed, 2026-01-21 at 11:30 -0800, Jeff Davis wrote:\\n> It seems to be fine in master, and it was only backported to 18, so\\n> the\\n> attached patch is only intended for REL_18_STABLE.\\n\\nCommitted.\\n\\nRegards,\\n\\tJeff Davis\\n\\n\\n\\n"},{"id":"19c00fcd20541113","threadId":"19be2095ebf4792a","snippet":"On Tue, 2026-01-06 at 14:20 -0800, Jeff Davis wrote: > Looks good to me. I closed the entry for this commitfest, though there are a few loose ends: * Not sure what to do about strerror & gettext","historyId":"30328","internalDate":"1769543076000","receivedAtUtc":"2026-01-27T19:44:36.000Z","from":"Jeff Davis <pgsql@j-davis.com>","subject":"Re: Remaining dependency on setlocale()","messageId":"<cf976b924de917c762b53e0d7bcb5ded2d0b1aa3.camel@j-davis.com>","body":"On Tue, 2026-01-06 at 14:20 -0800, Jeff Davis wrote:\\n> Looks good to me.\\n\\nI closed the entry for this commitfest, though there are a few loose\\nends:\\n\\n  * Not sure what to do about strerror & gettext. One idea is to wrap\\nboth in a uselocale() everywhere. For windows, we use the special\\nsetlocale() mode. For NetBSD, I don't know if we can or should do\\nanything -- maybe just prevent changing lc_messages?\\n\\n  * pg_strcasecmp() still used many places in the backend. We should\\nconsider replacing with an ASCII variant or one that uses the database\\ncollation.\\n\\n  * A number of places still rely on isalpha(), etc., for simple\\nparsing (e.g. ltree).\\n\\nRegards,\\n\\tJeff Davis\\n\\n\\n\\n"}]	Jeff Davis has committed a patch addressing remaining dependencies on setlocale() in PostgreSQL. The patch was specifically backported to REL_18_STABLE branch only, as the master branch was already fine. While the main commitfest entry has been closed, several loose ends remain unresolved. These include handling strerror and gettext functions, which could potentially be wrapped with uselocale() calls, with special setlocale() mode for Windows and uncertain approach for NetBSD. Additionally, pg_strcasecmp() is still widely used in the backend and should be replaced with either an ASCII variant or database collation-based implementation. Various places in the code continue relying on functions like isalpha() for simple parsing operations, such as in ltree functionality.	2026-01-27 19:44:36+00	Jeff Davis已提交了一个解决PostgreSQL中剩余setlocale()依赖的补丁。该补丁仅回移植到REL_18_STABLE分支，因为master分支已经正常。虽然主要的commitfest条目已关闭，但仍有几个未解决的问题。这些包括处理strerror和gettext函数，可能需要用uselocale()调用包装，Windows使用特殊的setlocale()模式，NetBSD的处理方式尚不确定。此外，pg_strcasecmp()在后端仍被广泛使用，应该替换为ASCII变体或基于数据库排序规则的实现。代码中的各个地方仍然依赖isalpha()等函数进行简单解析操作，例如在ltree功能中。
29	19bec801a96f066e	unnecessary executor overheads around seqscans	["amit.kapila16@gmail.com","amitlangote09@gmail.com","andres@anarazel.de","dgrowleyml@gmail.com","dilipbalaut@gmail.com","hlinnaka@iki.fi"]	[{"id":"19bfca0caec460c1","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote: > On 23/01/2026 22:16, Andres Freund wrote: > > Hi, > > > > In [1] I was looking at the profile of a seqscan with a","historyId":"24083","internalDate":"1769469944000","receivedAtUtc":"2026-01-26T23:25:44.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<qugnsw6pkl3ab4ttke3b2kwiq3kur46xegx5omuvv6z3vwcznh@562ojlz2oqia>","body":"Hi,\\n\\nOn 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote:\\n> On 23/01/2026 22:16, Andres Freund wrote:\\n> > Hi,\\n> >\\n> > In [1] I was looking at the profile of a seqscan with a where clause that\\n> > doesn't match any of the many rows.  I was a bit saddened by where we were\\n> > spending time.\\n> >\\n> >\\n> > - The fetching of variables, as well as the null check of scandesc, in\\n> >    SeqNext() is repeated in every loop iteration of ExecScanExtended, despite\\n> >    that obviously not being required after the first iteration\\n> >\\n> >    We could perhaps address this by moving the check to the callers of\\n> >    ExecScanExtended() or by extending ExecScanExtended to have an explicit\\n> >    beginscan callback that it calls after.\\n>\\n> For context, we're talking about this in SeqNext:\\n>\\n> > \\t/*\\n> > \\t * get information from the estate and scan state\\n> > \\t */\\n> > \\tscandesc = node->ss.ss_currentScanDesc;\\n> > \\testate = node->ss.ps.state;\\n> > \\tdirection = estate->es_direction;\\n> > \\tslot = node->ss.ss_ScanTupleSlot;\\n>\\n> Hmm. I guess the compiler doesn't know that the variables don't change\\n> between calls, so it has to fetch them on every iteration. Passing them\\n> through a 'const' pointer might give it clue, but I'm not sure how to\\n> shoehorn that here.\\n\\nMy understanding is that compilers very rarely utilize const on pointers for\\noptimization. The problem is that just because the current pointer is const\\ndoesn't mean there aren't other *non-const* pointers. And since there are a\\nlot of external function calls involved here, there's no way the compiler\\ncould provide that that isn't the case :(.\\n\\n\\n> Perhaps we should turn the ExecScanExtended() function inside out. Instead\\n> of passing SeqNext as a callback to ExecScanExtended(), we would have a\\n> function like this (for illustration purposes only, doesn't compile):\\n\\nThat would be one approach, would require structural changes in a fair number\\nof places though :/.\\n\\nA slightly simpler approach could be for ExecScanExtended to pass in these\\nparameters as arguments to the callbacks. For things like estate, direction\\nand scanslot, that makes plenty sense. It's a bit more problematic for the\\nscan descriptor, due to the \\"lazy start\\" we have in a few places.\\n\\nI very briefly prototyped that (relying on the fact that all callers cast to\\nthe callback type and that passing unused arguments just works even if the\\nfunction definition doesn't expect them), and that seems to do the trick.\\n\\nWhat shows up more visibly afterwards is that we set ExecScanExtended() sets\\necontext->ecxt_scantuple in every iteration, despite that not changing in\\nalmost all cases (I think for FDWs it could, fdwhandler.sgml just says that\\nthe scanslot \\"should\\" be used).\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19bfd51ff0aaaec7","threadId":"19bec801a96f066e","snippet":"On Tue, Jan 27, 2026 at 3:08 AM Andres Freund <andres@anarazel.de> wrote: > > Hi, > > On 2026-01-26 16:47:31 +0900, Amit Langote wrote: > > I tried my patch over your committed","historyId":"24510","internalDate":"1769481540000","receivedAtUtc":"2026-01-27T02:39:00.000Z","from":"Amit Langote <amitlangote09@gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<CA+HiwqE9g2tb96hgrNH81Q5PeK3YnwT7nrmVCnRWJVjFpKAtEA@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 3:08 AM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> Hi,\\n>\\n> On 2026-01-26 16:47:31 +0900, Amit Langote wrote:\\n> > I tried my patch over your committed SeqNext inlining patch and ran\\n> > the following benchmark but didn't notice in material difference:\\n> >\\n> > CREATE TABLE t (a int);\\n> > INSERT INTO t SELECT generate_series(1, 1000000);\\n> > ANALYZE t;\\n>\\n> Because the table isn't frozen, visibility checks will probably add enough\\n> per-row overhead to make any per-row micro-optimization harder to see.  On my\\n> somewhat older workstation freezing is a 17% improvement.\\n>\\n> > SET max_parallel_workers_per_gather = 0;\\n> > SELECT * FROM t WHERE a = -1;\\n> >\\n> > Perhaps not too surprising given it's just eliminating a couple of\\n> > instructions per row that the branch predictor probably handles well\\n> > anyway? Still seems worth having for code hygiene if nothing else.\\n> >\\n> > Same result (no diff in perf) when I apply it over your patch to move\\n> > the scandesc == NULL check.\\n>\\n> FWIW, on my cascade lake workstation it's a, surprisingly large, 3.5%, after\\n> freezing. Without freezing there maybe still is a difference, but it's very\\n> close to the noise floor.\\n\\nI did freeze but still don't see a measurable difference.  Though, I\\ntested on a VM, so the noise floor is probably higher than on your\\nbare metal workstation.  I'll try later on bare metal.\\n\\n-- \\nThanks, Amit Langote\\n\\n\\n"},{"id":"19bfef46958ba407","threadId":"19bec801a96f066e","snippet":"On 27/01/2026 01:25, Andres Freund wrote: > On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote: >> Perhaps we should turn the ExecScanExtended() function inside out. Instead >> of","historyId":"26762","internalDate":"1769508975000","receivedAtUtc":"2026-01-27T10:16:15.000Z","from":"Heikki Linnakangas <hlinnaka@iki.fi>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<0dc565fa-bcc0-4600-9cef-263822b08132@iki.fi>","body":"On 27/01/2026 01:25, Andres Freund wrote:\\n> On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote:\\n>> Perhaps we should turn the ExecScanExtended() function inside out. Instead\\n>> of passing SeqNext as a callback to ExecScanExtended(), we would have a\\n>> function like this (for illustration purposes only, doesn't compile):\\n> > That would be one approach, would require structural changes in a fair number\\n> of places though :/.\\n\\nExecScanExtended is only used in execScan.c and nodeSeqScan.c, so not that many places. Even replacing ExecScan() completely would be isolated to src/backend/executor.\\n\\n> A slightly simpler approach could be for ExecScanExtended to pass in these\\n> parameters as arguments to the callbacks. For things like estate, direction\\n> and scanslot, that makes plenty sense. It's a bit more problematic for the\\n> scan descriptor, due to the \\"lazy start\\" we have in a few places.\\n\\nYep, it's less flexible. We have to know beforehand which variables the function might want to avoid re-fetching, and add them all as parameters.\\n\\n> I very briefly prototyped that (relying on the fact that all callers cast to\\n> the callback type and that passing unused arguments just works even if the\\n> function definition doesn't expect them), and that seems to do the trick.\\n\\nThis can be a very hot codepath so if we can shave a few % off, I'm willing to hold my nose. But if we can do it more elegantly, even better...\\n\\n> What shows up more visibly afterwards is that we set ExecScanExtended() sets\\n> econtext->ecxt_scantuple in every iteration, despite that not changing in\\n> almost all cases (I think for FDWs it could, fdwhandler.sgml just says that\\n> the scanslot \\"should\\" be used).\\n\\nHuh, that's just a single store instruction. This really is a hot path. Or is it just that the first instruction after the function call causes some kind of a stall or data dependency, i.e. if that was removed, it'd just move to the next instruction instead?\\n\\nI wonder about the access to (econtext)->ecxt_per_tuple_memory. That never changes, but we're re-fetching that too on every iteration.\\n\\nInstrCountFiltered1() also fetches node->instrument, with a NULL check, on every iteration. Maybe keep a counter in a local variable and only call InstrCountFiltered1() when exiting the loop.\\n\\nI guess these don't show up in a profiler or you would've latched on them already..\\n\\n- Heikki\\n\\n\\n\\n"},{"id":"19bff26bc37bbc6e","threadId":"19bec801a96f066e","snippet":"On Mon, Jan 26, 2026 at 5:27 PM Amit Kapila <amit.kapila16@gmail.com> wrote: > > On Sat, Jan 24, 2026 at 9:01 PM Andres Freund <andres@anarazel.de> wrote: > > > > On 2026-","historyId":"27112","internalDate":"1769512255000","receivedAtUtc":"2026-01-27T11:10:55.000Z","from":"Dilip Kumar <dilipbalaut@gmail.com>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<CAFiTN-tAo978okqS-vAt-5QFLWZRa_QfUFBdT_0-9P_ujRXnKA@mail.gmail.com>","body":"On Mon, Jan 26, 2026 at 5:27 PM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n>\\n> On Sat, Jan 24, 2026 at 9:01 PM Andres Freund <andres@anarazel.de> wrote:\\n> >\\n> > On 2026-01-24 15:23:44 +0530, Amit Kapila wrote:\\n> > > On Sat, Jan 24, 2026 at 1:46 AM Andres Freund <andres@anarazel.de> wrote:\\n> > > >\\n> > > > - The checkXidAlive checks that have been added to table_scan_getnextslot()\\n> > > >   show up noticeably and in every loop iteration, despite afaict never being reachable\\n> > > >\\n> > > >   It's not obvious to me that this should\\n> > > >   a) be in table_scan_getnextslot(), rather than in beginscan - how could it\\n> > > >      change in the middle of a scan? That would require a wrapper around\\n> > > >      rd_tableam->scan_begin(), but that seems like it might be good anyway.\\n> > > >   b) not just be an assertion?\\n> > > >\\n> > >\\n> > > IIRC, the main reason for having this precautionary check in the API\\n> > > is to ensure that during logical decoding we never access the table AM\\n> > > or\\n> > > heap APIs directly when scanning catalog tables. This restriction\\n> > > exists because we only check for concurrent aborts inside the\\n> > > systable_* APIs.\\n> >\\n> > I know why the check exists - but why does it have to be in\\n> > table_scan_getnextslot(), which is executed very frequently, rather than\\n> > table_beginscan*(), which is executed much less frequently.\\n> >\\n>\\n> I thought about this point and couldn't think of any reason why this\\n> check can't be in table_beginscan*(). I think your idea of having a\\n> wrapper around scan_begin() to handle this check is a good one.\\n\\nHere is the patch. I've used table_scan_begin_wrapper() to wrap the\\nscan_begin() callback for now. If you have a better naming preference\\nto avoid the 'wrapper' suffix, please let me know.\\n\\n-- \\nRegards,\\nDilip Kumar\\nGoogle\\n"},{"id":"19c0068c12baf979","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-27 12:16:15 +0200, Heikki Linnakangas wrote: > On 27/01/2026 01:25, Andres Freund wrote: > > On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote: > > > Perhaps we","historyId":"29239","internalDate":"1769533379000","receivedAtUtc":"2026-01-27T17:02:59.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<lp4e5zipwolqcmnxvvlpx2ylmkjgip7cvbaud55dqdydfobupx@itmbp24b4ue2>","body":"Hi,\\n\\nOn 2026-01-27 12:16:15 +0200, Heikki Linnakangas wrote:\\n> On 27/01/2026 01:25, Andres Freund wrote:\\n> > On 2026-01-26 17:23:16 +0200, Heikki Linnakangas wrote:\\n> > > Perhaps we should turn the ExecScanExtended() function inside out. Instead\\n> > > of passing SeqNext as a callback to ExecScanExtended(), we would have a\\n> > > function like this (for illustration purposes only, doesn't compile):\\n> >\\n> > That would be one approach, would require structural changes in a fair number\\n> > of places though :/.\\n>\\n> ExecScanExtended is only used in execScan.c and nodeSeqScan.c, so not that\\n> many places. Even replacing ExecScan() completely would be isolated to\\n> src/backend/executor.\\n\\nI was assuming we'd not want a totally different structure for nodeSeqScan.c\\nthan for the rest. I think we really ought to use ExecScanExtended\\neverywhere. Probably not with multiple callsites (for no qual, no projection\\netc), but to get rid of the indirect function calls to \\"accessMtd\\".\\n\\n> > What shows up more visibly afterwards is that we set ExecScanExtended() sets\\n> > econtext->ecxt_scantuple in every iteration, despite that not changing in\\n> > almost all cases (I think for FDWs it could, fdwhandler.sgml just says that\\n> > the scanslot \\"should\\" be used).\\n>\\n> Huh, that's just a single store instruction. This really is a hot path. Or\\n> is it just that the first instruction after the function call causes some\\n> kind of a stall or data dependency, i.e. if that was removed, it'd just move\\n> to the next instruction instead?\\n\\nI was a bit surprised too. It might be a case of some store forwarding issue,\\nbecause very shortly afterwards we end up reading ecxt_scantuple (at the start\\nof expression evaluation). Or we're just hitting limits on the number of\\nin-flight stores.\\n\\n\\n> I wonder about the access to (econtext)->ecxt_per_tuple_memory. That never\\n> changes, but we're re-fetching that too on every iteration.\\n\\nThe load itself didn't show up crazily, but there's something related that\\ndoes show up quite prominently: ResetExprContext().  I briefly hacked upan\\ninline version of MemoryContextReset(), and that does help noticeably.\\n\\nAnother context related thing that does show up is all the switcheroo around\\nCurrentMemoryContext.\\n\\n\\n> InstrCountFiltered1() also fetches node->instrument, with a NULL check, on\\n> every iteration. Maybe keep a counter in a local variable and only call\\n> InstrCountFiltered1() when exiting the loop.\\n\\n\\n> I guess these don't show up in a profiler or you would've latched on them\\n> already..\\n\\nIt does show up, but only really after addressing the other things... There\\nare plenty more things that show up, fwiw:\\n\\n- Expression evaluation checks for NULL function args, even though we could\\n  know that they should not be NULL (this is complicated by the fact that\\n  sometimes we build \\"illegal\\" tuples, before constraint checking). That shows\\n  up surprisingly high.\\n\\n  I think if we added information about whether NOT NULL is reliable in\\n  tupledescs it could solve this.\\n\\n  While it'd allow optimizing some cases, it'd still be limited due strict\\n  function calls not being guaranteed to return NOT NULL.\\n\\n\\n- heap_getnextslot()'s calls to heapgettup_pagemode() should be inlined\\n\\n\\n- we probably should eventually inline ExecStoreBufferHeapTuple(),\\n  that way we would only need to handle the \\"buffer has changed\\" paths when\\n  heapgettup_pagemode() switches pages\\n\\n\\n- Expression evaluation has a too high startup overhead. This is partially due\\n  to it preparing to access all types of slots, which most of the time aren't\\n  needed.\\n\\n  This would be a lot easier if we didn't need to go through the indirection\\n  via ExprContext to find the right scan/outer/... slot during every\\n  evaluation. But unfortunately there are some callsites that do change the\\n  slot between executions.  Perhaps we could make it a per-expression\\n  operation to change the slot of an expression, which would update state\\n  inside the ExprState?\\n\\n\\n- The access to columns in slots is too expensive during expression\\n  evaluation. We go from the slot, via an indirect memory access, to the\\n  values array, then have to fetch the right element there. Then do the same\\n  for nulls.\\n\\n  I think to really do better we'd need to do two things:\\n\\n  - Use one NullableDatum array instead of two separate arrays for values and\\n    isnull.\\n\\n  - Store the array in place in the slot, as a flexible array member). That\\n    makes storing of per-slot-type data harder though.  We probably would need\\n    to embed the \\"common\\" part of the slot at the end of the custom part of\\n    the slot, which is more complicated...\\n\\n  That's a lot of work, I tried it before... There's a fair bit of fallout due\\n  to all the places that do stuff like forming tuples based on\\n  tts_values/tts_isnull.\\n\\n  I do wonder if it could already help to just store the offset to the values\\n  and isnull arrays inside the slot, instead of having to read pointers and\\n  then do address calculation based on those.\\n\\n\\n- The function call interface is way too expensive for simple operators\\n\\n  We need a simplified function call interface that doesn't shuffle everything\\n  through pointers...\\n\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19c00ea54a062e51","threadId":"19bec801a96f066e","snippet":"Hi, On 2026-01-27 16:40:55 +0530, Dilip Kumar wrote: > > > I know why the check exists - but why does it have to be in > > > table_scan_getnextslot(), which is executed very","historyId":"30232","internalDate":"1769541870000","receivedAtUtc":"2026-01-27T19:24:30.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: unnecessary executor overheads around seqscans","messageId":"<qnyy2a2rlohsq5mkehqehmdc2zzv7d3ren7hedw3hy5vup26yf@3yk4s3dtl6fn>","body":"Hi,\\n\\nOn 2026-01-27 16:40:55 +0530, Dilip Kumar wrote:\\n> > > I know why the check exists - but why does it have to be in\\n> > > table_scan_getnextslot(), which is executed very frequently, rather than\\n> > > table_beginscan*(), which is executed much less frequently.\\n> > >\\n> >\\n> > I thought about this point and couldn't think of any reason why this\\n> > check can't be in table_beginscan*(). I think your idea of having a\\n> > wrapper around scan_begin() to handle this check is a good one.\\n> \\n> Here is the patch. I've used table_scan_begin_wrapper() to wrap the\\n> scan_begin() callback for now. If you have a better naming preference\\n> to avoid the 'wrapper' suffix, please let me know.\\n\\nI'd probably just go for _internal(), _impl() or such.\\n\\n\\n\\n> diff --git a/src/backend/access/table/tableam.c b/src/backend/access/table/tableam.c\\n> index 87491796523..15a92c052d3 100644\\n> --- a/src/backend/access/table/tableam.c\\n> +++ b/src/backend/access/table/tableam.c\\n> [...]\\n> +/*\\n> + * table_scan_begin_wrapper\\n> + *\\n> + * A wrapper around the Table Access Method scan_begin callback. This handles\\n> + * centralized error checking—specifically ensuring we aren't performing\\n> + * table scan while CheckXidAlive is valid.  This state is reserved for\\n> + * specific logical decoding operations where direct relation scanning is\\n> + * prohibited.\\n> + */\\n> +TableScanDesc\\n> +table_scan_begin_wrapper(Relation rel, Snapshot snapshot, int nkeys,\\n> +\\t\\t\\t\\t\\t\\t ScanKeyData *key, ParallelTableScanDesc pscan,\\n> +\\t\\t\\t\\t\\t\\t uint32 flags)\\n> +{\\n> +\\t/*\\n> +\\t * We don't expect direct calls to this function with valid CheckXidAlive\\n> +\\t * for catalog or regular tables.  See detailed comments in xact.c where\\n> +\\t * these variables are declared.\\n> +\\t */\\n> +\\tif (unlikely(TransactionIdIsValid(CheckXidAlive) && !bsysscan))\\n> +\\t\\telog(ERROR, \\"unexpected table_scan_begin_wrapper call during logical decoding\\");\\n> +\\n> +\\treturn rel->rd_tableam->scan_begin(rel, snapshot, nkeys, key, pscan, flags);\\n> +}\\n\\nGiven that some of the callers are in inline functions in tableam.h, I would\\nimplement the wrapper there. I doubt it'll make a meaningful difference, but\\nit doesn't seem worth \\"risking\\" that.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"}]	Andres Freund initiated a discussion about optimizing PostgreSQL executor overhead in sequential scans. He identified multiple performance bottlenecks: repeated fetching of variables in SeqNext() during ExecScanExtended loops, unnecessary checkXidAlive checks in table_scan_getnextslot(), and redundant setting of econtext->ecxt_scantuple. Heikki Linnakangas suggested restructuring ExecScanExtended() or passing parameters as arguments to callbacks. Andres prototyped passing parameters to callbacks and found it effective. Dilip Kumar proposed moving checkXidAlive checks from table_scan_getnextslot() to table_beginscan*() functions, providing a patch with table_scan_begin_wrapper(). Andres agreed but suggested implementing the wrapper in tableam.h for potential inlining benefits. The discussion also covered deeper optimization opportunities including expression evaluation overhead, memory context switching costs, and function call interface improvements. Amit Langote tested patches but saw minimal performance differences in VM testing.	2026-01-27 19:24:30+00	Andres Freund发起了关于优化PostgreSQL执行器在顺序扫描中开销的讨论。他识别了多个性能瓶颈：在ExecScanExtended循环期间SeqNext()中重复获取变量、table_scan_getnextslot()中不必要的checkXidAlive检查，以及冗余设置econtext->ecxt_scantuple。Heikki Linnakangas建议重构ExecScanExtended()或将参数作为参数传递给回调函数。Andres原型化了向回调函数传递参数的方法并发现其有效。Dilip Kumar提议将checkXidAlive检查从table_scan_getnextslot()移至table_beginscan*()函数，并提供了带有table_scan_begin_wrapper()的补丁。Andres同意但建议在tableam.h中实现包装器以获得潜在的内联优势。讨论还涵盖了更深层的优化机会，包括表达式评估开销、内存上下文切换成本和函数调用接口改进。Amit Langote测试了补丁，但在VM测试中看到的性能差异微小。
29	19bfff779b0f694c	pgsql: Prevent invalidation of newly synced replication slots.	["akapila@postgresql.org","amit.kapila16@gmail.com","andres@anarazel.de","dbryan.green@gmail.com","greg@burd.me","robertmhaas@gmail.com","tgl@sss.pgh.pa.us","thomas.munro@gmail.com"]	[{"id":"19bfff779b0f694c","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote: > Prevent invalidation of newly synced replication slots. This commit has broken CI for me. On the \\"Windows -","historyId":"28104","internalDate":"1769525944000","receivedAtUtc":"2026-01-27T14:59:04.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmobdVhO0ckZfsBZ0wqDO4qHVCwZZx8sf=EinafvUam-dsQ@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote:\\n> Prevent invalidation of newly synced replication slots.\\n\\nThis commit has broken CI for me. On the \\"Windows - Server 2022, VS\\n2019 - Meson & ninja\\" build, the following shows up in\\n046_checkpoint_logical_slot_standby.log:\\n\\n2026-01-27 13:44:44.421 GMT startup[5172] FATAL:  could not rename\\nfile \\"backup_label\\" to \\"backup_label.old\\": Permission denied\\n\\nI imagine this is going to break CI for everybody else too, as well as cfbot.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c00026a2c7bb64","threadId":"19bfff779b0f694c","snippet":"Robert Haas <robertmhaas@gmail.com> writes: > On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote: >> Prevent invalidation of newly synced replication slots","historyId":"28185","internalDate":"1769526672000","receivedAtUtc":"2026-01-27T15:11:12.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<428236.1769526672@sss.pgh.pa.us>","body":"Robert Haas <robertmhaas@gmail.com> writes:\\n> On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote:\\n>> Prevent invalidation of newly synced replication slots.\\n\\n> This commit has broken CI for me.\\n\\nHmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\nto believe a Windows-only problem, but at least hamerkop has run\\nsince 851f664.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"},{"id":"19c0025985d49525","threadId":"19bfff779b0f694c","snippet":"I wrote: > Robert Haas <robertmhaas@gmail.com> writes: >> This commit has broken CI for me. > Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared > to believe a","historyId":"28457","internalDate":"1769528979000","receivedAtUtc":"2026-01-27T15:49:39.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<544727.1769528979@sss.pgh.pa.us>","body":"I wrote:\\n> Robert Haas <robertmhaas@gmail.com> writes:\\n>> This commit has broken CI for me.\\n\\n> Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\n> to believe a Windows-only problem, but at least hamerkop has run\\n> since 851f664.\\n\\nD'oh: hamerkop doesn't run any TAP tests, let alone ones that require\\n--enable-injection-points.  So that success proves nothing.\\n\\nOur other Windows animals (drongo, fairywren, unicorn) seem to be\\nconfigured with -Dtap_tests=enabled, but nothing about injection\\npoints, so they will also skip 046_checkpoint_logical_slot.\\nSeems like a bit of a blind spot in the buildfarm.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"},{"id":"19c0027e521e4830","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 10:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > Robert Haas <robertmhaas@gmail.com> writes: > > On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@","historyId":"28500","internalDate":"1769529118000","receivedAtUtc":"2026-01-27T15:51:58.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmoYvtJoU0eyw3XEmLLda_JV4qSJxJpVfoTtFL3uPs5+7vw@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 10:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> Robert Haas <robertmhaas@gmail.com> writes:\\n> > On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote:\\n> >> Prevent invalidation of newly synced replication slots.\\n>\\n> > This commit has broken CI for me.\\n>\\n> Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\n> to believe a Windows-only problem, but at least hamerkop has run\\n> since 851f664.\\n\\nI don't understand it, either. There's a bunch of error codes that we\\nmap to EACCES in _dosmaperr, but I don't know why any of those\\nproblems would have occurred here:\\n\\nERROR_ACCESS_DENIED, EACCES\\nERROR_CURRENT_DIRECTORY, EACCES\\nERROR_LOCK_VIOLATION, EACCES\\nERROR_SHARING_VIOLATION, EACCES\\nERROR_NETWORK_ACCESS_DENIED, EACCES\\nERROR_CANNOT_MAKE, EACCES\\nERROR_FAIL_I24, EACCES\\nERROR_DRIVE_LOCKED, EACCES\\nERROR_SEEK_ON_DEVICE, EACCES\\nERROR_NOT_LOCKED, EACCES\\nERROR_LOCK_FAILED, EACCES\\n\\n(Side note: Wouldn't it make a lot of sense to go back and kill\\n_dosmaperr in favor of display the actual Windows error code string?)\\n\\nWhat's also puzzling is that what this test is doing seems to be\\ntotally standard. 040_standby_failover_slots_sync.pl does this:\\n\\nmy $standby1 = PostgreSQL::Test::Cluster->new('standby1');\\n$standby1->init_from_backup(\\n        $primary, $backup_name,\\n        has_streaming => 1,\\n        has_restoring => 1);\\n\\nAnd 046_checkpont_logical_slot.pl does this:\\n\\nmy $standby = PostgreSQL::Test::Cluster->new('standby');\\n$standby->init_from_backup(\\n    $primary, $backup_name,\\n    has_streaming => 1,\\n    has_restoring => 1);\\n\\nSo why is 046 failing and 040 is fine? I have no idea.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c0039469215822","threadId":"19bfff779b0f694c","snippet":"Robert Haas <robertmhaas@gmail.com> writes: > What's also puzzling is that what this test is doing seems to be > totally standard. Yeah. I do notice something interesting when running","historyId":"28666","internalDate":"1769530268000","receivedAtUtc":"2026-01-27T16:11:08.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<547219.1769530268@sss.pgh.pa.us>","body":"Robert Haas <robertmhaas@gmail.com> writes:\\n> What's also puzzling is that what this test is doing seems to be\\n> totally standard.\\n\\nYeah.  I do notice something interesting when running it here:\\n046_checkpoint_logical_slot_mike.log shows that we are triggering\\nquite a few checkpoints (via pg_switch_wal()) in quick succession\\non the primary.  I wonder if that is somehow tickling a Windows\\nfilesystem restriction.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"},{"id":"19c003e82e138131","threadId":"19bfff779b0f694c","snippet":"On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote: > I imagine this is going to break CI for everybody else too, as well as cfbot. Just by the way, on that last point,","historyId":"28794","internalDate":"1769530573000","receivedAtUtc":"2026-01-27T16:16:13.000Z","from":"Thomas Munro <thomas.munro@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+hUKGJotCdMdhrwVST4xbsPzr-csDgzveNhKu4UAXEmCDJ4iA@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote:\\n> I imagine this is going to break CI for everybody else too, as well as cfbot.\\n\\nJust by the way, on that last point, we trained cfbot to watch out for\\nCI pass/fail in this account:\\n\\nhttps://github.com/postgres/postgres/commits/master/\\n\\nand then use the most recent pass as the base commit when applying\\npatches to make test branches.  So if master is broken for a while, it\\nno longer takes all the cfbot runs with it.  Mentioning just in case\\nanyone is confused by that...\\n\\nAs for what's happening... hmm, there are a few holes in the \\"shared\\nlocking\\" stuff you get with the flags we use.  For example you can't\\nunlink a directory that contains a file that has been unlinked but\\nsomeone still holds open.  Doesn't seem to be the case here.  But I\\nwonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that\\nhas already been unlinked (or renamed over) that someone still holds\\nopen, or something like that...\\n\\n\\n"},{"id":"19c003f22c3a49b7","threadId":"19bfff779b0f694c","snippet":"Hi, On 2026-01-27 10:51:58 -0500, Robert Haas wrote: > I don't understand it, either. There's a bunch of error codes that we > map to EACCES in _dosmaperr, but I don't know why any of","historyId":"28838","internalDate":"1769530651000","receivedAtUtc":"2026-01-27T16:17:31.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<o5t5teaoz3ohto3xeftdumixoqyuee4u54ysyk4lvhpp54bd2w@h6citz4to4ib>","body":"Hi,\\n\\nOn 2026-01-27 10:51:58 -0500, Robert Haas wrote:\\n> I don't understand it, either. There's a bunch of error codes that we\\n> map to EACCES in _dosmaperr, but I don't know why any of those\\n> problems would have occurred here:\\n> \\n> ERROR_ACCESS_DENIED, EACCES\\n> ERROR_CURRENT_DIRECTORY, EACCES\\n> ERROR_LOCK_VIOLATION, EACCES\\n> ERROR_SHARING_VIOLATION, EACCES\\n> ERROR_NETWORK_ACCESS_DENIED, EACCES\\n> ERROR_CANNOT_MAKE, EACCES\\n> ERROR_FAIL_I24, EACCES\\n> ERROR_DRIVE_LOCKED, EACCES\\n> ERROR_SEEK_ON_DEVICE, EACCES\\n> ERROR_NOT_LOCKED, EACCES\\n> ERROR_LOCK_FAILED, EACCES\\n> \\n> (Side note: Wouldn't it make a lot of sense to go back and kill\\n> _dosmaperr in favor of display the actual Windows error code string?)\\n\\nIt'd be great to somehow preserve the mapping to preserve the original error\\nmessage, but I don't really see how we could just give up on our mapping. We\\nrely on e.g. knowing that a read failed due to ENOENT, not\\nERROR_FILE_NOT_FOUND or whatnot.\\n\\n\\n> What's also puzzling is that what this test is doing seems to be\\n> totally standard. 040_standby_failover_slots_sync.pl does this:\\n> \\n> my $standby1 = PostgreSQL::Test::Cluster->new('standby1');\\n> $standby1->init_from_backup(\\n>         $primary, $backup_name,\\n>         has_streaming => 1,\\n>         has_restoring => 1);\\n> \\n> And 046_checkpont_logical_slot.pl does this:\\n> \\n> my $standby = PostgreSQL::Test::Cluster->new('standby');\\n> $standby->init_from_backup(\\n>     $primary, $backup_name,\\n>     has_streaming => 1,\\n>     has_restoring => 1);\\n> \\n> So why is 046 failing and 040 is fine? I have no idea.\\n\\n046 does a fair bit of stuff before the base backup is being taken, I guess?\\nBut what that concretely could be, I have no idea.\\n\\nIt'd be one thing if it failed while creating a base backup, but the fact that\\nit allows the base backup being created, but then fails during startup is just\\nplain odd.  The typical sharing violation issue seems like it'd require that\\nwe somehow are not waiting for pg_basebackup to actually have terminated?\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19c003f787cf141b","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote: > Robert Haas <robertmhaas@gmail.com> writes: > > What's also puzzling is that what this test is doing","historyId":"28887","internalDate":"1769530663000","receivedAtUtc":"2026-01-27T16:17:43.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmobXMhXFYM=mJ51f5PRFuj7eR9zn68Bvjndjz-k+daSotg@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:11 AM Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> Robert Haas <robertmhaas@gmail.com> writes:\\n> > What's also puzzling is that what this test is doing seems to be\\n> > totally standard.\\n>\\n> Yeah.  I do notice something interesting when running it here:\\n> 046_checkpoint_logical_slot_mike.log shows that we are triggering\\n> quite a few checkpoints (via pg_switch_wal()) in quick succession\\n> on the primary.  I wonder if that is somehow tickling a Windows\\n> filesystem restriction.\\n\\nMaybe, but it seems unlikely to me that this would mess up the\\nstandby, since it's a totally different node. What I kind of wonder is\\nif somehow there's still a process that has backup_label open, or has\\nclosed it but not recently enough for Windows to unlock it. However, I\\ndon't see why that would affect this test case and not others.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c0051d2d756f1b","threadId":"19bfff779b0f694c","snippet":"Hi, On 2026-01-28 05:16:13 +1300, Thomas Munro wrote: > On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote: > > I imagine this is going to break CI for everybody","historyId":"29049","internalDate":"1769531876000","receivedAtUtc":"2026-01-27T16:37:56.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<jqliu25wuvlxcjybekrpvmflgaod4iytlwekjyag2q43ml76fg@tfna2hbyhw4s>","body":"Hi,\\n\\nOn 2026-01-28 05:16:13 +1300, Thomas Munro wrote:\\n> On Wed, Jan 28, 2026 at 3:59 AM Robert Haas <robertmhaas@gmail.com> wrote:\\n> > I imagine this is going to break CI for everybody else too, as well as cfbot.\\n> \\n> Just by the way, on that last point, we trained cfbot to watch out for\\n> CI pass/fail in this account:\\n> \\n> https://github.com/postgres/postgres/commits/master/\\n> \\n> and then use the most recent pass as the base commit when applying\\n> patches to make test branches.  So if master is broken for a while, it\\n> no longer takes all the cfbot runs with it.  Mentioning just in case\\n> anyone is confused by that...\\n\\nAh. I was indeed confused by that for a bit.\\n\\n\\n> But I wonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that\\n> has already been unlinked (or renamed over) that someone still holds open,\\n> or something like that...\\n\\nI don't see a source of that that would be specific to this test though :(. We\\ndo wait for pg_basebackup to have shut down, which wrote backup.label (which\\nwas \\"manifactured\\" during streaming by basebackup.c).\\n\\n\\nPerhaps we should crank up log level in the test? No idea if it'll help, but\\nright now I don't even know where to start looking.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"},{"id":"19c006061eecf933","threadId":"19bfff779b0f694c","snippet":"> On Jan 27, 2026, at 10:49 AM, Tom Lane <tgl@sss.pgh.pa.us> wrote: > > I wrote: >> Robert Haas <robertmhaas@gmail.com> writes: >>> This commit has broken CI for me.","historyId":"29145","internalDate":"1769532818000","receivedAtUtc":"2026-01-27T16:53:38.000Z","from":"Greg Burd <greg@burd.me>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<54F8BC8B-6F9D-4B91-8B68-AA02B7643B94@burd.me>","body":"\\n> On Jan 27, 2026, at 10:49 AM, Tom Lane <tgl@sss.pgh.pa.us> wrote:\\n> \\n> I wrote:\\n>> Robert Haas <robertmhaas@gmail.com> writes:\\n>>> This commit has broken CI for me.\\n> \\n>> Hmm, I wonder why the buildfarm seems fine with it ... I'm prepared\\n>> to believe a Windows-only problem, but at least hamerkop has run\\n>> since 851f664.\\n> \\n> D'oh: hamerkop doesn't run any TAP tests, let alone ones that require\\n> --enable-injection-points.  So that success proves nothing.\\n> \\n> Our other Windows animals (drongo, fairywren, unicorn) seem to be\\n> configured with -Dtap_tests=enabled, but nothing about injection\\n> points, so they will also skip 046_checkpoint_logical_slot.\\n> Seems like a bit of a blind spot in the buildfarm.\\n> \\n> regards, tom lane\\n> \\n\\n\\nI'll see if I can update unicorn today to enable injection points to add some coverage on Win11/ARM64/MSVC.  No promises that will be diagnostic at all, but it seems like a good idea.\\n\\n\\n-Dinjection_points=true\\n\\n\\n-greg\\n\\n"},{"id":"19c00709ec06c5ca","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:53 AM Greg Burd <greg@burd.me> wrote: > I'll see if I can update unicorn today to enable injection points to add some coverage on Win11/ARM64/MSVC. No promises","historyId":"29286","internalDate":"1769533883000","receivedAtUtc":"2026-01-27T17:11:23.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmoZFs8Xqf4J5fEgXiZcpH4cK0jEygB7s13riPyGKB-n17w@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:53 AM Greg Burd <greg@burd.me> wrote:\\n> I'll see if I can update unicorn today to enable injection points to add some coverage on Win11/ARM64/MSVC.  No promises that will be diagnostic at all, but it seems like a good idea.\\n> -Dinjection_points=true\\n\\nSounds good!\\n\\nThanks,\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c008d8107e63b6","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:37 AM Andres Freund <andres@anarazel.de> wrote: > > But I wonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that","historyId":"29617","internalDate":"1769535771000","receivedAtUtc":"2026-01-27T17:42:51.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmobkmUMBocv0hxKiBj_5ZoTRE=qPz7QOu7voJ_j=dWNaaA@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:37 AM Andres Freund <andres@anarazel.de> wrote:\\n> > But I wonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that\\n> > has already been unlinked (or renamed over) that someone still holds open,\\n> > or something like that...\\n>\\n> I don't see a source of that that would be specific to this test though :(. We\\n> do wait for pg_basebackup to have shut down, which wrote backup.label (which\\n> was \\"manifactured\\" during streaming by basebackup.c).\\n>\\n> Perhaps we should crank up log level in the test? No idea if it'll help, but\\n> right now I don't even know where to start looking.\\n\\nI tried sticking a pg_sleep(30) in just before starting the standby\\nnode, and that didn't help, so it doesn't seem like it's a race\\ncondition.\\n\\nHere's what the standby log file looks like with log_min_messages=DEBUG2:\\n\\n2026-01-27 17:19:25.262 GMT postmaster[4932] DEBUG:  registering\\nbackground worker \\"logical replication launcher\\"\\n2026-01-27 17:19:25.264 GMT postmaster[4932] DEBUG:  dynamic shared\\nmemory system will support 229 segments\\n2026-01-27 17:19:25.264 GMT postmaster[4932] DEBUG:  created dynamic\\nshared memory control segment 3769552926 (9176 bytes)\\n2026-01-27 17:19:25.266 GMT postmaster[4932] DEBUG:  max_safe_fds =\\n990, usable_fds = 1000, already_open = 3\\n2026-01-27 17:19:25.268 GMT postmaster[4932] LOG:  starting PostgreSQL\\n19devel on x86_64-windows, compiled by msvc-19.29.30159, 64-bit\\n2026-01-27 17:19:25.271 GMT postmaster[4932] LOG:  listening on Unix\\nsocket \\"C:/Windows/TEMP/3xesO1s4ba/.s.PGSQL.17575\\"\\n2026-01-27 17:19:25.273 GMT postmaster[4932] DEBUG:  updating PMState\\nfrom PM_INIT to PM_STARTUP\\n2026-01-27 17:19:25.273 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 57 for io worker\\n2026-01-27 17:19:25.275 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 58 for io worker\\n2026-01-27 17:19:25.277 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 59 for io worker\\n2026-01-27 17:19:25.278 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 56 for checkpointer\\n2026-01-27 17:19:25.280 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 55 for background writer\\n2026-01-27 17:19:25.281 GMT postmaster[4932] DEBUG:  assigned pm child\\nslot 89 for startup\\n2026-01-27 17:19:25.308 GMT checkpointer[6560] DEBUG:  checkpointer\\nupdated shared memory configuration values\\n2026-01-27 17:19:25.314 GMT startup[2488] LOG:  database system was\\ninterrupted; last known up at 2026-01-27 17:19:21 GMT\\n2026-01-27 17:19:25.317 GMT startup[2488] DEBUG:  removing all\\ntemporary WAL segments\\nThe system cannot find the file specified.\\n2026-01-27 17:19:25.336 GMT startup[2488] DEBUG:  could not restore\\nfile \\"00000002.history\\" from archive: child process exited with exit\\ncode 1\\n2026-01-27 17:19:25.337 GMT startup[2488] DEBUG:  backup time\\n2026-01-27 17:19:21 GMT in file \\"backup_label\\"\\n2026-01-27 17:19:25.337 GMT startup[2488] DEBUG:  backup label\\npg_basebackup base backup in file \\"backup_label\\"\\n2026-01-27 17:19:25.337 GMT startup[2488] DEBUG:  backup timeline 1 in\\nfile \\"backup_label\\"\\n2026-01-27 17:19:25.337 GMT startup[2488] LOG:  starting backup\\nrecovery with redo LSN 0/2A000028, checkpoint LSN 0/2A000080, on\\ntimeline ID 1\\nThe system cannot find the file specified.\\n2026-01-27 17:19:25.352 GMT startup[2488] DEBUG:  could not restore\\nfile \\"00000001000000000000002A\\" from archive: child process exited\\nwith exit code 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  checkpoint record is\\nat 0/2A000080\\n2026-01-27 17:19:25.353 GMT startup[2488] LOG:  entering standby mode\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  redo record is at\\n0/2A000028; shutdown false\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  next transaction ID:\\n769; next OID: 24576\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  next MultiXactId: 1;\\nnext MultiXactOffset: 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  oldest unfrozen\\ntransaction ID: 760, in database 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  oldest MultiXactId:\\n1, in database 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  commit timestamp Xid\\noldest/newest: 0/0\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  transaction ID wrap\\nlimit is 2147484407, limited by database with OID 1\\n2026-01-27 17:19:25.353 GMT startup[2488] DEBUG:  MultiXactId wrap\\nlimit is 2147483648, limited by database with OID 1\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  starting up replication slots\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  xmin required by\\nslots: data 0, catalog 0\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  starting up\\nreplication origin progress state\\n2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  didn't need to\\nunlink permanent stats file \\"pg_stat/pgstat.stat\\" - didn't exist\\n2026-01-27 17:19:38.938 GMT startup[2488] FATAL:  could not rename\\nfile \\"backup_label\\" to \\"backup_label.old\\": Permission denied\\n2026-01-27 17:19:38.983 GMT postmaster[4932] DEBUG:  releasing pm child slot 89\\n2026-01-27 17:19:38.983 GMT postmaster[4932] LOG:  startup process\\n(PID 2488) exited with exit code 1\\n2026-01-27 17:19:38.983 GMT postmaster[4932] LOG:  aborting startup\\ndue to startup process failure\\n2026-01-27 17:19:38.983 GMT postmaster[4932] DEBUG:  cleaning up\\ndynamic shared memory control segment with ID 3769552926\\n2026-01-27 17:19:38.985 GMT postmaster[4932] LOG:  database system is shut down\\n\\nUnfortunately, I don't see any clues there. The \\"The system cannot\\nfind the file specified.\\" messages look like they might be a clue, but\\nI think they are not, because they also occur in\\n040_standby_failover_slots_sync_standby1.log, and that test passes. At\\nthe point where this log file shows the FATAL error, that log file\\ncontinues thus:\\n\\n2026-01-27 17:18:36.905 GMT startup[1420] DEBUG:  resetting unlogged\\nrelations: cleanup 1 init 0\\n2026-01-27 17:18:36.906 GMT startup[1420] DEBUG:  initializing for hot standby\\n2026-01-27 17:18:36.906 GMT startup[1420] LOG:  redo starts at 0/02000028\\n2026-01-27 17:18:36.906 GMT startup[1420] DEBUG:  recovery snapshots\\nare now enabled\\n2026-01-27 17:18:36.906 GMT startup[1420] CONTEXT:  WAL redo at\\n0/02000048 for Standby/RUNNING_XACTS: nextXid 769 latestCompletedXid\\n768 oldestRunningXid 769\\n2026-01-27 17:18:36.907 GMT startup[1420] DEBUG:  end of backup record reached\\n2026-01-27 17:18:36.907 GMT startup[1420] CONTEXT:  WAL redo at\\n0/02000100 for XLOG/BACKUP_END: 0/02000028\\n2026-01-27 17:18:36.907 GMT startup[1420] DEBUG:  end of backup reached\\n\\nWhich again seems totally normal.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c00ab94fdc7afb","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 12:42 PM Robert Haas <robertmhaas@gmail.com> wrote: > 2026-01-27 17:19:25.354 GMT startup[2488] DEBUG: didn't need to > unlink permanent stats file \\"pg_stat","historyId":"29798","internalDate":"1769537747000","receivedAtUtc":"2026-01-27T18:15:47.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+Tgmoa-RYWEkZi6tpp9TLrD+1kKFgxR6kgXCCiomMyDnh+ENw@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 12:42 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n> 2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  didn't need to\\n> unlink permanent stats file \\"pg_stat/pgstat.stat\\" - didn't exist\\n> 2026-01-27 17:19:38.938 GMT startup[2488] FATAL:  could not rename\\n> file \\"backup_label\\" to \\"backup_label.old\\": Permission denied\\n\\nAndrey Borodin pointed out to me off-list that there's a retry loop in\\npgrename(). The 13 second delay between the above two log messages\\nalmost certainly means that retry loop is iterating until it hits its\\n10 second timeout. This almost certainly means that the underlying\\nWindows error is ERROR_ACCESS_DENIED, ERROR_SHARING_VIOLATION, or\\nERROR_LOCK_VIOLATION, and that somebody else has the file open. But\\nnothing other than Perl touches that directory before we try to start\\nthe standby:\\n\\nmy $standby = PostgreSQL::Test::Cluster->new('standby');\\n$standby->init_from_backup(\\n        $primary, $backup_name,\\n        has_streaming => 1,\\n        has_restoring => 1);\\n$standby->append_conf(\\n        'postgresql.conf', qq(\\nhot_standby_feedback = on\\nprimary_slot_name = 'phys_slot'\\nprimary_conninfo = '$connstr_1 dbname=postgres'\\nlog_min_messages = 'debug2'\\n));\\n$standby->start;\\n\\nAs far as I can see, only init_from_backup() touches the backup_label\\nfile, and that just copies the directory using RecursiveCopy.pm, which\\nas far as I can tell is quite careful about closing file handles. So I\\nstill have no idea what's happening here.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c00ad17f6ab1a0","threadId":"19bfff779b0f694c","snippet":"Hi, On 2026-01-27 12:42:51 -0500, Robert Haas wrote: > I tried sticking a pg_sleep(30) in just before starting the standby > node, and that didn't help, so it doesn't seem like it's a","historyId":"29892","internalDate":"1769537858000","receivedAtUtc":"2026-01-27T18:17:38.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<y2tddikdvhr47nkybp457l7czr5alsosx2237n2eb4jkpcj4hr@wygnzz3kpqxl>","body":"Hi,\\n\\nOn 2026-01-27 12:42:51 -0500, Robert Haas wrote:\\n> I tried sticking a pg_sleep(30) in just before starting the standby\\n> node, and that didn't help, so it doesn't seem like it's a race\\n> condition.\\n\\nInteresting.\\n\\nIt could be worth trying to run the test in isolation, without all the other\\nconcurrent tests.\\n\\nGreg, have you tried to repro it interactively?\\n\\nBryan, you seem to have become the resident windows expert...\\n\\n\\n> 2026-01-27 17:19:25.337 GMT startup[2488] LOG:  starting backup\\n> recovery with redo LSN 0/2A000028, checkpoint LSN 0/2A000080, on\\n> timeline ID 1\\n> The system cannot find the file specified.\\n> 2026-01-27 17:19:25.352 GMT startup[2488] DEBUG:  could not restore\\n> file \\"00000001000000000000002A\\" from archive: child process exited\\n> with exit code 1\\n\\nI think that must be a message from \\"copy\\" (which we seem to be using for\\nrestore_command on windows).\\n\\nI don't know why the standby is created with has_restoring => 1. But it\\nshouldn't be related to the issue, I think?\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"}]	A recent commit by Amit Kapila to prevent invalidation of newly synced replication slots has broken CI on Windows platforms. Robert Haas reported that the test 046_checkpoint_logical_slot_standby.pl fails with a "Permission denied" error when trying to rename "backup_label" to "backup_label.old" during standby startup. The failure occurs specifically on Windows Server 2022 with VS 2019 using Meson & ninja build. Tom Lane noted that the buildfarm appears unaffected because Windows buildfarm animals don't run injection point tests, creating a blind spot in coverage. Investigation reveals the error involves a 13-second retry loop in pgrename(), suggesting another process has the backup_label file open, but the root cause remains unclear since the test code appears standard. Greg Burd offered to enable injection points on the unicorn buildfarm animal to provide Windows coverage. Despite debugging efforts including adding delays and verbose logging, developers haven't identified what's keeping the file locked on Windows.	2026-01-27 18:17:38+00	Amit Kapila最近提交的一个防止新同步复制槽失效的commit在Windows平台上破坏了CI。Robert Haas报告说测试046_checkpoint_logical_slot_standby.pl在备用服务器启动期间尝试将"backup_label"重命名为"backup_label.old"时失败，出现"Permission denied"错误。这个失败特别发生在使用Meson & ninja构建的Windows Server 2022与VS 2019环境中。Tom Lane注意到buildfarm看起来没有受到影响，因为Windows buildfarm机器不运行注入点测试，这在覆盖范围上造成了盲点。调查显示错误涉及pgrename()中的13秒重试循环，表明另一个进程打开了backup_label文件，但根本原因仍不清楚，因为测试代码看起来很标准。Greg Burd提议在unicorn buildfarm机器上启用注入点以提供Windows覆盖。尽管进行了调试努力，包括添加延迟和详细日志记录，开发人员仍未确定是什么在Windows上保持文件锁定。
29	19c008973d497d85	Report bytes and transactions actually sent downtream	["amit.kapila16@gmail.com","andres@anarazel.de","ashu.coek88@gmail.com","ashutosh.bapat.oss@gmail.com","bertranddrouvot.pg@gmail.com","shveta.malik@gmail.com"]	[{"id":"19c008973d497d85","threadId":"19c008973d497d85","snippet":"Hi, On 2025-12-11 10:29:42 +0530, Ashutosh Bapat wrote: > Please review. I'd simplify the patch to, initially, to just track the sent bytes. For one, that's by *far* the most useful","historyId":"29430","internalDate":"1769535520000","receivedAtUtc":"2026-01-27T17:38:40.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: Report bytes and transactions actually sent downtream","messageId":"<okmdepbsub6toaplj4o5i5f4xa4ckeihfihbk5x7ebbijpzzyu@dpmhunl4pupq>","body":"Hi,\\n\\nOn 2025-12-11 10:29:42 +0530, Ashutosh Bapat wrote:\\n> Please review.\\n\\nI'd simplify the patch to, initially, to just track the sent bytes.  For one,\\nthat's by *far* the most useful statistic.  But I also have some concerns\\nabout the other stats:\\n\\n\\n- To me filteredBytes is a pretty bogus number - the size that the output\\n  plugin would have sent and ReorderBufferChangeSize() are only kinda\\n  related. It'll be a hard number to interpret, I think.\\n\\n  It also seems to not account for filtering that happens based on the origin\\n  id.\\n\\n\\n- I don't have fundamental opposition to tracking the number of sent\\n  transactions, but I think the implementation is at the wrong place.\\n\\n  I think we ought to add explicit support for output plugins to filter\\n  transactions. Calling output plugins once for each change in a large\\n  transaction, which we already decided to not send out, makes no sense. It's\\n  far from free to do all the setup to decode a tuple, if the transaction is\\n  filtered, we shouldn't do that.\\n\\n  It's also far far from free to restore changes from disk if we are going to\\n  throw away the whole transaction.\\n\\n  The current way requires each output plugin to maintain its own tracking\\n  about whether it decided to not output the transaction, which doesn't seem\\n  right to me.\\n\\n  I'm also just not sure how useful it is, because most of the time we're\\n  going to filter on a per-change basis (e.g. only rels in a publication). But\\n  that's only sometimes going to affect the numbers of sent transactions.\\n\\n\\n  I'm not convinced as-is it's worth the breakage of all output plugins.\\n\\n\\nGreetings,\\n\\nAndres\\n\\n\\n"}]	Andres Freund reviews a patch for tracking bytes and transactions sent downstream in PostgreSQL logical replication. He suggests simplifying the initial implementation to only track sent bytes, which he considers the most useful statistic. He has concerns about the "filteredBytes" metric, calling it "bogus" because the output plugin size and ReorderBufferChangeSize() are only loosely related, making it difficult to interpret. For transaction tracking, he believes the implementation is at the wrong layer and advocates for explicit output plugin support to filter transactions earlier, avoiding costly tuple decoding and disk restoration for filtered transactions. He questions the utility of transaction counting since filtering typically occurs per-change rather than per-transaction, and suggests the current approach would break all existing output plugins.	2026-01-27 17:38:40+00	Andres Freund审查了一个用于跟踪PostgreSQL逻辑复制中下游发送字节数和事务数的补丁。他建议简化初始实现，只跟踪发送的字节数，认为这是最有用的统计数据。他对"filteredBytes"指标表示担忧，称其为"虚假的"，因为输出插件大小与ReorderBufferChangeSize()只是松散相关，难以解释。对于事务跟踪，他认为实现层次有误，主张为输出插件提供明确支持来更早地过滤事务，避免对被过滤事务进行昂贵的元组解码和磁盘恢复操作。他质疑事务计数的实用性，因为过滤通常按变更而非按事务进行，并指出当前方法会破坏所有现有的输出插件。
29	19be597e72b87c37	Skipping schema changes in publication	["1518981153@qq.com","amit.kapila16@gmail.com","barwick@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","houzj.fnst@fujitsu.com","shlok.kyal.oss@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19bfff3ab274417f","threadId":"19be597e72b87c37","snippet":"On Fri, 23 Jan 2026 at 18:41, vignesh C <vignesh21@gmail.com> wrote: > > On Wed, 21 Jan 2026 at 11:35, Dilip Kumar <dilipbalaut@gmail.com> wrote: > > > > On Mon, Jan 19,","historyId":"28057","internalDate":"1769524621000","receivedAtUtc":"2026-01-27T14:37:01.000Z","from":"vignesh C <vignesh21@gmail.com>","subject":"Re: Skipping schema changes in publication","messageId":"<CALDaNm3kX=16L-72m13CqXL9uAiHURNZ+BLo-HfTEYHDFejj-A@mail.gmail.com>","body":"On Fri, 23 Jan 2026 at 18:41, vignesh C <vignesh21@gmail.com> wrote:\\n>\\n> On Wed, 21 Jan 2026 at 11:35, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n> >\\n> > On Mon, Jan 19, 2026 at 3:08 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> > >\\n> > > Approaches for Supporting EXCEPT in Partitioned Tables\\n> > > ------------------------------------------------------------------------\\n> > >\\n> > > In an offline discussion with Peter Smith, Amit, and Shlok, we\\n> > > identified several approaches for supporting EXCEPT with partitioned\\n> > > tables and their partitions. I’d like to hear others’ opinions on\\n> > > these approaches.\\n> > >\\n> > > Consider the following partition hierarchy:\\n> > > tab_root\\n> > >   ├─ tab_part_1\\n> > >   │   ├─ tab_part_1_p1\\n> > >   │   └─ tab_part_1_p2\\n> > >   └─ tab_part_2\\n> > >       ├─ tab_part_2_p1\\n> > >       └─ tab_part_2_p2\\n> > >\\n> > >\\n> > > Approach 1:\\n> > > ---------------------------------\\n> > > If we exclude a table, then the data in that table and all of its\\n> > > partitions (i.e., the entire subtree under that table) should not be\\n> > > replicated.\\n> > >\\n> > > For example EXCEPT (tab_part_1) skips replication of tab_part_1 and\\n> > > all of its partitions.\\n> > >\\n> > > This behaviour remains the same with or without\\n> > > publish_via_partition_root. The publish_via_partition_root flag only\\n> > > affects publish_via_relid, i.e., the relation through which data is\\n> > > published.\\n> > >\\n> > > This approach involves certain implementation challenges. For brevity,\\n> > > these are documented in the attached 'Approach1_challenges' document.\\n> > >\\n> > > Approach 2:\\n> > > ---------------------------------------------------\\n> > > Assign meaning to ONLY and '*' for partition tables in the EXCEPT\\n> > > list. In HEAD, ONLY and '*' do not have any meaning for partitioned\\n> > > tables or partitions, and these keywords are currently ignored.\\n> > >\\n> > > Examples:\\n> > > 1. EXCEPT (ONLY tab_part_1) skips replication of only the table\\n> > > tab_part_1. Changes for tab_root, tab_part_1_p1, and tab_part_1_p2 are\\n> > > still replicated.\\n> > >\\n> > > ii. EXCEPT (tab_part_1*) skips replication of tables tab_part_1,\\n> > > tab_part_1_p1, and tab_part_1_p2\\n> > >\\n> > > The challenges described in Approach 1, particularly around tablesync\\n> > > handling and COPY behaviour, would still need to be addressed under\\n> > > this approach as well. ONLY or '*' with partitioned tables is not\\n> > > supported in HEAD, supporting it specifically for ALL TABLES EXCEPT\\n> > > may introduce additional confusion for users.\\n> > >\\n> > > Approach 3:\\n> > > ----------------\\n> > > Do not allow partitions to be specified in the EXCEPT clause.\\n> > >\\n> > > Only EXCEPT (tab_root) is supported, which excludes tab_root and all\\n> > > of its partitions. Specifying EXCEPT (tab_part_1) or EXCEPT\\n> > > (tab_part_1_p1) will result in an error.\\n> > >\\n> > > ~~\\n> > >\\n> > > While Approach 1 and Approach 2 offer more flexibility to the user\\n> > > compared to Approach 3, they also introduce additional design\\n> > > complexity which does not seem simpler to address.\\n> >\\n> > Thanks for explaining this, overall I like the Approach 1, and I also\\n> > see the problem when publish via root is given in that case COPY FROM\\n> > is executed on the root and it would be hard to exclude specific\\n> > partitions.\\n>\\n> Regarding the above issue which is also mentioned in\\n> Approach1_challenges at [1]:\\n> When a publication is created with publish_via_partition_root = true\\n> and a specific partition(tab_part_1_1) is excluded, the expected\\n> behavior is that changes from non-excluded partitions (for example,\\n> tab_part_2 and tab_part_1_2 and their descendants) are replicated,\\n> while changes from the excluded partition (tab_part_1_1 and its\\n> subtree) are not.\\n> tab_root\\n> ├── tab_part_1\\n> │   ├── tab_part_1_1        (except)\\n> │   │   ├── tab_part_1_1_1\\n> │   │   │   └── tab_part_1_1_1_1\\n> │   │   └── tab_part_1_1_2\\n> │   └── tab_part_1_2\\n> │       ├── tab_part_1_2_1\\n> │       └── tab_part_1_2_2\\n> └── tab_part_2\\n>\\n> In this situation, replication cannot be performed purely via the\\n> partition root (tab_root), because doing so would implicitly include\\n> data from the excluded child partitions.\\n>\\n> To address this, the publication creation should explicitly record the\\n> excluded partition(tab_part_1_1) in pg_publication_rel with an\\n> excluded = true flag. The publish_via_partition_root setting remains\\n> stored at the publication level, as it is today. With\\n> publish_via_partition_root = true, the publisher–subscriber mapping is\\n> not partition-to-partition. Instead, all eligible data is mapped to\\n> the subscriber’s partition root. Therefore,\\n> pg_get_publication_tables() should return only the top-level root\\n> table (tab_root) to the subscriber for table synchronization. During\\n> initial table sync, when the tablesync worker prepares the COPY\\n> command, it can query the publisher to determine the effective set of\\n> tables that belong to the publication after applying the exclusion\\n> rules. Based on this resolved table list, the tablesync worker can\\n> construct a COPY query that unions data only from the non-excluded\\n> partitions, for example:\\n> COPY (\\n>     SELECT * FROM tab_part_1_2_1\\n>     UNION ALL\\n>     SELECT * FROM tab_part_1_2_2\\n>     UNION ALL\\n>     SELECT * FROM tab_part_2\\n> )\\n>\\n> This ensures that only non-excluded data is copied and applied to\\n> tab_root on the subscriber, while preserving the semantics of\\n> publish_via_partition_root = true.\\n\\nHere is a patch which has the changes to handle the same.\\n\\nRegards,\\nVignesh\\n"}]	The discussion focuses on implementing EXCEPT functionality for partitioned tables in PostgreSQL publications. Three approaches are being evaluated: Approach 1 would exclude entire subtrees when a partitioned table is specified in EXCEPT; Approach 2 would introduce ONLY and '*' keywords to provide granular control over partition exclusion; Approach 3 would only allow root tables in EXCEPT clauses, rejecting partition specifications. The main challenge involves handling publish_via_partition_root scenarios where excluded partitions complicate table synchronization. vignesh C proposes a solution where excluded partitions are recorded in pg_publication_rel with an excluded flag, and tablesync workers construct UNION queries to copy only non-excluded partition data. This preserves publish_via_partition_root semantics while supporting selective partition exclusion. A patch implementing this approach has been provided for review.	2026-01-27 14:37:01+00	讨论的焦点是在PostgreSQL发布中为分区表实现EXCEPT功能。正在评估三种方法：方法1在EXCEPT中指定分区表时会排除整个子树；方法2会引入ONLY和'*'关键字以提供对分区排除的细粒度控制；方法3只允许在EXCEPT子句中使用根表，拒绝分区规范。主要挑战涉及处理publish_via_partition_root场景，其中排除的分区使表同步复杂化。vignesh C提出了一个解决方案，将排除的分区记录在pg_publication_rel中并设置excluded标志，tablesync工作进程构造UNION查询以仅复制非排除分区的数据。这在支持选择性分区排除的同时保持了publish_via_partition_root的语义。已提供实现此方法的补丁供审查。
29	19bfb105673a8b2e	pg_plan_advice	["ajay.pal.k@gmail.com","di@nmfay.com","jacob.champion@enterprisedb.com","jakub.wartak@enterprisedb.com","lukas@fittl.com","matheusssilv97@gmail.com","robertmhaas@gmail.com"]	[{"id":"19bfe6e57219eb4a","threadId":"19bfb105673a8b2e","snippet":"Hi, with v12 patch, found below observations, #1 Grouped Hash Join, This forces the join of dim1 and dim2 to happen first, and then places that resulting set on the inner side of a Hash Join against","historyId":"26105","internalDate":"1769500178000","receivedAtUtc":"2026-01-27T07:49:38.000Z","from":"Ajay Pal <ajay.pal.k@gmail.com>","subject":"Re: pg_plan_advice","messageId":"<CABRHmyvLPcx_K1T9Cwg4tFHiyh95fQU9tUhDwEFtvJiDsQDdaA@mail.gmail.com>","body":"Hi,\\n\\nwith v12 patch, found below observations,\\n\\n#1 Grouped Hash Join, This forces the join of dim1 and dim2 to happen\\nfirst, and then places that resulting set on the inner side of a Hash\\nJoin against fact.\\nbut the planner partially matches the generated advice.\\n\\nCREATE TABLE fact (f_id int, d1_id int, d2_id int, d3_id int);\\nCREATE TABLE dim1 (id int PRIMARY KEY, val text);\\nCREATE TABLE dim2 (id int PRIMARY KEY, val text);\\nCREATE TABLE dim3 (id int PRIMARY KEY, val text);\\n\\nINSERT INTO fact SELECT g, g%10, g%10, g%10 FROM generate_series(1, 10000) g;\\nINSERT INTO dim1 SELECT g, 'd1-'||g FROM generate_series(0, 9) g;\\nINSERT INTO dim2 SELECT g, 'd2-'||g FROM generate_series(0, 9) g;\\nINSERT INTO dim3 SELECT g, 'd3-'||g FROM generate_series(0, 9) g;\\nANALYZE fact, dim1, dim2, dim3;\\n\\n-- We want (dim1 JOIN dim2) to be the inner side of a Hash Join\\nSET LOCAL pg_plan_advice.advice = 'HASH_JOIN((dim1 dim2))';\\n\\npostgres=*# EXPLAIN (COSTS OFF, PLAN_ADVICE)\\nSELECT * FROM fact\\n                  JOIN dim1 ON fact.d1_id = dim1.id\\n                  JOIN dim2 ON fact.d2_id = dim2.id;\\n                        QUERY PLAN\\n-----------------------------------------------------------\\n Nested Loop\\n   Disabled: true\\n   ->  Nested Loop\\n         Disabled: true\\n         ->  Seq Scan on fact\\n         ->  Index Scan using dim1_pkey on dim1\\n               Index Cond: (id = fact.d1_id)\\n   ->  Index Scan using dim2_pkey on dim2\\n         Index Cond: (id = fact.d2_id)\\n Supplied Plan Advice:\\n   HASH_JOIN((dim1 dim2)) /* partially matched */\\n Generated Plan Advice:\\n   JOIN_ORDER(fact dim1 dim2)\\n   NESTED_LOOP_PLAIN(dim1 dim2)\\n   SEQ_SCAN(fact)\\n   INDEX_SCAN(dim1 public.dim1_pkey dim2 public.dim2_pkey)\\n   NO_GATHER(fact dim1 dim2)\\n(17 rows)\\n\\n#2 Multiple Instances of Same Table in Subqueries, here target the\\nsecond instance of dim1 inside the subquery 'sq'. both seq_scan and\\nindex_scan advices are not matching.\\n\\nSET LOCAL pg_plan_advice.advice = 'SEQ_SCAN(dim1#2@sq)\\nINDEX_SCAN(dim1@sq dim1_pkey)';\\n\\npostgres=*# EXPLAIN (COSTS OFF, PLAN_ADVICE)\\nSELECT * FROM fact\\nJOIN (\\n    SELECT a.id FROM dim1 a\\n    JOIN dim1 b ON a.id = b.id\\n    OFFSET 0\\n) sq ON fact.d1_id = sq.id;\\n                    QUERY PLAN\\n---------------------------------------------------\\n Hash Join\\n   Hash Cond: (fact.d1_id = b.id)\\n   ->  Seq Scan on fact\\n   ->  Hash\\n         ->  Seq Scan on dim1 b\\n Supplied Plan Advice:\\n   SEQ_SCAN(dim1#2@sq) /* not matched */\\n   INDEX_SCAN(dim1@sq dim1_pkey) /* not matched */\\n Generated Plan Advice:\\n   JOIN_ORDER(fact sq)\\n   HASH_JOIN(sq)\\n   SEQ_SCAN(b@sq fact)\\n   NO_GATHER(fact b@sq)\\n(13 rows)\\n\\nThanks\\nAjay\\n\\nOn Mon, Jan 26, 2026 at 9:38 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n>\\n> Here is v12.\\n>\\n> The big change in this version is that I've added extensive SGML\\n> documentation for v0005. If the README was a little too low-level for\\n> you, this might work better. If you'd like to view it without\\n> downloading the patch set, I've put it up here:\\n>\\n> https://robertmhaas.github.io/postgresql-static/html-pgpa-v12/pgplanadvice.html\\n>\\n> Aside from that:\\n>\\n> * Added a new GUC pg_plan_advice.always_store_advice_details. Without\\n> that, you can't generate advice or see feedback on supplied advice\\n> when using prepared queries, because we don't know at plan time that\\n> it's right to incur the overhead of generating that stuff, and most of\\n> the time it won't be.\\n> * Revoked privileges on pg_clear_collected_shared_advice() as I had\\n> already done on pg_get_collected_shared_advice().\\n> * Removed a bogus elog(ERROR) in pgpa_walker_would_advise() in favor\\n> of returning 0. I think somebody, likely Jakub, pointed this out\\n> earlier, but I didn't quite absorb what I was being told until I\\n> rediscovered the problem.\\n> * Added a bunch more tests. I think the test coverage is getting\\n> pretty decent now, but it could still use some tests targeting more\\n> complex scenarios and corner cases. If you are curious about the\\n> coverage report, see here:\\n>\\n> https://robertmhaas.github.io/postgresql-static/coveragereport-pgpa-v12/contrib/pg_plan_advice/index.html\\n>\\n> The low number for pgpa_scanner.l is basically bogus, but I don't know\\n> of a way to make it not bogus. The low number for pgpa_ast.c is due to\\n> a bunch of things related to bitmap scans not being right, which at\\n> this point is, I think, the largest outstanding issue with the patch.\\n> It's probably more interesting to look into ways of covering a few\\n> more lines from pgpa_planner.c and pgpa_walker.c, which is where a lot\\n> of the complexity in this code lives. Also, it would be nice to have\\n> coverage of foreign scan cases, but I'm not quite sure what I need to\\n> do to create tests for this module that also depend on postgres_fdw.\\n> Any tips appreciated.\\n>\\n> --\\n> Robert Haas\\n> EDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19bff71162659fd2","threadId":"19bfb105673a8b2e","snippet":"On Tue, Jan 27, 2026 at 2:49 AM Ajay Pal <ajay.pal.k@gmail.com> wrote: > #1 Grouped Hash Join, This forces the join of dim1 and dim2 to happen > first, and then places that resulting set on","historyId":"27539","internalDate":"1769517131000","receivedAtUtc":"2026-01-27T12:32:11.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pg_plan_advice","messageId":"<CA+TgmobbV53ogwJoXc2S-HXYi+bwGLHDrm1SOPkB_yKyOHbbmA@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 2:49 AM Ajay Pal <ajay.pal.k@gmail.com> wrote:\\n> #1 Grouped Hash Join, This forces the join of dim1 and dim2 to happen\\n> first, and then places that resulting set on the inner side of a Hash\\n> Join against fact.\\n> but the planner partially matches the generated advice.\\n>\\n> -- We want (dim1 JOIN dim2) to be the inner side of a Hash Join\\n> SET LOCAL pg_plan_advice.advice = 'HASH_JOIN((dim1 dim2))';\\n>\\n> postgres=*# EXPLAIN (COSTS OFF, PLAN_ADVICE)\\n> SELECT * FROM fact\\n>                   JOIN dim1 ON fact.d1_id = dim1.id\\n>                   JOIN dim2 ON fact.d2_id = dim2.id;\\n>                         QUERY PLAN\\n> -----------------------------------------------------------\\n>  Nested Loop\\n>    Disabled: true\\n>    ->  Nested Loop\\n>          Disabled: true\\n>          ->  Seq Scan on fact\\n>          ->  Index Scan using dim1_pkey on dim1\\n>                Index Cond: (id = fact.d1_id)\\n>    ->  Index Scan using dim2_pkey on dim2\\n>          Index Cond: (id = fact.d2_id)\\n>  Supplied Plan Advice:\\n>    HASH_JOIN((dim1 dim2)) /* partially matched */\\n>  Generated Plan Advice:\\n>    JOIN_ORDER(fact dim1 dim2)\\n>    NESTED_LOOP_PLAIN(dim1 dim2)\\n>    SEQ_SCAN(fact)\\n>    INDEX_SCAN(dim1 public.dim1_pkey dim2 public.dim2_pkey)\\n>    NO_GATHER(fact dim1 dim2)\\n> (17 rows)\\n\\nThanks for the report, but this is actually correct behavior. There's\\nno join clause between dim1 and dim2, so the planner doesn't consider\\na dim1-dim2 join. This is a good example of the phenomenon described\\nin the documentation: you can't force the planner to create an\\narbitrary plan that it wouldn't otherwise have considered. I might\\ntweak the documentation wording a little to try  to mention that this\\nis another way \\"partially matched\\" can happen, but there's no bug\\nhere.\\n\\n> #2 Multiple Instances of Same Table in Subqueries, here target the\\n> second instance of dim1 inside the subquery 'sq'. both seq_scan and\\n> index_scan advices are not matching.\\n>\\n> SET LOCAL pg_plan_advice.advice = 'SEQ_SCAN(dim1#2@sq)\\n> INDEX_SCAN(dim1@sq dim1_pkey)';\\n>\\n> postgres=*# EXPLAIN (COSTS OFF, PLAN_ADVICE)\\n> SELECT * FROM fact\\n> JOIN (\\n>     SELECT a.id FROM dim1 a\\n>     JOIN dim1 b ON a.id = b.id\\n>     OFFSET 0\\n> ) sq ON fact.d1_id = sq.id;\\n>                     QUERY PLAN\\n> ---------------------------------------------------\\n>  Hash Join\\n>    Hash Cond: (fact.d1_id = b.id)\\n>    ->  Seq Scan on fact\\n>    ->  Hash\\n>          ->  Seq Scan on dim1 b\\n>  Supplied Plan Advice:\\n>    SEQ_SCAN(dim1#2@sq) /* not matched */\\n>    INDEX_SCAN(dim1@sq dim1_pkey) /* not matched */\\n>  Generated Plan Advice:\\n>    JOIN_ORDER(fact sq)\\n>    HASH_JOIN(sq)\\n>    SEQ_SCAN(b@sq fact)\\n>    NO_GATHER(fact b@sq)\\n> (13 rows)\\n\\nI'm not sure what why you expected this to work. You can see what the\\ncorrect relation identifiers are from the generated plan advice, and\\nyou've used something else, so it doesn't match. It's documented in\\nboth the SGML documentation and the README that relation identifiers\\nare based on the relation alias, not the relation name.\\n\\nIn general, this seems like a good to reiterate that this is first and\\nforemost a plan stability feature. More than anything, these examples\\nshow that if you try to write your own plan advice from scratch to\\nforce a novel plan that the planner has never produced itself, you may\\nnot have much luck. If you do want to try to produce a novel plan, you\\nshould at least look at the generated plan advice and adapt it instead\\nof starting from scratch. And if you find, when trying to produce a\\nnovel plan, that it doesn't work, you need to consider the possibility\\nthat this is because the optimizer did not ever consider that plan,\\nand that is why pg_plan_advice is unable to induce the planner to\\nprefer it. That's not to say there can't be any remaining bugs in\\npg_plan_advice; there probably are. But it also is absolutely not a\\n\\"write your own plan and do anything you like\\" feature.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19bff803846fb943","threadId":"19bfb105673a8b2e","snippet":"Thank you Robert for clarification. On Tue, Jan 27, 2026 at 6:02 PM Robert Haas <robertmhaas@gmail.com> wrote: > > On Tue, Jan 27, 2026 at 2:49 AM Ajay Pal <ajay.pal.k@gmail.com>","historyId":"27596","internalDate":"1769518126000","receivedAtUtc":"2026-01-27T12:48:46.000Z","from":"Ajay Pal <ajay.pal.k@gmail.com>","subject":"Re: pg_plan_advice","messageId":"<CABRHmyvGE7ebajakpaOioYw8uD1yz2Kw+fW0KsUoGpANsvtBpA@mail.gmail.com>","body":"Thank you Robert for clarification.\\n\\nOn Tue, Jan 27, 2026 at 6:02 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n>\\n> On Tue, Jan 27, 2026 at 2:49 AM Ajay Pal <ajay.pal.k@gmail.com> wrote:\\n> > #1 Grouped Hash Join, This forces the join of dim1 and dim2 to happen\\n> > first, and then places that resulting set on the inner side of a Hash\\n> > Join against fact.\\n> > but the planner partially matches the generated advice.\\n> >\\n> > -- We want (dim1 JOIN dim2) to be the inner side of a Hash Join\\n> > SET LOCAL pg_plan_advice.advice = 'HASH_JOIN((dim1 dim2))';\\n> >\\n> > postgres=*# EXPLAIN (COSTS OFF, PLAN_ADVICE)\\n> > SELECT * FROM fact\\n> >                   JOIN dim1 ON fact.d1_id = dim1.id\\n> >                   JOIN dim2 ON fact.d2_id = dim2.id;\\n> >                         QUERY PLAN\\n> > -----------------------------------------------------------\\n> >  Nested Loop\\n> >    Disabled: true\\n> >    ->  Nested Loop\\n> >          Disabled: true\\n> >          ->  Seq Scan on fact\\n> >          ->  Index Scan using dim1_pkey on dim1\\n> >                Index Cond: (id = fact.d1_id)\\n> >    ->  Index Scan using dim2_pkey on dim2\\n> >          Index Cond: (id = fact.d2_id)\\n> >  Supplied Plan Advice:\\n> >    HASH_JOIN((dim1 dim2)) /* partially matched */\\n> >  Generated Plan Advice:\\n> >    JOIN_ORDER(fact dim1 dim2)\\n> >    NESTED_LOOP_PLAIN(dim1 dim2)\\n> >    SEQ_SCAN(fact)\\n> >    INDEX_SCAN(dim1 public.dim1_pkey dim2 public.dim2_pkey)\\n> >    NO_GATHER(fact dim1 dim2)\\n> > (17 rows)\\n>\\n> Thanks for the report, but this is actually correct behavior. There's\\n> no join clause between dim1 and dim2, so the planner doesn't consider\\n> a dim1-dim2 join. This is a good example of the phenomenon described\\n> in the documentation: you can't force the planner to create an\\n> arbitrary plan that it wouldn't otherwise have considered. I might\\n> tweak the documentation wording a little to try  to mention that this\\n> is another way \\"partially matched\\" can happen, but there's no bug\\n> here.\\n>\\n> > #2 Multiple Instances of Same Table in Subqueries, here target the\\n> > second instance of dim1 inside the subquery 'sq'. both seq_scan and\\n> > index_scan advices are not matching.\\n> >\\n> > SET LOCAL pg_plan_advice.advice = 'SEQ_SCAN(dim1#2@sq)\\n> > INDEX_SCAN(dim1@sq dim1_pkey)';\\n> >\\n> > postgres=*# EXPLAIN (COSTS OFF, PLAN_ADVICE)\\n> > SELECT * FROM fact\\n> > JOIN (\\n> >     SELECT a.id FROM dim1 a\\n> >     JOIN dim1 b ON a.id = b.id\\n> >     OFFSET 0\\n> > ) sq ON fact.d1_id = sq.id;\\n> >                     QUERY PLAN\\n> > ---------------------------------------------------\\n> >  Hash Join\\n> >    Hash Cond: (fact.d1_id = b.id)\\n> >    ->  Seq Scan on fact\\n> >    ->  Hash\\n> >          ->  Seq Scan on dim1 b\\n> >  Supplied Plan Advice:\\n> >    SEQ_SCAN(dim1#2@sq) /* not matched */\\n> >    INDEX_SCAN(dim1@sq dim1_pkey) /* not matched */\\n> >  Generated Plan Advice:\\n> >    JOIN_ORDER(fact sq)\\n> >    HASH_JOIN(sq)\\n> >    SEQ_SCAN(b@sq fact)\\n> >    NO_GATHER(fact b@sq)\\n> > (13 rows)\\n>\\n> I'm not sure what why you expected this to work. You can see what the\\n> correct relation identifiers are from the generated plan advice, and\\n> you've used something else, so it doesn't match. It's documented in\\n> both the SGML documentation and the README that relation identifiers\\n> are based on the relation alias, not the relation name.\\n>\\n> In general, this seems like a good to reiterate that this is first and\\n> foremost a plan stability feature. More than anything, these examples\\n> show that if you try to write your own plan advice from scratch to\\n> force a novel plan that the planner has never produced itself, you may\\n> not have much luck. If you do want to try to produce a novel plan, you\\n> should at least look at the generated plan advice and adapt it instead\\n> of starting from scratch. And if you find, when trying to produce a\\n> novel plan, that it doesn't work, you need to consider the possibility\\n> that this is because the optimizer did not ever consider that plan,\\n> and that is why pg_plan_advice is unable to induce the planner to\\n> prefer it. That's not to say there can't be any remaining bugs in\\n> pg_plan_advice; there probably are. But it also is absolutely not a\\n> \\"write your own plan and do anything you like\\" feature.\\n>\\n> --\\n> Robert Haas\\n> EDB: http://www.enterprisedb.com\\n\\n\\n"}]	Ajay Pal reported testing issues with pg_plan_advice v12 patch, presenting two cases where the advice didn't work as expected. The first involved a grouped hash join attempt where the planner showed "partially matched" because there was no join clause between dim1 and dim2 tables. Robert Haas clarified this is correct behavior - the planner cannot be forced to create arbitrary plans it wouldn't naturally consider. The second case involved multiple instances of the same table in subqueries with incorrect relation identifiers. Haas explained that relation identifiers must be based on aliases, not table names, as documented. He emphasized that pg_plan_advice is primarily a plan stability feature, not a tool for creating novel plans from scratch. Users should adapt generated plan advice rather than writing custom advice, as the optimizer may never have considered certain plan alternatives.	2026-01-27 12:48:46+00	Ajay Pal 报告了 pg_plan_advice v12 补丁的测试问题，展示了两个建议未按预期工作的案例。第一个涉及分组哈希连接尝试，规划器显示"部分匹配"，因为 dim1 和 dim2 表之间没有连接子句。Robert Haas 澄清这是正确行为 - 规划器无法被强制创建它本来不会考虑的任意计划。第二个案例涉及子查询中同一表的多个实例，使用了错误的关系标识符。Haas 解释关系标识符必须基于别名而非表名，这在文档中有说明。他强调 pg_plan_advice 主要是计划稳定性功能，而非从零开始创建新颖计划的工具。用户应该调整生成的计划建议而非编写自定义建议，因为优化器可能从未考虑过某些计划替代方案。
29	19be897af3bbca01	Newly created replication slot may be invalidated by checkpoint	["aekorotkov@gmail.com","amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","houzj.fnst@fujitsu.com","kuroda.hayato@fujitsu.com","li.evan.chao@gmail.com","mengjuan.cmj@alibaba-inc.com","michael@paquier.xyz","sawada.mshk@gmail.com","tomas@vondra.me","v.davydov@postgrespro.ru","vignesh21@gmail.com"]	[{"id":"19bfea218613c7f2","threadId":"19be897af3bbca01","snippet":"On Mon, Jan 26, 2026 at 3:06 PM Chao Li <li.evan.chao@gmail.com> wrote: > > > On Jan 26, 2026, at 13:35, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote: > > >","historyId":"26568","internalDate":"1769503570000","receivedAtUtc":"2026-01-27T08:46:10.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>","subject":"Re: Newly created replication slot may be invalidated by checkpoint","messageId":"<CAA4eK1KHObZ-giSMwrTchtvjXs8yj0sQw9Jt-x2M9Nqxapkjvg@mail.gmail.com>","body":"On Mon, Jan 26, 2026 at 3:06 PM Chao Li <li.evan.chao@gmail.com> wrote:\\n>\\n> > On Jan 26, 2026, at 13:35, Hayato Kuroda (Fujitsu) <kuroda.hayato@fujitsu.com> wrote:\\n> >\\n> > Dear Hou,\\n> >\\n> > Thanks for updating the patch. I ran tests and reproducer [1] for all versions.\\n> > Confirmed the issue happened before the patch and fixed after applying them.\\n> >\\n> > One difference between master and others is that pg_sync_replication_slots()\\n> > on HEAD is not returned. Because the behavior was changed by 0d2d4a0, not\\n> > related with the fix.\\n> >\\n> > I feel these patches are enough good shape.\\n> >\\n> > [1]: https://www.postgresql.org/message-id/TY7PR01MB14554DBE84290130EB421DD28F596A%40TY7PR01MB14554.jpnprd01.prod.outlook.com\\n> >\\n> > Best regards,\\n> > Hayato Kuroda\\n> > FUJITSU LIMITED\\n> >\\n>\\n> Yeah, I agree v4 is solid. I have a few nitpicks:\\n>\\n\\nPushed after minor cosmetic changes.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n"}]	The discussion centered on fixing an issue where newly created replication slots could be invalidated by checkpoint operations. Hayato Kuroda tested patches across all PostgreSQL versions and confirmed the issue was present before the fix and resolved after applying the patches. He noted a behavioral difference in pg_sync_replication_slots() on HEAD due to commit 0d2d4a0, but clarified this was unrelated to the current fix. Chao Li agreed that version 4 of the patches was solid, mentioning only minor nitpicks. The patches addressed the core problem of replication slot invalidation timing. Amit Kapila concluded the thread by pushing the patches after making minor cosmetic changes, indicating the fix has been committed to the PostgreSQL codebase.	2026-01-27 08:46:10+00	讨论集中于修复一个问题，即新创建的复制槽可能被检查点操作无效化。Hayato Kuroda在所有PostgreSQL版本上测试了补丁，并确认问题在修复前存在，应用补丁后得到解决。他注意到HEAD版本中pg_sync_replication_slots()的行为差异是由于提交0d2d4a0造成的，但澄清这与当前修复无关。Chao Li同意第4版补丁是可靠的，只提到了一些小问题。补丁解决了复制槽无效化时机的核心问题。Amit Kapila通过推送补丁（进行了少量外观更改）结束了讨论，表明修复已提交到PostgreSQL代码库。
29	19bf83726326e92c	Proposal: Cascade REPLICA IDENTITY changes to leaf partitions	["9erthalion6@gmail.com","alvherre@kurilemu.de","amit.kapila16@gmail.com","euler@eulerto.com","houzj.fnst@fujitsu.com","li.evan.chao@gmail.com","michael@paquier.xyz","peter@eisentraut.org","robertmhaas@gmail.com"]	[{"id":"19bfe3d8910c0370","threadId":"19bf83726326e92c","snippet":"On Mon, Jan 26, 2026 at 04:56:36PM +0800, Chao Li wrote: > I have verified the problem. The real problem is, after index > rebuild, indisreplident flag of index on child partition will be >","historyId":"25429","internalDate":"1769496987000","receivedAtUtc":"2026-01-27T06:56:27.000Z","from":"Michael Paquier <michael@paquier.xyz>","subject":"Re: Proposal: Cascade REPLICA IDENTITY changes to leaf partitions","messageId":"<aXhhm1i-ERVRXFjx@paquier.xyz>","body":"On Mon, Jan 26, 2026 at 04:56:36PM +0800, Chao Li wrote:\\n> I have verified the problem. The real problem is, after index\\n> rebuild, indisreplident flag of index on child partition will be\\n> lost, which should be a bug. I will start a new thread to give more\\n> details of the problem and propose a fix.\\n\\nThat sounds like a real problem, yes.  Thanks for starting a new\\nthread about that.\\n--\\nMichael\\n"},{"id":"19bfe5b7d6c404ec","threadId":"19bf83726326e92c","snippet":"> On Jan 27, 2026, at 14:56, Michael Paquier <michael@paquier.xyz> wrote: > > On Mon, Jan 26, 2026 at 04:56:36PM +0800, Chao Li wrote: >> I have verified the problem. The real","historyId":"25865","internalDate":"1769498920000","receivedAtUtc":"2026-01-27T07:28:40.000Z","from":"Chao Li <li.evan.chao@gmail.com>","subject":"Re: Proposal: Cascade REPLICA IDENTITY changes to leaf partitions","messageId":"<E1798721-9D88-4AD2-B032-F3CB22621048@gmail.com>","body":"\\n\\n> On Jan 27, 2026, at 14:56, Michael Paquier <michael@paquier.xyz> wrote:\\n> \\n> On Mon, Jan 26, 2026 at 04:56:36PM +0800, Chao Li wrote:\\n>> I have verified the problem. The real problem is, after index\\n>> rebuild, indisreplident flag of index on child partition will be\\n>> lost, which should be a bug. I will start a new thread to give more\\n>> details of the problem and propose a fix.\\n> \\n> That sounds like a real problem, yes.  Thanks for starting a new\\n> thread about that.\\n> --\\n> Michael\\n\\nThis is the new discussion for the bug:\\nhttps://www.postgresql.org/message-id/DB533C25-C6BA-4C0F-8046-96168E9CDD72%40gmail.com\\n\\nBest regards,\\n--\\nChao Li (Evan)\\nHighGo Software Co., Ltd.\\nhttps://www.highgo.com/\\n\\n\\n\\n\\n\\n\\n"}]	Chao Li identified a bug where the indisreplident flag of indexes on child partitions is lost after index rebuild operations. This flag is crucial for replica identity functionality in PostgreSQL partitioning. Michael Paquier confirmed this appears to be a legitimate problem that needs addressing. Chao Li has started a separate discussion thread specifically focused on this bug, providing detailed analysis and proposing a fix. The issue affects the proper functioning of replica identity settings on partitioned tables, which is important for logical replication and change data capture scenarios. The bug discovery emerged during work on cascading replica identity changes to leaf partitions, highlighting the complexity of maintaining consistent replica identity behavior across partition hierarchies.	2026-01-27 07:28:40+00	Chao Li发现了一个bug，即在索引重建操作后，子分区上索引的indisreplident标志会丢失。这个标志对于PostgreSQL分区中的replica identity功能至关重要。Michael Paquier确认这看起来是一个需要解决的合法问题。Chao Li已经启动了一个专门针对此bug的单独讨论线程，提供了详细分析并提出了修复方案。这个问题影响了分区表上replica identity设置的正常功能，这对于逻辑复制和变更数据捕获场景很重要。这个bug的发现出现在将replica identity更改级联到叶子分区的工作过程中，突显了在分区层次结构中维持一致的replica identity行为的复杂性。
29	19bfd04d9a46c4b2	Implement waiting for wal lsn replay: reloaded	["aekorotkov@gmail.com","alvherre@kurilemu.de","andres@anarazel.de","hlinnaka@iki.fi","jian.universality@gmail.com","li.evan.chao@gmail.com","michael@paquier.xyz","peter@eisentraut.org","thomas.munro@gmail.com","tomas@vondra.me","xunengzhou@gmail.com","y.sokolov@postgrespro.ru"]	[{"id":"19bfd04d9a46c4b2","threadId":"19bfd04d9a46c4b2","snippet":"Hi Alexander, Heikki spotted a misplaced wake-up call for replay waiters in PerformWalRecovery. He suggested that the WaitLSNWakeup needs to be invoked immediately after wal record is applied to avoid","historyId":"24354","internalDate":"1769476483000","receivedAtUtc":"2026-01-27T01:14:43.000Z","from":"Xuneng Zhou <xunengzhou@gmail.com>","subject":"Re: Implement waiting for wal lsn replay: reloaded","messageId":"<CABPTF7Wdq6KbvC3EhLX3Pz=ODCCPEX7qVQ+E=cokkB91an2E-A@mail.gmail.com>","body":"Hi Alexander,\\n\\nHeikki spotted a misplaced wake-up call for replay waiters in\\nPerformWalRecovery. He suggested that the WaitLSNWakeup needs to be\\ninvoked immediately after wal record is applied to avoid the potential\\nmissed wake-ups when recovery stops/pauses/promotes. It makes sense to\\nme. Please check the attached patch to fix that.\\n\\n-- \\nBest,\\nXuneng\\n"}]	Xuneng Zhou reports a bug fix for the WAL LSN replay waiting feature. Heikki identified that a wake-up call for replay waiters was misplaced in PerformWalRecovery function. The issue could cause missed wake-ups when recovery operations stop, pause, or promote. Heikki suggested moving the WaitLSNWakeup call to immediately after WAL records are applied to prevent this timing problem. Xuneng agrees with the analysis and has provided a patch to implement the fix. This appears to be a straightforward bug correction to ensure proper signaling of waiting processes during WAL replay scenarios.	2026-01-27 01:14:43+00	Xuneng Zhou 报告了 WAL LSN 重放等待功能的一个错误修复。Heikki 发现在 PerformWalRecovery 函数中重放等待者的唤醒调用位置错误。该问题可能导致在恢复操作停止、暂停或提升时错过唤醒信号。Heikki 建议将 WaitLSNWakeup 调用移动到 WAL 记录应用之后立即执行，以防止这种时序问题。Xuneng 同意这一分析并提供了实现修复的补丁。这似乎是一个直接的错误修正，用于确保在 WAL 重放场景中正确向等待进程发送信号。
31	19bed67824d1f608	eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)	["andres@anarazel.de","hlinnaka@iki.fi","li.evan.chao@gmail.com","melanieplageman@gmail.com","reshkekirill@gmail.com","robertmhaas@gmail.com","x4mmm@yandex-team.ru","xunengzhou@gmail.com"]	[{"id":"19c01ae75c038fdf","threadId":"19bed67824d1f608","snippet":"On Wed, Jan 7, 2026 at 3:15 AM Chao Li <li.evan.chao@gmail.com> wrote: > > I believe the reason why we add Assert(TransactionIdIsValid(dead_after)) under HEAPTUPLE_RECENTLY_DEAD is to","historyId":"30940","internalDate":"1769554713000","receivedAtUtc":"2026-01-27T22:58:33.000Z","from":"Melanie Plageman <melanieplageman@gmail.com>","subject":"Re: eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)","messageId":"<CAAKRu_ZkhzypqsmPb69n1YgE=rPbuKtV2h1BwBXyqMzSymsv3Q@mail.gmail.com>","body":"On Wed, Jan 7, 2026 at 3:15 AM Chao Li <li.evan.chao@gmail.com> wrote:\\n>\\n> I believe the reason why we add Assert(TransactionIdIsValid(dead_after)) under HEAPTUPLE_RECENTLY_DEAD is to ensure that when HeapTupleSatisfiesVacuumHorizon() returns HEAPTUPLE_RECENTLY_DEAD, dead_after must be set. So the goal of the assert is to catch bugs of HeapTupleSatisfiesVacuumHorizon().\\n>\\n> From this perspective, I now feel dead_after should be initialized to InvalidTransactionId. Otherwise, say HeapTupleSatisfiesVacuumHorizon() has a bug and miss to set dead_after, then the assert mostly like won’t be fired, because it holds a random value, most likely not be 0.\\n\\nActually, thinking about it more, I decided to remove the assertions\\non dead_after from those patches entirely. I don't use dead_after and\\nonly pass it in because HeapTupleSatisfiesVacuumHorizon requires it.\\nIn fact, I don't care if the function correctly sets dead_after since\\nI don't use it.\\n\\n> +       /* set if the query doesn't modify the rel */\\n> +       SO_HINT_REL_READ_ONLY = 1 << 10,\\n> ```\\n>\\n> Nit: I think it’s better to replace “rel” to “relation”. For a function comment, if there is a parameter named “rel”, then we can use it to refer to the parameter, without such a context, I guess here a while word is better.\\n\\nk\\n\\nI'm currently working on a new version that incorporates Andres'\\nreview feedback and will post soon.\\n\\n- Melanie\\n\\n\\n"}]	Melanie Plageman is working on a patch to eliminate xl_heap_visible WAL records to reduce WAL volume and eventually enable setting visibility map bits on access. In response to Chao Li's feedback about assertion handling in HeapTupleSatisfiesVacuumHorizon(), Melanie decided to remove the dead_after assertions entirely from her patches, explaining that she doesn't use the dead_after parameter and only passes it because the function requires it. She doesn't need the function to correctly set dead_after since it's unused in her implementation. Melanie acknowledged a minor naming suggestion from Chao Li to use "relation" instead of "rel" in comments for better clarity. She indicated she's incorporating review feedback from Andres and will post an updated version soon.	2026-01-27 22:58:33+00	Melanie Plageman正在开发一个补丁，旨在消除xl_heap_visible WAL记录以减少WAL量，并最终实现在访问时设置可见性映射位。针对Chao Li关于HeapTupleSatisfiesVacuumHorizon()中断言处理的反馈，Melanie决定完全移除她补丁中的dead_after断言，解释说她不使用dead_after参数，传递它只是因为函数需要。由于在她的实现中未使用该参数，她不需要函数正确设置dead_after。Melanie接受了Chao Li的一个小建议，即在注释中使用"relation"而不是"rel"以提高清晰度。她表示正在整合Andres的审查反馈，并将很快发布更新版本。
31	19be67781ef21b94	AIX support	["hlinnaka@iki.fi","peter@eisentraut.org","postgres-ibm-aix@wwpdl.vnet.ibm.com","sriram.rk@in.ibm.com","tgl@sss.pgh.pa.us","tristan@partin.io"]	[{"id":"19c012384fd56c77","threadId":"19be67781ef21b94","snippet":"Srirama Kucherlapati <sriram.rk@in.ibm.com> writes: > We have set the below flags for building the source > export OBJECT_MODE=64 > export FLAG64=\\"-maix64\\" > export CC__=/","historyId":"30546","internalDate":"1769545598000","receivedAtUtc":"2026-01-27T20:26:38.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: AIX support","messageId":"<573836.1769545598@sss.pgh.pa.us>","body":"Srirama Kucherlapati <sriram.rk@in.ibm.com> writes:\\n> We have set the below flags for building the source\\n\\n> export OBJECT_MODE=64\\n> export FLAG64=\\"-maix64\\"\\n> export CC__=/opt/freeware/bin//gcc-12\\n> export CXX__=/opt/freeware/bin//g++-12\\n> export CC64=\\"${CC__}\\"\\n> export CFLAGS=\\"${FLAG64} -O2 \\"\\n> export GLOBAL_CC_OPTIONS=\\"-O2\\"\\n> export CC=\\"${CC64} \\"\\n> export LDFLAGS=\\"-L/opt/freeware/lib64 -L/usr/lib64 -L/opt/freeware/lib -L/usr/lib -Wl,-blibpath:/opt/freeware/lib64:/opt/freeware/lib:/usr/lib:/lib\\"\\n> export LDFLAGS=$LDFLAGS:/opt/freeware/lib64/perl5/5.38/CORE/:\\n> export PYTHON=/opt/freeware/bin/python3.9\\n> export AR='/usr/bin/ar -X64’\\n\\n\\nOuch.  Our normal expectation is that you can build a working\\nPostgres with nothing more complicated than\\n\\n\\t./configure && make && make install\\n\\n(well, maybe you want a nondefault --prefix and some feature\\noptions, but getting to a working executable shouldn't take\\nmuch more than that).  It's totally not okay to expect users\\nto preset a bunch of environment variables, especially not if\\nthat requirement appears nowhere in the documentation.\\n\\nSo one TODO item for your patch is to restore (and update)\\nthe AIX-specific portions of the documentation, particularly\\nthe build instructions.  But I do not want to see anything as\\nmessy as the above in the build instructions.\\n\\nAfter re-reading what used to be in installation.sgml, I'm inclined\\nto suggest that we just say that only 64-bit builds using gcc are\\nsupported on AIX.  Surely the number of users still wanting 32-bit\\nPostgres on AIX is indistinguishable from zero.  Then we could remove\\nthe documentation about likely failure modes of a 32-bit build.\\n(Also, perhaps we could bake the bits about OBJECT_MODE=64 and -maix64\\ninto the autoconf/meson logic and not burden users with dealing with\\nthose?)\\n\\nAfter some digging, I realized that the cause of my build failure with\\nnot finding libgcc_s.a was that you'd removed this stanza that\\nMakefile.aix used to have:\\n\\n# when building with gcc, need to make sure that libgcc can be found\\nifeq ($(GCC), yes)\\nlibpath := $(libpath):$(dir $(shell gcc -print-libgcc-file-name))\\nendif\\n\\nI don't really understand how it works for you without that.\\nI suppose that your explicit setting of LDFLAGS masked the problem,\\nbut doing that did not work for me, which I found was because our\\nrpath logic overrides any externally-given -Wl,-blibpath setting.\\nWere you perhaps building with --disable-rpath?  In any case, manually\\nputting every required directory into LDFLAGS is not sustainable.\\nThere's a reason our makefiles work so hard to build that list\\nautomatically.\\n\\nIn any case, once I put back the missing Makefile.aix bit, I was\\nable to get a working 64-bit build after doing what installation.sgml\\nused to tell people:\\n\\n     For a 64-bit build, set <envar>OBJECT_MODE</envar> to 64 and\\n     pass <literal>CC=\\"gcc -maix64\\"</literal>\\n     to <command>configure</command>.\\n\\n(It also said to set LDFLAGS=\\"-Wl,-bbigtoc\\", but that doesn't\\nseem to be necessary anymore?)\\n\\nHowever, my build doesn't pass the core regression tests.  There\\nis one failure in float8.out, which on investigation is because\\nlgamma(NaN) is failing (returning ERANGE) instead of silently\\nreturning NaN.  That behavior is directly contradictory to what\\n\\"man lgamma\\" says, so I guess they fixed it in recent AIX, but we\\nprobably need a workaround for AIXen that are still in the field.\\ncfarm119 is running a just slightly back-rev AIX:\\n$ oslevel -s\\n7300-01-02-2320\\n\\nWith the patch attached, I can get through \\"make installcheck\\".\\nHowever, I'm unable to attempt \\"make check-world\\" because\\nsrc/test/modules/test_cplusplusext doesn't compile:\\n\\ng++ -Wall -Wpointer-arith -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wshadow=compatible-local -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -g -O2  -fvisibility=hidden -fvisibility-inlines-hidden -I. -I. -I../../../../src/include     -c -o test_cplusplusext.o test_cplusplusext.cpp\\nIn file included from ../../../../src/include/c.h:57,\\n                 from ../../../../src/include/postgres.h:48,\\n                 from test_cplusplusext.cpp:18:\\n../../../../src/include/pg_config.h:588:24: error: expected unqualified-id before '__int128'\\n  588 | #define PG_INT128_TYPE __int128\\n      |                        ^~~~~~~~\\n../../../../src/include/c.h:580:9: note: in expansion of macro 'PG_INT128_TYPE'\\n  580 | typedef PG_INT128_TYPE int128\\n      |         ^~~~~~~~~~~~~~\\n../../../../src/include/pg_config.h:588:24: error: expected unqualified-id before '__int128'\\n  588 | #define PG_INT128_TYPE __int128\\n      |                        ^~~~~~~~\\n../../../../src/include/c.h:586:18: note: in expansion of macro 'PG_INT128_TYPE'\\n  586 | typedef unsigned PG_INT128_TYPE uint128\\n      |                  ^~~~~~~~~~~~~~\\nmake: *** [<builtin>: test_cplusplusext.o] Error 1\\n      |                  ^~~~~~~~~~~~~~\\nmake[5]: *** [<builtin>: test_cplusplusext.o] Error 1\\n\\nI poked at trying to fix that, without success.  This is a\\nreasonably late-model g++:\\n\\n$ g++ --version\\ng++ (GCC) 13.3.0\\nCopyright (C) 2023 Free Software Foundation, Inc.\\nThis is free software; see the source for copying conditions.  There is NO\\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\\n\\nso I don't know why it doesn't like __int128.  This is very new code,\\nso there may be a non-AIX-specific issue for us to fix.  (But I\\ncould not reproduce the issue on the nearest version I have at hand,\\ng++ (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\\nfrom Fedora 38.)\\n\\nAnother thing I noticed: ps status isn't working.  (All the postmaster\\nchild processes look the same in \\"ps auxww\\".)  I suppose you need to\\nrestore the AIX support in ps_status.c.\\n\\nFWIW, attached is a delta patch showing where I am now (on top of\\nyour v11 patch and the pgstat_slru.c hack I showed earlier).\\n\\n\\t\\t\\tregards, tom lane\\n\\n"},{"id":"19c0169081bd448f","threadId":"19be67781ef21b94","snippet":"... btw, I was annoyed to notice that AIX still does this in 64-bit builds: checking size of void *... 8 checking size of size_t... 8 checking size of long... 8 checking size of long long... 8 checking","historyId":"30700","internalDate":"1769550155000","receivedAtUtc":"2026-01-27T21:42:35.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: AIX support","messageId":"<581905.1769550155@sss.pgh.pa.us>","body":"... btw, I was annoyed to notice that AIX still does this in\\n64-bit builds:\\n\\nchecking size of void *... 8\\nchecking size of size_t... 8\\nchecking size of long... 8\\nchecking size of long long... 8\\nchecking size of intmax_t... 8\\nchecking alignment of short... 2\\nchecking alignment of int... 4\\nchecking alignment of long... 8\\nchecking alignment of int64_t... 8\\nchecking alignment of double... 4\\n\\nNormally we reject alignof(double) < alignof(int64), for the reasons\\nexplained in configure.ac:\\n\\n# We require 'double' to have the strictest alignment among the basic types,\\n# because otherwise the C ABI might impose 8-byte alignment on some of the\\n# other C types that correspond to TYPALIGN_DOUBLE SQL types.  That could\\n# cause a mismatch between the tuple layout and the C struct layout of a\\n# catalog tuple.  We used to carefully order catalog columns such that any\\n# fixed-width, attalign=4 columns were at offsets divisible by 8 regardless\\n# of MAXIMUM_ALIGNOF to avoid that, but we no longer support any platforms\\n# where TYPALIGN_DOUBLE != MAXIMUM_ALIGNOF.\\n\\nI see that your patch summarily overrides that restriction (without\\nbothering to touch this comment), but I fear that the chances of\\nthat being acceptable as-is are zero.  We're not going to go back to\\nhaving to count bytes every time we change a system catalog rowtype\\nthat involves an 'int8' or 'float8' column.\\n\\nI think the only way we could deal with this in a maintainable\\nfashion would be to remove the assumption that int64 and double\\nhave the same alignment requirement.  That is tech debt that\\nwe really should have cleaned up years ago anyway.  The main\\nthing that's discouraged people from pursuing it is the fear\\nof adding overhead to tuple assembly/disassembly loops.  But\\nI think maybe we could avoid adding such overhead by mapping\\ntwo different type alignment symbols at the source-code level\\ninto appropriate values at runtime.  Or a bunch of conditional\\ncompilation, or whatever.  Any modern machine is going to have\\nto be able to deal with both 4-byte and 8-byte alignment\\nrequirements, it's just a question of which datatypes have\\nwhich requirement.\\n\\nWhile I don't foresee that being an enormous patch, it's not trivial\\neither.  I'd encourage you to write and submit it as a separate patch\\nrather than something directly tied to the AIX-restoration patch.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"},{"id":"19c016ff401a44b2","threadId":"19be67781ef21b94","snippet":"I wrote: > With the patch attached, I can get through \\"make installcheck\\". > However, I'm unable to attempt \\"make check-world\\" because > src/test/modules/","historyId":"30739","internalDate":"1769550615000","receivedAtUtc":"2026-01-27T21:50:15.000Z","from":"Tom Lane <tgl@sss.pgh.pa.us>","subject":"Re: AIX support","messageId":"<582533.1769550615@sss.pgh.pa.us>","body":"I wrote:\\n> With the patch attached, I can get through \\"make installcheck\\".\\n> However, I'm unable to attempt \\"make check-world\\" because\\n> src/test/modules/test_cplusplusext doesn't compile:\\n\\nAh, I figured out that bit: g++ will take this if you specify -maix64\\nto it too.  The built module would not have worked anyway without\\nthat, since it'd be 32-bit (AFAICT neither gcc nor g++ react to\\nthe OBJECT_MODE environment variable).\\n\\nIt's not exactly clear why gcc will accept __int128 in 32-bit mode\\nwhile g++ won't, but that seems like another good reason to decide\\nthat we won't support 32-bit builds on AIX anymore.\\n\\n\\t\\t\\tregards, tom lane\\n\\n\\n"}]	Tom Lane is reviewing Srirama Kucherlapati's patch to restore AIX support in PostgreSQL. He criticizes the complex environment variable setup required for building, arguing it should work with simple "./configure && make" commands. Lane suggests supporting only 64-bit builds with gcc and incorporating OBJECT_MODE=64 and -maix64 flags into autoconf/meson logic. He identifies several issues: missing libgcc_s.a detection logic from Makefile.aix, lgamma(NaN) returning ERANGE instead of NaN on AIX 7.3, compilation failures in test_cplusplusext due to __int128 handling in g++, and broken ps status display. A major concern is AIX's 4-byte double alignment versus 8-byte int64 alignment, which violates PostgreSQL's catalog tuple layout assumptions. Lane suggests this alignment issue requires a separate substantial patch to decouple int64 and double alignment requirements.	2026-01-27 21:50:15+00	Tom Lane正在审查Srirama Kucherlapati恢复PostgreSQL中AIX支持的补丁。他批评构建所需的复杂环境变量设置，认为应该能通过简单的"./configure && make"命令工作。Lane建议仅支持使用gcc的64位构建，并将OBJECT_MODE=64和-maix64标志集成到autoconf/meson逻辑中。他发现了几个问题：Makefile.aix中缺少libgcc_s.a检测逻辑，AIX 7.3上lgamma(NaN)返回ERANGE而不是NaN，test_cplusplusext由于g++中__int128处理导致编译失败，以及ps状态显示损坏。一个主要问题是AIX的4字节double对齐与8字节int64对齐，这违反了PostgreSQL的目录元组布局假设。Lane建议这个对齐问题需要一个单独的重要补丁来解耦int64和double对齐要求。
33	19c048d1c94a45b3	trivial designated initializers	["alvherre@kurilemu.de","melanieplageman@gmail.com","peter@eisentraut.org","postgres@jeltef.nl"]	[{"id":"19c048d1c94a45b3","threadId":"19c048d1c94a45b3","snippet":"Hi We use C99 designated struct initializers in many places, but for some reason we don't do it in the tupleLockExtraInfo array in heapam.c nor in InternalBGWorkers array in bgworker.c. I've","historyId":"33689","internalDate":"1769602856000","receivedAtUtc":"2026-01-28T12:20:56.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>","subject":"trivial designated initializers","messageId":"<202601281204.sdxbr5qvpunk@alvherre.pgsql>","body":"Hi\\n\\nWe use C99 designated struct initializers in many places, but for some\\nreason we don't do it in the tupleLockExtraInfo array in heapam.c nor in\\nInternalBGWorkers array in bgworker.c.  I've had this trivial patch\\nrotting in a worktree for a long time.  Any opposition to this change?\\n\\nThanks,\\n\\n-- \\nÁlvaro Herrera               48°01'N 7°57'E  —  https://www.EnterpriseDB.com/\\n\\"Postgres is bloatware by design: it was built to house\\n PhD theses.\\" (Joey Hellerstein, SIGMOD annual conference 2002)\\n"},{"id":"19c0538125294d6f","threadId":"19c048d1c94a45b3","snippet":"On Wed, Jan 28, 2026 at 7:21 AM Álvaro Herrera <alvherre@kurilemu.de> wrote: > > We use C99 designated struct initializers in many places, but for some > reason we don't do it in the","historyId":"34620","internalDate":"1769614065000","receivedAtUtc":"2026-01-28T15:27:45.000Z","from":"Melanie Plageman <melanieplageman@gmail.com>","subject":"Re: trivial designated initializers","messageId":"<CAAKRu_bMLz3PLcQFGnm6rcL9pg4g45OnUHMkgM2=k-_yF7i0ew@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 7:21 AM Álvaro Herrera <alvherre@kurilemu.de> wrote:\\n>\\n> We use C99 designated struct initializers in many places, but for some\\n> reason we don't do it in the tupleLockExtraInfo array in heapam.c nor in\\n> InternalBGWorkers array in bgworker.c.  I've had this trivial patch\\n> rotting in a worktree for a long time.  Any opposition to this change?\\n\\nI find these much easier to understand with the designated\\ninitializers (and I am a big fan of designated initializers in\\ngeneral). So +1\\n\\n- Melanie\\n\\n\\n"},{"id":"19c06cbb51f50693","threadId":"19c048d1c94a45b3","snippet":"On Wed, 28 Jan 2026 at 16:28, Melanie Plageman <melanieplageman@gmail.com> wrote: > I find these much easier to understand with the designated > initializers (and I am a big fan of","historyId":"36362","internalDate":"1769640514000","receivedAtUtc":"2026-01-28T22:48:34.000Z","from":"Jelte Fennema-Nio <postgres@jeltef.nl>","subject":"Re: trivial designated initializers","messageId":"<CAGECzQRvucd6qyFzJU=2iOcOdshXnGB7PenXnRTYkS1Pq1ZA_A@mail.gmail.com>","body":"On Wed, 28 Jan 2026 at 16:28, Melanie Plageman\\n<melanieplageman@gmail.com> wrote:\\n> I find these much easier to understand with the designated\\n> initializers (and I am a big fan of designated initializers in\\n> general). So +1\\n\\nyes, +1\\n\\n\\n"},{"id":"19c0710d02dfc4a4","threadId":"19c048d1c94a45b3","snippet":"On 28.01.26 13:20, Álvaro Herrera wrote: > { /* LockTupleKeyShare */ > - AccessShareLock, > - MultiXactStatusForKeyShare, > - -1 /* KeyShare does not allow updating tuples */ > + .hwlock","historyId":"36850","internalDate":"1769645056000","receivedAtUtc":"2026-01-29T00:04:16.000Z","from":"Peter Eisentraut <peter@eisentraut.org>","subject":"Re: trivial designated initializers","messageId":"<a44072f3-15d8-4118-b6cb-0345b30ca3eb@eisentraut.org>","body":"On 28.01.26 13:20, Álvaro Herrera wrote:\\n>   \\t{\\t\\t\\t\\t\\t\\t\\t/* LockTupleKeyShare */\\n> -\\t\\tAccessShareLock,\\n> -\\t\\tMultiXactStatusForKeyShare,\\n> -\\t\\t-1\\t\\t\\t\\t\\t\\t/* KeyShare does not allow updating tuples */\\n> +\\t\\t.hwlock = AccessShareLock,\\n> +\\t\\t.lockstatus = MultiXactStatusForKeyShare,\\n> +\\t\\t/* KeyShare does not allow updating tuples */\\n> +\\t\\t.updstatus = -1\\n>   \\t},\\n\\nYou could spruce this up further like\\n\\n[LockTupleKeyShare] = {\\n    .hwlock = AccessShareLock,\\n    ...\\n},\\n...\\n\\nThe comments \\"/* KeyShare does not allow updating tuples */\\" etc. seem repetitive and don't actually explain why -1 is an appropriate value. You could instead write a comment by the declaration of the updstatus field, like \\"set to -1 if the tuple lock mode does not allow updating tuples (see get_mxact_status_for_lock())\\".\\n\\n\\n\\n"}]	Álvaro Herrera proposes converting two PostgreSQL arrays to use C99 designated struct initializers: the tupleLockExtraInfo array in heapam.c and InternalBGWorkers array in bgworker.c. This would make the code more consistent with other parts of PostgreSQL that already use designated initializers. Melanie Plageman and Jelte Fennema-Nio both express support for the change, finding designated initializers easier to understand and generally preferring them. Peter Eisentraut also supports the idea but suggests further improvements, including using array index designators and consolidating repetitive comments. He recommends moving explanatory comments to the struct field declaration rather than repeating them for each array element. The proposal appears to have unanimous support with constructive suggestions for enhancement.	2026-01-29 00:04:16+00	Álvaro Herrera提议将PostgreSQL中的两个数组转换为使用C99指定结构体初始化器：heapam.c中的tupleLockExtraInfo数组和bgworker.c中的InternalBGWorkers数组。这将使代码与PostgreSQL中已经使用指定初始化器的其他部分保持一致。Melanie Plageman和Jelte Fennema-Nio都表示支持这一变更，认为指定初始化器更易于理解且通常更喜欢使用它们。Peter Eisentraut也支持这个想法，但建议进一步改进，包括使用数组索引指定符和整合重复的注释。他建议将解释性注释移到结构体字段声明处，而不是为每个数组元素重复注释。该提议似乎获得了一致支持，并有建设性的增强建议。
33	19bfb105673a8b2e	pg_plan_advice	["di@nmfay.com","jacob.champion@enterprisedb.com","jakub.wartak@enterprisedb.com","lukas@fittl.com","matheusssilv97@gmail.com","robertmhaas@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19c059940e97b5d1","threadId":"19bfb105673a8b2e","snippet":"On Mon, Jan 12, 2026 at 12:13 PM Robert Haas <robertmhaas@gmail.com> wrote: > If not, I'll rearrange > the series to move 0004 to the front, and plan to commit that first. That","historyId":"35056","internalDate":"1769620419000","receivedAtUtc":"2026-01-28T17:13:39.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pg_plan_advice","messageId":"<CA+TgmoaZMOikxK=LqS+Jn+835h9S139JLGk-3LyETVXw5W5j=w@mail.gmail.com>","body":"On Mon, Jan 12, 2026 at 12:13 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n> If not, I'll rearrange\\n> the series to move 0004 to the front, and plan to commit that first.\\n\\nThat rearrangement got done in v11, and I've now committed that patch\\nafter fixing a few typos that I found. Cautiously, woohoo, but let's\\nsee if anything breaks.\\n\\nHere's v13. Aside from dropping the now-committed patch, the other big\\nchange here is that I've fixed the way bitmap heap scans work by\\nreducing scope. Previously, you could write things like\\nBITMAP_HEAP_SCAN(foo some_foo_idx) or BITMAP_HEAP_SCAN(foo\\n&&(foo_a_idx foo_b_idx)) to try to compel a particular choice of index\\nwith a bitmap heap scan; however, it didn't actually work. I've now\\nremoved that, and now all of the arguments to BITMAP_HEAP_SCAN() are\\nrelation identifiers, and it specifies only that they should use some\\nkind of bitmap heap scan. I'm not sure that this is the right thing to\\ndo, but it might be, for a couple of reasons:\\n\\n1. The decision as to what should be included in a bitmap path is not\\nmade by the general costing machinery, but by choose_bitmap_and(),\\nwhich uses its own special algorithm. A general principle of\\npg_plan_advice is that it doesn't let you force the optimizer to\\nconsider options that are rejected for reasons other than cost. This\\nis a grey area. choose_bitmap_and() considers cost, but it also has\\nother heuristics to limit the search space. We could allow overriding\\nthe former part of the heuristic but not the latter, but that seems\\ncomplicated, and might also make this whole thing even more confusing\\nto use, since it would be really unclear why you could force some\\nindex combinations and not others. We could also allow forcing any\\ncombination, but that needs a lot of thought, since it deviates from\\nthe general design principle and might open a king-sized can of worms.\\nPoint being, the idea that BITMAP_HEAP_SCAN() has no business allowing\\nan index specification in the first place is not completely without\\nmerit.\\n\\n2. The only situations in which we consider multiple actual bitmap\\npaths (vs. potential bitmap paths, as discussed in the previous point)\\nis when there are possibly-useful parameterizations that we don't want\\nto ignore. However, I studied what happens in the core regression\\ntests, and it seems like we don't really have that many test cases\\nwhere just forcing some kind of bitmap heap scan wouldn't be good\\nenough. To use a parameterized bitmap heap scan path, we have to be\\nunder the inner side of a nested loop with the parameterized rel on\\nthe other side, so if the advice produces any other join order or join\\nmethod, then the parameterized paths won't even be considered and\\nthere's only one path to choose from. However, it is true that we\\nmight make the wrong decision about which bitmap path to use on the\\ninner side of a parameterized nested loop. In the future, that could\\nbe addressed either by adding control over choice of parameterization\\nor by re-adding something like what I had in earlier patch versions\\nwhere you can specify particular indexes. But. I don't think we need\\nto decide right now which of those things we might ultimately want to\\ndo.\\n\\n(Another interesting point is that in a healthy number of cases where\\nwe consider both parameterized and unparameterized bitmap paths, we\\nconsider the same indexes or sets of indexes in both cases.)\\n\\nI've gone ahead and removed the \\"WIP\\" designation from the\\npg_plan_advice patch in this version. There are still a few areas that\\nneed some more investigation, and I'm sure there are still bugs, but I\\nfeel like the bitmap scan thing was the last really big area where\\nthere was a huge problem staring any potential reviewer right in the\\nface. The remaining XXX comments are things where review comments\\nwould actually be pretty helpful -- not to tell me that I have an XXX\\ncomment, but to suggest what the resolution might be. Of course, I'll\\ncontinue looking into that on my own, as well.\\n\\nThanks to all who have reviewed so far, and please keep it coming. I\\nam especially in need of more code review at this point.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n"},{"id":"19c06fb877cbf6df","threadId":"19bfb105673a8b2e","snippet":"Hello Just noticed this in the committed patch, it doesn't seem intentional: (the last line wasn't part of the patch, probably an accidental leftover) src/backend/optimizer/ptah/costsize.c:1462","historyId":"36723","internalDate":"1769643649000","receivedAtUtc":"2026-01-28T23:40:49.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>","subject":"Re: pg_plan_advice","messageId":"<CAN4CZFPvwjNJEZ_JT9Y67yR7C=KMNa=LNefOB8ZY7TKDcmAXOA@mail.gmail.com>","body":"Hello\\n\\nJust noticed this in the committed patch, it doesn't seem intentional:\\n(the last line wasn't part of the patch, probably an accidental leftover)\\n\\nsrc/backend/optimizer/ptah/costsize.c:1462\\n\\n        if (path->parallel_workers == 0)\\n                enable_mask |= PGS_CONSIDER_NONPARTIAL;\\n        path->disabled_nodes =\\n                (baserel->pgs_mask & enable_mask) != enable_mask ? 1 : 0;\\n        path->disabled_nodes = 0;\\n\\n\\n"}]	Robert Haas committed part of the pg_plan_advice patch series after rearranging to move patch 0004 to the front, and released v13 of the remaining patches. The major change in v13 involves fixing bitmap heap scans by reducing scope - removing the ability to specify particular indexes within BITMAP_HEAP_SCAN() directives, now only allowing relation identifiers to specify some kind of bitmap heap scan should be used. This decision addresses complexity around choose_bitmap_and() algorithm which uses special heuristics beyond just cost considerations. Haas removed the "WIP" designation, noting that while some areas need investigation and bugs likely remain, the bitmap scan issue was the last major problem. He requests continued code review. Zsolt Parragi then reported finding an accidental leftover line in the committed patch at src/backend/optimizer/ptah/costsize.c:1462 where "path->disabled_nodes = 0;" appears to be unintentional.	2026-01-28 23:40:49+00	Robert Haas在重新排列补丁系列后提交了pg_plan_advice补丁系列的一部分，将补丁0004移到前面，并发布了其余补丁的v13版本。v13的主要变化涉及通过减少范围来修复位图堆扫描 - 移除了在BITMAP_HEAP_SCAN()指令中指定特定索引的能力，现在只允许关系标识符来指定应该使用某种位图堆扫描。这个决定解决了围绕choose_bitmap_and()算法的复杂性，该算法使用了超出成本考虑的特殊启发式方法。Haas移除了"WIP"标记，指出虽然某些领域需要调查且可能仍有bug，但位图扫描问题是最后一个主要问题。他请求继续进行代码审查。Zsolt Parragi随后报告在已提交补丁的src/backend/optimizer/ptah/costsize.c:1462处发现了意外遗留行，其中"path->disabled_nodes = 0;"似乎是无意的。
33	19be67781ef21b94	AIX support	["aditya.kamath1@ibm.com","alvherre@kurilemu.de","andres@anarazel.de","hlinnaka@iki.fi","michael@paquier.xyz","peter@eisentraut.org","postgres-ibm-aix@wwpdl.vnet.ibm.com","robertmhaas@gmail.com","sriram.rk@in.ibm.com","tristan@partin.io"]	[{"id":"19c046b94d8dfa2a","threadId":"19be67781ef21b94","snippet":"Hi Andrew, Thank you for your review comments for AIX so far. While we are working on the rest of the comments you had sent here is our explanation for using the '-D_H_FLOAT' flag in the source","historyId":"33455","internalDate":"1769595941000","receivedAtUtc":"2026-01-28T10:25:41.000Z","from":"Aditya Kamath <Aditya.Kamath1@ibm.com>","subject":"RE: AIX support","messageId":"<LV8PR15MB64883FC333B351ABD169E874D691A@LV8PR15MB6488.namprd15.prod.outlook.com>","body":"Hi Andrew,\\n\\nThank you for your review comments for AIX so far.\\n\\nWhile we are working on the rest of the comments you had sent here is our explanation for using the  '-D_H_FLOAT’ flag in the source directory meson.build file.\\n\\n>> +  # This flag is required to make sure the user spefic float.h is\\n>> +  # picked instead of the system float.h header file, which doesnot\\n>> +  # have definition like float8, etc\\n>> +  cflags += '-D_H_FLOAT’\\n\\n>I don't understand this one - how does defining _H_FLOAT lead to a >different\\n>header being picked? Also, float8 is defined in c.h, so it hardly could >be\\n>influenced by a system float.h header?\\n\\n>Our float.h header is only included as \\"utils/float.h\\", so it really >shouldn’t\\n>be confused with a system header?\\n\\n\\nSo If we do not use the flag the error we get is as follows,\\n\\nFAILED: src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o\\ngcc -Isrc/backend/utils/activity/wait_event_names.a.p -Isrc/include/utils -I../src/include/utils -Isrc/include -I../src/include -I/opt/freeware/include -I/opt/freeware/include/libxml2 -fdiagnostics-color=always -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -O2 -g -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wmissing-prototypes -Wpointer-arith -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wshadow=compatible-local -Wformat-security -Wdeclaration-after-statement -Wno-format-truncation -Wno-stringop-truncation -maix64 -fPIC -pthread -DBUILDING_DLL1233 -MD -MQ src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o -MF src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o.d -o src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o -c ../src/backend/utils/activity/wait_event_funcs.c\\nIn file included from /usr/include/sys/limits.h:307,\\n                 from /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/13/include-fixed/stdio.h:589,\\n                 from ../src/include/c.h:65,\\n                 from ../src/include/postgres.h:48,\\n                 from ../src/backend/utils/activity/wait_event_funcs.c:15:\\n../src/include/utils/float.h:28:19: error: expected ';' before 'int'\\n   28 | extern PGDLLIMPORT int extra_float_digits;\\n../src/include/utils/float.h:289:37: error: unknown type name 'float4'\\n  289 | float4_min(const float4 val1, const float4 val2)\\n../src/include/utils/float.h:294:15: error: unknown type name 'float8'\\n  294 | static inline float8\\n\\nThe reason this happened is because -I../src/include/utils argument in the command included the float.h header first before the ./src/include/c.h header of postgresql which actually has the\\nPGDLLIMPORT, float4 and float8 definitions.\\n\\nSo, the header files have mismatched in the order they are processed. If we eliminate -I../src/include/utils in the command, then it will work.\\n\\nBut that will not happen automatically since we use include_directories() everywhere which adds both the source and the build directory includes. If we can get meson to not use\\n-I../src/include/ in AIX while including headers we will be able to compile.\\n\\nWe are currently experimenting with implicit_include_directories from the document below to see if we can remove the same\\nhttps://mesonbuild.com/Include-directories.html.\\n\\nReason for -D_H_FLOAT\\n\\nThis prevents AIX libc’s float.h to be included via c.h -> stdio.h -> limits.h -> float.h. The real problem is header include order in AIX. Compiler sees src/include/utils/float.h first and then c.h. This is a problem. When this flag is set, AIX’s float.h is skipped causing system header include chain to change. AIX no longer injects float.h early which results in c.h included before utils/float.h. the way Postgres expects.\\n\\nLet us know what you think.\\n\\n\\nIs there a preferred or cleaner way you know to ensure the correct include ordering like using implicit_include_directories so that utils/float.h is not included before c.h?\\n\\nHave a nice day ahead.\\n\\nThanks and regards,\\nAditya.\\n\\n\\n\\nFrom: Srirama Kucherlapati <sriram.rk@in.ibm.com>\\nDate: Wednesday, 28 January 2026 at 9:34 AM\\nTo: Aditya Kamath <Aditya.Kamath1@ibm.com>\\nSubject: FW: [EXTERNAL] Re: AIX support\\n\\nFYI\\n\\n\\nWarm regards,\\n\\nSriram.\\n\\n\\n\\n------------------------------------------\\n\\nVIOS/SSP Development,\\n\\nISDL, IBM India Pvt Ltd.\\n\\n\\n\\nFrom: Andres Freund <andres@anarazel.de>\\nDate: Monday, 26 January 2026 at 21:11\\nTo: Srirama Kucherlapati <sriram.rk@in.ibm.com>\\nCc: Peter Eisentraut <peter@eisentraut.org>, pgsql-hackers@lists.postgresql.org <pgsql-hackers@lists.postgresql.org>, Heikki Linnakangas <hlinnaka@iki.fi>, Tristan Partin <tristan@partin.io>, AIX PG user <postgres-ibm-aix@wwpdl.vnet.ibm.com>\\nSubject: [EXTERNAL] Re: AIX support\\n\\nHi,\\n\\nFrom what I can tell the meson patch *AGAIN* is missing mkldexport.sh. Also,\\nyou seem to reference the script as files('port/aix/mkldexport.sh'), but that\\nthat's not a path that makes sense for our source code structure (nor where\\nthe \\"complete\\" patch adds it).\\n\\nYou really need to actually start testing your patches.\\n\\n\\nDoesn't the meson patch also require the changes to src/tools/gen_export.pl?\\n\\n\\nOn 2026-01-23 16:11:25 +0000, Srirama Kucherlapati wrote:\\n> diff --git a/meson.build b/meson.build\\n> index 6e7ddd74683..17ad9c6ca32 100644\\n> --- a/meson.build\\n> +++ b/meson.build\\n> @@ -198,6 +198,8 @@ endif\\n>  # that purpose.\\n>  portname = host_system\\n>\\n> +dep_static_lib = declare_dependency()\\n\\nAdd a comment saying something like\\n\\n# In some configurations we don't want to install static libraries. For those\\n# dep_static_lib can be set to disabler() below.\\n\\n\\nThe introduction of dep_static_lib should be broken out into its own patch.\\n\\n\\n\\n> +  # This flag is required to make sure the user spefic float.h is\\n> +  # picked instead of the system float.h header file, which doesnot\\n> +  # have definition like float8, etc\\n> +  cflags += '-D_H_FLOAT'\\n\\nI don't understand this one - how does defining _H_FLOAT lead to a different\\nheader being picked? Also, float8 is defined in c.h, so it hardly could be\\ninfluenced by a system float.h header?\\n\\nOur float.h header is only included as \\"utils/float.h\\", so it really shouldn't\\nbe confused with a system header?\\n\\n\\n> @@ -1765,10 +1793,49 @@ endforeach\\n>  # as long, char, short, or int.  Note that we intentionally do not consider\\n>  # any types wider than 64 bits, as allowing MAXIMUM_ALIGNOF to exceed 8\\n>  # would be too much of a penalty for disk and memory space.\\n> -alignof_double = cdata.get('ALIGNOF_DOUBLE')\\n> -if cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>') > alignof_double\\n> -  error('alignment of int64_t is greater than the alignment of double')\\n> -endif\\n> +if host_system != 'aix'\\n> +  alignof_double = cdata.get('ALIGNOF_DOUBLE')\\n> +  if cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>') > alignof_double\\n> +       error('alignment of int64_t is greater than the alignment of double')\\n> +  endif\\n> +else\\n> +  # The AIX 'power' alignment rules apply the natural alignment of the \\"first\\n> +  # member\\" if it is of a floating-point data type (or is an aggregate whose\\n> +  # recursively \\"first\\" member or element is such a type). The alignment\\n> +  # associated with these types for subsequent members use an alignment value\\n> +  # where the floating-point data type is considered to have 4-byte alignment.\\n> +  # More info\\n> +  # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=99557 \\n> +  #\\n> +  # The double is aligned to 4-bytes on AIX in aggregates. But to maintain\\n> +  # alignement across platforms the max alignment of long should be considered.\\n\\nHow are these \\"AIX 'power' alignment rules\\" for float not just completely\\nbroken?\\n\\nI assume this means that 4 byte aligned floats work just fine, but have\\ndegraded peformance?\\n\\nIs there documentation about this that isn't an already fixed bug report in gcc?\\n\\n\\nMaybe I'm confused, but doesn't this power alignment rule mean that the\\ncc.alignment('double') will always return 8? That computation won't apply the\\n\\"subsequent member\\" rule, and therefore will have an alignment of 8. Which in\\nturn seems to make this entire change pointless?\\n\\n\\n> +  # Get the alignment values\\n> +  ac_cv_alignof_long    = cc.alignment('long', args: test_c_args, prefix: '#include <stdint.h>')\\n> +  ac_cv_alignof_double  = cc.alignment('double', args: test_c_args, prefix: '#include <stdint.h>')\\n> +  ac_cv_alignof_int64_t = cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>')\\n\\nI've previously complained about these av_cv_ variable names. This isn't\\nautoconf. What is this doing here?\\n\\nWhy do we need a platform specific alignment determination for long, int64?\\n\\n\\n> +  message('Alignment of long    : @0@'.format(ac_cv_alignof_long))\\n> +  message('Alignment of double  : @0@'.format(ac_cv_alignof_double))\\n> +  message('Alignment of int64_t : @0@'.format(ac_cv_alignof_int64_t))\\n\\nThese are already going to be output by cc.alignment, this is just redundant,\\nno?\\n\\n\\n> +  # Start with long\\n> +  alignof_double = ac_cv_alignof_long\\n> +  message('MAX ALIGN ac_cv_alignof_long')\\n> +\\n> +  # Compare with double\\n> +  if alignof_double < ac_cv_alignof_double\\n> +    alignof_double = ac_cv_alignof_double\\n> +    message('MAX ALIGN ac_cv_alignof_double')\\n> +  endif\\n> +\\n> +  # Compare with int64_t\\n> +  if alignof_double < ac_cv_alignof_int64_t\\n> +    alignof_double = ac_cv_alignof_int64_t\\n> +    message('MAX ALIGN ac_cv_alignof_int64_t')\\n> +  endif\\n> +endif\\n> +message('MAX ALIGN OF DOUBLE : @0@'.format(alignof_double))\\n\\nThis is a lot of output for something that's just computing a maximum of three\\nvariables.\\n\\n\\n\\n> diff --git a/src/backend/meson.build b/src/backend/meson.build\\n> index b831a541652..4838f245ab3 100644\\n> --- a/src/backend/meson.build\\n> +++ b/src/backend/meson.build\\n> @@ -125,6 +125,24 @@ if host_system == 'windows'\\n>      '--FILEDESC', 'PostgreSQL Server',])\\n>  endif\\n>\\n> +if host_system == 'aix'\\n> +  # The '.' argument leads mkldexport.sh to emit \\"#! .\\", which refers to the\\n> +  # main executable, allowing extension libraries to resolve their undefined\\n> +  # symbols to symbols in the postgres binary.\\n> +  postgres_imp = custom_target('postgres.imp',\\n> +    command: [files('port/aix/mkldexport.sh'), '@INPUT@', '.'],\\n> +    input: postgres_lib,\\n> +    output: 'postgres.imp',\\n> +    capture: true,\\n> +    install: true,\\n> +    install_dir: dir_lib,\\n> +    build_by_default: false,\\n> +  )\\n> +  backend_link_args += '-Wl,-bE:@0@'.format(postgres_imp.full_path())\\n> +  backend_link_depends += postgres_imp\\n> +endif\\n\\nThis should be moved next to the msvc specific block (the one about\\npostgres_def) and should use an elif.\\n\\n\\n\\nGreetings,\\n\\nAndres Freund\\n"},{"id":"19c05316845be7e1","threadId":"19be67781ef21b94","snippet":"Hi Andres, I can explain this differently as well. We know that include_directories property in meson will include the source and the build directory in the command. Ex: If we give “src/include” then “","historyId":"34439","internalDate":"1769613625000","receivedAtUtc":"2026-01-28T15:20:25.000Z","from":"Aditya Kamath <Aditya.Kamath1@ibm.com>","subject":"RE: AIX support","messageId":"<LV8PR15MB64888765A43D229EA5D1CFE6D691A@LV8PR15MB6488.namprd15.prod.outlook.com>","body":"Hi Andres,\\n\\nI can explain this differently as well.\\n\\nWe know that include_directories property in meson will include the source and the build directory in the command. Ex: If we give “src/include” then “-Isrc/include” and “-I../src/include” are added.\\n\\n>> +  # This flag is required to make sure the user spefic float.h is\\n>> +  # picked instead of the system float.h header file, which doesnot\\n>> +  # have definition like float8, etc\\n>> +  cflags += '-D_H_FLOAT’\\n\\n>I don't understand this one - how does defining _H_FLOAT lead to a >different\\n>header being picked?\\n\\nBelow is the error message we get in AIX if we do not use '-D_H_FLOAT’\\nFAILED: src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o\\ngcc -Isrc/backend/utils/activity/wait_event_names.a.p -Isrc/include/utils -I../src/include/utils -Isrc/include -I../src/include -I/opt/freeware/include -I/opt/freeware/include/libxml2 -fdiagnostics-color=always -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -O2 -g -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wmissing-prototypes -Wpointer-arith -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wshadow=compatible-local -Wformat-security -Wdeclaration-after-statement -Wno-format-truncation -Wno-stringop-truncation -maix64 -fPIC -pthread -DBUILDING_DLL1233 -MD -MQ\\n./src/include/utils/float.h:28:19: error: expected ';' before 'int'\\n   28 | extern PGDLLIMPORT int extra_float_digits;\\n\\n\\nThere is a clear missing of float.h definitions, the reason being float.h got included before \\"src/include/c.h”.\\n\\n\\nKindly observe the command  \\"-I../src/include/utils” flag came in the front.\\n\\nNow in c.h when stdio.h is called in AIX at line 65, then AIX system limits.h is called and then within that AIX system float.h is called.\\n\\nBut here is the catch. It won’t pick the AIX system float.h. It will pick the Postgres \\"src/include/utilsfloat.h”.\\n\\nThe reason being the compiler is designed to pick what comes first in -I flag. One proof of that is here. https://gcc.gnu.org/onlinedocs/cpp/Wrapper-Headers.html\\n\\nI am assuming all systems behave like this.\\n\\nThis is the root cause of the problem. That \\"-I../src/include/utils” which meson adds.\\n\\nSo now \\"src/include/utils/float.h”.is picked up first even before \\"src/include/c.h”.\\n\\nThat is why we saw the error. When we define “_H_FLOAT” we essentially force the system header to be ignored in the system limits.h where it is called and then the Postgres  \\"src/include/utils/float.h” takes over.\\n\\nHope this explains Andres.\\n\\nThere are multiple things we can do here.\\n\\nOne being define “_H_FLOAT”\\n\\nThe other being use  #include_next float.h under ifdef _AIX guard\\n\\nThe third we are experimenting is to have implicit_include_directories: false as per document here https://mesonbuild.com/Include-directories.html, but that might difficult since recursive include directories exists in Postgres.\\n\\n\\nKindly let us know if this explanation helps and what you think. Also If there is a preferred or cleaner way you know let us know.\\n\\n\\nHave a nice day ahead.\\n\\n\\nThanks and regards,\\n\\nAditya.\\n\\n\\nFrom: Aditya Kamath <Aditya.Kamath1@ibm.com>\\nDate: Wednesday, 28 January 2026 at 3:55 PM\\nTo: Srirama Kucherlapati <sriram.rk@in.ibm.com>, peter@eisentraut.org <peter@eisentraut.org>, andres@anarazel.de <andres@anarazel.de>\\nCc: pgsql-hackers@lists.postgresql.org <pgsql-hackers@lists.postgresql.org>, hlinnaka@iki.fi <hlinnaka@iki.fi>, tristan@partin.io <tristan@partin.io>, postgres-ibm-aix@wwpdl.vnet.ibm.com <postgres-ibm-aix@wwpdl.vnet.ibm.com>\\nSubject: Re: [EXTERNAL] Re: AIX support\\n\\nHi Andrew,\\n\\nThank you for your review comments for AIX so far.\\n\\nWhile we are working on the rest of the comments you had sent here is our explanation for using the  '-D_H_FLOAT’ flag in the source directory meson.build file.\\n\\n>> +  # This flag is required to make sure the user spefic float.h is\\n>> +  # picked instead of the system float.h header file, which doesnot\\n>> +  # have definition like float8, etc\\n>> +  cflags += '-D_H_FLOAT’\\n\\n>I don't understand this one - how does defining _H_FLOAT lead to a >different\\n>header being picked? Also, float8 is defined in c.h, so it hardly could >be\\n>influenced by a system float.h header?\\n\\n>Our float.h header is only included as \\"utils/float.h\\", so it really >shouldn’t\\n>be confused with a system header?\\n\\n\\nSo If we do not use the flag the error we get is as follows,\\n\\nFAILED: src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o\\ngcc -Isrc/backend/utils/activity/wait_event_names.a.p -Isrc/include/utils -I../src/include/utils -Isrc/include -I../src/include -I/opt/freeware/include -I/opt/freeware/include/libxml2 -fdiagnostics-color=always -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -O2 -g -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wmissing-prototypes -Wpointer-arith -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wshadow=compatible-local -Wformat-security -Wdeclaration-after-statement -Wno-format-truncation -Wno-stringop-truncation -maix64 -fPIC -pthread -DBUILDING_DLL1233 -MD -MQ src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o -MF src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o.d -o src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o -c ../src/backend/utils/activity/wait_event_funcs.c\\nIn file included from /usr/include/sys/limits.h:307,\\n                 from /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/13/include-fixed/stdio.h:589,\\n                 from ../src/include/c.h:65,\\n                 from ../src/include/postgres.h:48,\\n                 from ../src/backend/utils/activity/wait_event_funcs.c:15:\\n../src/include/utils/float.h:28:19: error: expected ';' before 'int'\\n   28 | extern PGDLLIMPORT int extra_float_digits;\\n../src/include/utils/float.h:289:37: error: unknown type name 'float4'\\n  289 | float4_min(const float4 val1, const float4 val2)\\n../src/include/utils/float.h:294:15: error: unknown type name 'float8'\\n  294 | static inline float8\\n\\nThe reason this happened is because -I../src/include/utils argument in the command included the float.h header first before the ./src/include/c.h header of postgresql which actually has the\\nPGDLLIMPORT, float4 and float8 definitions.\\n\\nSo, the header files have mismatched in the order they are processed. If we eliminate -I../src/include/utils in the command, then it will work.\\n\\nBut that will not happen automatically since we use include_directories() everywhere which adds both the source and the build directory includes. If we can get meson to not use\\n-I../src/include/ in AIX while including headers we will be able to compile.\\n\\nWe are currently experimenting with implicit_include_directories from the document below to see if we can remove the same\\nhttps://mesonbuild.com/Include-directories.html.\\n\\nReason for -D_H_FLOAT\\n\\nThis prevents AIX libc’s float.h to be included via c.h -> stdio.h -> limits.h -> float.h. The real problem is header include order in AIX. Compiler sees src/include/utils/float.h first and then c.h. This is a problem. When this flag is set, AIX’s float.h is skipped causing system header include chain to change. AIX no longer injects float.h early which results in c.h included before utils/float.h. the way Postgres expects.\\n\\nLet us know what you think.\\n\\n\\nIs there a preferred or cleaner way you know to ensure the correct include ordering like using implicit_include_directories so that utils/float.h is not included before c.h?\\n\\nHave a nice day ahead.\\n\\nThanks and regards,\\nAditya.\\n\\n\\n\\nFrom: Srirama Kucherlapati <sriram.rk@in.ibm.com>\\nDate: Wednesday, 28 January 2026 at 9:34 AM\\nTo: Aditya Kamath <Aditya.Kamath1@ibm.com>\\nSubject: FW: [EXTERNAL] Re: AIX support\\n\\nFYI\\n\\n\\nWarm regards,\\n\\nSriram.\\n\\n\\n\\n------------------------------------------\\n\\nVIOS/SSP Development,\\n\\nISDL, IBM India Pvt Ltd.\\n\\n\\n\\nFrom: Andres Freund <andres@anarazel.de>\\nDate: Monday, 26 January 2026 at 21:11\\nTo: Srirama Kucherlapati <sriram.rk@in.ibm.com>\\nCc: Peter Eisentraut <peter@eisentraut.org>, pgsql-hackers@lists.postgresql.org <pgsql-hackers@lists.postgresql.org>, Heikki Linnakangas <hlinnaka@iki.fi>, Tristan Partin <tristan@partin.io>, AIX PG user <postgres-ibm-aix@wwpdl.vnet.ibm.com>\\nSubject: [EXTERNAL] Re: AIX support\\n\\nHi,\\n\\nFrom what I can tell the meson patch *AGAIN* is missing mkldexport.sh. Also,\\nyou seem to reference the script as files('port/aix/mkldexport.sh'), but that\\nthat's not a path that makes sense for our source code structure (nor where\\nthe \\"complete\\" patch adds it).\\n\\nYou really need to actually start testing your patches.\\n\\n\\nDoesn't the meson patch also require the changes to src/tools/gen_export.pl?\\n\\n\\nOn 2026-01-23 16:11:25 +0000, Srirama Kucherlapati wrote:\\n> diff --git a/meson.build b/meson.build\\n> index 6e7ddd74683..17ad9c6ca32 100644\\n> --- a/meson.build\\n> +++ b/meson.build\\n> @@ -198,6 +198,8 @@ endif\\n>  # that purpose.\\n>  portname = host_system\\n>\\n> +dep_static_lib = declare_dependency()\\n\\nAdd a comment saying something like\\n\\n# In some configurations we don't want to install static libraries. For those\\n# dep_static_lib can be set to disabler() below.\\n\\n\\nThe introduction of dep_static_lib should be broken out into its own patch.\\n\\n\\n\\n> +  # This flag is required to make sure the user spefic float.h is\\n> +  # picked instead of the system float.h header file, which doesnot\\n> +  # have definition like float8, etc\\n> +  cflags += '-D_H_FLOAT'\\n\\nI don't understand this one - how does defining _H_FLOAT lead to a different\\nheader being picked? Also, float8 is defined in c.h, so it hardly could be\\ninfluenced by a system float.h header?\\n\\nOur float.h header is only included as \\"utils/float.h\\", so it really shouldn't\\nbe confused with a system header?\\n\\n\\n> @@ -1765,10 +1793,49 @@ endforeach\\n>  # as long, char, short, or int.  Note that we intentionally do not consider\\n>  # any types wider than 64 bits, as allowing MAXIMUM_ALIGNOF to exceed 8\\n>  # would be too much of a penalty for disk and memory space.\\n> -alignof_double = cdata.get('ALIGNOF_DOUBLE')\\n> -if cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>') > alignof_double\\n> -  error('alignment of int64_t is greater than the alignment of double')\\n> -endif\\n> +if host_system != 'aix'\\n> +  alignof_double = cdata.get('ALIGNOF_DOUBLE')\\n> +  if cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>') > alignof_double\\n> +       error('alignment of int64_t is greater than the alignment of double')\\n> +  endif\\n> +else\\n> +  # The AIX 'power' alignment rules apply the natural alignment of the \\"first\\n> +  # member\\" if it is of a floating-point data type (or is an aggregate whose\\n> +  # recursively \\"first\\" member or element is such a type). The alignment\\n> +  # associated with these types for subsequent members use an alignment value\\n> +  # where the floating-point data type is considered to have 4-byte alignment.\\n> +  # More info\\n> +  # https://gcc.gnu.org/bugzilla/show_bug.cgi?id=99557 \\n> +  #\\n> +  # The double is aligned to 4-bytes on AIX in aggregates. But to maintain\\n> +  # alignement across platforms the max alignment of long should be considered.\\n\\nHow are these \\"AIX 'power' alignment rules\\" for float not just completely\\nbroken?\\n\\nI assume this means that 4 byte aligned floats work just fine, but have\\ndegraded peformance?\\n\\nIs there documentation about this that isn't an already fixed bug report in gcc?\\n\\n\\nMaybe I'm confused, but doesn't this power alignment rule mean that the\\ncc.alignment('double') will always return 8? That computation won't apply the\\n\\"subsequent member\\" rule, and therefore will have an alignment of 8. Which in\\nturn seems to make this entire change pointless?\\n\\n\\n> +  # Get the alignment values\\n> +  ac_cv_alignof_long    = cc.alignment('long', args: test_c_args, prefix: '#include <stdint.h>')\\n> +  ac_cv_alignof_double  = cc.alignment('double', args: test_c_args, prefix: '#include <stdint.h>')\\n> +  ac_cv_alignof_int64_t = cc.alignment('int64_t', args: test_c_args, prefix: '#include <stdint.h>')\\n\\nI've previously complained about these av_cv_ variable names. This isn't\\nautoconf. What is this doing here?\\n\\nWhy do we need a platform specific alignment determination for long, int64?\\n\\n\\n> +  message('Alignment of long    : @0@'.format(ac_cv_alignof_long))\\n> +  message('Alignment of double  : @0@'.format(ac_cv_alignof_double))\\n> +  message('Alignment of int64_t : @0@'.format(ac_cv_alignof_int64_t))\\n\\nThese are already going to be output by cc.alignment, this is just redundant,\\nno?\\n\\n\\n> +  # Start with long\\n> +  alignof_double = ac_cv_alignof_long\\n> +  message('MAX ALIGN ac_cv_alignof_long')\\n> +\\n> +  # Compare with double\\n> +  if alignof_double < ac_cv_alignof_double\\n> +    alignof_double = ac_cv_alignof_double\\n> +    message('MAX ALIGN ac_cv_alignof_double')\\n> +  endif\\n> +\\n> +  # Compare with int64_t\\n> +  if alignof_double < ac_cv_alignof_int64_t\\n> +    alignof_double = ac_cv_alignof_int64_t\\n> +    message('MAX ALIGN ac_cv_alignof_int64_t')\\n> +  endif\\n> +endif\\n> +message('MAX ALIGN OF DOUBLE : @0@'.format(alignof_double))\\n\\nThis is a lot of output for something that's just computing a maximum of three\\nvariables.\\n\\n\\n\\n> diff --git a/src/backend/meson.build b/src/backend/meson.build\\n> index b831a541652..4838f245ab3 100644\\n> --- a/src/backend/meson.build\\n> +++ b/src/backend/meson.build\\n> @@ -125,6 +125,24 @@ if host_system == 'windows'\\n>      '--FILEDESC', 'PostgreSQL Server',])\\n>  endif\\n>\\n> +if host_system == 'aix'\\n> +  # The '.' argument leads mkldexport.sh to emit \\"#! .\\", which refers to the\\n> +  # main executable, allowing extension libraries to resolve their undefined\\n> +  # symbols to symbols in the postgres binary.\\n> +  postgres_imp = custom_target('postgres.imp',\\n> +    command: [files('port/aix/mkldexport.sh'), '@INPUT@', '.'],\\n> +    input: postgres_lib,\\n> +    output: 'postgres.imp',\\n> +    capture: true,\\n> +    install: true,\\n> +    install_dir: dir_lib,\\n> +    build_by_default: false,\\n> +  )\\n> +  backend_link_args += '-Wl,-bE:@0@'.format(postgres_imp.full_path())\\n> +  backend_link_depends += postgres_imp\\n> +endif\\n\\nThis should be moved next to the msvc specific block (the one about\\npostgres_def) and should use an elif.\\n\\n\\n\\nGreetings,\\n\\nAndres Freund\\n"},{"id":"19c05367e86c0703","threadId":"19be67781ef21b94","snippet":"On Mon, Jan 26, 2026 at 10:41 AM Andres Freund <andres@anarazel.de> wrote: > You really need to actually start testing your patches. +1. The quality of the patches posted to this thread is","historyId":"34575","internalDate":"1769613958000","receivedAtUtc":"2026-01-28T15:25:58.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: AIX support","messageId":"<CA+Tgmobh=69ud8J62XFAErS-R=mxXC_9RT85hoFMPG_M8+650Q@mail.gmail.com>","body":"On Mon, Jan 26, 2026 at 10:41 AM Andres Freund <andres@anarazel.de> wrote:\\n> You really need to actually start testing your patches.\\n\\n+1. The quality of the patches posted to this thread is very\\nnoticeably lower than what we typically expect or accept. They are\\nmissing files, or they don't work, or the changes are not properly\\nexplained, or they do things that are clearly unlike anything else we\\ndo anywhere in the source tree, or they change how things work for\\nother platforms rather than just being AIX-specific, or they don't\\nwork unless you follow a bunch of undocumented steps, or whatever the\\ncase may be.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c0545103201c5e","threadId":"19be67781ef21b94","snippet":"On Wed, Jan 28, 2026 at 10:20 AM Aditya Kamath <Aditya.Kamath1@ibm.com> wrote: > But here is the catch. It won't pick the AIX system float.h. It will pick the Postgres \\"src/include/","historyId":"34677","internalDate":"1769614912000","receivedAtUtc":"2026-01-28T15:41:52.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: AIX support","messageId":"<CA+TgmoatPGOAfL8Wa3uZ1OGXd34EKOzgm6hXSTa1swS=bbQoag@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 10:20 AM Aditya Kamath <Aditya.Kamath1@ibm.com> wrote:\\n> But here is the catch. It won’t pick the AIX system float.h. It will pick the Postgres \\"src/include/utilsfloat.h”.\\n\\nPostgreSQL's header should always be included as \\"utils/float.h\\" and\\nthe system header should always be included as \\"float.h\\" (or, well,\\n<float.h>, presumably). So this confusion should not exist unless the\\ninclude paths are messed up. It doesn't seem correct to me that the\\ninclude path includes src/include/utils rather than just src/include,\\nbut I see the same thing here:\\n\\n    \\"command\\": \\"ccache clang\\n-Isrc/backend/utils/activity/wait_event_names.a.p -Isrc/include/utils\\n-I../pgsql/src/include/utils -Isrc/include -I../pgsql/src/include\\n-I/opt/local/include -I/opt/local/include/libxml2\\n-I/opt/local/libexec/openssl3/include -fdiagnostics-color=always -Wall\\n-Winvalid-pch -O2 -g -isysroot\\n/Library/Developer/CommandLineTools/SDKs/MacOSX14.2.sdk\\n-fno-strict-aliasing -fwrapv -fexcess-precision=standard\\n-Wmissing-prototypes -Wpointer-arith -Werror=vla\\n-Werror=unguarded-availability-new -Wendif-labels\\n-Wmissing-format-attribute -Wcast-function-type -Wformat-security\\n-Wdeclaration-after-statement -Wmissing-variable-declarations\\n-Wno-unused-command-line-argument -Wno-compound-token-split-by-macro\\n-Wno-format-truncation -Wno-cast-function-type-strict -DBUILDING_DLL\\n-MD -MQ src/backend/utils/activity/wait_event_names.a.p/wait_event.c.o\\n-MF src/backend/utils/activity/wait_event_names.a.p/wait_event.c.o.d\\n-o src/backend/utils/activity/wait_event_names.a.p/wait_event.c.o -c\\n../pgsql/src/backend/utils/activity/wait_event.c\\",\\n\\nwhich happens because of:\\n\\nwait_event = static_library('wait_event_names',\\n  waitevent_sources,\\n  dependencies: [backend_code],\\n  include_directories: include_directories('../../../include/utils'),\\n  kwargs: internal_lib_args,\\n)\\n\\nwhich happens because wait_event_funcs.c contains:\\n\\n#include \\"wait_event_funcs_data.c\\"\\n\\nand for some reason, that file gets placed in src/include/utils.\\n\\nThe attached patch, which also adjusts wait_events.c, fixes it for me.\\n\\nThis is kind of a good example of how you are not pursuing your goals\\nhere in the best way possible. The issue here is legitimate, in the\\nsense that including src/include/utils in the include path for some\\nfile doesn't seem legit to me. But fixing that problem by defining,\\njust on AIX, the same symbol that the system header defines seems like\\nclearly the wrong fix. What if we needed to include the actual float.h\\nsomewhere? What if the problem also occurred on some other platform?\\nPlease put a bit more thought into the right ways to (1) describe the\\nthings you find to us and (2) fix them.\\n\\nThanks,\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n"},{"id":"19c05609aebece68","threadId":"19be67781ef21b94","snippet":"On 2026-Jan-28, Aditya Kamath wrote: > Below is the error message we get in AIX if we do not use '-D_H_FLOAT' > FAILED: src/backend/utils/activity/wait_event_names.ap/wait_event_funcs.co","historyId":"34836","internalDate":"1769615687000","receivedAtUtc":"2026-01-28T15:54:47.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>","subject":"Re: AIX support","messageId":"<202601281533.bq3epjmozbjc@alvherre.pgsql>","body":"On 2026-Jan-28, Aditya Kamath wrote:\\n\\n> Below is the error message we get in AIX if we do not use '-D_H_FLOAT’\\n> FAILED: src/backend/utils/activity/wait_event_names.a.p/wait_event_funcs.c.o\\n> gcc -Isrc/backend/utils/activity/wait_event_names.a.p -Isrc/include/utils -I../src/include/utils -Isrc/include -I../src/include -I/opt/freeware/include -I/opt/freeware/include/libxml2 -fdiagnostics-color=always -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -O2 -g -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wmissing-prototypes -Wpointer-arith -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wshadow=compatible-local -Wformat-security -Wdeclaration-after-statement -Wno-format-truncation -Wno-stringop-truncation -maix64 -fPIC -pthread -DBUILDING_DLL1233 -MD -MQ\\n> ./src/include/utils/float.h:28:19: error: expected ';' before 'int'\\n>    28 | extern PGDLLIMPORT int extra_float_digits;\\n\\nThis makes no sense to me.\\n\\n> There is a clear missing of float.h definitions, the reason being\\n> float.h got included before \\"src/include/c.h”.\\n\\nWe have a rule that postgres.h must always go first in all our backend\\nsource files, and wait_event_funcs.c is no exception.  This file\\nincludes postgres.h before anything else; and postgres.h in turns\\nincludes c.h before anything else.  So the claim that \\"float.h\\" got\\nsomehow included before c.h is not easy to believe.  Also,\\nwait_event_funcs.c does not include \\"float.h\\".\\n\\nNote also that we don't have all that many places that include\\n<float.h>.  So why is float.h being included by wait_event_names.c?\\n\\n> Kindly observe the command  \\"-I../src/include/utils” flag came in the front.\\n\\nThis only means that if your source code asks for any files to be\\nincluded, they will be sought there.  It does not imply to actually\\ninclude any files.\\n\\nMaybe you can post the output of doing \\"gcc -E\\" for the file where this\\nbreaks in your system (without the -D_FLOAT_H of course), that is the\\noutput of the C preprocessor, to try to understand what it is doing.\\n\\n... Oh, I see now that gcc's manpage says there's a distinction between\\n-I and -iquote:\\n\\n       -I dir\\n       -iquote dir\\n           [...]\\n           Directories  specified  with  -iquote apply only to the\\n           quote  form  of   the   directive,   \\"#include \\"file\\"\\".\\n           Directories  specified with -I, -isystem, or -idirafter\\n           apply to lookup  for  both  the  \\"#include \\"file\\"\\"  and\\n           \\"#include <file>\\" directives.\\n\\n-- \\nÁlvaro Herrera               48°01'N 7°57'E  —  https://www.EnterpriseDB.com/\\n\\"Thou shalt not follow the NULL pointer, for chaos and madness await\\nthee at its end.\\" (2nd Commandment for C programmers)\\n\\n\\n"},{"id":"19c05aaad9a1d7bd","threadId":"19be67781ef21b94","snippet":"Hi, On 2026-01-28 10:41:52 -0500, Robert Haas wrote: > On Wed, Jan 28, 2026 at 10:20 AM Aditya Kamath <Aditya.Kamath1@ibm.com> wrote: > > But here is the catch. It won't pick the AIX","historyId":"35194","internalDate":"1769621581000","receivedAtUtc":"2026-01-28T17:33:01.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: AIX support","messageId":"<vua2n6svb6fac3fmz42ahqxndmgbgor7vpxtemis5evasfpzb3@ogs4ewexkpjm>","body":"Hi,\\n\\nOn 2026-01-28 10:41:52 -0500, Robert Haas wrote:\\n> On Wed, Jan 28, 2026 at 10:20 AM Aditya Kamath <Aditya.Kamath1@ibm.com> wrote:\\n> > But here is the catch. It won’t pick the AIX system float.h. It will pick the Postgres \\"src/include/utilsfloat.h”.\\n>\\n> PostgreSQL's header should always be included as \\"utils/float.h\\" and\\n> the system header should always be included as \\"float.h\\" (or, well,\\n> <float.h>, presumably). So this confusion should not exist unless the\\n> include paths are messed up. It doesn't seem correct to me that the\\n> include path includes src/include/utils rather than just src/include,\\n> but I see the same thing here:\\n\\nI agree that this is wrong.\\n\\nCCing Michael and Bertrand, they added this in fa88928470b5 and 1e68e43d3f0f.\\n\\n\\n> which happens because of:\\n>\\n> wait_event = static_library('wait_event_names',\\n>   waitevent_sources,\\n>   dependencies: [backend_code],\\n>   include_directories: include_directories('../../../include/utils'),\\n>   kwargs: internal_lib_args,\\n> )\\n>\\n> which happens because wait_event_funcs.c contains:\\n>\\n> #include \\"wait_event_funcs_data.c\\"\\n>\\n> and for some reason, that file gets placed in src/include/utils.\\n\\nThe reason for that is that the same invocation also generates\\nwait_event_types.h, which is included by other headers.\\n\\n\\n> The attached patch, which also adjusts wait_events.c, fixes it for me.\\n\\nUnfortunately I suspect that'll cause issues with make builds, because there\\nthe files are generated in a different place (src/backend/activity) and then\\nonly wait_event_types.h is copied to src/include. So including the files as\\nutils/ won't work.\\n\\n\\nI'd fix that aspect by doing the same thing in the autoconf build as we do in\\nmeson, i.e. keep the file in the include dir. We already do that e.g. for\\nguc_tables.inc.c, see this src/backend/utils/Makefile stanza:\\n\\n# These generated headers must be symlinked into src/include/.\\n# We use header-stamp to record that we've done this because the symlinks\\n# themselves may appear older than fmgr-stamp.\\n$(top_builddir)/src/include/utils/header-stamp: fmgr-stamp errcodes.h probes.h guc_tables.inc.c\\n\\tcd '$(dir $@)' && for file in fmgroids.h fmgrprotos.h errcodes.h probes.h guc_tables.inc.c; do \\\\\\n\\t  rm -f $$file && $(LN_S) \\"../../../$(subdir)/$$file\\" . ; \\\\\\n\\tdone\\n\\ttouch $@\\n\\n\\nAlternatively: I'm not a fan of including .c files that are not actually\\nworking C.  You could just make wait_event_funcs_data.c be a complete C file,\\ndefining waitEventData, that is then built as a standalone file.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n\\n"}]	The PostgreSQL team is reviewing a patch set for AIX support. IBM developers Aditya Kamath and Srirama Kucherlapati are facing criticism from core developers Andres Freund and Robert Haas regarding patch quality. Key issues include missing files (mkldexport.sh), inconsistent testing, and problematic solutions like using `-D_H_FLOAT` to resolve header inclusion conflicts.\n\nThe primary technical issue involves header ordering problems on AIX where PostgreSQL's `utils/float.h` gets included before `c.h`, causing compilation failures. The IBM team's proposed `-D_H_FLOAT` solution prevents system float.h inclusion, but reviewers consider this approach incorrect.\n\nRobert Haas identified that the root cause stems from meson incorrectly adding `-I../src/include/utils` to include paths for wait_event compilation, which shouldn't happen. He proposed a cleaner fix by adjusting the build configuration. Álvaro Herrera questioned the technical explanation, suggesting the problem description doesn't align with PostgreSQL's include practices.\n\nAndres Freund emphasized that this represents a broader meson build system issue rather than an AIX-specific problem. The discussion remains unresolved, with reviewers expecting higher-quality patches and cleaner architectural solutions from the IBM team.	2026-01-28 17:33:01+00	PostgreSQL团队正在审查AIX支持的补丁集。IBM开发者Aditya Kamath和Srirama Kucherlapati因补丁质量问题受到核心开发者Andres Freund和Robert Haas的批评。关键问题包括缺失文件(mkldexport.sh)、测试不一致，以及使用`-D_H_FLOAT`解决头文件包含冲突等有问题的解决方案。\n\n主要技术问题涉及AIX上的头文件顺序问题，PostgreSQL的`utils/float.h`在`c.h`之前被包含，导致编译失败。IBM团队提出的`-D_H_FLOAT`解决方案阻止系统float.h包含，但审查者认为这种方法不正确。\n\nRobert Haas识别出根本原因源于meson错误地为wait_event编译添加了`-I../src/include/utils`到包含路径，这不应该发生。他提出了通过调整构建配置的更清洁修复方案。Álvaro Herrera质疑技术解释，认为问题描述与PostgreSQL的包含实践不符。\n\nAndres Freund强调这代表的是更广泛的meson构建系统问题，而不是AIX特定问题。讨论仍未解决，审查者期望IBM团队提供更高质量的补丁和更清洁的架构解决方案。
33	19c06f613dba8d54	Document NULL	["alvherre@kurilemu.de","david.g.johnston@gmail.com","dgrowleyml@gmail.com","jian.universality@gmail.com","marcos@f10.com.br","nagata@sraoss.co.jp","peter@eisentraut.org","pgsql@j-davis.com","tgl@sss.pgh.pa.us"]	[{"id":"19c06f613dba8d54","threadId":"19c06f613dba8d54","snippet":"On Tue, Jan 6, 2026 at 12:11 PM Marcos Pegoraro <marcos@f10.com.br> wrote: Em ter., 11 de nov. de 2025 às 12:34, Álvaro Herrera <alvherre@kurilemu.de> escreveu: I have rebased this;","historyId":"36663","internalDate":"1769643261000","receivedAtUtc":"2026-01-28T23:34:21.000Z","from":"\\"David G. Johnston\\" <david.g.johnston@gmail.com>","subject":"Re: Document NULL","messageId":"<CAKFQuwaULsfcG=9JmuGO7VXvTOH8hxsuGhwq2zASAYi48SmfRA@mail.gmail.com>","body":"On Tue, Jan 6, 2026 at 12:11 PM Marcos Pegoraro <marcos@f10.com.br> wrote:\\n\\n> Em ter., 11 de nov. de 2025 às 12:34, Álvaro Herrera <alvherre@kurilemu.de>\\n> escreveu:\\n>\\n>> I have rebased this; here's v9.  I haven't reviewed it in depth, but\\n>> intend to give it a read and get it pushed sometime in the\\n>> not-too-distant future, so if anybody wants to review it some more, it'd\\n>> be appreciated.\\n>>\\n>\\n> - Reading this document I see that he uses \\"the empty string\\" but DOCs\\n> uses more \\"an empty string\\".\\n> Then a few minutes ago I sent a patch [1] to use \\"an empty string\\" instead\\n> of \\"the empty string\\".\\n> If that patch is accepted then this could be done here too.\\n>\\n\\nThat patch probably isn't going in and the two phrasing do tend to denote\\ndifferent things even if being correct is hard.  I made a couple of tweaks\\nbut in any case either wording tends to adequately convey the necessary\\nmeaning.\\n\\n\\n> - I think using several commands and their results in a <programlisting>\\n> is difficult to read,\\n> mainly because some commands result on 2 or more lines, some an empty\\n> line,\\n> so it is difficult to see what command generated what result. Maybe\\n> separate them into 2 blocks, maybe.\\n>\\n>\\n\\nI decided to do manual inline comments in the output where it seemed\\nnecessary.  Let's see how that plays out.\\n\\nVersion 10 attached as a single patch (just needs a commit message)\\n\\nI brought the introductory paragraph current.\\nNotably, I went with \\"Null\\" as the \\\\pset display null value instead of \\\\N\\n(find-replace and fixes, did not re-run commands in psql, looks correct\\nthough and it is fairly mechanical).\\n\\nDavid J.\\n"}]	David G. Johnston provided version 10 of a documentation patch about NULL handling in PostgreSQL. The patch addresses feedback from Marcos Pegoraro regarding terminology consistency, specifically the use of "an empty string" versus "the empty string" in documentation. Johnston noted that a related patch for this terminology change probably won't be accepted, as both phrasings convey different meanings appropriately. He addressed readability concerns about programlisting blocks containing multiple commands and results by adding manual inline comments where necessary. The updated patch includes a current introductory paragraph and uses "Null" as the \\pset display null value instead of \\N. The patch is ready for commit and awaits a commit message.	2026-01-28 23:34:21+00	David G. Johnston提供了关于PostgreSQL中NULL处理的文档补丁第10版。该补丁解决了Marcos Pegoraro关于术语一致性的反馈，特别是文档中使用"an empty string"与"the empty string"的问题。Johnston指出相关的术语更改补丁可能不会被接受，因为两种表述都能适当地传达不同的含义。他通过在必要时添加手动内联注释来解决关于programlisting块包含多个命令和结果的可读性问题。更新的补丁包含当前的介绍段落，并使用"Null"作为\\pset显示null值而不是\\N。该补丁已准备好提交，等待提交消息。
33	19bed67824d1f608	eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)	["andres@anarazel.de","hlinnaka@iki.fi","li.evan.chao@gmail.com","melanieplageman@gmail.com","reshkekirill@gmail.com","robertmhaas@gmail.com","x4mmm@yandex-team.ru","xunengzhou@gmail.com"]	[{"id":"19c06e538603a4eb","threadId":"19bed67824d1f608","snippet":"Thanks for the review! I pushed v33 0001-0003 after incorporating your feedback. On Fri, Jan 23, 2026 at 7:28 PM Andres Freund <andres@anarazel.de> wrote: > > On 2026-01-06 12:31:57 -0500,","historyId":"36562","internalDate":"1769642170000","receivedAtUtc":"2026-01-28T23:16:10.000Z","from":"Melanie Plageman <melanieplageman@gmail.com>","subject":"Re: eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)","messageId":"<CAAKRu_bs+gZ83QDacmBxunPvCGnXJ05hxP2BDPJ3BGwdbGRXzg@mail.gmail.com>","body":"Thanks for the review!\\nI pushed v33 0001-0003 after incorporating your feedback.\\n\\nOn Fri, Jan 23, 2026 at 7:28 PM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> On 2026-01-06 12:31:57 -0500, Melanie Plageman wrote:\\n>\\n> > +      */\\n> > +     if ((old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n> > +     {\\n> > +             vacrel->vm_new_visible_pages++;\\n> > +             if (presult.all_frozen)\\n> > +             {\\n> > +                     vacrel->vm_new_visible_frozen_pages++;\\n> > +                     *vm_page_frozen = true;\\n>\\n> Not this patches fault, but I find \\"vm_new_visible_pages\\" and\\n> \\"vm_new_visible_frozen_pages\\" pretty odd names. The concept is all-visible and\\n> frozen. The page itself isn't visible or invisible...\\n\\nI thought having the extra word \\"all\\" in there made it too long. And\\nsince \\"vm\\" is there, that isn't set unless the page is\\n_all_-visible/all-frozen. But if you think it gives people the wrong\\nidea, I am willing to change it. I can omit vm and make it:\\nnew_all_visible_all_frozen_pages\\nnew_all_visible_pages\\nnew_all_frozen_pages\\n\\nIs that clearer?\\n\\n> > From 5c65e73246b4968ddfa9d3739f53d0d8734b8727 Mon Sep 17 00:00:00 2001\\n> > From: Melanie Plageman <melanieplageman@gmail.com>\\n> > Date: Tue, 2 Dec 2025 15:07:42 -0500\\n> > Subject: [PATCH v33 04/16] Set the VM in heap_page_prune_and_freeze()\\n> >\\n> > This has no independent benefit. It is meant for ease of review. As of\\n> > this commit, there is still a separate WAL record emitted for setting\\n> > the VM after pruning and freezing. But it is easier to review if moving\\n> > the logic into pruneheap.c is separate from setting the VM in the same\\n> > WAL record.\\n>\\n> It seems a bit noisy to refactor the related code in some of the preceding\\n> commits and then refactor it into a slightly different shape as part of this\\n> commit (c.f. heap_page_will_set_vm()).\\n\\nI understand what you are saying. I don't see a good way to keep it\\nreviewable otherwise, though.\\n\\n> It's also a bit odd that a function that sounds rather read-only does stuff\\n> like clearing VM/all-visible.\\n\\nI thought about this a lot. Ultimately, I ended up keeping it the way it is.\\nI think the other option is changing from this:\\n\\n    do_set_vm = heap_page_will_set_vm(&prstate,\\n                                      params->relation,\\n                                      blockno, buffer, page,\\n                                      vmbuffer,\\n                                      params->reason,\\n                                      do_prune, do_freeze,\\n                                      prstate.lpdead_items,\\n                                      &old_vmbits, &new_vmbits);\\n\\nto this:\\n\\n    heap_page_prepare_vm_set(&prstate,\\n                                params->relation,\\n                                blockno, buffer, page,\\n                                vmbuffer,\\n                                params->reason,\\n                                do_prune, do_freeze,\\n                                prstate.lpdead_items,\\n                                &old_vmbits, &new_vmbits);\\n\\n    do_set_vm = (new_vmbits & VISIBILITYMAP_VALID_BITS) != 0;\\n\\nor heap_page_plan_vm_set()\\n\\nheap_page_will_set_vm() has symmetry with heap_page_will_freeze(), the\\nhelper that decides whether or not we will freeze tuples. I like that\\nsymmetry since heap_page_will_set_vm() decides whether or not to set\\nthe VM.\\n\\nNow, heap_page_plan/prepare_vm_set() does indirectly hint that\\nsomething like clearing VM/all-visible could happen -- if you\\nunderstand that preparing the VM to have bits set also includes\\nclearing any existing corruption. And \\"prepare\\" or \\"plan\\" has more\\nsymmetry with prune_freeze_plan() -- though that function does not\\nmake changes on the page.\\n\\nUltimately, clearing the VM/page of corruption is pretty anomalous\\nfrom the rest of the code in heap_page_prune_and_freeze(). All other\\nchanges to the page are done in a single critical section at the\\nbottom of the function.\\n\\nI could see an argument for moving identify_and_fix_vm_corruption()\\nout of the helper and into heap_page_prune_and_freeze() but then we'd\\nhave to move visibilitymap_get_status() out too. And that takes away a\\nlot of the benefit of encapsulating all that logic.\\n\\nUltimately, I don't like any of those alternative structures. But if\\nyou prefer the names and return value change I have above\\n(heap_page_prepare/plan_vm_set()), I'm fine with going with that.\\n\\n> Why are we not doing fixing up of the page *before* we prune it?  It's a bit\\n> insane that we do the WAL logging for pruning, which in turn will often\\n> include an FPI, before we do the fixups. The fixes aren't WAL logged, so this\\n> actually leads to the standby getting further out of sync.\\n>\\n> I realize this isn't your mess, but brrr.\\n\\nWell, after this patch set, clearing the VM does happen before we emit\\nWAL for pruning. It wouldn't be hard to move the corruption fixups to\\nthe beginning of heap_page_prune_and_freeze() in the new code\\nstructure. But it would split visibility map-related logic into two\\nparts of heap_page_prune_and_freeze(). Would it be worth it? What\\nbenefit would we get? Do you just feel that it should logically come\\nfirst?\\n\\n> Do we actually forsee a case where only one of HEAP_PAGE_PRUNE_FREEZE |\\n> HEAP_PAGE_PRUNE_UPDATE_VM would be set?\\n\\nYes, when setting the VM on-access, it is too expensive to call\\nheap_prepare_freeze_tuple() on each tuple. I could work on trying to\\noptimize it, but it isn't currently viable.\\n\\n> > -     if ((old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0)\\n> > +     if ((presult.old_vmbits & VISIBILITYMAP_ALL_VISIBLE) == 0 &&\\n> > +             (presult.new_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0)\\n> >       {\\n> >               vacrel->vm_new_visible_pages++;\\n> > -             if (presult.all_frozen)\\n> > +             if ((presult.new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n> >               {\\n> >                       vacrel->vm_new_visible_frozen_pages++;\\n> >                       *vm_page_frozen = true;\\n> >               }\\n> >       }\\n> > -     else if ((old_vmbits & VISIBILITYMAP_ALL_FROZEN) == 0 &&\\n> > -                      presult.all_frozen)\\n> > +     else if ((presult.old_vmbits & VISIBILITYMAP_ALL_FROZEN) == 0 &&\\n> > +                      (presult.new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n> >       {\\n> > +             Assert((presult.new_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0);\\n> >               vacrel->vm_new_frozen_pages++;\\n> >               *vm_page_frozen = true;\\n> >       }\\n>\\n> It's a bit odd that we figure out all of this by inspecting old/new vmbits and\\n> have that logic in multiple places.\\n\\nI changed PruneFreezeResult to have just the counters that have to be\\nreflected in vacrel for logging (vm_new_frozen_pages, etc) instead of\\npassing the bits back.\\n\\n> > Subject: [PATCH v33 05/16] Move VM assert into prune/freeze code\\n>\\n> Feels like a somewhat too narrow description, given that it changes the API\\n> for heap_page_prune_and_freeze() by removing variables from PruneFreezeResult.\\n\\nI've tried to fix this.\\n\\n> > +/*\\n> > + * Wrapper for heap_page_would_be_all_visible() which can be used for callers\\n> > + * that expect no LP_DEAD on the page. Currently assert-only, but there is no\\n> > + * reason not to use it outside of asserts.\\n> > + */\\n>\\n> If so, why would we want it in pruneheap.c? Seems a bit odd to have\\n> heap_page_would_be_all_visible() defined in vacuumlazy.c but defined\\n> heap_page_is_all_visible() in pruneheap.c.\\n\\nYou're right. I've kept them both in vacuumlazy.c\\n\\n> > From cdf5776fadeae3430c692999b37f8a7ec944bda1 Mon Sep 17 00:00:00 2001\\n> > From: Melanie Plageman <melanieplageman@gmail.com>\\n> > Date: Tue, 2 Dec 2025 16:16:22 -0500\\n\\n> > +static TransactionId\\n> > +get_conflict_xid(bool do_prune, bool do_freeze, bool do_set_vm,\\n> > +                              uint8 old_vmbits, uint8 new_vmbits,\\n> > +                              TransactionId latest_xid_removed, TransactionId frz_conflict_horizon,\\n> > +                              TransactionId visibility_cutoff_xid)\\n> > +{\\n>\\n> The logic for horizons is now split between this and \\"Calculate what the\\n> snapshot conflict horizon should be for a record\\" in heap_page_will_freeze().\\n\\nThat is true in master too. We determine frz_conflict_horizon in\\nheap_page_will_freeze() and later before emitting the WAL record\\ndecide which of the latest_xid_removed and frz_conflict_horizon that\\nwe should use as the snapshot conflict horizon for the combined\\nrecord.\\n\\nAll I've done is expand that part (the part before emitting the WAL\\nrecord) a bit because now we have to consider what the horizon would\\nbe if we set the VM.\\n\\nIf I really wanted to calculate it only in a single place, I could\\nmaintain a new variable, all_frozen_except_dead, and remove the\\nfrz_conflict_horizon from heap_page_will_freeze(). Then, in\\nget_conflict_xid(), I could have the following logic:\\n\\n    if (do_set_vm)\\n        conflict_xid = visibility_cutoff_xid;\\n    else if (do_freeze)\\n    {\\n        if (all_frozen_except_dead)\\n            conflict_xid = visibility_cutoff_xid;\\n        else\\n        {\\n            conflict_xid = OldestXmin;\\n            TransactionIdRetreat(conflict_xid);\\n        }\\n    }\\n    else\\n        conflict_xid = InvalidTransactionId;\\n\\nI think using all_frozen_except_dead while maintaining\\nvisibility_cutoff_xid (in heap_prune_record_unchanged_lp_normal()) has\\nthe potential to be confusing, though. We'd need to keep updating\\nvisibility_cutoff_xid when all_visible is false but\\nall_frozen_except_dead is true as well as when all_visible is true.\\nAnd because we don't care about all_visible_except_dead, it gets even\\nmore confusing to make sure we are maintaining the right variables in\\nthe right situations.\\n\\nAlternatively, we could keep maintenance of visibility_cutoff_xid the\\nsame and only use all_frozen_except_dead to avoid having the conflict\\nxid calculation in two places. We would just set it after\\nprune_freeze_plan() and use it the way it is in the snippet above. But\\nI don't know if this is better than just having a separate freeze\\nconflict horizon calculated in the will_freeze code. It is just as\\nconfusing to understand and just as many variables but in a different\\nplace.\\n\\nFor now, I've kept it as is.\\n\\n> Although I guess I don't understand that code:\\n>\\n>                 /*\\n>                  * Calculate what the snapshot conflict horizon should be for a record\\n>                  * freezing tuples. We can use the visibility_cutoff_xid as our cutoff\\n>                  * for conflicts when the whole page is eligible to become all-frozen\\n>                  * in the VM once we're done with it. Otherwise, we generate a\\n>                  * conservative cutoff by stepping back from OldestXmin.\\n>                  */\\n>                 if (prstate->all_frozen)\\n>                         prstate->frz_conflict_horizon = prstate->visibility_cutoff_xid;\\n>                 else\\n>                 {\\n>                         /* Avoids false conflicts when hot_standby_feedback in use */\\n>                         prstate->frz_conflict_horizon = prstate->cutoffs->OldestXmin;\\n>                         TransactionIdRetreat(prstate->frz_conflict_horizon);\\n>                 }\\n>\\n> Why does it make sense to use OldestXmin? Consider e.g. the case where there\\n> is one very old tuple that needs to be frozen and one new live tuple on a\\n> page. Because of the new tuple we can't mark the page all-frozen. But there's\\n> also no reason to not use much less aggressive horizon than OldestXmin, namely\\n> the newer of xmin,xmax of the old frozen tuple?\\n\\nWe don't track the newest frozen xmin right now. Doing so wouldn't be\\nfree (i.e. more comparisons which may matter in a query without much\\nother overhead). And we can't get rid of any of the other cutoffs we\\ntrack. We'd still need to maintain the visibility_cutoff_xid and\\nlatest_removed_xid. Which also means it doesn't simplify the code.\\n\\nThe only purpose it would serve is to make the snapshot conflict\\nhorizon more accurate/more aggressive when we freeze tuples, which\\nwould lead to canceling less queries than master -- which is outside\\nthe purview of this patch. There's also a set of complications around\\nmaintaining this number accurately mentioned by Peter in [1].\\n\\nI've added a new patch in the series 0001 that expands the comment\\nabout this in heap_page_will_freeze() and describes that we are using\\na coarse cutoff because we don't track anything else.\\n\\nBut I don't think changing this behavior is a blocker for this feature.\\n\\n> I also don't understand what the \\"false conflicts\\" thing is referencing.\\n\\nYea, neither do I. I ported that comment over (it's from before I\\nstarted modifying this code) and have never really understood what it\\nmeant -- wouldn't we have more false conflicts if we use a newer\\ncutoff? (because OldestXmin will be newer than visibility_cutoff_xid).\\nIf the page isn't all-visible, we won't maintain\\nvisibility_cutoff_xid. But if we did actually track the newest live\\ntuple xmin on the page, that could very well be newer than OldestXmin\\nand thus using OldestXmin would cancel less and avoid more false\\nconflicts. But that feels like a _very_ big stretch (in a hypothetical\\nworld that doesn't exist). Anyway, I've deleted the comment (in 0001)\\nsince it clearly is not adding value.\\n\\n> > +     TransactionId conflict_xid;\\n> > +\\n> > +     /*\\n> > +      * We can omit the snapshot conflict horizon if we are not pruning or\\n> > +      * freezing any tuples and are setting an already all-visible page\\n> > +      * all-frozen in the VM. In this case, all of the tuples on the page must\\n> > +      * already be visible to all MVCC snapshots on the standby.\\n> > +      */\\n>\\n> The last sentence here is a bit confusing, because they don't just need to\\n> already be visible to everyone, they already need to be frozen. Right?\\n\\nRight. Well that also means that all tuples are visible to all MVCC\\nsnapshots on the standby too -- I picked that language up from\\nsomewhere else in the code and thought it sounded good. But I've\\nedited it to say frozen, which is more accurate.\\n\\n> > +     if (!do_prune &&\\n> > +             !do_freeze &&\\n> > +             do_set_vm &&\\n>\\n> I'm confused by the do_set_vm check here. Doesn't it mean that we will *not*\\n> return InvalidTransactionId if !prstate->attempt_update_vm?  I don't undestand\\n> why that would make sense.\\n>\\n> I guess we'll compute a bogus cutoff in that cse, but never use it, since\\n> we'll also not emit WAL?  Or maybe we'll just unnecessarily go through the\\n> code below, because the code turns out to do ok regardles?  It's confusing\\n> either way.\\n\\nAh no, that was a relic from when I didn't clear the new vmbits in the\\nevent that they were the same as old_vmbits. Now that I do that, I\\ndon't need to qualify it with do_set_vm anymore. I've fixed that.\\n\\n> > +             (old_vmbits & VISIBILITYMAP_ALL_VISIBLE) != 0 &&\\n> > +             (new_vmbits & VISIBILITYMAP_ALL_FROZEN) != 0)\\n>\\n> I wonder if some of this code would end up cleaner if we tracked the bits we\\n> intend to add, rather than the target set of bits is.\\n\\nI played around with this idea. Unfortunately, this specific check\\nwouldn't be much simpler, as I'd have to check that _only_ the\\nall-frozen bit is set. And I think that it is probably more clear with\\nexplicit old and new vmbits. Those make it clear that we are setting a\\nformerly all-visible page all-frozen.\\n\\nIn some of the other places where I use old/new vmbits, I tried only\\nusing the delta/bits that need to be newly set. But, for example, in\\nvisibilitymap_set(), I need both the all-visible and all-frozen bits\\nto be passed (even if all-visible is already set), because it asserts\\nthat if all-frozen is passed both all-visible and all-frozen are\\npassed. If I only keep track of the new bits that need to be set, I\\nwould require other logic before visibilitymap_set(). And it makes\\nsense that visibilitymap_set() requires both because you don't ever\\nwant people setting just all-frozen -- and you don't want the API to\\nmake it easy to do that.\\n\\n> > +     /*\\n> > +      * If we are updating the VM, the conflict horizon is almost always the\\n> > +      * visibility cutoff XID.\\n> > +      *\\n> > +      * Separately, if we are freezing any tuples, as an optimization, we can\\n> > +      * use the visibility_cutoff_xid as the conflict horizon if the page will\\n> > +      * be all-frozen.\\n>\\n> What does \\"as an optimization\\" mean here?\\n\\nWhat I meant was that visibility_cutoff_xid is going to be older than\\nOldestXmin for an all-frozen page, so it will lead to canceling fewer\\nqueries. So, using it is kind of an \\"optimization\\". But I re-read that\\ncomment and it was way too confusing. I actually cut that whole\\nparagraph because it should be discussed in heap_page_will_freeze()\\nwhere we are actually handling it.\\n\\n> Note that the code actually uses visibility_cutoff_xid even if the page is\\n> just marked all-visible, but not all-frozen (due to the do_set_vm check being\\n> earlier)\\n\\nAnd that is correct. But the comment (which is now removed) was\\nmisleading, you are right.\\n\\n> > This is true even if there are LP_DEAD line pointers\\n> > +      * because we ignored those when maintaining the visibility_cutoff_xid.\\n>\\n> I must just be missing something because I can't follow this at all.  I guess\\n> it could be correct because we later then add in knowledge of removed xids in\\n> via the TransactionIdFollows check below? But if that's it, this is extremely\\n> confusingly worded.\\n\\nYes, we add in latest_xid_removed which is what makes it correct. But\\nI agree that the wording was terrible. I've cut those details from\\nget_conflict_xid() and kept them where they are relevant in\\nheap_page_will_freeze().\\n\\n- Melanie\\n\\n[1] https://www.postgresql.org/message-id/CAH2-WzkB-Pt3zPeTXvMik6jcJn%2BdcpUqO-tt_hc13bD6sGRLPg%40mail.gmail.com\\n"}]	Melanie Plageman responded to Andres Freund's review of v33 patches 0001-0003 for eliminating xl_heap_visible WAL records. The discussion covers several technical concerns: variable naming consistency (suggesting "new_all_visible_pages" vs "vm_new_visible_pages"), function naming clarity for heap_page_will_set_vm() which performs side effects like clearing VM corruption, and the timing of corruption fixes relative to WAL logging. Andres questioned the logic for snapshot conflict horizons, particularly why OldestXmin is used when freezing non-all-frozen pages instead of tracking newer frozen tuple xmins. Melanie explained this would require additional overhead without simplifying existing code. She addressed API changes, clarified that HEAP_PAGE_PRUNE_FREEZE and HEAP_PAGE_PRUNE_UPDATE_VM flags serve different purposes (the latter for expensive on-access VM setting), and improved comment clarity around conflict horizon calculations. The patch series aims to reduce WAL volume by combining VM updates with pruning/freezing operations rather than using separate xl_heap_visible records.	2026-01-28 23:16:10+00	Melanie Plageman回应了Andres Freund对v33补丁0001-0003的审查，该补丁旨在消除xl_heap_visible WAL记录。讨论涵盖了几个技术问题：变量命名一致性（建议使用"new_all_visible_pages"而非"vm_new_visible_pages"），函数heap_page_will_set_vm()的命名清晰度（该函数执行清除VM损坏等副作用），以及损坏修复相对于WAL日志记录的时序。Andres质疑快照冲突范围的逻辑，特别是为什么在冻结非全冻结页面时使用OldestXmin而不是跟踪更新的冻结元组xmin。Melanie解释这需要额外开销而不会简化现有代码。她处理了API更改，澄清了HEAP_PAGE_PRUNE_FREEZE和HEAP_PAGE_PRUNE_UPDATE_VM标志服务于不同目的（后者用于昂贵的访问时VM设置），并改进了冲突范围计算相关注释的清晰度。该补丁系列旨在通过将VM更新与剪枝/冻结操作结合而不是使用单独的xl_heap_visible记录来减少WAL量。
33	19bea7defb8a17b6	Proposal: Conflict log history table for Logical Replication	["amit.kapila16@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","sawada.mshk@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19c02cee34168c40","threadId":"19bea7defb8a17b6","snippet":"Some review comments for the v25* patches: ////////// Patch v25-0001 ////////// 1. + /* + * Conflict log tables are managed by the system to record logical + * replication conflicts. We do not allow","historyId":"31653","internalDate":"1769573601000","receivedAtUtc":"2026-01-28T04:13:21.000Z","from":"Peter Smith <smithpb2250@gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","messageId":"<CAHut+Psbygz+QOLOBX5ByqE_dg4bERCO2mASBe9i_Z4qfA8bYA@mail.gmail.com>","body":"Some review comments for the v25* patches:\\n\\n//////////\\nPatch v25-0001\\n//////////\\n\\n1.\\n+ /*\\n+ * Conflict log tables are managed by the system to record logical\\n+ * replication conflicts.  We do not allow locking rows in CONFLICT\\n+ * relations.\\n+ */\\n+ if (IsConflictNamespace(RelationGetNamespace(rel)))\\n+ ereport(ERROR,\\n+ (errcode(ERRCODE_WRONG_OBJECT_TYPE),\\n+ errmsg(\\"cannot lock rows in conflict log table \\\\\\"%s\\\\\\"\\",\\n+ RelationGetRelationName(rel))));\\n\\n\\nI felt the code comment should be changed, too.\\n\\ne.g. That comment sentence \\"We do not allow locking rows in CONFLICT\\nrelations\\" seemed redundant because you already said the CLT is\\n\\"managed by the system\\", and also it is basically just repeating the\\nsame info as the error message.\\n\\nSuggest either:\\na) remove it, or\\nb) change /CONFLICT/pg_conflict namespace/\\n\\n//////////\\nPatch v25-0002\\n//////////\\n\\nNo review comments.\\n\\n//////////\\nPatch v25-0003 (docs)\\n//////////\\n\\n======\\ndoc/src/sgml/logical-replication.sgml\\n\\n(29.8 Conflicts)\\n\\n1.\\nThere is an earlier sentence on this page:\\n\\"Note that there are other conflict scenarios, such as exclusion\\nconstraint violations. Currently, we do not provide additional details\\nfor them in the log.\\"\\n\\n~\\n\\nThat \\"in the log part\\" wording maybe needs to be changed/removed now\\nbecause the destination might be a CLT, not a log.\\n\\nSUGGESTION:\\nCurrently, we do not provide additional details for them.\\n\\n~~~\\n\\n2.\\n   <para>\\n-   The log format for logical replication conflicts is as follows:\\n+   The <link linkend=\\"sql-createsubscription-params-with-conflict-log-destination\\"><literal>conflict_log_destination</literal></link>\\n+   parameter can automatically creates a dedicated conflict log\\ntable.  This table is created in the dedicated\\n+   <literal>pg_conflict</literal> namespace.  The name of the\\nconflict log table\\n+   is <literal>pg_conflict_&lt;subid&gt;</literal>. The predefined\\nschema of this table is\\n+   detailed in\\n+   <xref linkend=\\"logical-replication-conflict-log-schema\\"/>.\\n+  </para>\\n+\\n\\n2a.\\nTypo: /can automatically creates/can automatically create/\\n\\n~\\n\\n2b.\\nIt sounds a bit strange to say \\"a dedicated\\" 2x in 2 sentences. Maybe\\nomit the first one:\\n\\nSUGGESTION\\n... can automatically create a conflict log table.\\n\\n~\\n\\n2c.\\nPerhaps the \\"conflict log table\\" should be using <firstterm> SGML markup here.\\n\\n~~~\\n\\n3.\\n+  <para>\\n+   The conflicting row data, including the incoming remote row\\n(<literal>remote_tuple</literal>)\\n+   and the associated local conflict details\\n(<literal>local_conflicts</literal>), is stored in\\n+   <type>JSON</type> formats, for flexible querying and analysis.\\n+  </para>\\n\\n/formats, for/format for/\\n\\n~~~\\n\\n4.\\n+  <para>\\n+   If <link linkend=\\"sql-createsubscription-params-with-conflict-log-destination\\"><literal>conflict_log_destination</literal></link>\\n+   is set to log conflicts to the server log, the following format is used:\\n\\nI'm not sure you need that link because the same parameter was already\\nlinked a bit earlier on this same page.\\n\\n~~~\\n\\n(29.9 Restrictions)\\n\\n5.\\n+   <listitem>\\n+    <para>\\n+     Conflict log tables (see <link\\nlinkend=\\"sql-createsubscription-params-with-conflict-log-destination\\"><literal>conflict_log_destination</literal></link>\\nparameter)\\n+     are never published, even when using FOR ALL TABLES in a publication.\\n+    </para>\\n+   </listitem>\\n\\nThat FOR ALL TABLES ought to have <literal> SGML markup.\\n\\n======\\ndoc/src/sgml/ref/create_subscription.sgml\\n\\n6.\\nI still feel that somewhere in here, there ought to be some link/s\\nback to the \\"29.8 Conflicts\\" details about the CLT schema and LOG\\nformats.\\n\\nSUGGESTION\\nconflict_log_destination / log: ... See <link> for the format used to\\nlog conflict details.\\n\\nconflict_log_destination / table: ... See <link> for the predefined\\nschema of the conflict log table.\\n\\n======\\nKind Regards,\\nPeter Smith.\\nFujitsu Australia\\n\\n\\n"},{"id":"19c047d58081e1f7","threadId":"19bea7defb8a17b6","snippet":"On Tue, Jan 27, 2026 at 9:24 AM Dilip Kumar <dilipbalaut@gmail.com> wrote: > > > Also fixed all pending doc comments. > Thanks for the patch, Please find a few comments: patch0001: 1)","historyId":"33580","internalDate":"1769601828000","receivedAtUtc":"2026-01-28T12:03:48.000Z","from":"shveta malik <shveta.malik@gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","messageId":"<CAJpy0uB6C6HfZcpDLFkywROGokdUZq0oX_EMhJz_gB17qaJmKw@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 9:24 AM Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n>\\n>\\n> Also fixed all pending doc comments.\\n>\\n\\nThanks for the patch, Please find a few comments:\\n\\npatch0001:\\n\\n1)\\n+/*\\n+ * GetLogDestination\\n+ *\\n+ * Convert string to enum by comparing against standardized labels.\\n+ */\\n+ConflictLogDest\\n+GetLogDestination(const char *dest)\\n\\nIMO the name of the function should be GetConflictLogDest, otherwise\\nthe current name might suggest it applies to all the logs related to\\nsubscription, which is misleading.\\n\\n2)\\n+ { .attname = \\"schemaname\\",       .atttypid = TEXTOID },\\n\\nI checked the catalog tables known to me which refer to namespace, all\\nuse namespace or nsp in their names, none use 'schema'. Examples:\\npg_namespace, pg_class, pg_type. pg_constraint.  Shall we use nspname\\ninstead?\\n\\n<No issues found in my local testing for 0001>\\n\\n~~\\n\\npatch0002:\\n\\n1)\\nconflict.c compiles without these:\\n\\n+#include \\"utils/fmgroids.h\\"\\n+#include \\"utils/json.h\\"\\n\\n2)\\n+ /*\\n+ * Get the conflict log destination. Also, (if there is one) return the\\n+ * CLT relation already opened and ready for insertion.\\n+ */\\n+ conflictlogrel = GetConflictLogDestAndTable(&dest);\\n\\n'CLT relation' means conflict log table relation. Shall we correct it\\nto mention either table alone or relation alone?\\n\\n3)\\nThis is defined in conflict.h:\\n\\n+/* The single source of truth for the conflict log table schema */\\n+static const ConflictLogColumnDef ConflictLogSchema[] =\\n+{\\n....\\n+ { .attname = \\"local_conflicts\\",  .atttypid = JSONARRAYOID }\\n+};\\n\\nwhile its element 'local_conflicts' is defined in conflict.c:\\n\\n+/* Schema for the elements within the 'local_conflicts' JSON array */\\n+static const ConflictLogColumnDef LocalConflictSchema[] =\\n+{\\n...\\n+};\\n\\nIt takes some time to figure this part out as a reader of code. I\\nthink we shall define LocalConflictSchema schema immediately after\\nConflictLogSchema for anyone to understand it better, unless there is\\nsomething blocking it?\\n\\n4)\\n+# Verify that '2' is present inside the JSON structure using a regex\\n+# This matches the key/value pattern for \\"a\\": 2\\n+like($raw_json, qr/\\\\\\\\\\"a\\\\\\\\\\":2/, 'Verified that key 2 exists in the\\nlocal_conflicts');\\n+\\n\\nReviewing further. Testing of 0002 yet to be finished.\\n\\nthanks\\nShveta\\n\\n\\n"},{"id":"19c04803e8815c30","threadId":"19bea7defb8a17b6","snippet":"On Wed, Jan 28, 2026 at 5:33 PM shveta malik <shveta.malik@gmail.com> wrote: > > > 4) > +# Verify that '2' is present inside the JSON structure using a regex > +# This","historyId":"33623","internalDate":"1769602016000","receivedAtUtc":"2026-01-28T12:06:56.000Z","from":"shveta malik <shveta.malik@gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","messageId":"<CAJpy0uC4a2SpBBO7cgiKdaEzYu9t7oQMsm9oVHtGaDOEkjta1g@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 5:33 PM shveta malik <shveta.malik@gmail.com> wrote:\\n>\\n>\\n> 4)\\n> +# Verify that '2' is present inside the JSON structure using a regex\\n> +# This matches the key/value pattern for \\"a\\": 2\\n> +like($raw_json, qr/\\\\\\\\\\"a\\\\\\\\\\":2/, 'Verified that key 2 exists in the\\n> local_conflicts');\\n> +\\n\\nOops, I missed adding my feedback for pt4 earlier, here it is:\\n\\nTo properly validate correctness, given that local_conflicts is an\\narray of multiple local tuple details here, we should also check that\\nit contains the keys b:3 and c:4.\\n\\nthanks\\nShveta\\n\\n\\n"},{"id":"19c066847b2c590b","threadId":"19bea7defb8a17b6","snippet":"On Wed, Jan 28, 2026 at 11:04 PM shveta malik <shveta.malik@gmail.com> wrote: > > patch0002: > ... > > 3) > This is defined in conflict.h: > > +/* The single source of","historyId":"36102","internalDate":"1769633985000","receivedAtUtc":"2026-01-28T20:59:45.000Z","from":"Peter Smith <smithpb2250@gmail.com>","subject":"Re: Proposal: Conflict log history table for Logical Replication","messageId":"<CAHut+Pv5ayMryrT+NJZd6=bcjmR_CaWr12Xkn00Jn+SSEW1FLg@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 11:04 PM shveta malik <shveta.malik@gmail.com> wrote:\\n>\\n\\n> patch0002:\\n>\\n...\\n>\\n> 3)\\n> This is defined in conflict.h:\\n>\\n> +/* The single source of truth for the conflict log table schema */\\n> +static const ConflictLogColumnDef ConflictLogSchema[] =\\n> +{\\n> ....\\n> + { .attname = \\"local_conflicts\\",  .atttypid = JSONARRAYOID }\\n> +};\\n>\\n> while its element 'local_conflicts' is defined in conflict.c:\\n>\\n> +/* Schema for the elements within the 'local_conflicts' JSON array */\\n> +static const ConflictLogColumnDef LocalConflictSchema[] =\\n> +{\\n> ...\\n> +};\\n>\\n> It takes some time to figure this part out as a reader of code. I\\n> think we shall define LocalConflictSchema schema immediately after\\n> ConflictLogSchema for anyone to understand it better, unless there is\\n> something blocking it?\\n>\\n\\n+1.\\n\\nI had asked for this same change last year [1 - #17]\\n\\n======\\n[1] https://www.postgresql.org/message-id/CAHut%2BPtSggpJH36YOwdfmY5gU6yr7Wa-%3Dreht4c2v%2Bn8FYUKJg%40mail.gmail.com\\n\\nKind Regards,\\nPeter Smith.\\nFujitsu Australia\\n\\n\\n"}]	Peter Smith provides detailed review comments for v25 patches of the conflict log history table feature for logical replication. He suggests documentation improvements including typo fixes, better SGML markup usage, and clearer wording about conflict log destinations. Key issues include redundant comments about row locking restrictions, inconsistent terminology between "log" and "table" destinations, and missing cross-references between documentation sections.\n\nShveta Malik adds her own review feedback, recommending function renaming (GetLogDestination to GetConflictLogDest), using "nspname" instead of "schemaname" for consistency with PostgreSQL catalogs, and reorganizing code structure. She suggests moving LocalConflictSchema definition closer to ConflictLogSchema in the header file for better code readability. Both reviewers identify areas needing refinement in the test cases, particularly around JSON validation patterns.\n\nPeter Smith supports Shveta's suggestion about relocating the LocalConflictSchema definition, referencing his earlier similar feedback. The discussion focuses on code organization, naming consistency, and documentation clarity rather than fundamental design issues.	2026-01-28 20:59:45+00	Peter Smith 为逻辑复制冲突日志历史表功能的 v25 补丁提供了详细的审查意见。他建议改进文档，包括修复拼写错误、更好地使用 SGML 标记，以及更清晰地描述冲突日志目标。主要问题包括关于行锁定限制的冗余注释、"日志"和"表"目标之间的术语不一致，以及文档部分之间缺少交叉引用。\n\nShveta Malik 添加了自己的审查反馈，建议重命名函数（GetLogDestination 改为 GetConflictLogDest），为了与 PostgreSQL 目录保持一致使用"nspname"而不是"schemaname"，以及重新组织代码结构。她建议将 LocalConflictSchema 定义移至头文件中更靠近 ConflictLogSchema 的位置，以提高代码可读性。两位审查者都识别了测试用例中需要改进的地方，特别是围绕 JSON 验证模式。\n\nPeter Smith 支持 Shveta 关于重新定位 LocalConflictSchema 定义的建议，引用了他之前的类似反馈。讨论重点关注代码组织、命名一致性和文档清晰度，而非根本设计问题。
33	19bed51841b76f7b	Custom oauth validator options	["alvherre@kurilemu.de","david.g.johnston@gmail.com","dhyan@nataraj.su","jacob.champion@enterprisedb.com","myon@debian.org","robertmhaas@gmail.com","vasukianand0119@gmail.com","zsolt.parragi@percona.com"]	[{"id":"19c055a126b17124","threadId":"19bed51841b76f7b","snippet":"I implemented a DefineCustomValidatorStringVariable PoC - I don't like it that much. It adds too much boilerplate code for a very specific feature. If you say we should go with a more limited","historyId":"34793","internalDate":"1769616289000","receivedAtUtc":"2026-01-28T16:04:49.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>","subject":"Re: Custom oauth validator options","messageId":"<CAN4CZFPmF9fGOcFubwOxqXymhVo_RvbUx3bLoYQcfk=f0mwECw@mail.gmail.com>","body":"I implemented a DefineCustomValidatorStringVariable PoC - I don't like\\nit that much. It adds too much boilerplate code for a very specific\\nfeature. If you say we should go with a more limited approach, I think\\nmy earlier simple version is better, because it is simple. I'll also\\ntry to think about other approaches.\\n\\nAnd also let me go back to my concern that\\n\\n> Scoping validators to a specific prefix fixes the collision issue, but\\n> it also goes in a different direction.\\n\\nI wrote this because of the simple \\"guc.some_name\\" example, as the\\nfixed guc prefix - and previously I also looked into\\nMarkGUCPrefixReserved, and I realized that there's no easy way to use\\nthat for enforcing prefixes for a library.\\n\\nAnd then I realized that maybe that needs an improvement, the behavior\\nof MarkGUCPrefixReserved and DefineCustom*Variable seems like a legacy\\nthing and not something that was intentionally designed that way.\\n\\nWhat do you think about the following patches?\\n\\n0001: defines a new guc, guc_prefix_enforcement that potentially\\nchanges the behavior of prefix reservation. It has a few modes, based\\non which missing prefix reservations or variables defined outside the\\nreserved prefix result in warnings or errors during library load time.\\nThis is unrelated to pgc_hba, and applies to all custom variables.\\n\\n0002: the same patch as before, with your comment (su_backend,\\nbackend, suset, user can be set in pg_hba) addressed, and also always\\nenforces proper prefix reservation for pg_hba variables using 0001.\\n\\n* We don't have to worry about collisions, because prefixes are always\\nenforced in pg_hba, so people can't \\"redefine\\" the fixed key/value\\npairs or columns\\n* It also introduces the idea of enforcing guc prefixes for\\nextensions. In theory this setting should start with a relaxed default\\n(I would say warning mode), and changed to strict in a later major\\nversion, enforcing proper guc rules by default. That way, third party\\nextensions won't be able to define gucs like pam_use_hostname.\\n\\nI realize that\\n\\n1. This is also scope creep\\n2. 0001 probably should be a separate thread/discussion\\n\\nBut I first wanted to ask your opinion about the idea / what do you\\nthink about the interaction of the two patches.\\n"},{"id":"19c0599aaead79c6","threadId":"19bed51841b76f7b","snippet":"On 2026-Jan-28, Zsolt Parragi wrote: > 0001: defines a new guc, guc_prefix_enforcement that potentially > changes the behavior of prefix reservation. It has a few modes, based > on which","historyId":"35094","internalDate":"1769617419000","receivedAtUtc":"2026-01-28T16:23:39.000Z","from":"\\"Álvaro Herrera\\" <alvherre@kurilemu.de>","subject":"Re: Custom oauth validator options","messageId":"<202601281620.m3hrqtih5b2w@alvherre.pgsql>","body":"On 2026-Jan-28, Zsolt Parragi wrote:\\n\\n> 0001: defines a new guc, guc_prefix_enforcement that potentially\\n> changes the behavior of prefix reservation. It has a few modes, based\\n> on which missing prefix reservations or variables defined outside the\\n> reserved prefix result in warnings or errors during library load time.\\n> This is unrelated to pgc_hba, and applies to all custom variables.\\n\\nI didn't actually read this patch, but I wonder if this is something we\\nshould attempt in the context of the larger refactoring done by the\\npatch series here,\\nhttps://postgr.es/m/2438819.yKrmzQ4Hd0@thinkpad-pgpro\\nI'm afraid it's likely to be very outdated at the moment, I think it'll\\nneed a difficult rebase, but I invite you to have a look at what it\\noffered when it was last posted, and see if it would help write what\\nyou're trying to achieve here.\\n\\nThanks\\n\\n-- \\nÁlvaro Herrera               48°01'N 7°57'E  —  https://www.EnterpriseDB.com/\\n\\"I'm always right, but sometimes I'm more right than other times.\\"\\n                                                  (Linus Torvalds)\\nhttps://lore.kernel.org/git/Pine.LNX.4.58.0504150753440.7211@ppc970.osdl.org/\\n\\n\\n"},{"id":"19c060dcabfc05ec","threadId":"19bed51841b76f7b","snippet":"> but I wonder if this is something we > should attempt in the context of the larger refactoring done by the > patch series here, That patch series is interesting but it is about SQL (table,","historyId":"35589","internalDate":"1769628073000","receivedAtUtc":"2026-01-28T19:21:13.000Z","from":"Zsolt Parragi <zsolt.parragi@percona.com>","subject":"Re: Custom oauth validator options","messageId":"<CAN4CZFPUfTj-BF-m5=F7_MnY_T3+Qh-DuG7N7ojdbJDkT8JHeA@mail.gmail.com>","body":"> but I wonder if this is something we\\n> should attempt in the context of the larger refactoring done by the\\n> patch series here,\\n\\nThat patch series is interesting but it is about SQL (table, index,\\noperator) options, while this is about guc variable validation and\\nextension. These seem unrelated to me.\\n\\n\\n"}]	Zsolt Parragi implemented a DefineCustomValidatorStringVariable proof of concept for custom OAuth validator options but finds it adds too much boilerplate code. He proposes two alternative patches: one introducing a new GUC called guc_prefix_enforcement to modify prefix reservation behavior with warning/error modes during library load time, and another addressing pg_hba variable prefix enforcement. The approach aims to prevent GUC collisions by enforcing proper prefixes for extensions, potentially changing default behavior in future versions. Álvaro Herrera suggests considering this work in context of a larger refactoring patch series, though Parragi clarifies that the referenced series deals with SQL options rather than GUC variable validation, making them unrelated efforts.	2026-01-28 19:21:13+00	Zsolt Parragi为自定义OAuth验证器选项实现了DefineCustomValidatorStringVariable概念验证，但发现它添加了太多样板代码。他提出了两个替代补丁：一个引入名为guc_prefix_enforcement的新GUC来修改前缀保留行为，在库加载时提供警告/错误模式，另一个解决pg_hba变量前缀强制执行。该方法旨在通过为扩展强制执行适当的前缀来防止GUC冲突，可能会在未来版本中更改默认行为。Álvaro Herrera建议在更大的重构补丁系列的上下文中考虑这项工作，不过Parragi澄清引用的系列处理的是SQL选项而不是GUC变量验证，使它们成为不相关的工作。
33	19bfff779b0f694c	pgsql: Prevent invalidation of newly synced replication slots.	["akapila@postgresql.org","amit.kapila16@gmail.com","andres@anarazel.de","dbryan.green@gmail.com","greg@burd.me","robertmhaas@gmail.com","thomas.munro@gmail.com","x4mmm@yandex-team.ru"]	[{"id":"19c02e174d8aa943","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 8:29 PM Robert Haas <robertmhaas@gmail.com> wrote: > > On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote: > > Prevent","historyId":"31754","internalDate":"1769574831000","receivedAtUtc":"2026-01-28T04:33:51.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CAA4eK1Kr+RVqKWwky5cFiMaeRd+jCk_g0ZCmFsxjXshH5R0K6w@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 8:29 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n>\\n> On Tue, Jan 27, 2026 at 12:56 AM Amit Kapila <akapila@postgresql.org> wrote:\\n> > Prevent invalidation of newly synced replication slots.\\n>\\n> This commit has broken CI for me. On the \\"Windows - Server 2022, VS\\n> 2019 - Meson & ninja\\" build, the following shows up in\\n> 046_checkpoint_logical_slot_standby.log:\\n>\\n> 2026-01-27 13:44:44.421 GMT startup[5172] FATAL:  could not rename\\n> file \\"backup_label\\" to \\"backup_label.old\\": Permission denied\\n>\\n> I imagine this is going to break CI for everybody else too, as well as cfbot.\\n>\\n\\nI'll try to reproduce and look into it.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n"},{"id":"19c0325487eb8c08","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:46 PM Robert Haas <robertmhaas@gmail.com> wrote: > > On Tue, Jan 27, 2026 at 12:42 PM Robert Haas <robertmhaas@gmail.com> wrote: > > 2026-01-27 17:19:","historyId":"32098","internalDate":"1769579277000","receivedAtUtc":"2026-01-28T05:47:57.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CAA4eK1KU_q0mCwSOL3G5O7DH0DA4DKv8jvQy-O6pyt2eQUqpmA@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:46 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n>\\n> On Tue, Jan 27, 2026 at 12:42 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n> > 2026-01-27 17:19:25.354 GMT startup[2488] DEBUG:  didn't need to\\n> > unlink permanent stats file \\"pg_stat/pgstat.stat\\" - didn't exist\\n> > 2026-01-27 17:19:38.938 GMT startup[2488] FATAL:  could not rename\\n> > file \\"backup_label\\" to \\"backup_label.old\\": Permission denied\\n>\\n> Andrey Borodin pointed out to me off-list that there's a retry loop in\\n> pgrename(). The 13 second delay between the above two log messages\\n> almost certainly means that retry loop is iterating until it hits its\\n> 10 second timeout.\\n>\\n\\nYes, this is correct. I am able to reproduce it. In pgrename(), we use\\nMoveFileEx() windows API which fails with errorcode 32 which further\\nmaps to doserrr 13 via _dosmaperr. It is following mapping\\nERROR_SHARING_VIOLATION, EACCES in doserrors struct.\\n\\n This almost certainly means that the underlying\\n> Windows error is ERROR_ACCESS_DENIED, ERROR_SHARING_VIOLATION, or\\n> ERROR_LOCK_VIOLATION, and that somebody else has the file open.\\n>\\n\\nIt is ERROR_SHARING_VIOLATION.\\n\\n But\\n> nothing other than Perl touches that directory before we try to start\\n> the standby:\\n>\\n> my $standby = PostgreSQL::Test::Cluster->new('standby');\\n> $standby->init_from_backup(\\n>         $primary, $backup_name,\\n>         has_streaming => 1,\\n>         has_restoring => 1);\\n> $standby->append_conf(\\n>         'postgresql.conf', qq(\\n> hot_standby_feedback = on\\n> primary_slot_name = 'phys_slot'\\n> primary_conninfo = '$connstr_1 dbname=postgres'\\n> log_min_messages = 'debug2'\\n> ));\\n> $standby->start;\\n>\\n> As far as I can see, only init_from_backup() touches the backup_label\\n> file, and that just copies the directory using RecursiveCopy.pm, which\\n> as far as I can tell is quite careful about closing file handles. So I\\n> still have no idea what's happening here.\\n>\\n\\nIt is not clear to me either why the similar test like\\n040_standby_failover_slots_sync is successful and\\n046_checkpoint_logical_slot is failing. I am still thinking about it\\nbut thought of sharing the information I could gather by debugging.\\n\\nDo let me know if you could think of gathering any other information\\nwhich can be of help here.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n"},{"id":"19c037ca79c4a66d","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 5:37 PM Andres Freund <andres@anarazel.de> wrote: > On 2026-01-28 05:16:13 +1300, Thomas Munro wrote: > > But I wonder if you can't rename(\\"old\\",","historyId":"32511","internalDate":"1769584979000","receivedAtUtc":"2026-01-28T07:22:59.000Z","from":"Thomas Munro <thomas.munro@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+hUKGKx+-g9w9XUHBp8oRDc_3yOMtbSg3Se-rAy=2WzT4oqNg@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 5:37 PM Andres Freund <andres@anarazel.de> wrote:\\n> On 2026-01-28 05:16:13 +1300, Thomas Munro wrote:\\n> > But I wonder if you can't rename(\\"old\\", \\"new\\") where \\"new\\" is a file that\\n> > has already been unlinked (or renamed over) that someone still holds open,\\n> > or something like that...\\n>\\n> I don't see a source of that that would be specific to this test though :(. We\\n> do wait for pg_basebackup to have shut down, which wrote backup.label (which\\n> was \\"manifactured\\" during streaming by basebackup.c).\\n\\nI have no specific ideas, but just in case it's helpful for this\\ndiscussion, I looked at my old test suite[1] where I tried to\\ncatalogue all the edge conditions around this sort of stuff\\nempirically, and saw that rename() always fails like that if the file\\nis open (that is, it doesn't require a more complicated sequence with\\nan earlier unlink/rename of the new name):\\n\\n+ /*\\n+ * Windows can't rename over an open non-unlinked file, even with\\n+ * have_posix_unlink_semantics.\\n+ */\\n+ pgwin32_dirmod_loops = 2; /* minimize looping to fail fast in testing */\\n+ PG_EXPECT_SYS(rename(path, path2) == -1,\\n+  \\"Windows: can't rename name1.txt -> name2.txt while name2.txt is open\\");\\n+ PG_EXPECT_EQ(errno, EACCES);\\n\\n[1] https://www.postgresql.org/message-id/flat/CA%2BhUKG%2BajSQ_8eu2AogTncOnZ5me2D-Cn66iN_-wZnRjLN%2Bicg%40mail.gmail.com\\n\\n\\n"},{"id":"19c0434f6b5f3b0e","threadId":"19bfff779b0f694c","snippet":"> On 28 Jan 2026, at 10:47, Amit Kapila <amit.kapila16@gmail.com> wrote: > > Do let me know if you could think of gathering any other information > which can be of help here.","historyId":"33070","internalDate":"1769597081000","receivedAtUtc":"2026-01-28T10:44:41.000Z","from":"Andrey Borodin <x4mmm@yandex-team.ru>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<1DF1F535-4027-4F33-98B5-7577D11053C9@yandex-team.ru>","body":"\\n\\n> On 28 Jan 2026, at 10:47, Amit Kapila <amit.kapila16@gmail.com> wrote:\\n> \\n> Do let me know if you could think of gathering any other information\\n> which can be of help here.\\n\\nInterestingly, increasing timeout in pgrename() to 500 seconds fixes \\"Windows - Server 2022, VS 2019 - Meson & ninja \\", but does not fix \\"Windows - Server 2022, VS 2019 - Meson & ninja\\".\\n\\ndiff --git a/src/port/dirmod.c b/src/port/dirmod.c\\nindex 467b50d6f09..da38e37aa45 100644\\n--- a/src/port/dirmod.c\\n+++ b/src/port/dirmod.c\\n@@ -88,7 +88,7 @@ pgrename(const char *from, const char *to)\\n                        return -1;\\n #endif\\n-               if (++loops > 100)              /* time out after 10 sec */\\n+               if (++loops > 5000)             /* time out after 10 sec */\\n                        return -1;\\n                pg_usleep(100000);              /* us */\\n        }\\n\\n\\nBest regards, Andrey Borodin.\\n\\n"},{"id":"19c043709e4f8932","threadId":"19bfff779b0f694c","snippet":"On Wed, Jan 28, 2026 at 11:17 AM Amit Kapila <amit.kapila16@gmail.com> wrote: > > It is not clear to me either why the similar test like > 040_standby_failover_slots_sync is successful","historyId":"33110","internalDate":"1769597218000","receivedAtUtc":"2026-01-28T10:46:58.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CAA4eK1KOjv0sLKfwWddR_tLzK=Tfnsszy-PKM4xHTs7nFX3nMg@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 11:17 AM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n>\\n> It is not clear to me either why the similar test like\\n> 040_standby_failover_slots_sync is successful and\\n> 046_checkpoint_logical_slot is failing. I am still thinking about it\\n> but thought of sharing the information I could gather by debugging.\\n>\\n\\nIt seems there is some interaction with previous test in same file\\nwhich is causing this failure as we are using the primary node from\\nprevious test. When I tried to comment out get_changes and its\\ncorresponding injection_point in the previous test as attached, the\\nentire test passed. I think if we use a freshly created primary node,\\nthis test will pass but I wanted to spend some more time to see\\nhow/why previous test is causing this issue?\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n"},{"id":"19c0455992dc1b67","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026 at 11:47 PM Andres Freund <andres@anarazel.de> wrote: > > I don't know why the standby is created with has_restoring => 1. > This is not required. I think","historyId":"33254","internalDate":"1769599218000","receivedAtUtc":"2026-01-28T11:20:18.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CAA4eK1+T7BsNedCk+xKoMp1C10=OL9BqaqeTtKA3UT3Wt8DZRw@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:47 PM Andres Freund <andres@anarazel.de> wrote:\\n>\\n> I don't know why the standby is created with has_restoring => 1.\\n>\\n\\nThis is not required. I think this is copy-paste oversight.\\n\\n> But it\\n> shouldn't be related to the issue, I think?\\n>\\n\\nYeah, tried without this as well apart from other experiments.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n\\n\\n"},{"id":"19c049a203cd7406","threadId":"19bfff779b0f694c","snippet":"On Wed, Jan 28, 2026 at 4:16 PM Amit Kapila <amit.kapila16@gmail.com> wrote: > > On Wed, Jan 28, 2026 at 11:17 AM Amit Kapila <amit.kapila16@gmail.com> wrote: > > > > It","historyId":"33751","internalDate":"1769603710000","receivedAtUtc":"2026-01-28T12:35:10.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CAA4eK1LhMuxYdf6aR+UZuxdp7+SJUT_4Mf9yz7eiXdY1VB0Z+g@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 4:16 PM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n>\\n> On Wed, Jan 28, 2026 at 11:17 AM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n> >\\n> > It is not clear to me either why the similar test like\\n> > 040_standby_failover_slots_sync is successful and\\n> > 046_checkpoint_logical_slot is failing. I am still thinking about it\\n> > but thought of sharing the information I could gather by debugging.\\n> >\\n>\\n> It seems there is some interaction with previous test in same file\\n> which is causing this failure as we are using the primary node from\\n> previous test. When I tried to comment out get_changes and its\\n> corresponding injection_point in the previous test as attached, the\\n> entire test passed. I think if we use a freshly created primary node,\\n> this test will pass but I wanted to spend some more time to see\\n> how/why previous test is causing this issue?\\n>\\n\\nI noticed that the previous test didn't quitted the background psql\\nsession used for concurrent checkpoint. By quitting that background\\nsession, the test passed for me consistently. See attached. It is\\nwritten in comments atop background_psql: \\"Be sure to \\"quit\\" the\\nreturned object when done with it.\\". Now, this background session\\ndoesn't directly access the backup_label file but it could be\\naccessing one of the parent directories where backup_label is present.\\nOne of gen-AI says as follows: \\"In Windows, MoveFileEx (Error 32:\\nERROR_SHARING_VIOLATION) can fail if a process is accessing the file's\\nparent directory in a way that creates a lock. While the error message\\nusually points to the file itself, the parent folder is a critical\\npart of the operation.\\". I admit that I don't know the internals of\\nMoveFileEx, so can't say with complete conviction but the attached\\nsounds like a reasonable fix. Can anyone else who can reproduce the\\nissue once test the attached patch and share the results?\\n\\nDoes this fix/theory sound plausible?\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n"},{"id":"19c04aed6e534033","threadId":"19bfff779b0f694c","snippet":"On Wed, Jan 28, 2026 at 7:35 AM Amit Kapila <amit.kapila16@gmail.com> wrote: > Does this fix/theory sound plausible? I wondered about this yesterday, too. I didn't actually understand how","historyId":"33942","internalDate":"1769605069000","receivedAtUtc":"2026-01-28T12:57:49.000Z","from":"Robert Haas <robertmhaas@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CA+TgmoZZtHcY200WKPSfOdAhNfjC_NTuRSkdr0jkQXC2zdRcAQ@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 7:35 AM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n> Does this fix/theory sound plausible?\\n\\nI wondered about this yesterday, too. I didn't actually understand how\\nthe existence of the background psql could be causing the failure, but\\nI thought it might be. However, I couldn't figure out the correct\\nincantation to get rid of it in my testing, as I thought I would need\\nto detach the injection point first or something.\\n\\nIf it fixes it for you, I would suggest committing promptly. I think\\nwe are too dependent on CI now to leave it broken for any period of\\ntime, and indeed I suggest getting set up so that you test your\\ncommits against it before committing.\\n\\n-- \\nRobert Haas\\nEDB: http://www.enterprisedb.com\\n\\n\\n"},{"id":"19c051f62dac5ec7","threadId":"19bfff779b0f694c","snippet":"On Wed, Jan 28, 2026 at 6:28 PM Robert Haas <robertmhaas@gmail.com> wrote: > > On Wed, Jan 28, 2026 at 7:35 AM Amit Kapila <amit.kapila16@gmail.com> wrote: > > Does this fix/","historyId":"34381","internalDate":"1769612445000","receivedAtUtc":"2026-01-28T15:00:45.000Z","from":"Amit Kapila <amit.kapila16@gmail.com>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<CAA4eK1JTZ1OexK8g1xa3V8NPitDyJ+cW8GsWaO7rQLP8kd2_Ng@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 6:28 PM Robert Haas <robertmhaas@gmail.com> wrote:\\n>\\n> On Wed, Jan 28, 2026 at 7:35 AM Amit Kapila <amit.kapila16@gmail.com> wrote:\\n> > Does this fix/theory sound plausible?\\n>\\n> I wondered about this yesterday, too. I didn't actually understand how\\n> the existence of the background psql could be causing the failure, but\\n> I thought it might be. However, I couldn't figure out the correct\\n> incantation to get rid of it in my testing, as I thought I would need\\n> to detach the injection point first or something.\\n>\\n\\nYeah, it would be better to quit these sessions after the test is\\ncomplete because there are other two background sessions as well. I\\nused the method to quit these sessions as used in\\n\\\\src\\\\test\\\\modules\\\\test_misc\\\\t\\\\005_timeouts.pl. The attached passes for\\nme on both Linux and Windows (check on HEAD only as of now). I'll do\\nsome more testing on back branches as well and push tomorrow morning\\nif there are no more comments.\\n\\n-- \\nWith Regards,\\nAmit Kapila.\\n"},{"id":"19c0586e46ff7b1c","threadId":"19bfff779b0f694c","snippet":"Hi, On 2026-01-28 18:05:10 +0530, Amit Kapila wrote: > I noticed that the previous test didn't quitted the background psql > session used for concurrent checkpoint. By quitting that","historyId":"34944","internalDate":"1769619239000","receivedAtUtc":"2026-01-28T16:53:59.000Z","from":"Andres Freund <andres@anarazel.de>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<j3fa57s3im2wbuhz33cmbg56lgpbrtt25qq7irou336pawd2jo@lloejwmt3sxs>","body":"Hi,\\n\\nOn 2026-01-28 18:05:10 +0530, Amit Kapila wrote:\\n> I noticed that the previous test didn't quitted the background psql\\n> session used for concurrent checkpoint. By quitting that background\\n> session, the test passed for me consistently. See attached. It is\\n> written in comments atop background_psql: \\"Be sure to \\"quit\\" the\\n> returned object when done with it.\\". Now, this background session\\n> doesn't directly access the backup_label file but it could be\\n> accessing one of the parent directories where backup_label is present.\\n\\nHm. I've seen (and complained about [1]) weird errors when not shutting down\\nIPC::Run processes - mostly the test hanging at the end though.\\n\\n\\n> One of gen-AI says as follows: \\"In Windows, MoveFileEx (Error 32:\\n> ERROR_SHARING_VIOLATION) can fail if a process is accessing the file's\\n> parent directory in a way that creates a lock. While the error message\\n> usually points to the file itself, the parent folder is a critical\\n> part of the operation.\\".\\n\\nI don't see how that could be the plausible reason - after all we have a lot\\nof other open files open in the relevant directories.  But: It seems to fix\\nthe problem for you, so it's worth going for it, as it's the right thing to do\\nanyway.\\n\\n\\nI think it'd be worth, separately from committing the workaround, trying to\\nfigure out what's holding the file open. Andrey observed that the tests pass\\nfor him with a much longer timeout. If you can reproduce it locally, I'd try\\nto use something like [2] to see what has handles open to the relevant files,\\nwhile waiting for the timeout.\\n\\nGreetings,\\n\\nAndres Freund\\n\\n[1] https://postgr.es/m/20240619030727.ldp3mcrjbd5fqwj5%40awork3.anarazel.de\\n[2] https://learn.microsoft.com/en-us/sysinternals/downloads/handle\\n\\n\\n"},{"id":"19c05c51b1ae0718","threadId":"19bfff779b0f694c","snippet":"On Tue, Jan 27, 2026, at 1:17 PM, Andres Freund wrote: > Hi, > > On 2026-01-27 12:42:51 -0500, Robert Haas wrote: >> I tried sticking a pg_sleep(30) in just before starting the standby","historyId":"35306","internalDate":"1769623283000","receivedAtUtc":"2026-01-28T18:01:23.000Z","from":"Greg Burd <greg@burd.me>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<85eb570f-ae23-4199-8f50-1772ccf63266@app.fastmail.com>","body":"\\nOn Tue, Jan 27, 2026, at 1:17 PM, Andres Freund wrote:\\n> Hi,\\n>\\n> On 2026-01-27 12:42:51 -0500, Robert Haas wrote:\\n>> I tried sticking a pg_sleep(30) in just before starting the standby\\n>> node, and that didn't help, so it doesn't seem like it's a race\\n>> condition.\\n>\\n> Interesting.\\n>\\n> It could be worth trying to run the test in isolation, without all the other\\n> concurrent tests.\\n>\\n> Greg, have you tried to repro it interactively?\\n\\nNope, not yet.  I'm working on my ailing animals now and updated unicorn to include injection points.\\n\\n-greg\\n\\n> Bryan, you seem to have become the resident windows expert...\\n>\\n>\\n>> 2026-01-27 17:19:25.337 GMT startup[2488] LOG:  starting backup\\n>> recovery with redo LSN 0/2A000028, checkpoint LSN 0/2A000080, on\\n>> timeline ID 1\\n>> The system cannot find the file specified.\\n>> 2026-01-27 17:19:25.352 GMT startup[2488] DEBUG:  could not restore\\n>> file \\"00000001000000000000002A\\" from archive: child process exited\\n>> with exit code 1\\n>\\n> I think that must be a message from \\"copy\\" (which we seem to be using for\\n> restore_command on windows).\\n>\\n> I don't know why the standby is created with has_restoring => 1. But it\\n> shouldn't be related to the issue, I think?\\n>\\n> Greetings,\\n>\\n> Andres Freund\\n\\n\\n"},{"id":"19c05cc4239fe0f1","threadId":"19bfff779b0f694c","snippet":"> On 28 Jan 2026, at 21:53, Andres Freund <andres@anarazel.de> wrote: > > Andrey observed that the tests pass > for him with a much longer timeout. Unfortunately, I was wrong. The job","historyId":"35346","internalDate":"1769623775000","receivedAtUtc":"2026-01-28T18:09:35.000Z","from":"Andrey Borodin <x4mmm@yandex-team.ru>","subject":"Re: pgsql: Prevent invalidation of newly synced replication slots.","messageId":"<46DAB528-A3E8-455E-B1BA-370865490ABD@yandex-team.ru>","body":"\\n\\n> On 28 Jan 2026, at 21:53, Andres Freund <andres@anarazel.de> wrote:\\n> \\n> Andrey observed that the tests pass\\n> for him with a much longer timeout.\\n\\nUnfortunately, I was wrong. The job \\"Windows - Server 2022, MinGW64 - Meson\\" which failed yesterday did not fail today.\\nBut it did not succeed either. CirrusCI seems just did not run it. I do not understand why.\\nAnyway, I cannot prove that it is race condition. On a contrary, test fails on any big timeout (pg_ctl will bail out) deterministically.\\n\\n\\nBest regards, Andrey Borodin.\\n\\n"}]	A commit that prevents invalidation of newly synced replication slots has broken CI builds on Windows, specifically failing with "could not rename file 'backup_label' to 'backup_label.old': Permission denied" errors. The issue appears to be an ERROR_SHARING_VIOLATION where something is holding the backup_label file open during the rename operation. Amit Kapila investigated and discovered that the failure occurs due to interaction with a previous test that left background psql sessions running without proper cleanup. These sessions may be accessing parent directories in a way that creates file locks on Windows. The proposed fix involves properly quitting background psql sessions after test completion, following the documented requirement to "quit" background_psql objects when done. Testing shows this resolves the issue consistently on both Linux and Windows. The fix addresses a broader test hygiene issue beyond just this specific failure.	2026-01-28 18:09:35+00	一个防止新同步的复制槽失效的提交破坏了Windows上的CI构建，具体表现为"could not rename file 'backup_label' to 'backup_label.old': Permission denied"错误。问题似乎是ERROR_SHARING_VIOLATION，即某些进程持有backup_label文件的打开句柄导致重命名操作失败。Amit Kapila调查发现，故障是由于与前一个测试的交互导致的，该测试遗留了未正确清理的后台psql会话。这些会话可能以某种方式访问父目录，在Windows上创建了文件锁。建议的修复方案是在测试完成后正确退出后台psql会话，遵循文档要求在完成后"quit" background_psql对象。测试显示这个方案在Linux和Windows上都能一致地解决问题。该修复解决了一个超出此特定故障范围的更广泛的测试卫生问题。
33	19bfaa2fe006e548	Exit walsender before confirming remote flush in logical replication	["a.silitskiy@postgrespro.ru","aekorotkov@gmail.com","amit.kapila16@gmail.com","andres@anarazel.de","dilipbalaut@gmail.com","horikyota.ntt@gmail.com","htamfids@gmail.com","kuroda.hayato@fujitsu.com","masao.fujii@gmail.com","michael@paquier.xyz","osumi.takamichi@fujitsu.com","peter.eisentraut@enterprisedb.com","ronan@dunklau.fr","sawada.mshk@gmail.com","smithpb2250@gmail.com","v.davydov@postgrespro.ru"]	[{"id":"19c03b73a7c67150","threadId":"19bfaa2fe006e548","snippet":"On Monday, January 26th, 2026 at 15:08, Fujii Masao <masao.fujii@gmail.com> wrote: > Regarding the GUC name, wal_sender_shutdown seems simple and sufficient to me. > This isn't a","historyId":"32816","internalDate":"1769588848000","receivedAtUtc":"2026-01-28T08:27:28.000Z","from":"Ronan Dunklau <ronan@dunklau.fr>","subject":"Re: Exit walsender before confirming remote flush in logical replication","messageId":"<xf9b6kmx0DFSMe9zJ3hP-kxRMeOhOMwf7v914ctQ_YtPEVLlqCFkbrrw924XLR4LJynEtBX7omSa5taFyK-uoTPeWwusZiBXRYQholbUjhc=@dunklau.fr>","body":"On Monday, January 26th, 2026 at 15:08, Fujii Masao <masao.fujii@gmail.com> wrote:\\n \\n> Regarding the GUC name, wal_sender_shutdown seems simple and sufficient to me.\\n> This isn't a blocker, so I'm fine with the current name for now and\\n> revisiting it later if needed.\\n\\nAre we considering other approaches to this ? Having the behavior be either \\"wait indefinitely\\" or \\"terminate immediately\\" is a bit coarse I think: a timeout for the wait (maybe named wal_sender_stop_timeout ?) would allow for the same usage as this patch provides (set it to -1 for indefinite wait, 0 for immediate shutdown, or any positive value to give a chance to the walsender to catch up before we terminate it forcibly).\\n\\nThe problem we have as of now is when the walreceiver is indeed connected and not reaching wal_sender_timeout as it's still processing: a distinct timeout would alleviate that.\\n\\nRegards,\\n\\n--\\nRonan Dunklau\\n\\n\\n"},{"id":"19c045bc210986a9","threadId":"19bfaa2fe006e548","snippet":"Thanks for the review! Updated the patch based on your comments. Regards, Andrey Silitskiy","historyId":"33303","internalDate":"1769599634000","receivedAtUtc":"2026-01-28T11:27:14.000Z","from":"Andrey Silitskiy <a.silitskiy@postgrespro.ru>","subject":"Re: Exit walsender before confirming remote flush in logical replication","messageId":"<d91f4092-8dd8-4ecf-b26a-cd79d84cb444@postgrespro.ru>","body":"Thanks for the review!\\n\\nUpdatedthe patchbasedonyourcomments. Regards, Andrey Silitskiy"},{"id":"19c04617ca32c7ee","threadId":"19bfaa2fe006e548","snippet":"Dear Ronan, Thanks for participating in the discussion. On Jan 28, 2026 Ronan Dunklau <ronan(at)dunklau(dot)fr> wrote: > ... a timeout for the wait (maybe named wal_sender_stop_timeout ?)","historyId":"33352","internalDate":"1769600011000","receivedAtUtc":"2026-01-28T11:33:31.000Z","from":"Andrey Silitskiy <a.silitskiy@postgrespro.ru>","subject":"Re: Exit walsender before confirming remote flush in logical replication","messageId":"<26b41b30-2484-4fa7-b951-b97805101bd7@postgrespro.ru>","body":"Dear Ronan,\\nThanks for participating in the discussion.\\n\\nOn Jan 28, 2026 Ronan Dunklau <ronan(at)dunklau(dot)fr> wrote:\\n> ... a timeout for the wait (maybe named wal_sender_stop_timeout ?) would\\n> allow for the same usage ...\\n\\nSounds like an option.\\nThis is also possible in the current implementation, but your option offers\\na simpler interface if we do not plan to add new wallsender completion modes.\\nThe naming of the parameter is also a question, because wal_sender_timeout\\nalready exists (which also fits the name wal_sender_stop_timeout quite well).\\nThe difference between these parameters may not be obvious to users.\\nThoughts?\\n\\nRegards,\\nAndrey Silitskiy\\n\\n\\n"}]	The discussion focuses on a patch to allow PostgreSQL's walsender to exit before confirming remote flush in logical replication. Fujii Masao suggests the GUC name "wal_sender_shutdown" is sufficient. Ronan Dunklau proposes an alternative approach using a timeout mechanism instead of the current binary "wait indefinitely" or "terminate immediately" behavior. He suggests "wal_sender_stop_timeout" as a parameter name that could accept -1 for indefinite wait, 0 for immediate shutdown, or positive values for timed wait. Andrey Silitskiy acknowledges this timeout approach is feasible but raises concerns about naming confusion with the existing "wal_sender_timeout" parameter, noting the difference between these parameters may not be obvious to users. The team continues to evaluate different approaches and parameter naming conventions.	2026-01-28 11:33:31+00	讨论集中在一个补丁上，该补丁允许PostgreSQL的walsender在逻辑复制中确认远程刷新之前退出。Fujii Masao建议GUC名称"wal_sender_shutdown"已经足够。Ronan Dunklau提出了一种替代方法，使用超时机制代替当前的"无限等待"或"立即终止"的二元行为。他建议使用"wal_sender_stop_timeout"作为参数名，可以接受-1表示无限等待，0表示立即关闭，或正值表示定时等待。Andrey Silitskiy承认这种超时方法是可行的，但担心与现有的"wal_sender_timeout"参数在命名上会造成混淆，指出用户可能不明显看出这些参数之间的差异。团队继续评估不同的方法和参数命名约定。
33	19be99a6948cab2b	Extended Statistics set/restore/clear functions.	["corey.huinker@gmail.com","li.evan.chao@gmail.com","michael@paquier.xyz","tndrwang@gmail.com"]	[{"id":"19c021d1b1b39e61","threadId":"19be99a6948cab2b","snippet":"I don't see a strong need to do that on this thread for the moment, let's first focus on finishing this project :) I agree 100%, just pointing out a target of opportunity.","historyId":"31165","internalDate":"1769561965000","receivedAtUtc":"2026-01-28T00:59:25.000Z","from":"Corey Huinker <corey.huinker@gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<CADkLM=d3aqhdWTjeg9V3YcybRPL1PP+G=eNnnABgjxU-QyzDjQ@mail.gmail.com>","body":">\\n>  I\\n> don't see a strong need to do that on this thread for the moment,\\n> let's first focus on finishing this project :)\\n>\\n\\nI agree 100%, just pointing out a target of opportunity.\\n"},{"id":"19c027ea9b80aabc","threadId":"19be99a6948cab2b","snippet":"On Wed, Jan 28, 2026 at 08:51:54AM +0900, Michael Paquier wrote: > On Tue, Jan 27, 2026 at 11:14:12AM -0500, Corey Huinker wrote: > >> 0001 - adds a test left out of dependencies > >","historyId":"31396","internalDate":"1769568364000","receivedAtUtc":"2026-01-28T02:46:04.000Z","from":"Michael Paquier <michael@paquier.xyz>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<aXl4bMfSTQUxM_yy@paquier.xyz>","body":"On Wed, Jan 28, 2026 at 08:51:54AM +0900, Michael Paquier wrote:\\n> On Tue, Jan 27, 2026 at 11:14:12AM -0500, Corey Huinker wrote:\\n> >> 0001 - adds a test left out of dependencies\\n> \\n> Applied this one now, you are right that it should have been added in\\n> 302879bd68d1, so my mistake I guess.\\n\\nThis code in v32-0002 has given me a pause, because we define numexprs\\nand use it down the road for some input validation:\\n+    /* decode expression (if any) */\\n+    exprdatum = SysCacheGetAttr(STATEXTOID,\\n+                                tup,\\n+                                Anum_pg_statistic_ext_stxexprs,\\n+                                &isnull);\\n+\\n+    if (!isnull)\\n+    {\\n[...]\\n+    }\\n+    numexprs = list_length(exprs);\\n\\nActually, I think that the patch split has been done incorrectly\\nbecause missing this code on HEAD also means that we do not perform a \\ncorrect validation of ndistinct and dependencies data when any of\\nthese include expressions, because we are missing the negative\\nattribute numbers, numexprs remaining at 0 all the time.  This can be\\neasily demonstrated with a statext object like that;\\nCREATE STATISTICS stats_obj (dependencies) ON lower(name), upper(name)\\n  FROM tab_obj;\\n\\nThe restore function would reject input like that, but it should be\\nvalid:\\n[{\\"attributes\\": [-1], \\"dependency\\": -2, \\"degree\\": 1.000000},\\n {\\"attributes\\": [-2], \\"dependency\\": -1, \\"degree\\": 1.000000}]\\n\\nI'll go fix that now with some tests to cover things, after extracting\\nthe relevant portion of the code from v32-0002.\\n--\\nMichael\\n"},{"id":"19c02e1bbc23406e","threadId":"19be99a6948cab2b","snippet":"On Wed, Jan 28, 2026 at 11:46:04AM +0900, Michael Paquier wrote: > I'll go fix that now with some tests to cover things, after extracting > the relevant portion of the code from v32-0002. I","historyId":"31792","internalDate":"1769574852000","receivedAtUtc":"2026-01-28T04:34:12.000Z","from":"Michael Paquier <michael@paquier.xyz>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<aXmRxBsfNT4Nn8mq@paquier.xyz>","body":"On Wed, Jan 28, 2026 at 11:46:04AM +0900, Michael Paquier wrote:\\n> I'll go fix that now with some tests to cover things, after extracting\\n> the relevant portion of the code from v32-0002.\\n\\nI have begun putting my head on the MCV part, and found what looks\\nlike a memory overread by injecting buggy values for\\nmost_common_val_nulls.  Quick example:\\ncreate table test (name text);\\nCREATE STATISTICS test_stat_mcv_exprs (mcv)\\n  ON lower(name), upper(name)\\n  FROM test;\\n-- 4 elements in total in most_common_val_nulls, logic reads 8,\\n-- reads past 4 of them.\\nSELECT pg_catalog.pg_restore_extended_stats('schemaname', 'public',\\n  'relname', 'test',\\n  'statistics_schemaname', 'public',\\n  'statistics_name', 'test_stat_mcv_exprs',\\n  'inherited', false,\\n  'most_common_vals', '{{four,FOUR},{one,ONE},{tre,TRE},{two,TWO}}'::text[],\\n  'most_common_val_nulls', '{{f},{f},{f},{f}}'::boolean[],\\n  'most_common_freqs', '{0.25,0.25,0.25,0.25}'::double precision[],\\n  'most_common_base_freqs', '{0.0625,0.0625,0.0625,0.625}'::double precision[]);\\n\\nThe boundary checks for the most_common_freqs and\\nmost_common_base_freqs are OK: these should be 1-dimension, with a\\nnumber of elements matching the number of items in most_common_vals.\\nAs far as I can see, most_common_vals is also OK, we check after a\\n2-dimension array made of N arrays with a number of elements matching\\nwith the object definition.\\n\\nmost_common_val_nulls is problematic: we check that it is a\\n2-dimension array, we also check that its number of internal arrays\\nmatch with the number of elements in most_common_vals.  However, we do\\n*not* check that the internal arrays have a number of items matching\\nwith the number of items in most_common_vals.  In this example,\\n{{f},{f},{f},{f}} is too short, {{f,f},{f,f},{f,f},{f,f}} would be\\nright.\\n\\nIt means that we are missing more sanity checks in import_mcv(), from\\nwhat I can see.  Without these checks, statext_mcv_import(), that\\nrebuilds the MCVItems would then read past the contents of nulls_arr\\nwith an index larger than the number of items inserted (second \\"i\\"\\nloop based on \\"nitems\\").\\n\\nExcept for this issue, statext_mcv_import() and import_mcv(), which\\nare the heart of the logic for MCV values, seem pretty clean to me.\\n\\nI have spent some time looking at the patch and fixed a couple of\\nissues, adjusting a few things.  It would be a good idea to add more\\ntests for expressions in MCV definitions.  I have added a new object in\\nthe regression tests, we should also have some input validations and\\nchecks like the two other kinds.\\n\\nCould you look at the array bound issue please?  Let's use the\\nattached as a base of work for now, this is what's standing now at the\\ntop of my dev branch for the review of the MCV patch.\\n--\\nMichael\\n"},{"id":"19c02f0234c7191a","threadId":"19be99a6948cab2b","snippet":"On Wed, Jan 28, 2026 at 01:34:12PM +0900, Michael Paquier wrote: > Could you look at the array bound issue please? Let's use the > attached as a base of work for now, this is what's","historyId":"31846","internalDate":"1769575798000","receivedAtUtc":"2026-01-28T04:49:58.000Z","from":"Michael Paquier <michael@paquier.xyz>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<aXmVdiAXPzsmKckE@paquier.xyz>","body":"On Wed, Jan 28, 2026 at 01:34:12PM +0900, Michael Paquier wrote:\\n> Could you look at the array bound issue please?  Let's use the\\n> attached as a base of work for now, this is what's standing now at the\\n> top of my dev branch for the review of the MCV patch.\\n\\nBy the way, why not just removing entirely most_common_val_nulls from\\nthe input arguments and rely on the values in most_common_vals to\\ndetermine which value is NULL?  It seems useless to me to have\\nmost_common_val_nulls knowing that we are relying already on\\ndeconstruct_array_builtin() to determine if the input values are NULL\\nor not.  That would also simplify the code a lot, especially in\\nstatext_mcv_import() where we check that either the input from\\nmost_common_val_nulls or the nulls array returned by\\ndeconstruct_array_builtin() are NULL to decide if we should check the\\ninput or not.  And that would remove entirely the overread issue,\\nreducing the input blast.  :)\\n--\\nMichael\\n"},{"id":"19c032227e651b9a","threadId":"19be99a6948cab2b","snippet":"On Tue, Jan 27, 2026 at 11:50 PM Michael Paquier <michael@paquier.xyz> wrote: On Wed, Jan 28, 2026 at 01:34:12PM +0900, Michael Paquier wrote: > Could you look at the array bound issue please?","historyId":"32058","internalDate":"1769579073000","receivedAtUtc":"2026-01-28T05:44:33.000Z","from":"Corey Huinker <corey.huinker@gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<CADkLM=fxKO6YgA_LbPd+dKJFPXZdo0hQvk2fv3yGZYS7U4bVmA@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 11:50 PM Michael Paquier <michael@paquier.xyz>\\nwrote:\\n\\n> On Wed, Jan 28, 2026 at 01:34:12PM +0900, Michael Paquier wrote:\\n> > Could you look at the array bound issue please?  Let's use the\\n> > attached as a base of work for now, this is what's standing now at the\\n> > top of my dev branch for the review of the MCV patch.\\n>\\n> By the way, why not just removing entirely most_common_val_nulls from\\n> the input arguments and rely on the values in most_common_vals to\\n> determine which value is NULL?  It seems useless to me to have\\n> most_common_val_nulls knowing that we are relying already on\\n> deconstruct_array_builtin() to determine if the input values are NULL\\n> or not.  That would also simplify the code a lot, especially in\\n> statext_mcv_import() where we check that either the input from\\n> most_common_val_nulls or the nulls array returned by\\n> deconstruct_array_builtin() are NULL to decide if we should check the\\n> input or not.  And that would remove entirely the overread issue,\\n> reducing the input blast.  :)\\n>\\n\\nThe short answer overcaution. The longer answer is we ingest it because\\npg_mcv_list() returns it (\\nhttps://www.postgresql.org/docs/current/functions-statistics.html) and I\\nassumed that it must be necessary for some corner-case input, otherwise why\\nwould pg_mcv_list() export it? In retrospect, its lack of presence in\\npg_stats view should have been a clue that we could get by without it. I'm\\nhappy to rip it out and submit another patchset.\\n"},{"id":"19c0337c883004eb","threadId":"19be99a6948cab2b","snippet":"On Wed, Jan 28, 2026 at 12:44:33AM -0500, Corey Huinker wrote: > The short answer overcaution. The longer answer is we ingest it because > pg_mcv_list() returns it ( > https://www.postgresql.","historyId":"32154","internalDate":"1769580497000","receivedAtUtc":"2026-01-28T06:08:17.000Z","from":"Michael Paquier <michael@paquier.xyz>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<aXmn0biuVWTtu2TF@paquier.xyz>","body":"On Wed, Jan 28, 2026 at 12:44:33AM -0500, Corey Huinker wrote:\\n> The short answer overcaution. The longer answer is we ingest it because\\n> pg_mcv_list() returns it (\\n> https://www.postgresql.org/docs/current/functions-statistics.html) and I\\n> assumed that it must be necessary for some corner-case input, otherwise why\\n> would pg_mcv_list() export it? In retrospect, its lack of presence in\\n> pg_stats view should have been a clue that we could get by without it. I'm\\n> happy to rip it out and submit another patchset.\\n\\nIt seems to me that this comes down to the text[] representation when\\nwe read this data from the catalogs, where we can just rely on NULL\\nbeing in the value, and the official marker in this case:\\nhttps://www.postgresql.org/docs/current/arrays.html#ARRAYS-INPUT\\n\\nThat's what your code relies on already anyway when deconstructing the\\ninput received from the restore function.  Doubling on that with an\\nextra array in input is error-prone IMO, as the overread issue I've\\nspotted today is proving.  The other two 1-dimension arrays for freqs\\nand base_freqs are of course needed, we cannot and should not rebuild\\nthem on-the-fly..\\n\\nFor the in-core initial computation, statext_mcv_build() relies on the\\ndata gathered in StatsBuildData during ANALYZE before building the set\\nof MCV data, where my guess is that it is just more useful to store\\nthis state as-is, and it's been built based on the Datum lookups.\\nPerhaps we have a couple of specific cases where checking for we want\\nsome NULL-ness knowledge?  It would be less expensive than a full\\narray deconstruction, for sure, especially if the MCVs are large text\\nvalues.\\n--\\nMichael\\n"},{"id":"19c033b94674b864","threadId":"19be99a6948cab2b","snippet":"It seems to me that this comes down to the text[] representation when we read this data from the catalogs, where we can just rely on NULL being in the value, and the official marker in this case: https","historyId":"32194","internalDate":"1769580737000","receivedAtUtc":"2026-01-28T06:12:17.000Z","from":"Corey Huinker <corey.huinker@gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<CADkLM=d2pSA+9RqELkYSijBhJrnS2xpt0rmMEq70C5a+7kpBQw@mail.gmail.com>","body":">\\n> It seems to me that this comes down to the text[] representation when\\n> we read this data from the catalogs, where we can just rely on NULL\\n> being in the value, and the official marker in this case:\\n> https://www.postgresql.org/docs/current/arrays.html#ARRAYS-INPUT\\n\\n\\nAnd we're doing a lot of casting ANYARRAY to text throughout this and the\\nattribute stats, so that our assurance that we can live without nulls.\\n\\nPerhaps we have a couple of specific cases where checking for we want\\n> some NULL-ness knowledge?  It would be less expensive than a full\\n> array deconstruction, for sure, especially if the MCVs are large text\\n> values.\\n>\\n\\nIt's a good theory, or maybe the original coder just assumed that the\\ncaller of pg_mcv_list() SRF could lateral-unnest the output and keep only\\nthe interesting columns.\\n\\nRebasing and null-rip-out underway.\\n"},{"id":"19c03a4a7203a437","threadId":"19be99a6948cab2b","snippet":"On Wed, Jan 28, 2026 at 1:12 AM Corey Huinker <corey.huinker@gmail.com> wrote: It seems to me that this comes down to the text[] representation when we read this data from the catalogs, where we","historyId":"32705","internalDate":"1769587619000","receivedAtUtc":"2026-01-28T08:06:59.000Z","from":"Corey Huinker <corey.huinker@gmail.com>","subject":"Re: Extended Statistics set/restore/clear functions.","messageId":"<CADkLM=dgvTvuOy+ZOWQX51gGtLgAmQqqZw7Oi74tWrQ542_bvQ@mail.gmail.com>","body":"On Wed, Jan 28, 2026 at 1:12 AM Corey Huinker <corey.huinker@gmail.com>\\nwrote:\\n\\n>\\n>\\n>> It seems to me that this comes down to the text[] representation when\\n>> we read this data from the catalogs, where we can just rely on NULL\\n>> being in the value, and the official marker in this case:\\n>> https://www.postgresql.org/docs/current/arrays.html#ARRAYS-INPUT\\n>\\n>\\n> And we're doing a lot of casting ANYARRAY to text throughout this and the\\n> attribute stats, so that our assurance that we can live without nulls.\\n>\\n> Perhaps we have a couple of specific cases where checking for we want\\n>> some NULL-ness knowledge?  It would be less expensive than a full\\n>> array deconstruction, for sure, especially if the MCVs are large text\\n>> values.\\n>>\\n>\\n> It's a good theory, or maybe the original coder just assumed that the\\n> caller of pg_mcv_list() SRF could lateral-unnest the output and keep only\\n> the interesting columns.\\n>\\n> Rebasing and null-rip-out underway.\\n>\\n\\nv34\\n\\n- Now with fewer redundant null structures!\\n- Changes to the documentation to reflect the fact that the *name\\nparameters are all text types\\n"}]	The discussion focuses on completing extended statistics set/restore/clear functions for PostgreSQL. Michael Paquier identified and fixed a critical issue where numexprs validation was missing for expressions in ndistinct and dependencies data, causing incorrect rejections of valid input with negative attribute numbers. He discovered a memory overread bug in the MCV (Most Common Values) part when most_common_val_nulls arrays have insufficient elements, demonstrating the issue with boundary checks. Michael suggested removing the most_common_val_nulls parameter entirely, arguing it's redundant since NULL values can be determined directly from most_common_vals using PostgreSQL's standard array NULL representation. Corey Huinker agreed this approach would simplify the code and eliminate the overread issue, explaining the parameter was included out of overcaution because pg_mcv_list() exports it. The latest v34 patch removes the redundant null structures and updates documentation to clarify that name parameters are text types.	2026-01-28 08:06:59+00	讨论重点是完成PostgreSQL的扩展统计信息set/restore/clear函数。Michael Paquier发现并修复了一个关键问题，即在ndistinct和dependencies数据中缺少对表达式的numexprs验证，这导致带有负属性编号的有效输入被错误拒绝。他发现了MCV（最常见值）部分的内存越界读取错误，当most_common_val_nulls数组元素不足时会出现边界检查问题。Michael建议完全删除most_common_val_nulls参数，认为它是多余的，因为可以使用PostgreSQL标准数组NULL表示法直接从most_common_vals确定NULL值。Corey Huinker同意这种方法会简化代码并消除越界读取问题，解释说包含该参数是出于过度谨慎，因为pg_mcv_list()导出了它。最新的v34补丁删除了冗余的null结构，并更新文档以明确name参数是text类型。
33	19be597e72b87c37	Skipping schema changes in publication	["1518981153@qq.com","amit.kapila16@gmail.com","barwick@gmail.com","bharath.rupireddyforpostgres@gmail.com","dilipbalaut@gmail.com","houzj.fnst@fujitsu.com","shlok.kyal.oss@gmail.com","shveta.malik@gmail.com","smithpb2250@gmail.com","vignesh21@gmail.com"]	[{"id":"19c030821b5c06f2","threadId":"19be597e72b87c37","snippet":"On Tue, Jan 27, 2026 at 8:25 PM vignesh C <vignesh21@gmail.com> wrote: > > On Fri, 23 Jan 2026 at 18:41, vignesh C <vignesh21@gmail.com> wrote: > > > > On Wed, 21 Jan 2026","historyId":"31894","internalDate":"1769577367000","receivedAtUtc":"2026-01-28T05:16:07.000Z","from":"shveta malik <shveta.malik@gmail.com>","subject":"Re: Skipping schema changes in publication","messageId":"<CAJpy0uBfEuzYX+qjAPM+GV5duOwMNqO6fkDtsN1OzONVNR9WGQ@mail.gmail.com>","body":"On Tue, Jan 27, 2026 at 8:25 PM vignesh C <vignesh21@gmail.com> wrote:\\n>\\n> On Fri, 23 Jan 2026 at 18:41, vignesh C <vignesh21@gmail.com> wrote:\\n> >\\n> > On Wed, 21 Jan 2026 at 11:35, Dilip Kumar <dilipbalaut@gmail.com> wrote:\\n> > >\\n> > > On Mon, Jan 19, 2026 at 3:08 PM shveta malik <shveta.malik@gmail.com> wrote:\\n> > > >\\n> > > > Approaches for Supporting EXCEPT in Partitioned Tables\\n> > > > ------------------------------------------------------------------------\\n> > > >\\n> > > > In an offline discussion with Peter Smith, Amit, and Shlok, we\\n> > > > identified several approaches for supporting EXCEPT with partitioned\\n> > > > tables and their partitions. I’d like to hear others’ opinions on\\n> > > > these approaches.\\n> > > >\\n> > > > Consider the following partition hierarchy:\\n> > > > tab_root\\n> > > >   ├─ tab_part_1\\n> > > >   │   ├─ tab_part_1_p1\\n> > > >   │   └─ tab_part_1_p2\\n> > > >   └─ tab_part_2\\n> > > >       ├─ tab_part_2_p1\\n> > > >       └─ tab_part_2_p2\\n> > > >\\n> > > >\\n> > > > Approach 1:\\n> > > > ---------------------------------\\n> > > > If we exclude a table, then the data in that table and all of its\\n> > > > partitions (i.e., the entire subtree under that table) should not be\\n> > > > replicated.\\n> > > >\\n> > > > For example EXCEPT (tab_part_1) skips replication of tab_part_1 and\\n> > > > all of its partitions.\\n> > > >\\n> > > > This behaviour remains the same with or without\\n> > > > publish_via_partition_root. The publish_via_partition_root flag only\\n> > > > affects publish_via_relid, i.e., the relation through which data is\\n> > > > published.\\n> > > >\\n> > > > This approach involves certain implementation challenges. For brevity,\\n> > > > these are documented in the attached 'Approach1_challenges' document.\\n> > > >\\n> > > > Approach 2:\\n> > > > ---------------------------------------------------\\n> > > > Assign meaning to ONLY and '*' for partition tables in the EXCEPT\\n> > > > list. In HEAD, ONLY and '*' do not have any meaning for partitioned\\n> > > > tables or partitions, and these keywords are currently ignored.\\n> > > >\\n> > > > Examples:\\n> > > > 1. EXCEPT (ONLY tab_part_1) skips replication of only the table\\n> > > > tab_part_1. Changes for tab_root, tab_part_1_p1, and tab_part_1_p2 are\\n> > > > still replicated.\\n> > > >\\n> > > > ii. EXCEPT (tab_part_1*) skips replication of tables tab_part_1,\\n> > > > tab_part_1_p1, and tab_part_1_p2\\n> > > >\\n> > > > The challenges described in Approach 1, particularly around tablesync\\n> > > > handling and COPY behaviour, would still need to be addressed under\\n> > > > this approach as well. ONLY or '*' with partitioned tables is not\\n> > > > supported in HEAD, supporting it specifically for ALL TABLES EXCEPT\\n> > > > may introduce additional confusion for users.\\n> > > >\\n> > > > Approach 3:\\n> > > > ----------------\\n> > > > Do not allow partitions to be specified in the EXCEPT clause.\\n> > > >\\n> > > > Only EXCEPT (tab_root) is supported, which excludes tab_root and all\\n> > > > of its partitions. Specifying EXCEPT (tab_part_1) or EXCEPT\\n> > > > (tab_part_1_p1) will result in an error.\\n> > > >\\n> > > > ~~\\n> > > >\\n> > > > While Approach 1 and Approach 2 offer more flexibility to the user\\n> > > > compared to Approach 3, they also introduce additional design\\n> > > > complexity which does not seem simpler to address.\\n> > >\\n> > > Thanks for explaining this, overall I like the Approach 1, and I also\\n> > > see the problem when publish via root is given in that case COPY FROM\\n> > > is executed on the root and it would be hard to exclude specific\\n> > > partitions.\\n> >\\n> > Regarding the above issue which is also mentioned in\\n> > Approach1_challenges at [1]:\\n> > When a publication is created with publish_via_partition_root = true\\n> > and a specific partition(tab_part_1_1) is excluded, the expected\\n> > behavior is that changes from non-excluded partitions (for example,\\n> > tab_part_2 and tab_part_1_2 and their descendants) are replicated,\\n> > while changes from the excluded partition (tab_part_1_1 and its\\n> > subtree) are not.\\n> > tab_root\\n> > ├── tab_part_1\\n> > │   ├── tab_part_1_1        (except)\\n> > │   │   ├── tab_part_1_1_1\\n> > │   │   │   └── tab_part_1_1_1_1\\n> > │   │   └── tab_part_1_1_2\\n> > │   └── tab_part_1_2\\n> > │       ├── tab_part_1_2_1\\n> > │       └── tab_part_1_2_2\\n> > └── tab_part_2\\n> >\\n> > In this situation, replication cannot be performed purely via the\\n> > partition root (tab_root), because doing so would implicitly include\\n> > data from the excluded child partitions.\\n> >\\n> > To address this, the publication creation should explicitly record the\\n> > excluded partition(tab_part_1_1) in pg_publication_rel with an\\n> > excluded = true flag. The publish_via_partition_root setting remains\\n> > stored at the publication level, as it is today. With\\n> > publish_via_partition_root = true, the publisher–subscriber mapping is\\n> > not partition-to-partition. Instead, all eligible data is mapped to\\n> > the subscriber’s partition root. Therefore,\\n> > pg_get_publication_tables() should return only the top-level root\\n> > table (tab_root) to the subscriber for table synchronization. During\\n> > initial table sync, when the tablesync worker prepares the COPY\\n> > command, it can query the publisher to determine the effective set of\\n> > tables that belong to the publication after applying the exclusion\\n> > rules. Based on this resolved table list, the tablesync worker can\\n> > construct a COPY query that unions data only from the non-excluded\\n> > partitions, for example:\\n> > COPY (\\n> >     SELECT * FROM tab_part_1_2_1\\n> >     UNION ALL\\n> >     SELECT * FROM tab_part_1_2_2\\n> >     UNION ALL\\n> >     SELECT * FROM tab_part_2\\n> > )\\n> >\\n> > This ensures that only non-excluded data is copied and applied to\\n> > tab_root on the subscriber, while preserving the semantics of\\n> > publish_via_partition_root = true.\\n\\nI agree with the suggested changes in tablesync. It will be good if we\\ncan add these details in the commit-msg section of the patch. Also\\nplease mention how increment replication is impacted (or supposed to\\nwork) with Approach1.\\n\\n> Here is a patch which has the changes to handle the same.\\n>\\n\\nThank You for the patch.\\n\\n1)\\nThere are certain parts of Approach 3 still present in Approach 1, as\\nan example:\\n\\n1a)\\n+      For partitioned tables, only the root partitioned table may be specified\\n+      in <literal>EXCEPT TABLE</literal>.\\n\\n1b)\\n+ /*\\n+ * Only the topmost ancestor of a partitioned table can be specified\\n+ * in EXCEPT TABLES clause of a FOR ALL TABLES publication. So fetch\\n+ * the publications excluding the topmost ancestor only.\\n+ */\\n+ GetRelationPublications(llast_oid(ancestors), NULL, &exceptpuboids);\\n+\\n\\n1c)\\n+ /* Check if the partiton is part of EXCEPT list of any publication */\\n+ GetRelationPublications(RelationGetRelid(attachrel), NULL, &except_pubids);\\n+ if (except_pubids != NIL)\\n+ ereport(ERROR,\\n+ (errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE),\\n+ errmsg(\\"cannot attach relation \\\\\\"%s\\\\\\" as partition because it is\\npart of EXCEPT list in publication\\",\\n+ RelationGetRelationName(attachrel))));\\n+\\n\\nOverall, please take a diff of v35 and v37 to find such parts and\\nplease correct these and others (if any).\\n\\n2)\\nAlso I don't think if below is correct statement for Approach 1:\\n\\n+ * 2. For a partition, if the topmost ancestor is part of\\n+ *   the EXCEPT TABLE list, we don't publish it.\\n\\nEven if any ancestor is part of EXECPT list (not only top most) we\\nshould not publish that partition, isn't it?\\n\\n3)\\nI tried a scenario and found that incremental replication is not\\nworking correctly. Attached the failing test as Approach1_v37_fail.txt\\n\\nOnce these basic things are corrected, I can review further.\\n\\nthanks\\nShveta\\n"}]	Shveta Malik is reviewing vignesh C's patch for supporting EXCEPT with partitioned tables in PostgreSQL publications. The discussion centers on three approaches: Approach 1 allows excluding any partition and its subtree, Approach 2 uses ONLY and '*' keywords for partition exclusion, and Approach 3 restricts exclusions to root partitioned tables only. Vignesh submitted a patch implementing Approach 1, which handles the complexity of publish_via_partition_root by storing excluded partitions in pg_publication_rel and using UNION ALL queries during tablesync to copy only non-excluded data. Shveta identified several issues in the v37 patch: remnants of Approach 3 code still present, incorrect logic that only checks topmost ancestors instead of any ancestors in the EXCEPT list, and failing incremental replication functionality. She requests corrections to these basic issues before further review can proceed.	2026-01-28 05:16:07+00	Shveta Malik正在审查vignesh C为PostgreSQL发布中分区表的EXCEPT支持提交的补丁。讨论围绕三种方法展开：方法1允许排除任何分区及其子树，方法2使用ONLY和'*'关键字进行分区排除，方法3将排除限制为仅根分区表。Vignesh提交了实现方法1的补丁，该方法通过在pg_publication_rel中存储被排除的分区，并在tablesync期间使用UNION ALL查询仅复制未排除的数据来处理publish_via_partition_root的复杂性。Shveta在v37补丁中发现了几个问题：仍然存在方法3的代码残留，仅检查最顶层祖先而非EXCEPT列表中任何祖先的错误逻辑，以及增量复制功能失效。她要求在进行进一步审查前先修正这些基本问题。
\.


--
-- Data for Name: github_hacker_discussions; Type: TABLE DATA; Schema: public; Owner: n8n-user
--

COPY public.github_hacker_discussions (subject, issueid, url, lastupdate) FROM stdin;
Remaining dependency on setlocale()	4	https://api.github.com/repos/IvorySQL/PGNexus/issues/4	2026-01-27 20:11:41+00
Fix accidentally cast away qualifiers	5	https://api.github.com/repos/IvorySQL/PGNexus/issues/5	\N
proposal: parentid and naturalid for plpgsql nodes	6	https://api.github.com/repos/IvorySQL/PGNexus/issues/6	\N
DOC: fixes multiple errors in alter table doc	10	https://api.github.com/repos/IvorySQL/PGNexus/issues/10	\N
[PATCH] ANALYZE: hash-accelerate MCV tracking for equality-only types	11	https://api.github.com/repos/IvorySQL/PGNexus/issues/11	\N
Report bytes and transactions actually sent downtream	122	https://github.com/IvorySQL/PGNexus/issues/122	\N
Proposal: Cascade REPLICA IDENTITY changes to leaf partitions	124	https://github.com/IvorySQL/PGNexus/issues/124	\N
Remove redundant AssertVariableIsOfType uses in pg_upgrade	13	https://api.github.com/repos/IvorySQL/PGNexus/issues/13	2026-01-24 00:30:19+00
Implement waiting for wal lsn replay: reloaded	125	https://github.com/IvorySQL/PGNexus/issues/125	\N
commented out code	17	https://api.github.com/repos/IvorySQL/PGNexus/issues/17	2026-01-24 00:30:19+00
let ALTER COLUMN SET DATA TYPE cope with trigger dependency	19	https://api.github.com/repos/IvorySQL/PGNexus/issues/19	2026-01-24 00:30:19+00
[PATCH] psql: add \\dcs to list all constraints	21	https://api.github.com/repos/IvorySQL/PGNexus/issues/21	2026-01-24 00:30:19+00
CREATE TABLE LIKE INCLUDING TRIGGERS	22	https://api.github.com/repos/IvorySQL/PGNexus/issues/22	2026-01-24 00:30:19+00
Change COPY ... ON_ERROR ignore to ON_ERROR ignore_row	16	https://api.github.com/repos/IvorySQL/PGNexus/issues/16	2026-01-24 00:30:19+00
SQL Property Graph Queries (SQL/PGQ)	23	https://api.github.com/repos/IvorySQL/PGNexus/issues/23	2026-01-24 00:30:19+00
SQL:2011 Application Time Update & Delete	24	https://api.github.com/repos/IvorySQL/PGNexus/issues/24	2026-01-24 00:30:19+00
Mystery with REVOKE PRIVILEGE	26	https://api.github.com/repos/IvorySQL/PGNexus/issues/26	2026-01-24 00:30:19+00
Likely undefined behavior with some flexible arrays	27	https://api.github.com/repos/IvorySQL/PGNexus/issues/27	2026-01-24 00:30:19+00
ReadRecentBuffer() doesn't scale well	29	https://api.github.com/repos/IvorySQL/PGNexus/issues/29	2026-01-24 00:30:19+00
Flush some statistics within running transactions	30	https://api.github.com/repos/IvorySQL/PGNexus/issues/30	2026-01-24 00:30:19+00
refactor architecture-specific popcount code	33	https://api.github.com/repos/IvorySQL/PGNexus/issues/33	2026-01-24 00:30:19+00
Speed up COPY FROM text/CSV parsing using SIMD	34	https://api.github.com/repos/IvorySQL/PGNexus/issues/34	2026-01-24 00:30:19+00
pg_plan_advice	123	https://github.com/IvorySQL/PGNexus/issues/123	2026-01-29 00:42:42+00
pgsql: Prevent invalidation of newly synced replication slots.	121	https://github.com/IvorySQL/PGNexus/issues/121	2026-01-29 00:42:42+00
Skipping schema changes in publication	18	https://api.github.com/repos/IvorySQL/PGNexus/issues/18	2026-01-29 00:42:42+00
Inval reliability, especially for inplace updates	38	https://github.com/IvorySQL/PGNexus/issues/38	\N
Patch: dumping tables data in multiple chunks in pg_dump	28	https://api.github.com/repos/IvorySQL/PGNexus/issues/28	2026-01-25 00:45:01+00
Assert the timestamp is available for ORIGN_DIFFERS conflicts	20	https://api.github.com/repos/IvorySQL/PGNexus/issues/20	2026-01-25 00:45:01+00
tablecmds: reject CLUSTER ON for partitioned tables earlier	8	https://api.github.com/repos/IvorySQL/PGNexus/issues/8	2026-01-25 00:45:01+00
Race conditions in logical decoding	35	https://api.github.com/repos/IvorySQL/PGNexus/issues/35	2026-01-25 00:45:01+00
ALTER TABLE: warn when actions do not recurse to partitions	37	https://api.github.com/repos/IvorySQL/PGNexus/issues/37	2026-01-25 00:45:01+00
Use correct collation in pg_trgm	7	https://api.github.com/repos/IvorySQL/PGNexus/issues/7	2026-01-25 00:45:01+00
Remove PG_MMAP_FLAGS	36	https://api.github.com/repos/IvorySQL/PGNexus/issues/36	2026-01-26 00:30:21+00
Add WALRCV_CONNECTING state to walreceiver	12	https://api.github.com/repos/IvorySQL/PGNexus/issues/12	2026-01-26 00:30:21+00
Adding REPACK [concurrently]	15	https://api.github.com/repos/IvorySQL/PGNexus/issues/15	2026-01-26 00:30:21+00
Newly created replication slot may be invalidated by checkpoint	57	https://github.com/IvorySQL/PGNexus/issues/57	2026-01-27 20:11:41+00
trivial designated initializers	126	https://github.com/IvorySQL/PGNexus/issues/126	\N
Document NULL	127	https://github.com/IvorySQL/PGNexus/issues/127	\N
[BUG] [PATCH] Allow physical replication slots to recover from archive after invalidation	39	https://github.com/IvorySQL/PGNexus/issues/39	\N
Extensible storage manager API - SMGR hook Redux	40	https://github.com/IvorySQL/PGNexus/issues/40	\N
[PATCH] llvmjit: always add the simplifycfg pass	42	https://github.com/IvorySQL/PGNexus/issues/42	\N
Having problems generating a code coverage report	43	https://github.com/IvorySQL/PGNexus/issues/43	\N
Assert when executing query on partitioned table	45	https://github.com/IvorySQL/PGNexus/issues/45	\N
UPDATE run check constraints for affected columns only	46	https://github.com/IvorySQL/PGNexus/issues/46	2026-01-25 00:45:01+00
Limit memory usage by postgres_fdw batches	50	https://github.com/IvorySQL/PGNexus/issues/50	2026-01-25 00:45:01+00
Refactor recovery conflict signaling a little	47	https://github.com/IvorySQL/PGNexus/issues/47	2026-01-25 00:45:01+00
Fix a typo in comment	48	https://github.com/IvorySQL/PGNexus/issues/48	2026-01-25 00:45:01+00
DOCS - "\\d mytable" also shows any publications that publish mytable	49	https://github.com/IvorySQL/PGNexus/issues/49	2026-01-25 00:45:01+00
pg_upgrade: optimize replication slot caught-up check	53	https://github.com/IvorySQL/PGNexus/issues/53	2026-01-25 00:45:01+00
Remove redundant initialization of smgr pointer for relcache	54	https://github.com/IvorySQL/PGNexus/issues/54	2026-01-25 00:45:01+00
warning: dereferencing type-punned pointer	55	https://github.com/IvorySQL/PGNexus/issues/55	2026-01-25 00:45:01+00
Hackorum - a new mailing list frontend	56	https://github.com/IvorySQL/PGNexus/issues/56	2026-01-25 00:45:01+00
[PATCH] Avoid potential NULL dereference in LIKE/ILIKE with C locale	58	https://github.com/IvorySQL/PGNexus/issues/58	2026-01-25 00:45:01+00
Reduce build times of pg_trgm GIN indexes	60	https://github.com/IvorySQL/PGNexus/issues/60	2026-01-25 00:45:01+00
New year, new commitfest app improvements	84	https://github.com/IvorySQL/PGNexus/issues/84	\N
Some tests for TOAST, STORAGE MAIN/EXTENDED	97	https://github.com/IvorySQL/PGNexus/issues/97	\N
Fix gistkillitems & add regression test to microvacuum	63	https://github.com/IvorySQL/PGNexus/issues/63	2026-01-25 00:45:01+00
Deadlock detector fails to activate on a hot standby replica	64	https://github.com/IvorySQL/PGNexus/issues/64	2026-01-25 00:45:01+00
Checkpointer write combining	65	https://github.com/IvorySQL/PGNexus/issues/65	2026-01-25 00:45:01+00
pg_waldump: support decoding of WAL inside tarfile	66	https://github.com/IvorySQL/PGNexus/issues/66	2026-01-25 00:45:01+00
Is abort() still needed in WalSndShutdown()?	67	https://github.com/IvorySQL/PGNexus/issues/67	2026-01-25 00:45:01+00
Non-text mode for pg_dumpall	68	https://github.com/IvorySQL/PGNexus/issues/68	2026-01-25 00:45:01+00
Optimize IS DISTINCT FROM with non-nullable inputs	69	https://github.com/IvorySQL/PGNexus/issues/69	2026-01-25 00:45:01+00
Auto-tune shared_buffers to use available huge pages	70	https://github.com/IvorySQL/PGNexus/issues/70	2026-01-25 00:45:01+00
WIP - xmlvalidate implementation from TODO list	71	https://github.com/IvorySQL/PGNexus/issues/71	2026-01-25 00:45:01+00
display hot standby state in psql prompt	52	https://github.com/IvorySQL/PGNexus/issues/52	2026-01-25 00:45:01+00
More speedups for tuple deformation	72	https://github.com/IvorySQL/PGNexus/issues/72	2026-01-25 00:45:01+00
Fix rounding method used to compute huge pages	31	https://api.github.com/repos/IvorySQL/PGNexus/issues/31	2026-01-25 00:45:01+00
Import Statistics in postgres_fdw before resorting to sampling.	14	https://api.github.com/repos/IvorySQL/PGNexus/issues/14	2026-01-25 00:45:01+00
Time to add FIDO2 support?	74	https://github.com/IvorySQL/PGNexus/issues/74	2026-01-25 00:45:01+00
Unstable path in index regress test query	76	https://github.com/IvorySQL/PGNexus/issues/76	2026-01-25 00:45:01+00
Don't synchronously wait for already-in-progress IO in read stream	78	https://github.com/IvorySQL/PGNexus/issues/78	2026-01-25 00:45:01+00
[PATCH] tests: verify renamed index functionality in alter_table	79	https://github.com/IvorySQL/PGNexus/issues/79	2026-01-25 00:45:01+00
[PATCH] Reserve protocol 3.1 explicitly in pqcomm.h	80	https://github.com/IvorySQL/PGNexus/issues/80	2026-01-25 00:45:01+00
unnecessary executor overheads around seqscans	92	https://github.com/IvorySQL/PGNexus/issues/92	2026-01-27 20:11:41+00
[PATCH] Refactor *_abbrev_convert() functions	94	https://github.com/IvorySQL/PGNexus/issues/94	2026-01-26 00:30:21+00
[oauth] Stabilize the libpq-oauth ABI (and allow alternative implementations?)	87	https://github.com/IvorySQL/PGNexus/issues/87	2026-01-26 00:30:21+00
ON CONFLICT DO SELECT (take 3)	77	https://github.com/IvorySQL/PGNexus/issues/77	2026-01-26 00:30:21+00
[PATCH] Align verify_heapam.c error message offset with test expectations	41	https://github.com/IvorySQL/PGNexus/issues/41	2026-01-26 00:30:21+00
libpq: Bump protocol version to version 3.2 at least until the first/second beta	88	https://github.com/IvorySQL/PGNexus/issues/88	2026-01-26 00:30:21+00
proposal: plpgsql - FOREACH t IN JSON ARRAY expr	89	https://github.com/IvorySQL/PGNexus/issues/89	2026-01-26 00:30:21+00
unclear OAuth error message	90	https://github.com/IvorySQL/PGNexus/issues/90	2026-01-26 00:30:21+00
Converting README documentation to Markdown	91	https://github.com/IvorySQL/PGNexus/issues/91	2026-01-26 00:30:21+00
Time to drop RADIUS support?	75	https://github.com/IvorySQL/PGNexus/issues/75	2026-01-26 00:30:21+00
Add SQL/JSON ON MISMATCH clause to JSON_VALUE	93	https://github.com/IvorySQL/PGNexus/issues/93	2026-01-26 00:30:21+00
Proposal: Adding compression of temporary files	73	https://github.com/IvorySQL/PGNexus/issues/73	2026-01-26 00:30:21+00
alignas (C11)	82	https://github.com/IvorySQL/PGNexus/issues/82	2026-01-26 00:30:21+00
Optional skipping of unchanged relations during ANALYZE?	9	https://api.github.com/repos/IvorySQL/PGNexus/issues/9	2026-01-26 00:30:21+00
Buffer locking is special (hints, checksums, AIO writes)	98	https://github.com/IvorySQL/PGNexus/issues/98	\N
AIX support	25	https://api.github.com/repos/IvorySQL/PGNexus/issues/25	2026-01-29 00:42:42+00
eliminate xl_heap_visible to reduce WAL (and eventually set VM on-access)	86	https://github.com/IvorySQL/PGNexus/issues/86	2026-01-29 00:42:42+00
Proposal: Conflict log history table for Logical Replication	62	https://github.com/IvorySQL/PGNexus/issues/62	2026-01-29 00:42:42+00
Custom oauth validator options	85	https://github.com/IvorySQL/PGNexus/issues/85	2026-01-29 00:42:42+00
Extended Statistics set/restore/clear functions.	51	https://github.com/IvorySQL/PGNexus/issues/51	2026-01-29 00:42:42+00
docs: clarify ALTER TABLE behavior on partitioned tables	59	https://github.com/IvorySQL/PGNexus/issues/59	2026-01-27 01:01:21+00
ABI Compliance Checker GSoC Project	96	https://github.com/IvorySQL/PGNexus/issues/96	2026-01-26 00:30:21+00
[PATCH] Add monitoring guidance to replication slot documentation	99	https://github.com/IvorySQL/PGNexus/issues/99	\N
pg_stat_statements: add missing tests for nesting_level	100	https://github.com/IvorySQL/PGNexus/issues/100	\N
Fix a reference error for window functions: In the function 'find_window_functions', the deduplication logic should be removed	101	https://github.com/IvorySQL/PGNexus/issues/101	\N
[BUG] [PATCH] pg_basebackup produces wrong incremental files after relation truncation in segmented tables	102	https://github.com/IvorySQL/PGNexus/issues/102	\N
RFC: adding pytest as a supported test framework	103	https://github.com/IvorySQL/PGNexus/issues/103	\N
Cleaning up PREPARE query strings?	104	https://github.com/IvorySQL/PGNexus/issues/104	\N
RFC: Allow EXPLAIN to Output Page Fault Information	105	https://github.com/IvorySQL/PGNexus/issues/105	\N
[PATCH] Replace COUNT(NULL) with '0'::bigint	106	https://github.com/IvorySQL/PGNexus/issues/106	\N
Make copyObject work in C++	108	https://github.com/IvorySQL/PGNexus/issues/108	\N
Add GoAway protocol message for graceful but fast server shutdown/switchover	109	https://github.com/IvorySQL/PGNexus/issues/109	\N
Safer hash table initialization macro	110	https://github.com/IvorySQL/PGNexus/issues/110	\N
Exit walsender before confirming remote flush in logical replication	119	https://github.com/IvorySQL/PGNexus/issues/119	2026-01-29 00:42:42+00
Issues with ON CONFLICT UPDATE and REINDEX CONCURRENTLY	107	https://github.com/IvorySQL/PGNexus/issues/107	2026-01-27 01:01:21+00
Parallel CREATE INDEX for GIN indexes	120	https://github.com/IvorySQL/PGNexus/issues/120	\N
\.


--
-- Data for Name: news_feeds; Type: TABLE DATA; Schema: public; Owner: n8n-user
--

COPY public.news_feeds (jobid, subject, source, pubdate, messages, summary, summary_zh) FROM stdin;
\.


--
-- Data for Name: poll_ts; Type: TABLE DATA; Schema: public; Owner: n8n-user
--

COPY public.poll_ts (jobtype, last_poll_ts) FROM stdin;
rss	2026-01-29 00:39:02.444+00
email	2026-01-29 00:42:21.586+00
\.


--
-- Data for Name: rss_feeds; Type: TABLE DATA; Schema: public; Owner: n8n-user
--

COPY public.rss_feeds (jobid, title, url, author, pubdate, content, snippet, summary, summary_zh) FROM stdin;
4	Using the shared plan cache for Amazon Aurora PostgreSQL	https://aws.amazon.com/blogs/database/using-the-shared-plan-cache-for-amazon-aurora-postgresql/	Stephen Wood	2026-01-20 20:21:19+00	\N	In this post, we discuss how the Shared Plan Cache feature of the Amazon Aurora PostgreSQL-Compatible Edition can significantly reduce memory consumption of generic SQL plans in high-concurrency environments, transforming what could be a 40GB memory overhead into a manageable 400MB footprint.\n \nImagine your Aurora PostgreSQL database cluster is serving thousands of concurrent connections, each executing the same prepared statements. You notice memory usage increasing to tens of gigabytes, yet the queries themselves are simple. What's happening? You're likely experiencing the hidden cost of plan duplication, a problem that the shared plan cache can elegantly solve.\n \nUnderstanding generic plans in PostgreSQL\n \nPrepared statements are commonly used in applications (when they define functions or methods that interact with the database), where these statements are included in their database access code/methods. The preparation phase includes both the SQL statement structure and placeholders, which will be filled with actual values when the application executes the prepared statement. In the preparation phase, the statement is parsed, analyzed and rewritten, thereby saving on repetitive parsing and analyzing work when it is executed.\n \nBefore diving into the solution, let's understand how PostgreSQL handles prepared statements. In PostgreSQL and Aurora PostgreSQL, prepared statements can be executed using two types of plans:\n \n \n \nCustom plans: Created fresh for each execution with specific parameter values where literals are included.\n \n \nGeneric plans: Parameter-independent plans that are reused across executions where literals are not included.\n \n \nBy default, PostgreSQL uses an intelligent approach to decide between these two plan types:\n \n \n \nThe first five executions of a prepared statement use custom plans\n \n \nThe average cost of these custom plans is calculated\n \n \nOn the sixth execution, a generic plan is created\n \n \nIf the generic plan's cost is comparable to or better than the average custom plan cost, it's used for subsequent executions\n \n \nThis approach saves planning time for frequently executed queries, but it comes with a hidden cost in environments with many concurrent database connections.\n \nThe problem: memory inefficiency at scale\n \nWhile this approach works well for individual connections, it creates two significant inefficiencies in environments with many concurrent database connections:\n \n \n \nUnnecessary plan generation: Even when a generic plan won't be used (because custom plans are more efficient), the system still creates and stores it in memory for cost comparison purposes. For example, for partitioned tables, there is a higher chance of a generic plan not being used because the cost is calculated for the leaf partitions and then summed up.\n \n \nPlan duplication: When the same query is executed across hundreds or thousands of sessions, each session maintains its own copy of the identical generic plan, leading to massive memory duplication.\n \n \nLet's demonstrate this problem with a concrete example:\n \nSetting up the test environment\n \nFor this example, we create 2 tables t1 and t2 each with 1000 partitions in a new session. We then insert 100,000 rows into each table by looping 100 times with each loop iteration inserting 1000 values. We finally gather fresh statistics on both tables.\n \nNote: In order to use the shared plan cache feature you must be using Aurora PostgreSQL version 17.6 and later or version 16.10 and later.\n \n \n \n-- Create partitioned tables\nCREATE TABLE t1(part_key int, c1 int) PARTITION BY RANGE(part_key);\nCREATE TABLE t2(part_key int, c1 int) PARTITION BY RANGE(part_key);\n\n\\pset pager\n\n-- Generate 1000 partitions for each table (simulating large-scale partitioning)\nSELECT 'CREATE TABLE t1_' || x || ' PARTITION OF t1 FOR VALUES FROM (' || x || ') TO (' || x+1 || ')'\nFROM generate_series(1, 1000) x;\n\\gexec\n\nSELECT 'CREATE TABLE t2_' || x || ' PARTITION OF t2 FOR VALUES FROM (' || x || ') TO (' || x+1 || ')'\nFROM generate_series(1, 1000) x;\n\\gexec\n\n-- Populate tables with sample data\nDO\n$do$\nBEGIN\nFOR i IN 1..100 LOOP\nINSERT INTO t1 SELECT x, i FROM generate_series(1, 1000) x;\nINSERT INTO t2 SELECT x, i FROM generate_series(1, 1000) x;\nEND LOOP;\nEND\n$do$;\n\n-- Update statistics for optimal query planning\nANALYZE t1, t2;\n \n \nYou can use the \\gexec switch here to run the output of our select as an independent SQL statement. You can disable the psql pager using \\pset pager to avoid having to hit enter multiple times when creating your table partitions.\n \nObserving memory consumption\n \nIn Session 1, we create and execute the following prepared statement:\n \n \n \n-- Create a prepared statement with a simple join\nPREPARE p2(int, int) AS \nSELECT sum(t1.c1) \nFROM t1, t2 \nWHERE t1.part_key = t2.part_key \nAND t1.c1 = $1 \nAND t1.part_key = $2;\n\n-- Execute 6 times to trigger generic plan creation\nEXECUTE p2(1, 4); -- Execution 1: Custom plan\nEXECUTE p2(1, 4); -- Execution 2: Custom plan\nEXECUTE p2(1, 4); -- Execution 3: Custom plan\nEXECUTE p2(1, 4); -- Execution 4: Custom plan\nEXECUTE p2(1, 4); -- Execution 5: Custom plan\nEXECUTE p2(1, 4); -- Execution 6: Generic plan created\n \n \nThen, we check the memory consumption:\n \n \n \n-- Check memory usage for cached plans\nSELECT name, ident, pg_size_pretty(total_bytes) as size\nFROM pg_backend_memory_contexts \nWHERE name = 'CachedPlan';\n-[ RECORD 1 ]-+---------------------------------------\nname | CachedPlan\nident | prepare p2(int, int) as +\n| select sum(t1.c1) +\n| from t1, t2 +\n| where t1.part_key = t2.part_key and +\n| t1.c1 = $1 and t1.part_key = $2;\nsize | 4161 kB\n \n \nFor this test we observe that the generic plan consumes approximately 4MB and remains in memory until the prepared statement is deallocated or the connection terminates.\n \nThe duplication problem\n \nNow, let's use another session (Session 2) and execute the same prepared statement:\n \n \n \n-- Session 2: Using the same prepared statement\nPREPARE p2(int, int) AS \nSELECT sum(t1.c1) \nFROM t1, t2 \nWHERE t1.part_key = t2.part_key \nAND t1.c1 = $1 \nAND t1.part_key = $2;\n\n-- Execute 6 times\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\n\n-- Check memory usage\nSELECT name, ident, pg_size_pretty(total_bytes) as size\nFROM pg_backend_memory_contexts \nWHERE name = 'CachedPlan';\n\n-[ RECORD 1 ]-+---------------------------------------\nname | CachedPlan\nident | prepare p2(int, int) as +\n| select sum(t1.c1) +\n| from t1, t2 +\n| where t1.part_key = t2.part_key and +\n| t1.c1 = $1 and t1.part_key = $2; \nsize | 4161 kB\n \n \nSession 2 also consumes 4MB for the exact same generic plan!\n \nThe multiplication effect\n \nThis duplication happens for every session that executes the prepared statement. Let's calculate the impact:\n \n \n \n1 prepared statement × 100 connections × 4MB = 400MB of memory\n \n \n100 different prepared statements × 100 connections × 4MB = 40GB of memory\n \n \nThis massive memory consumption occurs even though the sessions are storing identical copies of the same generic plan. In environments with many concurrent database connections, this can quickly exhaust available memory and force you to use larger, more expensive instance types.\n \nThe solution: Aurora PostgreSQL Shared Plan Cache\n \nAurora PostgreSQL solves this with shared plan cache (SPC), which keeps just one copy of each generic plan that the sessions can use. This dramatically reduces memory consumption while maintaining the performance benefits of plan caching.\n \nYou can enable the shared plan cache(SPC) using a cluster or instance parameter group:\n \napg_shared_plan_cache.enable = ON\n \nBecause apg_shared_plan_cache.enable is a dynamic parameter you don't have to restart the instance for the changes to take effect.\n \nSPC is implemented as a dynamic hash table, shared across the sessions, where the number of entries in the cache can be controlled by via apg_shared_plan_cache.max. You can also use the following parameters to control the minimum and the maximum size of an entry.\n \n \n \napg_shared_plan_cache.min_size_per_entry\napg_shared_plan_cache.max_size_per_entry\n \n \nDemonstrating the Shared Plan Cache in action\n \nLet's repeat our earlier experiment with the shared plan cache enabled:\n \nSession 1 (First Connection):\n \n \n \n-- Create and execute the same prepared statement\nPREPARE p2(int, int) AS \nSELECT sum(t1.c1) \nFROM t1, t2 \nWHERE t1.part_key = t2.part_key \nAND t1.c1 = $1 \nAND t1.part_key = $2;\n\n-- Execute 6 times\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\n\n-- Check memory usage\nSELECT name, ident, pg_size_pretty(total_bytes) as size\nFROM pg_backend_memory_contexts \nWHERE name = 'CachedPlan';\n \n \nThe first session still shows the 4MB plan in its local memory (needed to populate the shared cache).\n \nSession 2 (Subsequent Connection):\n \n \n \n-- Create the same prepared statement\nPREPARE p2(int, int) AS \nSELECT sum(t1.c1) \nFROM t1, t2 \nWHERE t1.part_key = t2.part_key \nAND t1.c1 = $1 \nAND t1.part_key = $2;\n\n-- Execute 6 times\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\nEXECUTE p2(1, 4);\n\n-- Check memory usage\nSELECT name, ident, pg_size_pretty(total_bytes) as size\nFROM pg_backend_memory_contexts \nWHERE name = 'CachedPlan';\n(0 rows)\n \n \nNo local plan storage! The second session is using the shared plan cache.\n \nMonitoring cache usage\n \nWe run the following SQL to show how many cache hits individual shared plans stored in our cache have received. Every hit represents a plan that has not needed to be duplicated in session memory.\n \n \n \n-- View shared plan cache statistics\nSELECT cache_key, query, hits\nFROM apg_shared_plan_cache();\n-[ RECORD 1 ]-------------------------------------\ncache_key | -5127257242415815179\nquery | prepare p2(int, int) as +\n| select sum(t1.c1) +\n| from t1, t2 +\n| where t1.part_key = t2.part_key and +\n| t1.c1 = $1 and t1.part_key = $2;\nhits | 2\n\n \n \nCleanup:\n \n \n \n-- clear the cache\nSELECT * FROM apg_shared_plan_cache_reset();\n\n-- drop the tables\nDROP TABLE t1;\nDROP TABLE t2;\n\n \n \nPerformance impact\n \nIn our example scenario with 100 different prepared statements across 100 connections, we observed a transformation from 40GB of duplicated plan storage down to just 400MB in the shared cache. The screenshot below shows a graph of the Freeable Memory Cloudwatch metric obtained from an instance where a test was run using pgbench with 100 distinct prepared statements (used from the example above) across 100 connections with apg_shared_plan_cache.enable = off. We can observe that between 02:05 and 02:10, FreeableMemory drops by approximately 40GB, which aligns with our expected duplicated plan storage footprint. When we enabled shared plan cache and ran the same test again, the memory impact was drastically reduced, requiring only a small amount of memory instead of 40GB.\n \n\n \nThis reduction means you can:\n \n \n \nRun the same workload on smaller instances, significantly reducing your AWS costs\n \n \nSupport more concurrent connections without hitting memory limits\n \n \nAvoid out-of-memory errors during traffic spikes\n \n \nBest practices\n \nThis feature is particularly beneficial when:\n \n \n \nYour application maintains hundreds or thousands of database connections\n \n \nYou use prepared statements extensively\n \n \nYour queries involve partitioned tables or complex operators (for example joins and common table expressions) that generate large plans\n \n \nYou observe high memory usage from backend processes\n \n \nYour workload has repetitive query patterns with parameterized queries\n \n \nWhile Shared Plan Cache offers significant benefits, note that this feature may not be suited for the following scenarios:\n \n \n \nWorkloads with highly unique, ad-hoc queries\n \n \nApplications that rarely reuse prepared statements\n \n \nEnvironments with few concurrent connections\n \n \nConclusion\n \nIn this post we showed you how you can enable the shared plan cache in Aurora PostgreSQL. We have shown that when using prepared statements across many concurrent database sessions, you save the same generic query plan being duplicated in memory.\n \nBy removing redundant plan storage across sessions, you can run more connections on smaller instances, reducing both operational complexity and costs. For further details on the different plan types see the PostgreSQL documentation on the prepare statement and Amazon Cloudwatch metrics for Amazon Aurora for further details on measuring freeable memory.\n \n \nAbout the authors\n \n \n \n \n  \n \n  \nSouvik Bhattacherjee\n \n  \nSouvik is a Senior Software Engineer at AWS where he focuses on advancing query processing capabilities in the Aurora PostgreSQL database. He has over 8 years of experience in the database/HPC industry where he contributed to topics related to database systems and high-performance computing systems.\n \n \n \n \n \n  \n \n  \nJungkook Lee\n \n  \nJungkook is a Senior Software Development Engineer at AWS, where he leads a team focused on improving performance and extending functionalities for Aurora PostgreSQL. With over 10 years of experience in database systems and distributed computing architectures, he specialized in query optimization and database performance.\n \n \n \n \n \n  \n \n  \nStephen Wood\n \n  \nStephen is a Senior Specialist Database Solutions Architect at AWS. Stephen specializes in Amazon RDS PostgreSQL, Amazon Aurora PostgreSQL, and Amazon Aurora DSQL. He has been working with database systems across different types of enterprises for the past 24 years and always loves working with new database technology.	Amazon Aurora PostgreSQL introduces Shared Plan Cache feature to address memory inefficiency in high-concurrency environments. Traditional PostgreSQL creates generic plans that get duplicated across sessions, causing massive memory consumption. With prepared statements across 100 connections, memory usage can reach 40GB due to identical plan duplication. The new shared plan cache stores one copy of each generic plan, reducing memory footprint from 40GB to 400MB. Enabled via apg_shared_plan_cache.enable parameter, it benefits workloads with many concurrent connections using prepared statements extensively.	\N
6	pg_utl_smtp v1.0 released	https://www.postgresql.org/about/news/pg_utl_smtp-v10-released-3217/	N/A	2026-01-22 00:00:00+00	\N	Grenoble, France - January 20, 2026\nPostgreSQL UTL_SMTP compatibility extension\npg_utl_smtp is a PostgreSQL extension to create, manage and use Oracle-style\nUTL_SMTP package. The use and behavior is just like with the UTL_SMTP Oracle\npackage. This work is released from the HexaRocket\nproject.\nThis extension allows email notifications to be sent from triggers or stored\nprocedures. By integrating the extension directly into the database, you can\ntrigger data-driven actions without waiting for application intervention.\nExamples include security alerts or notifications when certain minimum thresholds\nare reached.\npg_utl_smtp v1.0.0 has been released, this is the first release of the extension\nwhich is compatible from PostgreSQL 12 to current.\nThis extension uses plperl stored procedures based on the Net::SMTP Perl module\nto provide the procedures of the UTL_SMTP package.\nLinks & Credits\npg_utl_smtp is an open project under the PostgreSQL license created by Gilles Darold at\nHexaCluster Corp. as part of the HexaRocket\nmigration solution.  Any contribution to build a better tool is welcome. You can\nsend your ideas, features requests or patches using the GitHub tools.\nLinks :\nDownload:  https://github.com/HexaCluster/pg_utl_smtp/releases/\nSupport: use GitHub report tool at https://github.com/HexaCluster/pg_utl_smtp/issues\nAbout pg_utl_smtp\nThe pg_utl_smtp extension is an original work of HexaCluster Corp., HexaCluster is specialized in migration to PostgreSQL and PostgreSQL support. If you need more information please contact us\nDocumentation at https://github.com/HexaCluster/pg_utl_smtp#readme	HexaCluster Corp. released pg_utl_smtp v1.0.0, a PostgreSQL extension that provides Oracle UTL_SMTP package compatibility for sending email notifications from database triggers and stored procedures. The extension works with PostgreSQL 12 through current versions and uses plperl stored procedures based on the Net::SMTP Perl module. Part of the HexaRocket migration solution, it enables data-driven email actions like security alerts and threshold notifications directly from the database without application intervention. The open-source extension is available under PostgreSQL license.	\N
6	PostgreSQL Contributor Story: Florin Irion	https://enterprisedb.com/blog/postgresql-contributor-story-florin-irion	N/A	2026-01-22 12:35:17+00	\N	In 2025 we started a program to help colleagues who show promise for PostgreSQL Development to become contributors. In this post we highlight Florin's journey, a Staff SDE at EDB based in Italy.	EDB launched a program in 2025 to help promising colleagues become PostgreSQL contributors. This post features Florin Irion's journey, a Staff Software Development Engineer at EDB based in Italy, as part of their contributor development initiative.	\N
11	PostgreSQL Contributor Story: Florin Irion	https://enterprisedb.com/blog/postgresql-contributor-story-florin-irion	N/A	2026-01-22 12:35:17+00	\N	In 2025 we started a program to help colleagues who show promise for PostgreSQL Development to become contributors. In this post we highlight Florin's journey, a Staff SDE at EDB based in Italy.	EDB launched a program in 2025 to help promising colleagues become PostgreSQL contributors. This post profiles Florin Irion, a Staff Software Development Engineer at EDB Italy, documenting his journey from developer to PostgreSQL contributor through the company's mentorship program.\nEDB在2025年启动了一个项目，帮助有前途的同事成为PostgreSQL贡献者。这篇文章介绍了Florin Irion的经历，他是EDB意大利分公司的高级软件开发工程师，记录了他通过公司导师项目从开发者到PostgreSQL贡献者的历程。	\N
32	Databases, Data Lakes, And Encryption	https://www.percona.com/blog/databases-data-lakes-and-encryption/	Robert Bernier	2026-01-28 16:15:52+00	\N	\N	This article by Robert Bernier discusses the evolution of object storage and its relationship to databases, data lakes, and encryption. The piece explains how object storage has transformed from a solution for infrequently accessed data into the dominant archival medium for unstructured content. The content explores the intersection of these technologies, likely covering security considerations and best practices for implementing encryption across database and data lake architectures that utilize object storage systems.	Robert Bernier的这篇文章讨论了对象存储的演进及其与数据库、数据湖和加密的关系。文章解释了对象存储如何从解决不频繁访问数据的方案转变为非结构化内容的主要归档介质。内容探讨了这些技术的交集，可能涵盖了在利用对象存储系统的数据库和数据湖架构中实施加密的安全考虑和最佳实践。
25	Strategies for upgrading Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL from version 13	https://aws.amazon.com/blogs/database/strategies-for-upgrading-amazon-aurora-postgresql-and-amazon-rds-for-postgresql-from-version-13/	Abhimanyu Tomar	2026-01-27 17:36:14+00	<p>In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.</p> \n<p>Standard support for <a href="https://aws.amazon.com/rds/aurora/features/" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL-Compatible Edition</a> and <a href="https://aws.amazon.com/rds/postgresql/" target="_blank" rel="noopener noreferrer">Amazon Relational Database Service (Amazon RDS) for PostgreSQL</a> version 13 ends on February 28, 2026.</p> \n<p>These updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.</p> \n<p>For detailed upgrade instructions, refer to the official documentation for both <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" rel="noopener" target="_blank">Amazon Aurora PostgreSQL-Compatible</a> and <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL</a>:</p> \n<ul> \n <li><a href="https://repost.aws/articles/ARxQSsnCAlS6OhFm7M10vwjA/announcement-amazon-aurora-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n <li><a href="https://repost.aws/articles/ARRvHxJ_9sTDCGloBavca3kg/announcement-amazon-rds-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n</ul> \n<h2>Key benefits of PostgreSQL newer versions</h2> \n<p>Upgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.</p> \n<h3>Performance enhancements</h3> \n<p>Newer versions offer the following performance enhancements:</p> \n<ul> \n <li><strong>Vacuum emergency mode (v14+)</strong> – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions</li> \n <li><strong>Improved I/O performance</strong> <strong>(v17)</strong> – Offers <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to two times better write throughput</a> with enhanced WAL processing</li> \n <li><strong>Query optimization</strong> <strong>(v17+) </strong>– Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds</li> \n <li><strong>Memory efficiency</strong> <strong>(v17)</strong> – New vacuum memory structure consumes <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to 20 times less memory</a></li> \n</ul> \n<h3>Advanced monitoring and diagnostics</h3> \n<p>You can benefit from the following advanced monitoring and diagnostics features:</p> \n<ul> \n <li><strong>pg_stat_io</strong> <strong>(v16+)</strong> – Provides detailed statistics on I/O operations</li> \n <li><strong>pg_wait_events (v17+) </strong>– Supports in-database reference for wait events, removing manual documentation lookups</li> \n</ul> \n<h3>Logical replication improvements</h3> \n<p>Newer versions offer the following logical replication improvements:</p> \n<ul> \n <li><strong>Failover support</strong> <strong>(v17+)</strong> – You can automatically synchronize logical replication slots from primary to standby servers</li> \n <li><strong>Slot migration</strong> <strong>(v17+) </strong>– Logical replication slots can migrate through pg_upgrade, simplifying upgrades</li> \n <li><strong>Parallel apply</strong> <strong>(v16+)</strong> – This feature writes data directly to the target table using multiple background worker processes</li> \n <li><strong>Row filtering</strong> <strong>(v15+) </strong>– You have fine-grained control over what data is replicated</li> \n</ul> \n<h3>Developer experience</h3> \n<p>Newer versions offer an improved developer experience:</p> \n<ul> \n <li><strong>JSONB subscripting</strong> <strong>(v14+) </strong>– Intuitive syntax for accessing and modifying JSONB data</li> \n <li><strong>SQL/JSON JSON_TABLE (v17+) </strong>– The ability to transform JSON data into relational views</li> \n <li><strong>Query pipelining</strong> <strong>(v14+)</strong> – Reduced network latency for high-latency connections</li> \n</ul> \n<h3>Security enhancements</h3> \n<p>You have access to the following security enhancements:</p> \n<ul> \n <li><strong>pg_read_all_data and pg_write_all_data roles (v14+)</strong> – Streamlined read/write access control</li> \n <li><strong>pg_maintain role</strong> <strong>(v17+)</strong> – Enabling users to perform database maintenance tasks</li> \n <li><strong>(v15+) </strong>– Removal of PUBLIC creation permission on public schema</li> \n</ul> \n<h3>Amazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads</h3> \n<p>For Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.optimized.reads.html" target="_blank" rel="noopener noreferrer">performance optimizations</a>.</p> \n<p>Aurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:</p> \n<ul> \n <li><strong>Tiered cache</strong> – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)</li> \n <li><strong>Temporary objects</strong> – You can experience up to two times faster latency for advanced queries using local NVMe storage</li> \n</ul> \n<h2>PostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)</h2> \n<p>Upgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.</p> \n<h3>Changes in system catalog views</h3> \n<p>The following table summarizes changes in PostgreSQL v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Column Name</b></td> \n   <td><b>Action</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend_fsync</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_stat_checkpointer</td> \n   <td>CREATED</td> \n   <td>Separates checkpointer statistics from background writer</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_wait_events</td> \n   <td>CREATED</td> \n   <td>Wait event information</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes pg_stat_progress_vacuum column renames.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Old Name</b></td> \n   <td><b>New Name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>max_dead_tuples</td> \n   <td>max_dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>num_dead_tuples</td> \n   <td>dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_total</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_processed</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>dead_tuple_bytes</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes additional catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View/Table</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Old name</b></td> \n   <td><b>New name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>New column</td> \n   <td>–</td> \n   <td>dathasloginevt</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>Renamed</td> \n   <td>daticulocale</td> \n   <td>datlocale</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>pg_collation</td> \n   <td>Renamed</td> \n   <td>colliculocale</td> \n   <td>colllocale</td> \n   <td>Column renamed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes modified system views.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>New column(s) added</b></td> \n  </tr> \n  <tr> \n   <td>pg_replication_slots</td> \n   <td>failover; synced; invalidation_reason; inactive_since</td> \n  </tr> \n  <tr> \n   <td>pg_stat_progress_copy</td> \n   <td>tuples_skipped</td> \n  </tr> \n  <tr> \n   <td>pg_stat_subscription</td> \n   <td>worker_type</td> \n  </tr> \n  <tr> \n   <td>pg_stats</td> \n   <td>range_length_histogram; range_empty_frac; range_bounds_histogram</td> \n  </tr> \n  <tr> \n   <td>pg_subscription</td> \n   <td>subfailover</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes PostgreSQL v14 system catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Column name</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>pg_stat_activity</td> \n   <td>New column</td> \n   <td>query_id</td> \n   <td>Requires compute_query_id parameter</td> \n  </tr> \n  <tr> \n   <td>pg_stat_statements</td> \n   <td>New column</td> \n   <td>toplevel</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<h3>Important parameter-related changes</h3> \n<p>The following table summarizes parameter-related changes in PostgreSQL v14.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>compute_query_id</td> \n   <td>Controls query identifier computation</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>client_connection_check_interval</td> \n   <td>Sets the time interval between checks for disconnection while running queries</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>idle_session_timeout</td> \n   <td>Ends sessions not in a transaction that have been idle longer than the specified time</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>default_toast_compression</td> \n   <td>Sets the default compression method for compressible values</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>vacuum_failsafe_age</td> \n   <td>Age at which VACUUM should trigger failsafe to avoid a wraparound outage</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>huge_page_size</td> \n   <td>The size of huge page that should be requested</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>operator_precedence_warning</td> \n   <td>Completely removed</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>vacuum_cleanup_index_scale_factor</td> \n   <td>Removed (deprecated in v12)</td> \n  </tr> \n </tbody> \n</table> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Old value</b></td> \n   <td><b>New value</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>Default Changed</td> \n   <td>password_encryption</td> \n   <td>md5</td> \n   <td>scram-sha-256</td> \n   <td>Password encryption default changed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Version</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>Enhanced</td> \n   <td>wal_compression</td> \n   <td>Supports new algorithms: zstd, lz4</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>New</td> \n   <td>wal_decode_buffer_size</td> \n   <td>Buffer size for WAL decoding</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>vacuum_buffer_usage_limit</td> \n   <td>Limits buffer usage during vacuum</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>logical_replication_mode</td> \n   <td>Controls logical replication behavior</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 17</td> \n   <td>New</td> \n   <td>sync_replication_slots</td> \n   <td>Enables synchronization of replication slots</td> \n  </tr> \n </tbody> \n</table> \n<h2>Upgrade strategy options</h2> \n<p>You have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:</p> \n<ul> \n <li><a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">In-place upgrade</a> – You can perform this upgrade method using either the <a href="http://aws.amazon.com/cli" target="_blank" rel="noopener noreferrer">AWS Command Line Interface</a> (AWS CLI) or <a href="http://aws.amazon.com/console" target="_blank" rel="noopener noreferrer">AWS Management Console</a>. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.</li> \n <li><a href="https://aws.amazon.com/blogs/database/new-fully-managed-blue-green-deployment-in-amazon-aurora-postgresql-and-amazon-rds-for-postgresql/" target="_blank" rel="noopener noreferrer">Amazon RDS blue/green deployment</a> – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.</li> \n <li><a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Logical replication</a> – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.</li> \n <li><a href="https://aws.amazon.com/dms/" target="_blank" rel="noopener noreferrer">AWS Database Migration Service (AWS DMS)</a> – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.</li> \n</ul> \n<p>For detailed information about both in-place upgrades and various out-of-place upgrade options, refer to <a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches</a>. It examines the advantages and disadvantages of each approach.</p> \n<h2>Preparing to upgrade</h2> \n<p>Before upgrading, you should perform the following actions:</p> \n<ul> \n <li>Review your current database configuration</li> \n <li>Test the upgrade process in a staging environment</li> \n <li>Validate application compatibility</li> \n <li>Create comprehensive backup strategies</li> \n</ul> \n<p>If immediate upgrade isn’t feasible, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/extended-support.html" target="_blank" rel="noopener noreferrer">Amazon RDS Extended Support</a> provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.</p> \n<h2>Conclusion</h2> \n<p>Upgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.</p> \n<p>For detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have <a href="https://aws.amazon.com/premiumsupport/plans/enterprise/" target="_blank" rel="noopener noreferrer">AWS Enterprise Support</a>, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.</p> \n<hr> \n<h2>About the authors</h2> \n<footer> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50291.png" alt="Sachin Murkar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Sachin Murkar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/sachinmurkar/" rel="noopener">Sachin</a> is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50292.jpeg" alt="Abhimanyu Tomar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Abhimanyu Tomar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/abhimanyu-tomar/" rel="noopener">Abhimanyu</a> is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50293.jpeg" alt="Niraj Jani" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Niraj Jani</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/nirajjani22/" rel="noopener">Niraj</a> is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.</p>\n </div> \n</footer>	In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.\n \nStandard support for Amazon Aurora PostgreSQL-Compatible Edition and Amazon Relational Database Service (Amazon RDS) for PostgreSQL version 13 ends on February 28, 2026.\n \nThese updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.\n \nFor detailed upgrade instructions, refer to the official documentation for both Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL:\n \n \n \nAmazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nAmazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nKey benefits of PostgreSQL newer versions\n \nUpgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.\n \nPerformance enhancements\n \nNewer versions offer the following performance enhancements:\n \n \n \nVacuum emergency mode (v14+) – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions\n \n \nImproved I/O performance (v17) – Offers up to two times better write throughput with enhanced WAL processing\n \n \nQuery optimization (v17+) – Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds\n \n \nMemory efficiency (v17) – New vacuum memory structure consumes up to 20 times less memory\n \n \nAdvanced monitoring and diagnostics\n \nYou can benefit from the following advanced monitoring and diagnostics features:\n \n \n \npg_stat_io (v16+) – Provides detailed statistics on I/O operations\n \n \npg_wait_events (v17+) – Supports in-database reference for wait events, removing manual documentation lookups\n \n \nLogical replication improvements\n \nNewer versions offer the following logical replication improvements:\n \n \n \nFailover support (v17+) – You can automatically synchronize logical replication slots from primary to standby servers\n \n \nSlot migration (v17+) – Logical replication slots can migrate through pg_upgrade, simplifying upgrades\n \n \nParallel apply (v16+) – This feature writes data directly to the target table using multiple background worker processes\n \n \nRow filtering (v15+) – You have fine-grained control over what data is replicated\n \n \nDeveloper experience\n \nNewer versions offer an improved developer experience:\n \n \n \nJSONB subscripting (v14+) – Intuitive syntax for accessing and modifying JSONB data\n \n \nSQL/JSON JSON_TABLE (v17+) – The ability to transform JSON data into relational views\n \n \nQuery pipelining (v14+) – Reduced network latency for high-latency connections\n \n \nSecurity enhancements\n \nYou have access to the following security enhancements:\n \n \n \npg_read_all_data and pg_write_all_data roles (v14+) – Streamlined read/write access control\n \n \npg_maintain role (v17+) – Enabling users to perform database maintenance tasks\n \n \n(v15+) – Removal of PUBLIC creation permission on public schema\n \n \nAmazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads\n \nFor Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more performance optimizations.\n \nAurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:\n \n \n \nTiered cache – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)\n \n \nTemporary objects – You can experience up to two times faster latency for advanced queries using local NVMe storage\n \n \nPostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)\n \nUpgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.\n \nChanges in system catalog views\n \nThe following table summarizes changes in PostgreSQL v17.\n \n \n  \n  \n \n   Change Type \n   Column Name \n   Action \n   Notes \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend \n   REMOVED \n   – \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend_fsync \n   REMOVED \n   – \n  \n \n  \n \n   New View \n   pg_stat_checkpointer \n   CREATED \n   Separates checkpointer statistics from background writer \n  \n \n  \n \n   New View \n   pg_wait_events \n   CREATED \n   Wait event information \n  \n \n  \n \nThe following table summarizes pg_stat_progress_vacuum column renames.\n \n \n  \n  \n \n   Change Type \n   Old Name \n   New Name \n   Description \n  \n \n  \n \n   Renamed \n   max_dead_tuples \n   max_dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   Renamed \n   num_dead_tuples \n   dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   New column \n   – \n   indexes_total \n   New column added \n  \n \n  \n \n   New column \n   – \n   indexes_processed \n   New column added \n  \n \n  \n \n   New column \n   – \n   dead_tuple_bytes \n   New column added \n  \n \n  \n \nThe following table summarizes additional catalog changes.\n \n \n  \n  \n \n   View/Table \n   Change type \n   Old name \n   New name \n   Description \n  \n \n  \n \n   pg_database \n   New column \n   – \n   dathasloginevt \n   New column added \n  \n \n  \n \n   pg_database \n   Renamed \n   daticulocale \n   datlocale \n   Column renamed \n  \n \n  \n \n   pg_collation \n   Renamed \n   colliculocale \n   colllocale \n   Column renamed \n  \n \n  \n \nThe following table summarizes modified system views.\n \n \n  \n  \n \n   View name \n   New column(s) added \n  \n \n  \n \n   pg_replication_slots \n   failover; synced; invalidation_reason; inactive_since \n  \n \n  \n \n   pg_stat_progress_copy \n   tuples_skipped \n  \n \n  \n \n   pg_stat_subscription \n   worker_type \n  \n \n  \n \n   pg_stats \n   range_length_histogram; range_empty_frac; range_bounds_histogram \n  \n \n  \n \n   pg_subscription \n   subfailover \n  \n \n  \n \nThe following table summarizes PostgreSQL v14 system catalog changes.\n \n \n  \n  \n \n   View name \n   Change type \n   Column name \n   Notes \n  \n \n  \n \n   pg_stat_activity \n   New column \n   query_id \n   Requires compute_query_id parameter \n  \n \n  \n \n   pg_stat_statements \n   New column \n   toplevel \n   New column added \n  \n \n  \n \nImportant parameter-related changes\n \nThe following table summarizes parameter-related changes in PostgreSQL v14.\n \n \n  \n  \n \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   New \n   compute_query_id \n   Controls query identifier computation \n  \n \n  \n \n   New \n   client_connection_check_interval \n   Sets the time interval between checks for disconnection while running queries \n  \n \n  \n \n   New \n   idle_session_timeout \n   Ends sessions not in a transaction that have been idle longer than the specified time \n  \n \n  \n \n   New \n   default_toast_compression \n   Sets the default compression method for compressible values \n  \n \n  \n \n   New \n   vacuum_failsafe_age \n   Age at which VACUUM should trigger failsafe to avoid a wraparound outage \n  \n \n  \n \n   New \n   huge_page_size \n   The size of huge page that should be requested \n  \n \n  \n \n   Removed \n   operator_precedence_warning \n   Completely removed \n  \n \n  \n \n   Removed \n   vacuum_cleanup_index_scale_factor \n   Removed (deprecated in v12) \n  \n \n  \n \n \n  \n  \n \n   Change type \n   Parameter name \n   Old value \n   New value \n   Description/Notes \n  \n \n  \n \n   Default Changed \n   password_encryption \n   md5 \n   scram-sha-256 \n   Password encryption default changed \n  \n \n  \n \nThe following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.\n \n \n  \n  \n \n   Version \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   PostgreSQL 15 \n   Enhanced \n   wal_compression \n   Supports new algorithms: zstd, lz4 \n  \n \n  \n \n   PostgreSQL 15 \n   New \n   wal_decode_buffer_size \n   Buffer size for WAL decoding \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   vacuum_buffer_usage_limit \n   Limits buffer usage during vacuum \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   logical_replication_mode \n   Controls logical replication behavior \n  \n \n  \n \n   PostgreSQL 17 \n   New \n   sync_replication_slots \n   Enables synchronization of replication slots \n  \n \n  \n \nUpgrade strategy options\n \nYou have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:\n \n \n \nIn-place upgrade – You can perform this upgrade method using either the AWS Command Line Interface (AWS CLI) or AWS Management Console. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.\n \n \nAmazon RDS blue/green deployment – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.\n \n \nLogical replication – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.\n \n \nAWS Database Migration Service (AWS DMS) – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.\n \n \nFor detailed information about both in-place upgrades and various out-of-place upgrade options, refer to Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches. It examines the advantages and disadvantages of each approach.\n \nPreparing to upgrade\n \nBefore upgrading, you should perform the following actions:\n \n \n \nReview your current database configuration\n \n \nTest the upgrade process in a staging environment\n \n \nValidate application compatibility\n \n \nCreate comprehensive backup strategies\n \n \nIf immediate upgrade isn’t feasible, Amazon RDS Extended Support provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.\n \nConclusion\n \nUpgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.\n \nFor detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have AWS Enterprise Support, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.\n \n \nAbout the authors\n \n \n \n \n  \n \n  \nSachin Murkar\n \n  \nSachin is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.\n \n \n \n  \n \n  \nAbhimanyu Tomar\n \n  \nAbhimanyu is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.\n \n \n \n  \n \n  \nNiraj Jani\n \n  \nNiraj is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.	AWS has published guidance for upgrading Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL from version 13 before standard support ends on February 28, 2026. The post outlines key benefits of newer PostgreSQL versions, including performance enhancements like vacuum emergency mode and improved I/O performance, advanced monitoring features such as pg_stat_io, logical replication improvements, and security enhancements. It details breaking changes in system catalog views and configuration parameters that may affect applications. The article presents four upgrade strategies: in-place upgrades requiring downtime, blue/green deployments using logical replication for minimal downtime, direct logical replication with pglogical, and AWS DMS for change data capture. For organizations unable to upgrade immediately, Amazon RDS Extended Support provides up to three years of continued patches for a fee.	AWS发布了Amazon Aurora PostgreSQL和Amazon RDS for PostgreSQL从版本13升级的指导，标准支持将于2026年2月28日结束。该文章概述了新版PostgreSQL的主要优势，包括性能增强如vacuum紧急模式和改进的I/O性能、高级监控功能如pg_stat_io、逻辑复制改进以及安全增强。文章详细说明了系统目录视图和配置参数中可能影响应用程序的重大变更。文章介绍了四种升级策略：需要停机时间的就地升级、使用逻辑复制实现最小停机时间的蓝绿部署、使用pglogical的直接逻辑复制，以及用于变更数据捕获的AWS DMS。对于无法立即升级的组织，Amazon RDS Extended Support提供长达三年的持续补丁服务，但需付费。
27	Strategies for upgrading Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL from version 13	https://aws.amazon.com/blogs/database/strategies-for-upgrading-amazon-aurora-postgresql-and-amazon-rds-for-postgresql-from-version-13/	Abhimanyu Tomar	2026-01-27 17:36:14+00	<p>In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.</p> \n<p>Standard support for <a href="https://aws.amazon.com/rds/aurora/features/" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL-Compatible Edition</a> and <a href="https://aws.amazon.com/rds/postgresql/" target="_blank" rel="noopener noreferrer">Amazon Relational Database Service (Amazon RDS) for PostgreSQL</a> version 13 ends on February 28, 2026.</p> \n<p>These updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.</p> \n<p>For detailed upgrade instructions, refer to the official documentation for both <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" rel="noopener" target="_blank">Amazon Aurora PostgreSQL-Compatible</a> and <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL</a>:</p> \n<ul> \n <li><a href="https://repost.aws/articles/ARxQSsnCAlS6OhFm7M10vwjA/announcement-amazon-aurora-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n <li><a href="https://repost.aws/articles/ARRvHxJ_9sTDCGloBavca3kg/announcement-amazon-rds-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n</ul> \n<h2>Key benefits of PostgreSQL newer versions</h2> \n<p>Upgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.</p> \n<h3>Performance enhancements</h3> \n<p>Newer versions offer the following performance enhancements:</p> \n<ul> \n <li><strong>Vacuum emergency mode (v14+)</strong> – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions</li> \n <li><strong>Improved I/O performance</strong> <strong>(v17)</strong> – Offers <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to two times better write throughput</a> with enhanced WAL processing</li> \n <li><strong>Query optimization</strong> <strong>(v17+) </strong>– Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds</li> \n <li><strong>Memory efficiency</strong> <strong>(v17)</strong> – New vacuum memory structure consumes <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to 20 times less memory</a></li> \n</ul> \n<h3>Advanced monitoring and diagnostics</h3> \n<p>You can benefit from the following advanced monitoring and diagnostics features:</p> \n<ul> \n <li><strong>pg_stat_io</strong> <strong>(v16+)</strong> – Provides detailed statistics on I/O operations</li> \n <li><strong>pg_wait_events (v17+) </strong>– Supports in-database reference for wait events, removing manual documentation lookups</li> \n</ul> \n<h3>Logical replication improvements</h3> \n<p>Newer versions offer the following logical replication improvements:</p> \n<ul> \n <li><strong>Failover support</strong> <strong>(v17+)</strong> – You can automatically synchronize logical replication slots from primary to standby servers</li> \n <li><strong>Slot migration</strong> <strong>(v17+) </strong>– Logical replication slots can migrate through pg_upgrade, simplifying upgrades</li> \n <li><strong>Parallel apply</strong> <strong>(v16+)</strong> – This feature writes data directly to the target table using multiple background worker processes</li> \n <li><strong>Row filtering</strong> <strong>(v15+) </strong>– You have fine-grained control over what data is replicated</li> \n</ul> \n<h3>Developer experience</h3> \n<p>Newer versions offer an improved developer experience:</p> \n<ul> \n <li><strong>JSONB subscripting</strong> <strong>(v14+) </strong>– Intuitive syntax for accessing and modifying JSONB data</li> \n <li><strong>SQL/JSON JSON_TABLE (v17+) </strong>– The ability to transform JSON data into relational views</li> \n <li><strong>Query pipelining</strong> <strong>(v14+)</strong> – Reduced network latency for high-latency connections</li> \n</ul> \n<h3>Security enhancements</h3> \n<p>You have access to the following security enhancements:</p> \n<ul> \n <li><strong>pg_read_all_data and pg_write_all_data roles (v14+)</strong> – Streamlined read/write access control</li> \n <li><strong>pg_maintain role</strong> <strong>(v17+)</strong> – Enabling users to perform database maintenance tasks</li> \n <li><strong>(v15+) </strong>– Removal of PUBLIC creation permission on public schema</li> \n</ul> \n<h3>Amazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads</h3> \n<p>For Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.optimized.reads.html" target="_blank" rel="noopener noreferrer">performance optimizations</a>.</p> \n<p>Aurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:</p> \n<ul> \n <li><strong>Tiered cache</strong> – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)</li> \n <li><strong>Temporary objects</strong> – You can experience up to two times faster latency for advanced queries using local NVMe storage</li> \n</ul> \n<h2>PostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)</h2> \n<p>Upgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.</p> \n<h3>Changes in system catalog views</h3> \n<p>The following table summarizes changes in PostgreSQL v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Column Name</b></td> \n   <td><b>Action</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend_fsync</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_stat_checkpointer</td> \n   <td>CREATED</td> \n   <td>Separates checkpointer statistics from background writer</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_wait_events</td> \n   <td>CREATED</td> \n   <td>Wait event information</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes pg_stat_progress_vacuum column renames.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Old Name</b></td> \n   <td><b>New Name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>max_dead_tuples</td> \n   <td>max_dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>num_dead_tuples</td> \n   <td>dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_total</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_processed</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>dead_tuple_bytes</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes additional catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View/Table</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Old name</b></td> \n   <td><b>New name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>New column</td> \n   <td>–</td> \n   <td>dathasloginevt</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>Renamed</td> \n   <td>daticulocale</td> \n   <td>datlocale</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>pg_collation</td> \n   <td>Renamed</td> \n   <td>colliculocale</td> \n   <td>colllocale</td> \n   <td>Column renamed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes modified system views.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>New column(s) added</b></td> \n  </tr> \n  <tr> \n   <td>pg_replication_slots</td> \n   <td>failover; synced; invalidation_reason; inactive_since</td> \n  </tr> \n  <tr> \n   <td>pg_stat_progress_copy</td> \n   <td>tuples_skipped</td> \n  </tr> \n  <tr> \n   <td>pg_stat_subscription</td> \n   <td>worker_type</td> \n  </tr> \n  <tr> \n   <td>pg_stats</td> \n   <td>range_length_histogram; range_empty_frac; range_bounds_histogram</td> \n  </tr> \n  <tr> \n   <td>pg_subscription</td> \n   <td>subfailover</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes PostgreSQL v14 system catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Column name</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>pg_stat_activity</td> \n   <td>New column</td> \n   <td>query_id</td> \n   <td>Requires compute_query_id parameter</td> \n  </tr> \n  <tr> \n   <td>pg_stat_statements</td> \n   <td>New column</td> \n   <td>toplevel</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<h3>Important parameter-related changes</h3> \n<p>The following table summarizes parameter-related changes in PostgreSQL v14.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>compute_query_id</td> \n   <td>Controls query identifier computation</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>client_connection_check_interval</td> \n   <td>Sets the time interval between checks for disconnection while running queries</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>idle_session_timeout</td> \n   <td>Ends sessions not in a transaction that have been idle longer than the specified time</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>default_toast_compression</td> \n   <td>Sets the default compression method for compressible values</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>vacuum_failsafe_age</td> \n   <td>Age at which VACUUM should trigger failsafe to avoid a wraparound outage</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>huge_page_size</td> \n   <td>The size of huge page that should be requested</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>operator_precedence_warning</td> \n   <td>Completely removed</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>vacuum_cleanup_index_scale_factor</td> \n   <td>Removed (deprecated in v12)</td> \n  </tr> \n </tbody> \n</table> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Old value</b></td> \n   <td><b>New value</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>Default Changed</td> \n   <td>password_encryption</td> \n   <td>md5</td> \n   <td>scram-sha-256</td> \n   <td>Password encryption default changed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Version</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>Enhanced</td> \n   <td>wal_compression</td> \n   <td>Supports new algorithms: zstd, lz4</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>New</td> \n   <td>wal_decode_buffer_size</td> \n   <td>Buffer size for WAL decoding</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>vacuum_buffer_usage_limit</td> \n   <td>Limits buffer usage during vacuum</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>logical_replication_mode</td> \n   <td>Controls logical replication behavior</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 17</td> \n   <td>New</td> \n   <td>sync_replication_slots</td> \n   <td>Enables synchronization of replication slots</td> \n  </tr> \n </tbody> \n</table> \n<h2>Upgrade strategy options</h2> \n<p>You have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:</p> \n<ul> \n <li><a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">In-place upgrade</a> – You can perform this upgrade method using either the <a href="http://aws.amazon.com/cli" target="_blank" rel="noopener noreferrer">AWS Command Line Interface</a> (AWS CLI) or <a href="http://aws.amazon.com/console" target="_blank" rel="noopener noreferrer">AWS Management Console</a>. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.</li> \n <li><a href="https://aws.amazon.com/blogs/database/new-fully-managed-blue-green-deployment-in-amazon-aurora-postgresql-and-amazon-rds-for-postgresql/" target="_blank" rel="noopener noreferrer">Amazon RDS blue/green deployment</a> – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.</li> \n <li><a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Logical replication</a> – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.</li> \n <li><a href="https://aws.amazon.com/dms/" target="_blank" rel="noopener noreferrer">AWS Database Migration Service (AWS DMS)</a> – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.</li> \n</ul> \n<p>For detailed information about both in-place upgrades and various out-of-place upgrade options, refer to <a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches</a>. It examines the advantages and disadvantages of each approach.</p> \n<h2>Preparing to upgrade</h2> \n<p>Before upgrading, you should perform the following actions:</p> \n<ul> \n <li>Review your current database configuration</li> \n <li>Test the upgrade process in a staging environment</li> \n <li>Validate application compatibility</li> \n <li>Create comprehensive backup strategies</li> \n</ul> \n<p>If immediate upgrade isn’t feasible, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/extended-support.html" target="_blank" rel="noopener noreferrer">Amazon RDS Extended Support</a> provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.</p> \n<h2>Conclusion</h2> \n<p>Upgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.</p> \n<p>For detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have <a href="https://aws.amazon.com/premiumsupport/plans/enterprise/" target="_blank" rel="noopener noreferrer">AWS Enterprise Support</a>, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.</p> \n<hr> \n<h2>About the authors</h2> \n<footer> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50291.png" alt="Sachin Murkar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Sachin Murkar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/sachinmurkar/" rel="noopener">Sachin</a> is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50292.jpeg" alt="Abhimanyu Tomar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Abhimanyu Tomar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/abhimanyu-tomar/" rel="noopener">Abhimanyu</a> is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50293.jpeg" alt="Niraj Jani" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Niraj Jani</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/nirajjani22/" rel="noopener">Niraj</a> is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.</p>\n </div> \n</footer>	In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.\n \nStandard support for Amazon Aurora PostgreSQL-Compatible Edition and Amazon Relational Database Service (Amazon RDS) for PostgreSQL version 13 ends on February 28, 2026.\n \nThese updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.\n \nFor detailed upgrade instructions, refer to the official documentation for both Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL:\n \n \n \nAmazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nAmazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nKey benefits of PostgreSQL newer versions\n \nUpgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.\n \nPerformance enhancements\n \nNewer versions offer the following performance enhancements:\n \n \n \nVacuum emergency mode (v14+) – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions\n \n \nImproved I/O performance (v17) – Offers up to two times better write throughput with enhanced WAL processing\n \n \nQuery optimization (v17+) – Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds\n \n \nMemory efficiency (v17) – New vacuum memory structure consumes up to 20 times less memory\n \n \nAdvanced monitoring and diagnostics\n \nYou can benefit from the following advanced monitoring and diagnostics features:\n \n \n \npg_stat_io (v16+) – Provides detailed statistics on I/O operations\n \n \npg_wait_events (v17+) – Supports in-database reference for wait events, removing manual documentation lookups\n \n \nLogical replication improvements\n \nNewer versions offer the following logical replication improvements:\n \n \n \nFailover support (v17+) – You can automatically synchronize logical replication slots from primary to standby servers\n \n \nSlot migration (v17+) – Logical replication slots can migrate through pg_upgrade, simplifying upgrades\n \n \nParallel apply (v16+) – This feature writes data directly to the target table using multiple background worker processes\n \n \nRow filtering (v15+) – You have fine-grained control over what data is replicated\n \n \nDeveloper experience\n \nNewer versions offer an improved developer experience:\n \n \n \nJSONB subscripting (v14+) – Intuitive syntax for accessing and modifying JSONB data\n \n \nSQL/JSON JSON_TABLE (v17+) – The ability to transform JSON data into relational views\n \n \nQuery pipelining (v14+) – Reduced network latency for high-latency connections\n \n \nSecurity enhancements\n \nYou have access to the following security enhancements:\n \n \n \npg_read_all_data and pg_write_all_data roles (v14+) – Streamlined read/write access control\n \n \npg_maintain role (v17+) – Enabling users to perform database maintenance tasks\n \n \n(v15+) – Removal of PUBLIC creation permission on public schema\n \n \nAmazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads\n \nFor Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more performance optimizations.\n \nAurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:\n \n \n \nTiered cache – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)\n \n \nTemporary objects – You can experience up to two times faster latency for advanced queries using local NVMe storage\n \n \nPostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)\n \nUpgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.\n \nChanges in system catalog views\n \nThe following table summarizes changes in PostgreSQL v17.\n \n \n  \n  \n \n   Change Type \n   Column Name \n   Action \n   Notes \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend \n   REMOVED \n   – \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend_fsync \n   REMOVED \n   – \n  \n \n  \n \n   New View \n   pg_stat_checkpointer \n   CREATED \n   Separates checkpointer statistics from background writer \n  \n \n  \n \n   New View \n   pg_wait_events \n   CREATED \n   Wait event information \n  \n \n  \n \nThe following table summarizes pg_stat_progress_vacuum column renames.\n \n \n  \n  \n \n   Change Type \n   Old Name \n   New Name \n   Description \n  \n \n  \n \n   Renamed \n   max_dead_tuples \n   max_dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   Renamed \n   num_dead_tuples \n   dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   New column \n   – \n   indexes_total \n   New column added \n  \n \n  \n \n   New column \n   – \n   indexes_processed \n   New column added \n  \n \n  \n \n   New column \n   – \n   dead_tuple_bytes \n   New column added \n  \n \n  \n \nThe following table summarizes additional catalog changes.\n \n \n  \n  \n \n   View/Table \n   Change type \n   Old name \n   New name \n   Description \n  \n \n  \n \n   pg_database \n   New column \n   – \n   dathasloginevt \n   New column added \n  \n \n  \n \n   pg_database \n   Renamed \n   daticulocale \n   datlocale \n   Column renamed \n  \n \n  \n \n   pg_collation \n   Renamed \n   colliculocale \n   colllocale \n   Column renamed \n  \n \n  \n \nThe following table summarizes modified system views.\n \n \n  \n  \n \n   View name \n   New column(s) added \n  \n \n  \n \n   pg_replication_slots \n   failover; synced; invalidation_reason; inactive_since \n  \n \n  \n \n   pg_stat_progress_copy \n   tuples_skipped \n  \n \n  \n \n   pg_stat_subscription \n   worker_type \n  \n \n  \n \n   pg_stats \n   range_length_histogram; range_empty_frac; range_bounds_histogram \n  \n \n  \n \n   pg_subscription \n   subfailover \n  \n \n  \n \nThe following table summarizes PostgreSQL v14 system catalog changes.\n \n \n  \n  \n \n   View name \n   Change type \n   Column name \n   Notes \n  \n \n  \n \n   pg_stat_activity \n   New column \n   query_id \n   Requires compute_query_id parameter \n  \n \n  \n \n   pg_stat_statements \n   New column \n   toplevel \n   New column added \n  \n \n  \n \nImportant parameter-related changes\n \nThe following table summarizes parameter-related changes in PostgreSQL v14.\n \n \n  \n  \n \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   New \n   compute_query_id \n   Controls query identifier computation \n  \n \n  \n \n   New \n   client_connection_check_interval \n   Sets the time interval between checks for disconnection while running queries \n  \n \n  \n \n   New \n   idle_session_timeout \n   Ends sessions not in a transaction that have been idle longer than the specified time \n  \n \n  \n \n   New \n   default_toast_compression \n   Sets the default compression method for compressible values \n  \n \n  \n \n   New \n   vacuum_failsafe_age \n   Age at which VACUUM should trigger failsafe to avoid a wraparound outage \n  \n \n  \n \n   New \n   huge_page_size \n   The size of huge page that should be requested \n  \n \n  \n \n   Removed \n   operator_precedence_warning \n   Completely removed \n  \n \n  \n \n   Removed \n   vacuum_cleanup_index_scale_factor \n   Removed (deprecated in v12) \n  \n \n  \n \n \n  \n  \n \n   Change type \n   Parameter name \n   Old value \n   New value \n   Description/Notes \n  \n \n  \n \n   Default Changed \n   password_encryption \n   md5 \n   scram-sha-256 \n   Password encryption default changed \n  \n \n  \n \nThe following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.\n \n \n  \n  \n \n   Version \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   PostgreSQL 15 \n   Enhanced \n   wal_compression \n   Supports new algorithms: zstd, lz4 \n  \n \n  \n \n   PostgreSQL 15 \n   New \n   wal_decode_buffer_size \n   Buffer size for WAL decoding \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   vacuum_buffer_usage_limit \n   Limits buffer usage during vacuum \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   logical_replication_mode \n   Controls logical replication behavior \n  \n \n  \n \n   PostgreSQL 17 \n   New \n   sync_replication_slots \n   Enables synchronization of replication slots \n  \n \n  \n \nUpgrade strategy options\n \nYou have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:\n \n \n \nIn-place upgrade – You can perform this upgrade method using either the AWS Command Line Interface (AWS CLI) or AWS Management Console. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.\n \n \nAmazon RDS blue/green deployment – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.\n \n \nLogical replication – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.\n \n \nAWS Database Migration Service (AWS DMS) – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.\n \n \nFor detailed information about both in-place upgrades and various out-of-place upgrade options, refer to Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches. It examines the advantages and disadvantages of each approach.\n \nPreparing to upgrade\n \nBefore upgrading, you should perform the following actions:\n \n \n \nReview your current database configuration\n \n \nTest the upgrade process in a staging environment\n \n \nValidate application compatibility\n \n \nCreate comprehensive backup strategies\n \n \nIf immediate upgrade isn’t feasible, Amazon RDS Extended Support provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.\n \nConclusion\n \nUpgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.\n \nFor detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have AWS Enterprise Support, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.\n \n \nAbout the authors\n \n \n \n \n  \n \n  \nSachin Murkar\n \n  \nSachin is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.\n \n \n \n  \n \n  \nAbhimanyu Tomar\n \n  \nAbhimanyu is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.\n \n \n \n  \n \n  \nNiraj Jani\n \n  \nNiraj is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.	AWS announces that standard support for Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL version 13 ends February 28, 2026, requiring users to upgrade. Newer PostgreSQL versions (14-17) offer significant improvements including vacuum emergency mode, improved I/O performance with up to 2x better write throughput, enhanced monitoring via pg_stat_io and pg_wait_events, logical replication failover support, JSONB subscripting, and security enhancements. Aurora Optimized Reads in v14.9+ provides up to 8x faster query latency. Upgrade strategies include in-place upgrades, blue/green deployments, logical replication, and AWS DMS. Breaking changes affect system catalog views like pg_stat_bgwriter columns removal and parameter modifications. AWS Extended Support offers 3 years additional support as a paid option for delayed upgrades.	AWS宣布Amazon Aurora PostgreSQL和Amazon RDS for PostgreSQL版本13的标准支持将于2026年2月28日结束，用户需要升级。较新的PostgreSQL版本（14-17）提供显著改进，包括vacuum应急模式、改进的I/O性能（写入吞吐量提升最多2倍）、通过pg_stat_io和pg_wait_events增强监控、逻辑复制故障转移支持、JSONB下标访问和安全增强功能。Aurora Optimized Reads在v14.9+中提供最多8倍的查询延迟改进。升级策略包括就地升级、蓝绿部署、逻辑复制和AWS DMS。破坏性变更影响系统目录视图，如pg_stat_bgwriter列删除和参数修改。AWS Extended Support为延迟升级提供3年额外付费支持选项。
27	Phenomenology through PostgreSQL Documentation	https://www.cybertec-postgresql.com/en/phenomenology-through-postgresql-documentation/	Abhisek Goswami	2026-01-27 06:23:51+00	\r\n<p>Do you think the way you see the sunrise is the same for everyone?</p>\r\n\r\n\r\n\r\n<p>From where I live, the sun does not rise the way it does in postcards. It appears late, partially blocked by nearby buildings, sometimes sharp, sometimes muted, and often unnoticed until it is already well above the horizon. Someone standing on a hill sees it earlier. Someone near the sea sees it stretch slowly and wide. The sun itself does nothing different. What changes is where we stand when we observe it.</p>\r\n\r\n\r\n\r\n<p>This simple experience has a name: <strong>Phenomenology</strong>. It is the idea that reality exists independently, but our understanding of it is always shaped by perspective, timing, and constraints. We never describe the sun itself; we describe the sunrise as seen from a particular roof. </p>\r\n\r\n\r\n\r\n<p>Over time, I realised that this is exactly how documentation works when it works well.</p>\r\n\r\n\r\n\r\n<h2 id="h-documentation-as-observation-and-historical-record" class="wp-block-heading">Documentation as Observation and Historical Record</h2>\r\n\r\n\r\n\r\n<p>Phenomenology may sound philosophical, but in practice it is very concrete. It asks one question that matters deeply in engineering: from where is this description written?</p>\r\n\r\n\r\n\r\n<p>Long-lived systems accumulate history whether we like it or not. Features are introduced to solve earlier problems, constraints are added to protect correctness, and trade-offs are accepted because the alternatives were worse at that moment.</p>\r\n\r\n\r\n\r\n<p>Anyone who builds on such a system eventually performs a kind of archaeology, not out of curiosity, but because understanding intent is cheaper than rediscovering it through repeated experiments.</p>\r\n\r\n\r\n\r\n<p>This is where documentation stops being a supporting artifact and starts behaving like a feature. Not a runtime feature, not something you toggle on or off, but a process feature that preserves design context across time. </p>\r\n\r\n\r\n\r\n<p>When documentation captures who saw what, when, and under which constraints, archaeology becomes traceable instead of speculative.</p>\r\n\r\n\r\n\r\n<h2 id="h-contributor-context-as-the-differentiator" class="wp-block-heading">Contributor Context as the Differentiator</h2>\r\n\r\n\r\n\r\n<p>This is where I need to be precise, because vague praise does not help anyone.</p>\r\n\r\n\r\n\r\n<p>The documentation of <a href="https://www.postgresql.org/docs/">PostgreSQL</a> stands out not because it is shorter, friendlier, or more interactive than everything else, but because it consistently preserves design context close to the moment of change. Contributors do not just implement features; they describe what they changed, what guarantees hold, and where those guarantees stop holding.</p>\r\n\r\n\r\n\r\n<p>Documentation and release notes move with the code, not after it. Now, that closeness matters. It means the observer and the describer overlap. </p>\r\n\r\n\r\n\r\n<p>The person who stood on the roof when the sunrise looked a certain way is usually the person who wrote down what they saw. Over decades, that habit compounds into trust.</p>\r\n\r\n\r\n\r\n<h2 id="h-feature-origins-design-context-and-mvcc" class="wp-block-heading">Feature Origins, Design Context, and MVCC</h2>\r\n\r\n\r\n\r\n<p>Most features in PostgreSQL did not appear because someone invented an abstract capability. They appeared because someone ran into a real limitation, an inefficiency, or a correctness issue in an earlier version and worked through the implications until a solution emerged. That origin story, even when it is not written as a narrative, leaves traces in how the feature is documented.</p>\r\n\r\n\r\n\r\n<p>MVCC is a good example. Multi-Version Concurrency Control is not presented as a clever trick; it is documented as a set of guarantees and constraints around visibility and isolation. Different transactions can legitimately see different versions of the same data at the same time, and all of those views are correct within their isolation guarantees. There is no single global “now” inside the system.</p>\r\n\r\n\r\n\r\n<p>This is phenomenology expressed as mechanics. Observation depends on context, and the documentation reflects that by stating what is visible from which position. The important part is not the acronym itself, but the fact that the documentation does not pretend there is a single, observer-free truth.</p>\r\n\r\n\r\n\r\n<h2 id="h-docs-as-code-and-its-practical-limits" class="wp-block-heading">Docs as Code and its Practical Limits</h2>\r\n\r\n\r\n\r\n<p>I believe strongly in docs as code. Keeping documentation versioned with source, reviewed through the same workflows, and shipped alongside releases is necessary if documentation is to remain accurate over time. But docs as code by itself mostly protects behavioural correctness. It keeps descriptions aligned with what the system does now.</p>\r\n\r\n\r\n\r\n<p>What it does not automatically provide is etymology. It does not force anyone to explain why a feature exists, why certain trade-offs were accepted, or when a behaviour should not be relied upon. Many projects adopt docs as code and still end up with documentation that explains what and how, but leaves readers guessing about why.</p>\r\n\r\n\r\n\r\n<p>PostgreSQL goes further because of culture rather than tooling. Contributors document their own changes, release notes anchor those changes in time,and public discussions preserve the reasoning around them.</p>\r\n\r\n\r\n\r\n<p>The result is not explicit philosophy, but enough context to reconstruct intent when it matters.</p>\r\n\r\n\r\n\r\n<h2 id="h-the-john-doe-problem-and-the-new-developer-perspective" class="wp-block-heading">The John Doe problem and the New Developer Perspective</h2>\r\n\r\n\r\n\r\n<p>I often think about a simple scenario. John Doe buys a product and reads a manual that explains every feature perfectly from a usage point of view. He follows it carefully and still ends up confused, because the manual never explains the base assumptions the product relies on. Calibration shifts, internal references change, and behaviour that is technically correct feels wrong because the base was invisible.</p>\r\n\r\n\r\n\r\n<p>The same thing happens in software. When the base is hidden, people are forced into blind experimentation. When the base is visible, learning becomes intentional.</p>\r\n\r\n\r\n\r\n<p>For a developer building, for example, an analytics tool on top of <strong>pg_stat views</strong>, this difference is decisive.</p>\r\n\r\n\r\n\r\n<p>They can read the documentation to understand what those statistics are meant to represent, consult release notes to see when and why behaviour changed, and trace decisions back through commits and public discussions when their logic depends on those details.</p>\r\n\r\n\r\n\r\n<p>If something still remains unclear, the address book is effectively there: <strong><em>the contributor discussions are public, the context is discoverable, and questions can be asked in a focused way rather than through weeks of guesswork.</em></strong></p>\r\n\r\n\r\n\r\n<p><strong>Testing then becomes validation, not archaeology.</strong></p>\r\n\r\n\r\n\r\n<h2 id="h-behavioural-apis-versus-foundational-building-blocks" class="wp-block-heading">Behavioural APIs versus Foundational Building Blocks</h2>\r\n\r\n\r\n\r\n<p>It is useful to contrast this with excellent documentation that serves a different purpose. <a href="https://docs.stripe.com/">Stripe</a> documentation is world-class at describing behaviour through stable interfaces. It tells you exactly what will happen when you call an endpoint with given parameters, and it deliberately hides internal complexity so you can integrate quickly.</p>\r\n\r\n\r\n\r\n<p>PostgreSQL operates at a different layer. It is a building block. Other systems compose on top of it. The documentation therefore has a different responsibility: to expose assumptions, constraints, and limits so that higher-level behaviour can be built safely. </p>\r\n\r\n\r\n\r\n<p>Comparing the two without acknowledging this difference misses the point.</p>\r\n\r\n\r\n\r\n<h2 id="h-my-perspective-as-a-technical-writer" class="wp-block-heading">My perspective as a Technical Writer</h2>\r\n\r\n\r\n\r\n<p>I started as a developer who used documentation to learn tools. For a long time, I rarely found answers to why something was developed a certain way. Later, when I moved into technical writing, I found myself writing that missing context, trying to preserve intent rather than just describing behaviour.</p>\r\n\r\n\r\n\r\n<p>That second perspective made the gap obvious. In PostgreSQL, that gap is unusually small to zero. The people who experience the problem, design the solution, implement it, and document it often overlap. </p>\r\n\r\n\r\n\r\n<p>The documentation feels grounded because it is rooted in lived engineering decisions rather than retrospective explanations.</p>\r\n\r\n\r\n\r\n<h2 id="h-finally-my-lessons-and-observations-nbsp" class="wp-block-heading">Finally my lessons and observations </h2>\r\n\r\n\r\n\r\n<p>The sunrise does not look the same for everyone, but it becomes understandable once you know where the observer is standing and what blocks the view. </p>\r\n\r\n\r\n\r\n<p>PostgreSQL documentation works for the same reason. It does not claim a view from nowhere. It preserves perspective.</p>\r\n\r\n\r\n\r\n<p>As a technical writer, this shapes how I work. When I document APIs, docs as code is often enough because contracts are the product. When I document features and building blocks, I prefer a phenomenological approach, one that records who saw what, when, and under which constraints, because that is what future builders will need.</p>\r\n\r\n\r\n\r\n<p>That is why, in these terms, PostgreSQL documentation stands out.</p>\r\n\r\n\r\n\r\n<p>Let me know your thoughts!!!</p>\r\n<p>The post <a href="https://www.cybertec-postgresql.com/en/phenomenology-through-postgresql-documentation/">Phenomenology through PostgreSQL Documentation</a> appeared first on <a href="https://www.cybertec-postgresql.com/en">CYBERTEC PostgreSQL | Services &amp; Support</a>.</p>\n	Do you think the way you see the sunrise is the same for everyone?\n\r\n\r\n\r\n\r\nFrom where I live, the sun does not rise the way it does in postcards. It appears late, partially blocked by nearby buildings, sometimes sharp, sometimes muted, and often unnoticed until it is already well above the horizon. Someone standing on a hill sees it earlier. Someone near the sea sees it stretch slowly and wide. The sun itself does nothing different. What changes is where we stand when we observe it.\n\r\n\r\n\r\n\r\nThis simple experience has a name: Phenomenology. It is the idea that reality exists independently, but our understanding of it is always shaped by perspective, timing, and constraints. We never describe the sun itself; we describe the sunrise as seen from a particular roof. \n\r\n\r\n\r\n\r\nOver time, I realised that this is exactly how documentation works when it works well.\n\r\n\r\n\r\n\r\nDocumentation as Observation and Historical Record\n\r\n\r\n\r\n\r\nPhenomenology may sound philosophical, but in practice it is very concrete. It asks one question that matters deeply in engineering: from where is this description written?\n\r\n\r\n\r\n\r\nLong-lived systems accumulate history whether we like it or not. Features are introduced to solve earlier problems, constraints are added to protect correctness, and trade-offs are accepted because the alternatives were worse at that moment.\n\r\n\r\n\r\n\r\nAnyone who builds on such a system eventually performs a kind of archaeology, not out of curiosity, but because understanding intent is cheaper than rediscovering it through repeated experiments.\n\r\n\r\n\r\n\r\nThis is where documentation stops being a supporting artifact and starts behaving like a feature. Not a runtime feature, not something you toggle on or off, but a process feature that preserves design context across time. \n\r\n\r\n\r\n\r\nWhen documentation captures who saw what, when, and under which constraints, archaeology becomes traceable instead of speculative.\n\r\n\r\n\r\n\r\nContributor Context as the Differentiator\n\r\n\r\n\r\n\r\nThis is where I need to be precise, because vague praise does not help anyone.\n\r\n\r\n\r\n\r\nThe documentation of PostgreSQL stands out not because it is shorter, friendlier, or more interactive than everything else, but because it consistently preserves design context close to the moment of change. Contributors do not just implement features; they describe what they changed, what guarantees hold, and where those guarantees stop holding.\n\r\n\r\n\r\n\r\nDocumentation and release notes move with the code, not after it. Now, that closeness matters. It means the observer and the describer overlap. \n\r\n\r\n\r\n\r\nThe person who stood on the roof when the sunrise looked a certain way is usually the person who wrote down what they saw. Over decades, that habit compounds into trust.\n\r\n\r\n\r\n\r\nFeature Origins, Design Context, and MVCC\n\r\n\r\n\r\n\r\nMost features in PostgreSQL did not appear because someone invented an abstract capability. They appeared because someone ran into a real limitation, an inefficiency, or a correctness issue in an earlier version and worked through the implications until a solution emerged. That origin story, even when it is not written as a narrative, leaves traces in how the feature is documented.\n\r\n\r\n\r\n\r\nMVCC is a good example. Multi-Version Concurrency Control is not presented as a clever trick; it is documented as a set of guarantees and constraints around visibility and isolation. Different transactions can legitimately see different versions of the same data at the same time, and all of those views are correct within their isolation guarantees. There is no single global “now” inside the system.\n\r\n\r\n\r\n\r\nThis is phenomenology expressed as mechanics. Observation depends on context, and the documentation reflects that by stating what is visible from which position. The important part is not the acronym itself, but the fact that the documentation does not pretend there is a single, observer-free truth.\n\r\n\r\n\r\n\r\nDocs as Code and its Practical Limits\n\r\n\r\n\r\n\r\nI believe strongly in docs as code. Keeping documentation versioned with source, reviewed through the same workflows, and shipped alongside releases is necessary if documentation is to remain accurate over time. But docs as code by itself mostly protects behavioural correctness. It keeps descriptions aligned with what the system does now.\n\r\n\r\n\r\n\r\nWhat it does not automatically provide is etymology. It does not force anyone to explain why a feature exists, why certain trade-offs were accepted, or when a behaviour should not be relied upon. Many projects adopt docs as code and still end up with documentation that explains what and how, but leaves readers guessing about why.\n\r\n\r\n\r\n\r\nPostgreSQL goes further because of culture rather than tooling. Contributors document their own changes, release notes anchor those changes in time,and public discussions preserve the reasoning around them.\n\r\n\r\n\r\n\r\nThe result is not explicit philosophy, but enough context to reconstruct intent when it matters.\n\r\n\r\n\r\n\r\nThe John Doe problem and the New Developer Perspective\n\r\n\r\n\r\n\r\nI often think about a simple scenario. John Doe buys a product and reads a manual that explains every feature perfectly from a usage point of view. He follows it carefully and still ends up confused, because the manual never explains the base assumptions the product relies on. Calibration shifts, internal references change, and behaviour that is technically correct feels wrong because the base was invisible.\n\r\n\r\n\r\n\r\nThe same thing happens in software. When the base is hidden, people are forced into blind experimentation. When the base is visible, learning becomes intentional.\n\r\n\r\n\r\n\r\nFor a developer building, for example, an analytics tool on top of pg_stat views, this difference is decisive.\n\r\n\r\n\r\n\r\nThey can read the documentation to understand what those statistics are meant to represent, consult release notes to see when and why behaviour changed, and trace decisions back through commits and public discussions when their logic depends on those details.\n\r\n\r\n\r\n\r\nIf something still remains unclear, the address book is effectively there: the contributor discussions are public, the context is discoverable, and questions can be asked in a focused way rather than through weeks of guesswork.\n\r\n\r\n\r\n\r\nTesting then becomes validation, not archaeology.\n\r\n\r\n\r\n\r\nBehavioural APIs versus Foundational Building Blocks\n\r\n\r\n\r\n\r\nIt is useful to contrast this with excellent documentation that serves a different purpose. Stripe documentation is world-class at describing behaviour through stable interfaces. It tells you exactly what will happen when you call an endpoint with given parameters, and it deliberately hides internal complexity so you can integrate quickly.\n\r\n\r\n\r\n\r\nPostgreSQL operates at a different layer. It is a building block. Other systems compose on top of it. The documentation therefore has a different responsibility: to expose assumptions, constraints, and limits so that higher-level behaviour can be built safely. \n\r\n\r\n\r\n\r\nComparing the two without acknowledging this difference misses the point.\n\r\n\r\n\r\n\r\nMy perspective as a Technical Writer\n\r\n\r\n\r\n\r\nI started as a developer who used documentation to learn tools. For a long time, I rarely found answers to why something was developed a certain way. Later, when I moved into technical writing, I found myself writing that missing context, trying to preserve intent rather than just describing behaviour.\n\r\n\r\n\r\n\r\nThat second perspective made the gap obvious. In PostgreSQL, that gap is unusually small to zero. The people who experience the problem, design the solution, implement it, and document it often overlap. \n\r\n\r\n\r\n\r\nThe documentation feels grounded because it is rooted in lived engineering decisions rather than retrospective explanations.\n\r\n\r\n\r\n\r\nFinally my lessons and observations \n\r\n\r\n\r\n\r\nThe sunrise does not look the same for everyone, but it becomes understandable once you know where the observer is standing and what blocks the view. \n\r\n\r\n\r\n\r\nPostgreSQL documentation works for the same reason. It does not claim a view from nowhere. It preserves perspective.\n\r\n\r\n\r\n\r\nAs a technical writer, this shapes how I work. When I document APIs, docs as code is often enough because contracts are the product. When I document features and building blocks, I prefer a phenomenological approach, one that records who saw what, when, and under which constraints, because that is what future builders will need.\n\r\n\r\n\r\n\r\nThat is why, in these terms, PostgreSQL documentation stands out.\n\r\n\r\n\r\n\r\nLet me know your thoughts!!!\n\r\nThe post Phenomenology through PostgreSQL Documentation appeared first on CYBERTEC PostgreSQL | Services & Support.	The author draws parallels between phenomenology (how our perspective shapes understanding) and PostgreSQL's documentation approach. They argue that PostgreSQL documentation excels because it preserves design context and contributor perspective close to the moment of implementation. Unlike documentation that only describes current behavior, PostgreSQL's docs capture why features exist, what problems they solve, and their historical context. The author contrasts this with behavioral API documentation like Stripe's, noting PostgreSQL operates as a foundational building block requiring exposed assumptions and constraints. Features like MVCC are documented not as abstract concepts but as solutions to real problems with clear guarantees and limitations. The documentation's strength comes from contributors documenting their own changes, maintaining context across time, and enabling developers to understand intent rather than guess through experimentation.	作者将现象学（我们的视角如何塑造理解）与PostgreSQL的文档方法进行类比。他们认为PostgreSQL文档之所以出色，是因为它在实现时刻附近保留了设计背景和贡献者视角。与仅描述当前行为的文档不同，PostgreSQL的文档记录了功能存在的原因、它们解决的问题以及历史背景。作者将此与Stripe等行为API文档进行对比，指出PostgreSQL作为基础构建块运行，需要暴露假设和约束。像MVCC这样的功能不是作为抽象概念记录的，而是作为真实问题的解决方案，具有清晰的保证和限制。文档的强项来自于贡献者记录自己的更改，跨时间维护背景，并使开发者能够理解意图而不是通过实验猜测。
28	Strategies for upgrading Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL from version 13	https://aws.amazon.com/blogs/database/strategies-for-upgrading-amazon-aurora-postgresql-and-amazon-rds-for-postgresql-from-version-13/	Abhimanyu Tomar	2026-01-27 17:36:14+00	<p>In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.</p> \n<p>Standard support for <a href="https://aws.amazon.com/rds/aurora/features/" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL-Compatible Edition</a> and <a href="https://aws.amazon.com/rds/postgresql/" target="_blank" rel="noopener noreferrer">Amazon Relational Database Service (Amazon RDS) for PostgreSQL</a> version 13 ends on February 28, 2026.</p> \n<p>These updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.</p> \n<p>For detailed upgrade instructions, refer to the official documentation for both <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" rel="noopener" target="_blank">Amazon Aurora PostgreSQL-Compatible</a> and <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL</a>:</p> \n<ul> \n <li><a href="https://repost.aws/articles/ARxQSsnCAlS6OhFm7M10vwjA/announcement-amazon-aurora-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n <li><a href="https://repost.aws/articles/ARRvHxJ_9sTDCGloBavca3kg/announcement-amazon-rds-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n</ul> \n<h2>Key benefits of PostgreSQL newer versions</h2> \n<p>Upgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.</p> \n<h3>Performance enhancements</h3> \n<p>Newer versions offer the following performance enhancements:</p> \n<ul> \n <li><strong>Vacuum emergency mode (v14+)</strong> – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions</li> \n <li><strong>Improved I/O performance</strong> <strong>(v17)</strong> – Offers <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to two times better write throughput</a> with enhanced WAL processing</li> \n <li><strong>Query optimization</strong> <strong>(v17+) </strong>– Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds</li> \n <li><strong>Memory efficiency</strong> <strong>(v17)</strong> – New vacuum memory structure consumes <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to 20 times less memory</a></li> \n</ul> \n<h3>Advanced monitoring and diagnostics</h3> \n<p>You can benefit from the following advanced monitoring and diagnostics features:</p> \n<ul> \n <li><strong>pg_stat_io</strong> <strong>(v16+)</strong> – Provides detailed statistics on I/O operations</li> \n <li><strong>pg_wait_events (v17+) </strong>– Supports in-database reference for wait events, removing manual documentation lookups</li> \n</ul> \n<h3>Logical replication improvements</h3> \n<p>Newer versions offer the following logical replication improvements:</p> \n<ul> \n <li><strong>Failover support</strong> <strong>(v17+)</strong> – You can automatically synchronize logical replication slots from primary to standby servers</li> \n <li><strong>Slot migration</strong> <strong>(v17+) </strong>– Logical replication slots can migrate through pg_upgrade, simplifying upgrades</li> \n <li><strong>Parallel apply</strong> <strong>(v16+)</strong> – This feature writes data directly to the target table using multiple background worker processes</li> \n <li><strong>Row filtering</strong> <strong>(v15+) </strong>– You have fine-grained control over what data is replicated</li> \n</ul> \n<h3>Developer experience</h3> \n<p>Newer versions offer an improved developer experience:</p> \n<ul> \n <li><strong>JSONB subscripting</strong> <strong>(v14+) </strong>– Intuitive syntax for accessing and modifying JSONB data</li> \n <li><strong>SQL/JSON JSON_TABLE (v17+) </strong>– The ability to transform JSON data into relational views</li> \n <li><strong>Query pipelining</strong> <strong>(v14+)</strong> – Reduced network latency for high-latency connections</li> \n</ul> \n<h3>Security enhancements</h3> \n<p>You have access to the following security enhancements:</p> \n<ul> \n <li><strong>pg_read_all_data and pg_write_all_data roles (v14+)</strong> – Streamlined read/write access control</li> \n <li><strong>pg_maintain role</strong> <strong>(v17+)</strong> – Enabling users to perform database maintenance tasks</li> \n <li><strong>(v15+) </strong>– Removal of PUBLIC creation permission on public schema</li> \n</ul> \n<h3>Amazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads</h3> \n<p>For Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.optimized.reads.html" target="_blank" rel="noopener noreferrer">performance optimizations</a>.</p> \n<p>Aurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:</p> \n<ul> \n <li><strong>Tiered cache</strong> – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)</li> \n <li><strong>Temporary objects</strong> – You can experience up to two times faster latency for advanced queries using local NVMe storage</li> \n</ul> \n<h2>PostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)</h2> \n<p>Upgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.</p> \n<h3>Changes in system catalog views</h3> \n<p>The following table summarizes changes in PostgreSQL v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Column Name</b></td> \n   <td><b>Action</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend_fsync</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_stat_checkpointer</td> \n   <td>CREATED</td> \n   <td>Separates checkpointer statistics from background writer</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_wait_events</td> \n   <td>CREATED</td> \n   <td>Wait event information</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes pg_stat_progress_vacuum column renames.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Old Name</b></td> \n   <td><b>New Name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>max_dead_tuples</td> \n   <td>max_dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>num_dead_tuples</td> \n   <td>dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_total</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_processed</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>dead_tuple_bytes</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes additional catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View/Table</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Old name</b></td> \n   <td><b>New name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>New column</td> \n   <td>–</td> \n   <td>dathasloginevt</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>Renamed</td> \n   <td>daticulocale</td> \n   <td>datlocale</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>pg_collation</td> \n   <td>Renamed</td> \n   <td>colliculocale</td> \n   <td>colllocale</td> \n   <td>Column renamed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes modified system views.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>New column(s) added</b></td> \n  </tr> \n  <tr> \n   <td>pg_replication_slots</td> \n   <td>failover; synced; invalidation_reason; inactive_since</td> \n  </tr> \n  <tr> \n   <td>pg_stat_progress_copy</td> \n   <td>tuples_skipped</td> \n  </tr> \n  <tr> \n   <td>pg_stat_subscription</td> \n   <td>worker_type</td> \n  </tr> \n  <tr> \n   <td>pg_stats</td> \n   <td>range_length_histogram; range_empty_frac; range_bounds_histogram</td> \n  </tr> \n  <tr> \n   <td>pg_subscription</td> \n   <td>subfailover</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes PostgreSQL v14 system catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Column name</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>pg_stat_activity</td> \n   <td>New column</td> \n   <td>query_id</td> \n   <td>Requires compute_query_id parameter</td> \n  </tr> \n  <tr> \n   <td>pg_stat_statements</td> \n   <td>New column</td> \n   <td>toplevel</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<h3>Important parameter-related changes</h3> \n<p>The following table summarizes parameter-related changes in PostgreSQL v14.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>compute_query_id</td> \n   <td>Controls query identifier computation</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>client_connection_check_interval</td> \n   <td>Sets the time interval between checks for disconnection while running queries</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>idle_session_timeout</td> \n   <td>Ends sessions not in a transaction that have been idle longer than the specified time</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>default_toast_compression</td> \n   <td>Sets the default compression method for compressible values</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>vacuum_failsafe_age</td> \n   <td>Age at which VACUUM should trigger failsafe to avoid a wraparound outage</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>huge_page_size</td> \n   <td>The size of huge page that should be requested</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>operator_precedence_warning</td> \n   <td>Completely removed</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>vacuum_cleanup_index_scale_factor</td> \n   <td>Removed (deprecated in v12)</td> \n  </tr> \n </tbody> \n</table> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Old value</b></td> \n   <td><b>New value</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>Default Changed</td> \n   <td>password_encryption</td> \n   <td>md5</td> \n   <td>scram-sha-256</td> \n   <td>Password encryption default changed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Version</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>Enhanced</td> \n   <td>wal_compression</td> \n   <td>Supports new algorithms: zstd, lz4</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>New</td> \n   <td>wal_decode_buffer_size</td> \n   <td>Buffer size for WAL decoding</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>vacuum_buffer_usage_limit</td> \n   <td>Limits buffer usage during vacuum</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>logical_replication_mode</td> \n   <td>Controls logical replication behavior</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 17</td> \n   <td>New</td> \n   <td>sync_replication_slots</td> \n   <td>Enables synchronization of replication slots</td> \n  </tr> \n </tbody> \n</table> \n<h2>Upgrade strategy options</h2> \n<p>You have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:</p> \n<ul> \n <li><a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">In-place upgrade</a> – You can perform this upgrade method using either the <a href="http://aws.amazon.com/cli" target="_blank" rel="noopener noreferrer">AWS Command Line Interface</a> (AWS CLI) or <a href="http://aws.amazon.com/console" target="_blank" rel="noopener noreferrer">AWS Management Console</a>. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.</li> \n <li><a href="https://aws.amazon.com/blogs/database/new-fully-managed-blue-green-deployment-in-amazon-aurora-postgresql-and-amazon-rds-for-postgresql/" target="_blank" rel="noopener noreferrer">Amazon RDS blue/green deployment</a> – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.</li> \n <li><a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Logical replication</a> – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.</li> \n <li><a href="https://aws.amazon.com/dms/" target="_blank" rel="noopener noreferrer">AWS Database Migration Service (AWS DMS)</a> – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.</li> \n</ul> \n<p>For detailed information about both in-place upgrades and various out-of-place upgrade options, refer to <a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches</a>. It examines the advantages and disadvantages of each approach.</p> \n<h2>Preparing to upgrade</h2> \n<p>Before upgrading, you should perform the following actions:</p> \n<ul> \n <li>Review your current database configuration</li> \n <li>Test the upgrade process in a staging environment</li> \n <li>Validate application compatibility</li> \n <li>Create comprehensive backup strategies</li> \n</ul> \n<p>If immediate upgrade isn’t feasible, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/extended-support.html" target="_blank" rel="noopener noreferrer">Amazon RDS Extended Support</a> provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.</p> \n<h2>Conclusion</h2> \n<p>Upgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.</p> \n<p>For detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have <a href="https://aws.amazon.com/premiumsupport/plans/enterprise/" target="_blank" rel="noopener noreferrer">AWS Enterprise Support</a>, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.</p> \n<hr> \n<h2>About the authors</h2> \n<footer> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50291.png" alt="Sachin Murkar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Sachin Murkar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/sachinmurkar/" rel="noopener">Sachin</a> is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50292.jpeg" alt="Abhimanyu Tomar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Abhimanyu Tomar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/abhimanyu-tomar/" rel="noopener">Abhimanyu</a> is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50293.jpeg" alt="Niraj Jani" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Niraj Jani</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/nirajjani22/" rel="noopener">Niraj</a> is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.</p>\n </div> \n</footer>	In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.\n \nStandard support for Amazon Aurora PostgreSQL-Compatible Edition and Amazon Relational Database Service (Amazon RDS) for PostgreSQL version 13 ends on February 28, 2026.\n \nThese updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.\n \nFor detailed upgrade instructions, refer to the official documentation for both Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL:\n \n \n \nAmazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nAmazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nKey benefits of PostgreSQL newer versions\n \nUpgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.\n \nPerformance enhancements\n \nNewer versions offer the following performance enhancements:\n \n \n \nVacuum emergency mode (v14+) – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions\n \n \nImproved I/O performance (v17) – Offers up to two times better write throughput with enhanced WAL processing\n \n \nQuery optimization (v17+) – Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds\n \n \nMemory efficiency (v17) – New vacuum memory structure consumes up to 20 times less memory\n \n \nAdvanced monitoring and diagnostics\n \nYou can benefit from the following advanced monitoring and diagnostics features:\n \n \n \npg_stat_io (v16+) – Provides detailed statistics on I/O operations\n \n \npg_wait_events (v17+) – Supports in-database reference for wait events, removing manual documentation lookups\n \n \nLogical replication improvements\n \nNewer versions offer the following logical replication improvements:\n \n \n \nFailover support (v17+) – You can automatically synchronize logical replication slots from primary to standby servers\n \n \nSlot migration (v17+) – Logical replication slots can migrate through pg_upgrade, simplifying upgrades\n \n \nParallel apply (v16+) – This feature writes data directly to the target table using multiple background worker processes\n \n \nRow filtering (v15+) – You have fine-grained control over what data is replicated\n \n \nDeveloper experience\n \nNewer versions offer an improved developer experience:\n \n \n \nJSONB subscripting (v14+) – Intuitive syntax for accessing and modifying JSONB data\n \n \nSQL/JSON JSON_TABLE (v17+) – The ability to transform JSON data into relational views\n \n \nQuery pipelining (v14+) – Reduced network latency for high-latency connections\n \n \nSecurity enhancements\n \nYou have access to the following security enhancements:\n \n \n \npg_read_all_data and pg_write_all_data roles (v14+) – Streamlined read/write access control\n \n \npg_maintain role (v17+) – Enabling users to perform database maintenance tasks\n \n \n(v15+) – Removal of PUBLIC creation permission on public schema\n \n \nAmazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads\n \nFor Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more performance optimizations.\n \nAurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:\n \n \n \nTiered cache – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)\n \n \nTemporary objects – You can experience up to two times faster latency for advanced queries using local NVMe storage\n \n \nPostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)\n \nUpgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.\n \nChanges in system catalog views\n \nThe following table summarizes changes in PostgreSQL v17.\n \n \n  \n  \n \n   Change Type \n   Column Name \n   Action \n   Notes \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend \n   REMOVED \n   – \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend_fsync \n   REMOVED \n   – \n  \n \n  \n \n   New View \n   pg_stat_checkpointer \n   CREATED \n   Separates checkpointer statistics from background writer \n  \n \n  \n \n   New View \n   pg_wait_events \n   CREATED \n   Wait event information \n  \n \n  \n \nThe following table summarizes pg_stat_progress_vacuum column renames.\n \n \n  \n  \n \n   Change Type \n   Old Name \n   New Name \n   Description \n  \n \n  \n \n   Renamed \n   max_dead_tuples \n   max_dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   Renamed \n   num_dead_tuples \n   dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   New column \n   – \n   indexes_total \n   New column added \n  \n \n  \n \n   New column \n   – \n   indexes_processed \n   New column added \n  \n \n  \n \n   New column \n   – \n   dead_tuple_bytes \n   New column added \n  \n \n  \n \nThe following table summarizes additional catalog changes.\n \n \n  \n  \n \n   View/Table \n   Change type \n   Old name \n   New name \n   Description \n  \n \n  \n \n   pg_database \n   New column \n   – \n   dathasloginevt \n   New column added \n  \n \n  \n \n   pg_database \n   Renamed \n   daticulocale \n   datlocale \n   Column renamed \n  \n \n  \n \n   pg_collation \n   Renamed \n   colliculocale \n   colllocale \n   Column renamed \n  \n \n  \n \nThe following table summarizes modified system views.\n \n \n  \n  \n \n   View name \n   New column(s) added \n  \n \n  \n \n   pg_replication_slots \n   failover; synced; invalidation_reason; inactive_since \n  \n \n  \n \n   pg_stat_progress_copy \n   tuples_skipped \n  \n \n  \n \n   pg_stat_subscription \n   worker_type \n  \n \n  \n \n   pg_stats \n   range_length_histogram; range_empty_frac; range_bounds_histogram \n  \n \n  \n \n   pg_subscription \n   subfailover \n  \n \n  \n \nThe following table summarizes PostgreSQL v14 system catalog changes.\n \n \n  \n  \n \n   View name \n   Change type \n   Column name \n   Notes \n  \n \n  \n \n   pg_stat_activity \n   New column \n   query_id \n   Requires compute_query_id parameter \n  \n \n  \n \n   pg_stat_statements \n   New column \n   toplevel \n   New column added \n  \n \n  \n \nImportant parameter-related changes\n \nThe following table summarizes parameter-related changes in PostgreSQL v14.\n \n \n  \n  \n \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   New \n   compute_query_id \n   Controls query identifier computation \n  \n \n  \n \n   New \n   client_connection_check_interval \n   Sets the time interval between checks for disconnection while running queries \n  \n \n  \n \n   New \n   idle_session_timeout \n   Ends sessions not in a transaction that have been idle longer than the specified time \n  \n \n  \n \n   New \n   default_toast_compression \n   Sets the default compression method for compressible values \n  \n \n  \n \n   New \n   vacuum_failsafe_age \n   Age at which VACUUM should trigger failsafe to avoid a wraparound outage \n  \n \n  \n \n   New \n   huge_page_size \n   The size of huge page that should be requested \n  \n \n  \n \n   Removed \n   operator_precedence_warning \n   Completely removed \n  \n \n  \n \n   Removed \n   vacuum_cleanup_index_scale_factor \n   Removed (deprecated in v12) \n  \n \n  \n \n \n  \n  \n \n   Change type \n   Parameter name \n   Old value \n   New value \n   Description/Notes \n  \n \n  \n \n   Default Changed \n   password_encryption \n   md5 \n   scram-sha-256 \n   Password encryption default changed \n  \n \n  \n \nThe following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.\n \n \n  \n  \n \n   Version \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   PostgreSQL 15 \n   Enhanced \n   wal_compression \n   Supports new algorithms: zstd, lz4 \n  \n \n  \n \n   PostgreSQL 15 \n   New \n   wal_decode_buffer_size \n   Buffer size for WAL decoding \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   vacuum_buffer_usage_limit \n   Limits buffer usage during vacuum \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   logical_replication_mode \n   Controls logical replication behavior \n  \n \n  \n \n   PostgreSQL 17 \n   New \n   sync_replication_slots \n   Enables synchronization of replication slots \n  \n \n  \n \nUpgrade strategy options\n \nYou have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:\n \n \n \nIn-place upgrade – You can perform this upgrade method using either the AWS Command Line Interface (AWS CLI) or AWS Management Console. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.\n \n \nAmazon RDS blue/green deployment – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.\n \n \nLogical replication – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.\n \n \nAWS Database Migration Service (AWS DMS) – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.\n \n \nFor detailed information about both in-place upgrades and various out-of-place upgrade options, refer to Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches. It examines the advantages and disadvantages of each approach.\n \nPreparing to upgrade\n \nBefore upgrading, you should perform the following actions:\n \n \n \nReview your current database configuration\n \n \nTest the upgrade process in a staging environment\n \n \nValidate application compatibility\n \n \nCreate comprehensive backup strategies\n \n \nIf immediate upgrade isn’t feasible, Amazon RDS Extended Support provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.\n \nConclusion\n \nUpgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.\n \nFor detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have AWS Enterprise Support, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.\n \n \nAbout the authors\n \n \n \n \n  \n \n  \nSachin Murkar\n \n  \nSachin is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.\n \n \n \n  \n \n  \nAbhimanyu Tomar\n \n  \nAbhimanyu is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.\n \n \n \n  \n \n  \nNiraj Jani\n \n  \nNiraj is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.	AWS is ending standard support for Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL version 13 on February 28, 2026. The post outlines upgrade strategies and benefits of newer PostgreSQL versions (14-17), including performance enhancements like vacuum emergency mode, improved I/O performance, and memory efficiency improvements. Key new features include advanced monitoring tools (pg_stat_io, pg_wait_events), logical replication improvements with failover support, and security enhancements. The upgrade brings system catalog changes that may affect applications. Four upgrade strategies are available: in-place upgrade, blue/green deployment, logical replication, and AWS DMS. AWS offers Extended Support for up to 3 years as a paid service for organizations needing more time to upgrade.	AWS将于2026年2月28日结束对Amazon Aurora PostgreSQL和Amazon RDS for PostgreSQL版本13的标准支持。该文章概述了升级策略和新版本PostgreSQL（14-17）的优势，包括性能增强如vacuum紧急模式、改进的I/O性能和内存效率提升。主要新功能包括高级监控工具（pg_stat_io、pg_wait_events）、支持故障转移的逻辑复制改进以及安全增强功能。升级带来的系统目录更改可能会影响应用程序。提供四种升级策略：就地升级、蓝绿部署、逻辑复制和AWS DMS。对于需要更多时间升级的组织，AWS提供长达3年的付费Extended Support服务。
28	Phenomenology through PostgreSQL Documentation	https://www.cybertec-postgresql.com/en/phenomenology-through-postgresql-documentation/	Abhisek Goswami	2026-01-27 06:23:51+00	\r\n<p>Do you think the way you see the sunrise is the same for everyone?</p>\r\n\r\n\r\n\r\n<p>From where I live, the sun does not rise the way it does in postcards. It appears late, partially blocked by nearby buildings, sometimes sharp, sometimes muted, and often unnoticed until it is already well above the horizon. Someone standing on a hill sees it earlier. Someone near the sea sees it stretch slowly and wide. The sun itself does nothing different. What changes is where we stand when we observe it.</p>\r\n\r\n\r\n\r\n<p>This simple experience has a name: <strong>Phenomenology</strong>. It is the idea that reality exists independently, but our understanding of it is always shaped by perspective, timing, and constraints. We never describe the sun itself; we describe the sunrise as seen from a particular roof. </p>\r\n\r\n\r\n\r\n<p>Over time, I realised that this is exactly how documentation works when it works well.</p>\r\n\r\n\r\n\r\n<h2 id="h-documentation-as-observation-and-historical-record" class="wp-block-heading">Documentation as Observation and Historical Record</h2>\r\n\r\n\r\n\r\n<p>Phenomenology may sound philosophical, but in practice it is very concrete. It asks one question that matters deeply in engineering: from where is this description written?</p>\r\n\r\n\r\n\r\n<p>Long-lived systems accumulate history whether we like it or not. Features are introduced to solve earlier problems, constraints are added to protect correctness, and trade-offs are accepted because the alternatives were worse at that moment.</p>\r\n\r\n\r\n\r\n<p>Anyone who builds on such a system eventually performs a kind of archaeology, not out of curiosity, but because understanding intent is cheaper than rediscovering it through repeated experiments.</p>\r\n\r\n\r\n\r\n<p>This is where documentation stops being a supporting artifact and starts behaving like a feature. Not a runtime feature, not something you toggle on or off, but a process feature that preserves design context across time. </p>\r\n\r\n\r\n\r\n<p>When documentation captures who saw what, when, and under which constraints, archaeology becomes traceable instead of speculative.</p>\r\n\r\n\r\n\r\n<h2 id="h-contributor-context-as-the-differentiator" class="wp-block-heading">Contributor Context as the Differentiator</h2>\r\n\r\n\r\n\r\n<p>This is where I need to be precise, because vague praise does not help anyone.</p>\r\n\r\n\r\n\r\n<p>The documentation of <a href="https://www.postgresql.org/docs/">PostgreSQL</a> stands out not because it is shorter, friendlier, or more interactive than everything else, but because it consistently preserves design context close to the moment of change. Contributors do not just implement features; they describe what they changed, what guarantees hold, and where those guarantees stop holding.</p>\r\n\r\n\r\n\r\n<p>Documentation and release notes move with the code, not after it. Now, that closeness matters. It means the observer and the describer overlap. </p>\r\n\r\n\r\n\r\n<p>The person who stood on the roof when the sunrise looked a certain way is usually the person who wrote down what they saw. Over decades, that habit compounds into trust.</p>\r\n\r\n\r\n\r\n<h2 id="h-feature-origins-design-context-and-mvcc" class="wp-block-heading">Feature Origins, Design Context, and MVCC</h2>\r\n\r\n\r\n\r\n<p>Most features in PostgreSQL did not appear because someone invented an abstract capability. They appeared because someone ran into a real limitation, an inefficiency, or a correctness issue in an earlier version and worked through the implications until a solution emerged. That origin story, even when it is not written as a narrative, leaves traces in how the feature is documented.</p>\r\n\r\n\r\n\r\n<p>MVCC is a good example. Multi-Version Concurrency Control is not presented as a clever trick; it is documented as a set of guarantees and constraints around visibility and isolation. Different transactions can legitimately see different versions of the same data at the same time, and all of those views are correct within their isolation guarantees. There is no single global “now” inside the system.</p>\r\n\r\n\r\n\r\n<p>This is phenomenology expressed as mechanics. Observation depends on context, and the documentation reflects that by stating what is visible from which position. The important part is not the acronym itself, but the fact that the documentation does not pretend there is a single, observer-free truth.</p>\r\n\r\n\r\n\r\n<h2 id="h-docs-as-code-and-its-practical-limits" class="wp-block-heading">Docs as Code and its Practical Limits</h2>\r\n\r\n\r\n\r\n<p>I believe strongly in docs as code. Keeping documentation versioned with source, reviewed through the same workflows, and shipped alongside releases is necessary if documentation is to remain accurate over time. But docs as code by itself mostly protects behavioural correctness. It keeps descriptions aligned with what the system does now.</p>\r\n\r\n\r\n\r\n<p>What it does not automatically provide is etymology. It does not force anyone to explain why a feature exists, why certain trade-offs were accepted, or when a behaviour should not be relied upon. Many projects adopt docs as code and still end up with documentation that explains what and how, but leaves readers guessing about why.</p>\r\n\r\n\r\n\r\n<p>PostgreSQL goes further because of culture rather than tooling. Contributors document their own changes, release notes anchor those changes in time,and public discussions preserve the reasoning around them.</p>\r\n\r\n\r\n\r\n<p>The result is not explicit philosophy, but enough context to reconstruct intent when it matters.</p>\r\n\r\n\r\n\r\n<h2 id="h-the-john-doe-problem-and-the-new-developer-perspective" class="wp-block-heading">The John Doe problem and the New Developer Perspective</h2>\r\n\r\n\r\n\r\n<p>I often think about a simple scenario. John Doe buys a product and reads a manual that explains every feature perfectly from a usage point of view. He follows it carefully and still ends up confused, because the manual never explains the base assumptions the product relies on. Calibration shifts, internal references change, and behaviour that is technically correct feels wrong because the base was invisible.</p>\r\n\r\n\r\n\r\n<p>The same thing happens in software. When the base is hidden, people are forced into blind experimentation. When the base is visible, learning becomes intentional.</p>\r\n\r\n\r\n\r\n<p>For a developer building, for example, an analytics tool on top of <strong>pg_stat views</strong>, this difference is decisive.</p>\r\n\r\n\r\n\r\n<p>They can read the documentation to understand what those statistics are meant to represent, consult release notes to see when and why behaviour changed, and trace decisions back through commits and public discussions when their logic depends on those details.</p>\r\n\r\n\r\n\r\n<p>If something still remains unclear, the address book is effectively there: <strong><em>the contributor discussions are public, the context is discoverable, and questions can be asked in a focused way rather than through weeks of guesswork.</em></strong></p>\r\n\r\n\r\n\r\n<p><strong>Testing then becomes validation, not archaeology.</strong></p>\r\n\r\n\r\n\r\n<h2 id="h-behavioural-apis-versus-foundational-building-blocks" class="wp-block-heading">Behavioural APIs versus Foundational Building Blocks</h2>\r\n\r\n\r\n\r\n<p>It is useful to contrast this with excellent documentation that serves a different purpose. <a href="https://docs.stripe.com/">Stripe</a> documentation is world-class at describing behaviour through stable interfaces. It tells you exactly what will happen when you call an endpoint with given parameters, and it deliberately hides internal complexity so you can integrate quickly.</p>\r\n\r\n\r\n\r\n<p>PostgreSQL operates at a different layer. It is a building block. Other systems compose on top of it. The documentation therefore has a different responsibility: to expose assumptions, constraints, and limits so that higher-level behaviour can be built safely. </p>\r\n\r\n\r\n\r\n<p>Comparing the two without acknowledging this difference misses the point.</p>\r\n\r\n\r\n\r\n<h2 id="h-my-perspective-as-a-technical-writer" class="wp-block-heading">My perspective as a Technical Writer</h2>\r\n\r\n\r\n\r\n<p>I started as a developer who used documentation to learn tools. For a long time, I rarely found answers to why something was developed a certain way. Later, when I moved into technical writing, I found myself writing that missing context, trying to preserve intent rather than just describing behaviour.</p>\r\n\r\n\r\n\r\n<p>That second perspective made the gap obvious. In PostgreSQL, that gap is unusually small to zero. The people who experience the problem, design the solution, implement it, and document it often overlap. </p>\r\n\r\n\r\n\r\n<p>The documentation feels grounded because it is rooted in lived engineering decisions rather than retrospective explanations.</p>\r\n\r\n\r\n\r\n<h2 id="h-finally-my-lessons-and-observations-nbsp" class="wp-block-heading">Finally my lessons and observations </h2>\r\n\r\n\r\n\r\n<p>The sunrise does not look the same for everyone, but it becomes understandable once you know where the observer is standing and what blocks the view. </p>\r\n\r\n\r\n\r\n<p>PostgreSQL documentation works for the same reason. It does not claim a view from nowhere. It preserves perspective.</p>\r\n\r\n\r\n\r\n<p>As a technical writer, this shapes how I work. When I document APIs, docs as code is often enough because contracts are the product. When I document features and building blocks, I prefer a phenomenological approach, one that records who saw what, when, and under which constraints, because that is what future builders will need.</p>\r\n\r\n\r\n\r\n<p>That is why, in these terms, PostgreSQL documentation stands out.</p>\r\n\r\n\r\n\r\n<p>Let me know your thoughts!!!</p>\r\n<p>The post <a href="https://www.cybertec-postgresql.com/en/phenomenology-through-postgresql-documentation/">Phenomenology through PostgreSQL Documentation</a> appeared first on <a href="https://www.cybertec-postgresql.com/en">CYBERTEC PostgreSQL | Services &amp; Support</a>.</p>\n	Do you think the way you see the sunrise is the same for everyone?\n\r\n\r\n\r\n\r\nFrom where I live, the sun does not rise the way it does in postcards. It appears late, partially blocked by nearby buildings, sometimes sharp, sometimes muted, and often unnoticed until it is already well above the horizon. Someone standing on a hill sees it earlier. Someone near the sea sees it stretch slowly and wide. The sun itself does nothing different. What changes is where we stand when we observe it.\n\r\n\r\n\r\n\r\nThis simple experience has a name: Phenomenology. It is the idea that reality exists independently, but our understanding of it is always shaped by perspective, timing, and constraints. We never describe the sun itself; we describe the sunrise as seen from a particular roof. \n\r\n\r\n\r\n\r\nOver time, I realised that this is exactly how documentation works when it works well.\n\r\n\r\n\r\n\r\nDocumentation as Observation and Historical Record\n\r\n\r\n\r\n\r\nPhenomenology may sound philosophical, but in practice it is very concrete. It asks one question that matters deeply in engineering: from where is this description written?\n\r\n\r\n\r\n\r\nLong-lived systems accumulate history whether we like it or not. Features are introduced to solve earlier problems, constraints are added to protect correctness, and trade-offs are accepted because the alternatives were worse at that moment.\n\r\n\r\n\r\n\r\nAnyone who builds on such a system eventually performs a kind of archaeology, not out of curiosity, but because understanding intent is cheaper than rediscovering it through repeated experiments.\n\r\n\r\n\r\n\r\nThis is where documentation stops being a supporting artifact and starts behaving like a feature. Not a runtime feature, not something you toggle on or off, but a process feature that preserves design context across time. \n\r\n\r\n\r\n\r\nWhen documentation captures who saw what, when, and under which constraints, archaeology becomes traceable instead of speculative.\n\r\n\r\n\r\n\r\nContributor Context as the Differentiator\n\r\n\r\n\r\n\r\nThis is where I need to be precise, because vague praise does not help anyone.\n\r\n\r\n\r\n\r\nThe documentation of PostgreSQL stands out not because it is shorter, friendlier, or more interactive than everything else, but because it consistently preserves design context close to the moment of change. Contributors do not just implement features; they describe what they changed, what guarantees hold, and where those guarantees stop holding.\n\r\n\r\n\r\n\r\nDocumentation and release notes move with the code, not after it. Now, that closeness matters. It means the observer and the describer overlap. \n\r\n\r\n\r\n\r\nThe person who stood on the roof when the sunrise looked a certain way is usually the person who wrote down what they saw. Over decades, that habit compounds into trust.\n\r\n\r\n\r\n\r\nFeature Origins, Design Context, and MVCC\n\r\n\r\n\r\n\r\nMost features in PostgreSQL did not appear because someone invented an abstract capability. They appeared because someone ran into a real limitation, an inefficiency, or a correctness issue in an earlier version and worked through the implications until a solution emerged. That origin story, even when it is not written as a narrative, leaves traces in how the feature is documented.\n\r\n\r\n\r\n\r\nMVCC is a good example. Multi-Version Concurrency Control is not presented as a clever trick; it is documented as a set of guarantees and constraints around visibility and isolation. Different transactions can legitimately see different versions of the same data at the same time, and all of those views are correct within their isolation guarantees. There is no single global “now” inside the system.\n\r\n\r\n\r\n\r\nThis is phenomenology expressed as mechanics. Observation depends on context, and the documentation reflects that by stating what is visible from which position. The important part is not the acronym itself, but the fact that the documentation does not pretend there is a single, observer-free truth.\n\r\n\r\n\r\n\r\nDocs as Code and its Practical Limits\n\r\n\r\n\r\n\r\nI believe strongly in docs as code. Keeping documentation versioned with source, reviewed through the same workflows, and shipped alongside releases is necessary if documentation is to remain accurate over time. But docs as code by itself mostly protects behavioural correctness. It keeps descriptions aligned with what the system does now.\n\r\n\r\n\r\n\r\nWhat it does not automatically provide is etymology. It does not force anyone to explain why a feature exists, why certain trade-offs were accepted, or when a behaviour should not be relied upon. Many projects adopt docs as code and still end up with documentation that explains what and how, but leaves readers guessing about why.\n\r\n\r\n\r\n\r\nPostgreSQL goes further because of culture rather than tooling. Contributors document their own changes, release notes anchor those changes in time,and public discussions preserve the reasoning around them.\n\r\n\r\n\r\n\r\nThe result is not explicit philosophy, but enough context to reconstruct intent when it matters.\n\r\n\r\n\r\n\r\nThe John Doe problem and the New Developer Perspective\n\r\n\r\n\r\n\r\nI often think about a simple scenario. John Doe buys a product and reads a manual that explains every feature perfectly from a usage point of view. He follows it carefully and still ends up confused, because the manual never explains the base assumptions the product relies on. Calibration shifts, internal references change, and behaviour that is technically correct feels wrong because the base was invisible.\n\r\n\r\n\r\n\r\nThe same thing happens in software. When the base is hidden, people are forced into blind experimentation. When the base is visible, learning becomes intentional.\n\r\n\r\n\r\n\r\nFor a developer building, for example, an analytics tool on top of pg_stat views, this difference is decisive.\n\r\n\r\n\r\n\r\nThey can read the documentation to understand what those statistics are meant to represent, consult release notes to see when and why behaviour changed, and trace decisions back through commits and public discussions when their logic depends on those details.\n\r\n\r\n\r\n\r\nIf something still remains unclear, the address book is effectively there: the contributor discussions are public, the context is discoverable, and questions can be asked in a focused way rather than through weeks of guesswork.\n\r\n\r\n\r\n\r\nTesting then becomes validation, not archaeology.\n\r\n\r\n\r\n\r\nBehavioural APIs versus Foundational Building Blocks\n\r\n\r\n\r\n\r\nIt is useful to contrast this with excellent documentation that serves a different purpose. Stripe documentation is world-class at describing behaviour through stable interfaces. It tells you exactly what will happen when you call an endpoint with given parameters, and it deliberately hides internal complexity so you can integrate quickly.\n\r\n\r\n\r\n\r\nPostgreSQL operates at a different layer. It is a building block. Other systems compose on top of it. The documentation therefore has a different responsibility: to expose assumptions, constraints, and limits so that higher-level behaviour can be built safely. \n\r\n\r\n\r\n\r\nComparing the two without acknowledging this difference misses the point.\n\r\n\r\n\r\n\r\nMy perspective as a Technical Writer\n\r\n\r\n\r\n\r\nI started as a developer who used documentation to learn tools. For a long time, I rarely found answers to why something was developed a certain way. Later, when I moved into technical writing, I found myself writing that missing context, trying to preserve intent rather than just describing behaviour.\n\r\n\r\n\r\n\r\nThat second perspective made the gap obvious. In PostgreSQL, that gap is unusually small to zero. The people who experience the problem, design the solution, implement it, and document it often overlap. \n\r\n\r\n\r\n\r\nThe documentation feels grounded because it is rooted in lived engineering decisions rather than retrospective explanations.\n\r\n\r\n\r\n\r\nFinally my lessons and observations \n\r\n\r\n\r\n\r\nThe sunrise does not look the same for everyone, but it becomes understandable once you know where the observer is standing and what blocks the view. \n\r\n\r\n\r\n\r\nPostgreSQL documentation works for the same reason. It does not claim a view from nowhere. It preserves perspective.\n\r\n\r\n\r\n\r\nAs a technical writer, this shapes how I work. When I document APIs, docs as code is often enough because contracts are the product. When I document features and building blocks, I prefer a phenomenological approach, one that records who saw what, when, and under which constraints, because that is what future builders will need.\n\r\n\r\n\r\n\r\nThat is why, in these terms, PostgreSQL documentation stands out.\n\r\n\r\n\r\n\r\nLet me know your thoughts!!!\n\r\nThe post Phenomenology through PostgreSQL Documentation appeared first on CYBERTEC PostgreSQL | Services & Support.	The author explores how phenomenology applies to PostgreSQL documentation, arguing that good documentation preserves design context and perspective rather than claiming objective truth. They highlight PostgreSQL's documentation strength: contributors document their own changes close to implementation time, preserving the reasoning behind features like MVCC. This creates traceable archaeology instead of speculative guesswork for future developers. The author contrasts this with behavioral APIs like Stripe, noting PostgreSQL serves as a foundational building block requiring exposed assumptions and constraints. The documentation succeeds because it maintains contributor context, links features to their origins, and preserves decision-making rationale through integrated docs-as-code culture and public discussions.	作者探讨了现象学如何应用于PostgreSQL文档，认为好的文档应该保留设计背景和视角，而不是声称客观真理。他们强调了PostgreSQL文档的优势：贡献者在接近实现时记录自己的更改，保留了MVCC等功能背后的推理过程。这为未来开发者创造了可追溯的考古学，而非推测性的猜测。作者将其与Stripe等行为API进行对比，指出PostgreSQL作为基础构建块需要暴露假设和约束。该文档的成功在于它保持了贡献者背景，将功能与其起源联系起来，并通过集成的docs-as-code文化和公开讨论保留了决策制定的理由。
29	Strategies for upgrading Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL from version 13	https://aws.amazon.com/blogs/database/strategies-for-upgrading-amazon-aurora-postgresql-and-amazon-rds-for-postgresql-from-version-13/	Abhimanyu Tomar	2026-01-27 17:36:14+00	<p>In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.</p> \n<p>Standard support for <a href="https://aws.amazon.com/rds/aurora/features/" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL-Compatible Edition</a> and <a href="https://aws.amazon.com/rds/postgresql/" target="_blank" rel="noopener noreferrer">Amazon Relational Database Service (Amazon RDS) for PostgreSQL</a> version 13 ends on February 28, 2026.</p> \n<p>These updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.</p> \n<p>For detailed upgrade instructions, refer to the official documentation for both <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" rel="noopener" target="_blank">Amazon Aurora PostgreSQL-Compatible</a> and <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL</a>:</p> \n<ul> \n <li><a href="https://repost.aws/articles/ARxQSsnCAlS6OhFm7M10vwjA/announcement-amazon-aurora-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n <li><a href="https://repost.aws/articles/ARRvHxJ_9sTDCGloBavca3kg/announcement-amazon-rds-postgresql-13-x-end-of-standard-support-is-february-28-2026" target="_blank" rel="noopener noreferrer">Amazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026</a></li> \n</ul> \n<h2>Key benefits of PostgreSQL newer versions</h2> \n<p>Upgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.</p> \n<h3>Performance enhancements</h3> \n<p>Newer versions offer the following performance enhancements:</p> \n<ul> \n <li><strong>Vacuum emergency mode (v14+)</strong> – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions</li> \n <li><strong>Improved I/O performance</strong> <strong>(v17)</strong> – Offers <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to two times better write throughput</a> with enhanced WAL processing</li> \n <li><strong>Query optimization</strong> <strong>(v17+) </strong>– Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds</li> \n <li><strong>Memory efficiency</strong> <strong>(v17)</strong> – New vacuum memory structure consumes <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/" target="_blank" rel="noopener noreferrer">up to 20 times less memory</a></li> \n</ul> \n<h3>Advanced monitoring and diagnostics</h3> \n<p>You can benefit from the following advanced monitoring and diagnostics features:</p> \n<ul> \n <li><strong>pg_stat_io</strong> <strong>(v16+)</strong> – Provides detailed statistics on I/O operations</li> \n <li><strong>pg_wait_events (v17+) </strong>– Supports in-database reference for wait events, removing manual documentation lookups</li> \n</ul> \n<h3>Logical replication improvements</h3> \n<p>Newer versions offer the following logical replication improvements:</p> \n<ul> \n <li><strong>Failover support</strong> <strong>(v17+)</strong> – You can automatically synchronize logical replication slots from primary to standby servers</li> \n <li><strong>Slot migration</strong> <strong>(v17+) </strong>– Logical replication slots can migrate through pg_upgrade, simplifying upgrades</li> \n <li><strong>Parallel apply</strong> <strong>(v16+)</strong> – This feature writes data directly to the target table using multiple background worker processes</li> \n <li><strong>Row filtering</strong> <strong>(v15+) </strong>– You have fine-grained control over what data is replicated</li> \n</ul> \n<h3>Developer experience</h3> \n<p>Newer versions offer an improved developer experience:</p> \n<ul> \n <li><strong>JSONB subscripting</strong> <strong>(v14+) </strong>– Intuitive syntax for accessing and modifying JSONB data</li> \n <li><strong>SQL/JSON JSON_TABLE (v17+) </strong>– The ability to transform JSON data into relational views</li> \n <li><strong>Query pipelining</strong> <strong>(v14+)</strong> – Reduced network latency for high-latency connections</li> \n</ul> \n<h3>Security enhancements</h3> \n<p>You have access to the following security enhancements:</p> \n<ul> \n <li><strong>pg_read_all_data and pg_write_all_data roles (v14+)</strong> – Streamlined read/write access control</li> \n <li><strong>pg_maintain role</strong> <strong>(v17+)</strong> – Enabling users to perform database maintenance tasks</li> \n <li><strong>(v15+) </strong>– Removal of PUBLIC creation permission on public schema</li> \n</ul> \n<h3>Amazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads</h3> \n<p>For Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more <a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.optimized.reads.html" target="_blank" rel="noopener noreferrer">performance optimizations</a>.</p> \n<p>Aurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:</p> \n<ul> \n <li><strong>Tiered cache</strong> – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)</li> \n <li><strong>Temporary objects</strong> – You can experience up to two times faster latency for advanced queries using local NVMe storage</li> \n</ul> \n<h2>PostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)</h2> \n<p>Upgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.</p> \n<h3>Changes in system catalog views</h3> \n<p>The following table summarizes changes in PostgreSQL v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Column Name</b></td> \n   <td><b>Action</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>Removed from pg_stat_bgwriter</td> \n   <td>buffers_backend_fsync</td> \n   <td>REMOVED</td> \n   <td>–</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_stat_checkpointer</td> \n   <td>CREATED</td> \n   <td>Separates checkpointer statistics from background writer</td> \n  </tr> \n  <tr> \n   <td>New View</td> \n   <td>pg_wait_events</td> \n   <td>CREATED</td> \n   <td>Wait event information</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes pg_stat_progress_vacuum column renames.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change Type</b></td> \n   <td><b>Old Name</b></td> \n   <td><b>New Name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>max_dead_tuples</td> \n   <td>max_dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>Renamed</td> \n   <td>num_dead_tuples</td> \n   <td>dead_tuple_bytes</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_total</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>indexes_processed</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>New column</td> \n   <td>–</td> \n   <td>dead_tuple_bytes</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes additional catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View/Table</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Old name</b></td> \n   <td><b>New name</b></td> \n   <td><b>Description</b></td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>New column</td> \n   <td>–</td> \n   <td>dathasloginevt</td> \n   <td>New column added</td> \n  </tr> \n  <tr> \n   <td>pg_database</td> \n   <td>Renamed</td> \n   <td>daticulocale</td> \n   <td>datlocale</td> \n   <td>Column renamed</td> \n  </tr> \n  <tr> \n   <td>pg_collation</td> \n   <td>Renamed</td> \n   <td>colliculocale</td> \n   <td>colllocale</td> \n   <td>Column renamed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes modified system views.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>New column(s) added</b></td> \n  </tr> \n  <tr> \n   <td>pg_replication_slots</td> \n   <td>failover; synced; invalidation_reason; inactive_since</td> \n  </tr> \n  <tr> \n   <td>pg_stat_progress_copy</td> \n   <td>tuples_skipped</td> \n  </tr> \n  <tr> \n   <td>pg_stat_subscription</td> \n   <td>worker_type</td> \n  </tr> \n  <tr> \n   <td>pg_stats</td> \n   <td>range_length_histogram; range_empty_frac; range_bounds_histogram</td> \n  </tr> \n  <tr> \n   <td>pg_subscription</td> \n   <td>subfailover</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes PostgreSQL v14 system catalog changes.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>View name</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Column name</b></td> \n   <td><b>Notes</b></td> \n  </tr> \n  <tr> \n   <td>pg_stat_activity</td> \n   <td>New column</td> \n   <td>query_id</td> \n   <td>Requires compute_query_id parameter</td> \n  </tr> \n  <tr> \n   <td>pg_stat_statements</td> \n   <td>New column</td> \n   <td>toplevel</td> \n   <td>New column added</td> \n  </tr> \n </tbody> \n</table> \n<h3>Important parameter-related changes</h3> \n<p>The following table summarizes parameter-related changes in PostgreSQL v14.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>compute_query_id</td> \n   <td>Controls query identifier computation</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>client_connection_check_interval</td> \n   <td>Sets the time interval between checks for disconnection while running queries</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>idle_session_timeout</td> \n   <td>Ends sessions not in a transaction that have been idle longer than the specified time</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>default_toast_compression</td> \n   <td>Sets the default compression method for compressible values</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>vacuum_failsafe_age</td> \n   <td>Age at which VACUUM should trigger failsafe to avoid a wraparound outage</td> \n  </tr> \n  <tr> \n   <td>New</td> \n   <td>huge_page_size</td> \n   <td>The size of huge page that should be requested</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>operator_precedence_warning</td> \n   <td>Completely removed</td> \n  </tr> \n  <tr> \n   <td>Removed</td> \n   <td>vacuum_cleanup_index_scale_factor</td> \n   <td>Removed (deprecated in v12)</td> \n  </tr> \n </tbody> \n</table> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Old value</b></td> \n   <td><b>New value</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>Default Changed</td> \n   <td>password_encryption</td> \n   <td>md5</td> \n   <td>scram-sha-256</td> \n   <td>Password encryption default changed</td> \n  </tr> \n </tbody> \n</table> \n<p>The following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.</p> \n<table class="styled-table" border="1px" cellpadding="10px" width="100%"> \n <tbody> \n  <tr bgcolor="#d3d3d3"> \n   <td><b>Version</b></td> \n   <td><b>Change type</b></td> \n   <td><b>Parameter name</b></td> \n   <td><b>Description/Notes</b></td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>Enhanced</td> \n   <td>wal_compression</td> \n   <td>Supports new algorithms: zstd, lz4</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 15</td> \n   <td>New</td> \n   <td>wal_decode_buffer_size</td> \n   <td>Buffer size for WAL decoding</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>vacuum_buffer_usage_limit</td> \n   <td>Limits buffer usage during vacuum</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 16</td> \n   <td>New</td> \n   <td>logical_replication_mode</td> \n   <td>Controls logical replication behavior</td> \n  </tr> \n  <tr> \n   <td>PostgreSQL 17</td> \n   <td>New</td> \n   <td>sync_replication_slots</td> \n   <td>Enables synchronization of replication slots</td> \n  </tr> \n </tbody> \n</table> \n<h2>Upgrade strategy options</h2> \n<p>You have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:</p> \n<ul> \n <li><a href="https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.PostgreSQL.html" target="_blank" rel="noopener noreferrer">In-place upgrade</a> – You can perform this upgrade method using either the <a href="http://aws.amazon.com/cli" target="_blank" rel="noopener noreferrer">AWS Command Line Interface</a> (AWS CLI) or <a href="http://aws.amazon.com/console" target="_blank" rel="noopener noreferrer">AWS Management Console</a>. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.</li> \n <li><a href="https://aws.amazon.com/blogs/database/new-fully-managed-blue-green-deployment-in-amazon-aurora-postgresql-and-amazon-rds-for-postgresql/" target="_blank" rel="noopener noreferrer">Amazon RDS blue/green deployment</a> – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.</li> \n <li><a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Logical replication</a> – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.</li> \n <li><a href="https://aws.amazon.com/dms/" target="_blank" rel="noopener noreferrer">AWS Database Migration Service (AWS DMS)</a> – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.</li> \n</ul> \n<p>For detailed information about both in-place upgrades and various out-of-place upgrade options, refer to <a href="https://aws.amazon.com/blogs/database/part-1-upgrade-your-amazon-rds-for-postgresql-database-comparing-upgrade-approaches/" target="_blank" rel="noopener noreferrer">Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches</a>. It examines the advantages and disadvantages of each approach.</p> \n<h2>Preparing to upgrade</h2> \n<p>Before upgrading, you should perform the following actions:</p> \n<ul> \n <li>Review your current database configuration</li> \n <li>Test the upgrade process in a staging environment</li> \n <li>Validate application compatibility</li> \n <li>Create comprehensive backup strategies</li> \n</ul> \n<p>If immediate upgrade isn’t feasible, <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/extended-support.html" target="_blank" rel="noopener noreferrer">Amazon RDS Extended Support</a> provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.</p> \n<h2>Conclusion</h2> \n<p>Upgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.</p> \n<p>For detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have <a href="https://aws.amazon.com/premiumsupport/plans/enterprise/" target="_blank" rel="noopener noreferrer">AWS Enterprise Support</a>, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.</p> \n<hr> \n<h2>About the authors</h2> \n<footer> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50291.png" alt="Sachin Murkar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Sachin Murkar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/sachinmurkar/" rel="noopener">Sachin</a> is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50292.jpeg" alt="Abhimanyu Tomar" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Abhimanyu Tomar</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/abhimanyu-tomar/" rel="noopener">Abhimanyu</a> is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.</p>\n </div> \n <div class="blog-author-box"> \n  <div class="blog-author-image">\n   <img loading="lazy" class="aligncenter size-full wp-image-29797" src="https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2026/01/23/image-DBBLOG-50293.jpeg" alt="Niraj Jani" width="120" height="160">\n  </div> \n  <h3 class="lb-h4">Niraj Jani</h3> \n  <p><a target="_blank" href="https://www.linkedin.com/in/nirajjani22/" rel="noopener">Niraj</a> is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.</p>\n </div> \n</footer>	In this post, we help you plan your upgrade from PostgreSQL version 13 before standard support ends on February 28, 2026. We discuss the key benefits of upgrading, breaking changes to consider, and multiple upgrade strategies to choose from.\n \nStandard support for Amazon Aurora PostgreSQL-Compatible Edition and Amazon Relational Database Service (Amazon RDS) for PostgreSQL version 13 ends on February 28, 2026.\n \nThese updates can introduce changes that affect your application compatibility. Upgrades need careful evaluation, but the latest releases offer better features, performance, and security. Plan and test thoroughly before upgrading to newer major versions to get the most benefits with the least disruption.\n \nFor detailed upgrade instructions, refer to the official documentation for both Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL:\n \n \n \nAmazon Aurora PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nAmazon RDS for PostgreSQL 13.x end of standard support is February 28, 2026\n \n \nKey benefits of PostgreSQL newer versions\n \nUpgrading to newer PostgreSQL versions can help improve your database performance and adds new capabilities. In this section, we list some of the features introduced in newer PostgreSQL versions.\n \nPerformance enhancements\n \nNewer versions offer the following performance enhancements:\n \n \n \nVacuum emergency mode (v14+) – Helps prevent fatal transaction ID wraparound by aggressively managing old row versions\n \n \nImproved I/O performance (v17) – Offers up to two times better write throughput with enhanced WAL processing\n \n \nQuery optimization (v17+) – Provides better performance for IN clauses with B-tree indexes and parallel BRIN index builds\n \n \nMemory efficiency (v17) – New vacuum memory structure consumes up to 20 times less memory\n \n \nAdvanced monitoring and diagnostics\n \nYou can benefit from the following advanced monitoring and diagnostics features:\n \n \n \npg_stat_io (v16+) – Provides detailed statistics on I/O operations\n \n \npg_wait_events (v17+) – Supports in-database reference for wait events, removing manual documentation lookups\n \n \nLogical replication improvements\n \nNewer versions offer the following logical replication improvements:\n \n \n \nFailover support (v17+) – You can automatically synchronize logical replication slots from primary to standby servers\n \n \nSlot migration (v17+) – Logical replication slots can migrate through pg_upgrade, simplifying upgrades\n \n \nParallel apply (v16+) – This feature writes data directly to the target table using multiple background worker processes\n \n \nRow filtering (v15+) – You have fine-grained control over what data is replicated\n \n \nDeveloper experience\n \nNewer versions offer an improved developer experience:\n \n \n \nJSONB subscripting (v14+) – Intuitive syntax for accessing and modifying JSONB data\n \n \nSQL/JSON JSON_TABLE (v17+) – The ability to transform JSON data into relational views\n \n \nQuery pipelining (v14+) – Reduced network latency for high-latency connections\n \n \nSecurity enhancements\n \nYou have access to the following security enhancements:\n \n \n \npg_read_all_data and pg_write_all_data roles (v14+) – Streamlined read/write access control\n \n \npg_maintain role (v17+) – Enabling users to perform database maintenance tasks\n \n \n(v15+) – Removal of PUBLIC creation permission on public schema\n \n \nAmazon Aurora PostgreSQL-Compatible with Aurora Optimized Reads\n \nFor Amazon Aurora PostgreSQL-Compatible users, upgrading to v14.9+, v15.4+, v16.1+, and higher versions can offer more performance optimizations.\n \nAurora Optimized Reads delivers up to eight times faster query latency and up to 30% cost savings for large datasets. Aurora Optimized Reads supports two capabilities:\n \n \n \nTiered cache – You can extend DB instance caching capacity by up to five times more instance memory (on Aurora I/O-Optimized clusters)\n \n \nTemporary objects – You can experience up to two times faster latency for advanced queries using local NVMe storage\n \n \nPostgreSQL v13 deprecation: Catalog view changes and upgrade benefits (v14-v17)\n \nUpgrading from PostgreSQL v13 to newer versions can introduce some changes that might affect your applications. In this section, we highlight changes related to system catalogs and configuration parameters.\n \nChanges in system catalog views\n \nThe following table summarizes changes in PostgreSQL v17.\n \n \n  \n  \n \n   Change Type \n   Column Name \n   Action \n   Notes \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend \n   REMOVED \n   – \n  \n \n  \n \n   Removed from pg_stat_bgwriter \n   buffers_backend_fsync \n   REMOVED \n   – \n  \n \n  \n \n   New View \n   pg_stat_checkpointer \n   CREATED \n   Separates checkpointer statistics from background writer \n  \n \n  \n \n   New View \n   pg_wait_events \n   CREATED \n   Wait event information \n  \n \n  \n \nThe following table summarizes pg_stat_progress_vacuum column renames.\n \n \n  \n  \n \n   Change Type \n   Old Name \n   New Name \n   Description \n  \n \n  \n \n   Renamed \n   max_dead_tuples \n   max_dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   Renamed \n   num_dead_tuples \n   dead_tuple_bytes \n   Column renamed \n  \n \n  \n \n   New column \n   – \n   indexes_total \n   New column added \n  \n \n  \n \n   New column \n   – \n   indexes_processed \n   New column added \n  \n \n  \n \n   New column \n   – \n   dead_tuple_bytes \n   New column added \n  \n \n  \n \nThe following table summarizes additional catalog changes.\n \n \n  \n  \n \n   View/Table \n   Change type \n   Old name \n   New name \n   Description \n  \n \n  \n \n   pg_database \n   New column \n   – \n   dathasloginevt \n   New column added \n  \n \n  \n \n   pg_database \n   Renamed \n   daticulocale \n   datlocale \n   Column renamed \n  \n \n  \n \n   pg_collation \n   Renamed \n   colliculocale \n   colllocale \n   Column renamed \n  \n \n  \n \nThe following table summarizes modified system views.\n \n \n  \n  \n \n   View name \n   New column(s) added \n  \n \n  \n \n   pg_replication_slots \n   failover; synced; invalidation_reason; inactive_since \n  \n \n  \n \n   pg_stat_progress_copy \n   tuples_skipped \n  \n \n  \n \n   pg_stat_subscription \n   worker_type \n  \n \n  \n \n   pg_stats \n   range_length_histogram; range_empty_frac; range_bounds_histogram \n  \n \n  \n \n   pg_subscription \n   subfailover \n  \n \n  \n \nThe following table summarizes PostgreSQL v14 system catalog changes.\n \n \n  \n  \n \n   View name \n   Change type \n   Column name \n   Notes \n  \n \n  \n \n   pg_stat_activity \n   New column \n   query_id \n   Requires compute_query_id parameter \n  \n \n  \n \n   pg_stat_statements \n   New column \n   toplevel \n   New column added \n  \n \n  \n \nImportant parameter-related changes\n \nThe following table summarizes parameter-related changes in PostgreSQL v14.\n \n \n  \n  \n \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   New \n   compute_query_id \n   Controls query identifier computation \n  \n \n  \n \n   New \n   client_connection_check_interval \n   Sets the time interval between checks for disconnection while running queries \n  \n \n  \n \n   New \n   idle_session_timeout \n   Ends sessions not in a transaction that have been idle longer than the specified time \n  \n \n  \n \n   New \n   default_toast_compression \n   Sets the default compression method for compressible values \n  \n \n  \n \n   New \n   vacuum_failsafe_age \n   Age at which VACUUM should trigger failsafe to avoid a wraparound outage \n  \n \n  \n \n   New \n   huge_page_size \n   The size of huge page that should be requested \n  \n \n  \n \n   Removed \n   operator_precedence_warning \n   Completely removed \n  \n \n  \n \n   Removed \n   vacuum_cleanup_index_scale_factor \n   Removed (deprecated in v12) \n  \n \n  \n \n \n  \n  \n \n   Change type \n   Parameter name \n   Old value \n   New value \n   Description/Notes \n  \n \n  \n \n   Default Changed \n   password_encryption \n   md5 \n   scram-sha-256 \n   Password encryption default changed \n  \n \n  \n \nThe following table summarizes parameter-related changes in PostgreSQL v15, v16, and v17.\n \n \n  \n  \n \n   Version \n   Change type \n   Parameter name \n   Description/Notes \n  \n \n  \n \n   PostgreSQL 15 \n   Enhanced \n   wal_compression \n   Supports new algorithms: zstd, lz4 \n  \n \n  \n \n   PostgreSQL 15 \n   New \n   wal_decode_buffer_size \n   Buffer size for WAL decoding \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   vacuum_buffer_usage_limit \n   Limits buffer usage during vacuum \n  \n \n  \n \n   PostgreSQL 16 \n   New \n   logical_replication_mode \n   Controls logical replication behavior \n  \n \n  \n \n   PostgreSQL 17 \n   New \n   sync_replication_slots \n   Enables synchronization of replication slots \n  \n \n  \n \nUpgrade strategy options\n \nYou have multiple approaches to upgrade your Amazon Aurora PostgreSQL and Amazon RDS for PostgreSQL database:\n \n \n \nIn-place upgrade – You can perform this upgrade method using either the AWS Command Line Interface (AWS CLI) or AWS Management Console. In-place upgrades require downtime proportional to your database size. Test the exact duration by upgrading a snapshot first. This method suits workloads that can tolerate downtime and prefer simpler administration.\n \n \nAmazon RDS blue/green deployment – Amazon RDS blue/green deployments use PostgreSQL logical replication to maintain two synchronized environments. Upgrade the green (staging) environment using Amazon RDS one-click upgrade, test your application thoroughly, then switch production traffic with minimal downtime—typically under a minute. Although this method is simple to implement using the console or AWS CLI, be aware that DDL changes aren’t replicated and can break the replication process.\n \n \nLogical replication – Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL support logical replication through pglogical. The process involves creating an initial snapshot of the publisher database, copying it to the subscriber, then continuously replicating real-time changes. This approach offers minimal downtime and continuous replication but requires complex initial setup and longer synchronization for large databases. Logical replication can’t replicate DDL, sequence, and large object operations.\n \n \nAWS Database Migration Service (AWS DMS) – AWS DMS supports Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL as both source and target databases, with change data capture (CDC) capabilities. Although AWS DMS enables minimal-downtime upgrades and continuous replication, it doesn’t support all data types (like timestamp with time zone) and incurs additional costs during the migration period.\n \n \nFor detailed information about both in-place upgrades and various out-of-place upgrade options, refer to Upgrade your Amazon RDS for PostgreSQL or Amazon Aurora PostgreSQL database, Part 1: Comparing upgrade approaches. It examines the advantages and disadvantages of each approach.\n \nPreparing to upgrade\n \nBefore upgrading, you should perform the following actions:\n \n \n \nReview your current database configuration\n \n \nTest the upgrade process in a staging environment\n \n \nValidate application compatibility\n \n \nCreate comprehensive backup strategies\n \n \nIf immediate upgrade isn’t feasible, Amazon RDS Extended Support provides up to 3 years of continued security patches and bug fixes. RDS Extended Support is a paid service providing critical security and bug fixes for Amazon Aurora PostgreSQL-Compatible and Amazon RDS for PostgreSQL major versions up to 3 years beyond the standard support end date. Pricing increases based on years elapsed since standard support expiration. Use the RDS Extended Support window wisely to find the right upgrade path for your databases and applications. This can help you streamline your upgrade process for your production environment.\n \nConclusion\n \nUpgrading from PostgreSQL v13 can give you significant performance improvements, better security features, and more efficient operations.\n \nFor detailed technical guidance, consult the official AWS documentation and consider engaging AWS support for complex migration scenarios. If you have AWS Enterprise Support, your Technical Account Manager (TAM) can provide expert guidance throughout your upgrade journey. TAMs can connect you with AWS specialists and provide targeted resources to support a seamless upgrade process.\n \n \nAbout the authors\n \n \n \n \n  \n \n  \nSachin Murkar\n \n  \nSachin is a Cloud Support Database Engineer at AWS. He is a Subject Matter Expert in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. Based in the Pacific Northwest region, Sachin focuses on helping customers optimize their AWS database solutions, with particular expertise in Amazon RDS and Aurora.\n \n \n \n  \n \n  \nAbhimanyu Tomar\n \n  \nAbhimanyu is a Sr. Database Specialist Technical Account Manager at AWS. He is also a Subject Matter Expert in Amazon Aurora infrastructure, Amazon RDS for PostgreSQL, and Amazon Aurora PostgreSQL. He holds six AWS Certifications, including Solution Architect Professional. He helps enterprise customers optimize their databases on AWS, providing expert guidance for cloud migrations and technical improvements.\n \n \n \n  \n \n  \nNiraj Jani\n \n  \nNiraj is currently working as a Technical Account Manager and previously served as a Cloud Support Engineer. He is Subject Matter Expert in Amazon RDS and Amazon Aurora PostgreSQL and is based in the Pacific Northwest region. In his role, Niraj helps customers optimize the performance of their RDS and Aurora clusters and helps them troubleshoot a wide range of technical issues.	This AWS blog post outlines upgrade strategies for PostgreSQL version 13 on Amazon Aurora and RDS before standard support ends February 28, 2026. It details benefits of upgrading to newer versions including performance enhancements like vacuum emergency mode, improved I/O performance, and memory efficiency improvements. Key features in newer versions include advanced monitoring tools like pg_stat_io, logical replication improvements with failover support, developer experience enhancements like JSONB subscripting, and security improvements. The post highlights breaking changes in system catalog views and configuration parameters between versions. Four upgrade strategies are presented: in-place upgrades, blue/green deployments, logical replication, and AWS DMS. For organizations unable to upgrade immediately, AWS offers Extended Support for up to three years with additional costs.	这篇 AWS 博客文章概述了在标准支持于 2026 年 2 月 28 日结束之前，为 Amazon Aurora 和 RDS 上的 PostgreSQL 版本 13 制定升级策略。文章详细介绍了升级到新版本的好处，包括性能增强，如 vacuum 紧急模式、改进的 I/O 性能和内存效率提升。新版本的关键功能包括高级监控工具如 pg_stat_io、支持故障转移的逻辑复制改进、开发者体验增强如 JSONB 下标访问，以及安全改进。文章重点介绍了版本间系统目录视图和配置参数的重大变更。提出了四种升级策略：就地升级、蓝绿部署、逻辑复制和 AWS DMS。对于无法立即升级的组织，AWS 提供最多三年的 Extended Support，但需额外付费。
29	Phenomenology through PostgreSQL Documentation	https://www.cybertec-postgresql.com/en/phenomenology-through-postgresql-documentation/	Abhisek Goswami	2026-01-27 06:23:51+00	\r\n<p>Do you think the way you see the sunrise is the same for everyone?</p>\r\n\r\n\r\n\r\n<p>From where I live, the sun does not rise the way it does in postcards. It appears late, partially blocked by nearby buildings, sometimes sharp, sometimes muted, and often unnoticed until it is already well above the horizon. Someone standing on a hill sees it earlier. Someone near the sea sees it stretch slowly and wide. The sun itself does nothing different. What changes is where we stand when we observe it.</p>\r\n\r\n\r\n\r\n<p>This simple experience has a name: <strong>Phenomenology</strong>. It is the idea that reality exists independently, but our understanding of it is always shaped by perspective, timing, and constraints. We never describe the sun itself; we describe the sunrise as seen from a particular roof. </p>\r\n\r\n\r\n\r\n<p>Over time, I realised that this is exactly how documentation works when it works well.</p>\r\n\r\n\r\n\r\n<h2 id="h-documentation-as-observation-and-historical-record" class="wp-block-heading">Documentation as Observation and Historical Record</h2>\r\n\r\n\r\n\r\n<p>Phenomenology may sound philosophical, but in practice it is very concrete. It asks one question that matters deeply in engineering: from where is this description written?</p>\r\n\r\n\r\n\r\n<p>Long-lived systems accumulate history whether we like it or not. Features are introduced to solve earlier problems, constraints are added to protect correctness, and trade-offs are accepted because the alternatives were worse at that moment.</p>\r\n\r\n\r\n\r\n<p>Anyone who builds on such a system eventually performs a kind of archaeology, not out of curiosity, but because understanding intent is cheaper than rediscovering it through repeated experiments.</p>\r\n\r\n\r\n\r\n<p>This is where documentation stops being a supporting artifact and starts behaving like a feature. Not a runtime feature, not something you toggle on or off, but a process feature that preserves design context across time. </p>\r\n\r\n\r\n\r\n<p>When documentation captures who saw what, when, and under which constraints, archaeology becomes traceable instead of speculative.</p>\r\n\r\n\r\n\r\n<h2 id="h-contributor-context-as-the-differentiator" class="wp-block-heading">Contributor Context as the Differentiator</h2>\r\n\r\n\r\n\r\n<p>This is where I need to be precise, because vague praise does not help anyone.</p>\r\n\r\n\r\n\r\n<p>The documentation of <a href="https://www.postgresql.org/docs/">PostgreSQL</a> stands out not because it is shorter, friendlier, or more interactive than everything else, but because it consistently preserves design context close to the moment of change. Contributors do not just implement features; they describe what they changed, what guarantees hold, and where those guarantees stop holding.</p>\r\n\r\n\r\n\r\n<p>Documentation and release notes move with the code, not after it. Now, that closeness matters. It means the observer and the describer overlap. </p>\r\n\r\n\r\n\r\n<p>The person who stood on the roof when the sunrise looked a certain way is usually the person who wrote down what they saw. Over decades, that habit compounds into trust.</p>\r\n\r\n\r\n\r\n<h2 id="h-feature-origins-design-context-and-mvcc" class="wp-block-heading">Feature Origins, Design Context, and MVCC</h2>\r\n\r\n\r\n\r\n<p>Most features in PostgreSQL did not appear because someone invented an abstract capability. They appeared because someone ran into a real limitation, an inefficiency, or a correctness issue in an earlier version and worked through the implications until a solution emerged. That origin story, even when it is not written as a narrative, leaves traces in how the feature is documented.</p>\r\n\r\n\r\n\r\n<p>MVCC is a good example. Multi-Version Concurrency Control is not presented as a clever trick; it is documented as a set of guarantees and constraints around visibility and isolation. Different transactions can legitimately see different versions of the same data at the same time, and all of those views are correct within their isolation guarantees. There is no single global “now” inside the system.</p>\r\n\r\n\r\n\r\n<p>This is phenomenology expressed as mechanics. Observation depends on context, and the documentation reflects that by stating what is visible from which position. The important part is not the acronym itself, but the fact that the documentation does not pretend there is a single, observer-free truth.</p>\r\n\r\n\r\n\r\n<h2 id="h-docs-as-code-and-its-practical-limits" class="wp-block-heading">Docs as Code and its Practical Limits</h2>\r\n\r\n\r\n\r\n<p>I believe strongly in docs as code. Keeping documentation versioned with source, reviewed through the same workflows, and shipped alongside releases is necessary if documentation is to remain accurate over time. But docs as code by itself mostly protects behavioural correctness. It keeps descriptions aligned with what the system does now.</p>\r\n\r\n\r\n\r\n<p>What it does not automatically provide is etymology. It does not force anyone to explain why a feature exists, why certain trade-offs were accepted, or when a behaviour should not be relied upon. Many projects adopt docs as code and still end up with documentation that explains what and how, but leaves readers guessing about why.</p>\r\n\r\n\r\n\r\n<p>PostgreSQL goes further because of culture rather than tooling. Contributors document their own changes, release notes anchor those changes in time,and public discussions preserve the reasoning around them.</p>\r\n\r\n\r\n\r\n<p>The result is not explicit philosophy, but enough context to reconstruct intent when it matters.</p>\r\n\r\n\r\n\r\n<h2 id="h-the-john-doe-problem-and-the-new-developer-perspective" class="wp-block-heading">The John Doe problem and the New Developer Perspective</h2>\r\n\r\n\r\n\r\n<p>I often think about a simple scenario. John Doe buys a product and reads a manual that explains every feature perfectly from a usage point of view. He follows it carefully and still ends up confused, because the manual never explains the base assumptions the product relies on. Calibration shifts, internal references change, and behaviour that is technically correct feels wrong because the base was invisible.</p>\r\n\r\n\r\n\r\n<p>The same thing happens in software. When the base is hidden, people are forced into blind experimentation. When the base is visible, learning becomes intentional.</p>\r\n\r\n\r\n\r\n<p>For a developer building, for example, an analytics tool on top of <strong>pg_stat views</strong>, this difference is decisive.</p>\r\n\r\n\r\n\r\n<p>They can read the documentation to understand what those statistics are meant to represent, consult release notes to see when and why behaviour changed, and trace decisions back through commits and public discussions when their logic depends on those details.</p>\r\n\r\n\r\n\r\n<p>If something still remains unclear, the address book is effectively there: <strong><em>the contributor discussions are public, the context is discoverable, and questions can be asked in a focused way rather than through weeks of guesswork.</em></strong></p>\r\n\r\n\r\n\r\n<p><strong>Testing then becomes validation, not archaeology.</strong></p>\r\n\r\n\r\n\r\n<h2 id="h-behavioural-apis-versus-foundational-building-blocks" class="wp-block-heading">Behavioural APIs versus Foundational Building Blocks</h2>\r\n\r\n\r\n\r\n<p>It is useful to contrast this with excellent documentation that serves a different purpose. <a href="https://docs.stripe.com/">Stripe</a> documentation is world-class at describing behaviour through stable interfaces. It tells you exactly what will happen when you call an endpoint with given parameters, and it deliberately hides internal complexity so you can integrate quickly.</p>\r\n\r\n\r\n\r\n<p>PostgreSQL operates at a different layer. It is a building block. Other systems compose on top of it. The documentation therefore has a different responsibility: to expose assumptions, constraints, and limits so that higher-level behaviour can be built safely. </p>\r\n\r\n\r\n\r\n<p>Comparing the two without acknowledging this difference misses the point.</p>\r\n\r\n\r\n\r\n<h2 id="h-my-perspective-as-a-technical-writer" class="wp-block-heading">My perspective as a Technical Writer</h2>\r\n\r\n\r\n\r\n<p>I started as a developer who used documentation to learn tools. For a long time, I rarely found answers to why something was developed a certain way. Later, when I moved into technical writing, I found myself writing that missing context, trying to preserve intent rather than just describing behaviour.</p>\r\n\r\n\r\n\r\n<p>That second perspective made the gap obvious. In PostgreSQL, that gap is unusually small to zero. The people who experience the problem, design the solution, implement it, and document it often overlap. </p>\r\n\r\n\r\n\r\n<p>The documentation feels grounded because it is rooted in lived engineering decisions rather than retrospective explanations.</p>\r\n\r\n\r\n\r\n<h2 id="h-finally-my-lessons-and-observations-nbsp" class="wp-block-heading">Finally my lessons and observations </h2>\r\n\r\n\r\n\r\n<p>The sunrise does not look the same for everyone, but it becomes understandable once you know where the observer is standing and what blocks the view. </p>\r\n\r\n\r\n\r\n<p>PostgreSQL documentation works for the same reason. It does not claim a view from nowhere. It preserves perspective.</p>\r\n\r\n\r\n\r\n<p>As a technical writer, this shapes how I work. When I document APIs, docs as code is often enough because contracts are the product. When I document features and building blocks, I prefer a phenomenological approach, one that records who saw what, when, and under which constraints, because that is what future builders will need.</p>\r\n\r\n\r\n\r\n<p>That is why, in these terms, PostgreSQL documentation stands out.</p>\r\n\r\n\r\n\r\n<p>Let me know your thoughts!!!</p>\r\n<p>The post <a href="https://www.cybertec-postgresql.com/en/phenomenology-through-postgresql-documentation/">Phenomenology through PostgreSQL Documentation</a> appeared first on <a href="https://www.cybertec-postgresql.com/en">CYBERTEC PostgreSQL | Services &amp; Support</a>.</p>\n	Do you think the way you see the sunrise is the same for everyone?\n\r\n\r\n\r\n\r\nFrom where I live, the sun does not rise the way it does in postcards. It appears late, partially blocked by nearby buildings, sometimes sharp, sometimes muted, and often unnoticed until it is already well above the horizon. Someone standing on a hill sees it earlier. Someone near the sea sees it stretch slowly and wide. The sun itself does nothing different. What changes is where we stand when we observe it.\n\r\n\r\n\r\n\r\nThis simple experience has a name: Phenomenology. It is the idea that reality exists independently, but our understanding of it is always shaped by perspective, timing, and constraints. We never describe the sun itself; we describe the sunrise as seen from a particular roof. \n\r\n\r\n\r\n\r\nOver time, I realised that this is exactly how documentation works when it works well.\n\r\n\r\n\r\n\r\nDocumentation as Observation and Historical Record\n\r\n\r\n\r\n\r\nPhenomenology may sound philosophical, but in practice it is very concrete. It asks one question that matters deeply in engineering: from where is this description written?\n\r\n\r\n\r\n\r\nLong-lived systems accumulate history whether we like it or not. Features are introduced to solve earlier problems, constraints are added to protect correctness, and trade-offs are accepted because the alternatives were worse at that moment.\n\r\n\r\n\r\n\r\nAnyone who builds on such a system eventually performs a kind of archaeology, not out of curiosity, but because understanding intent is cheaper than rediscovering it through repeated experiments.\n\r\n\r\n\r\n\r\nThis is where documentation stops being a supporting artifact and starts behaving like a feature. Not a runtime feature, not something you toggle on or off, but a process feature that preserves design context across time. \n\r\n\r\n\r\n\r\nWhen documentation captures who saw what, when, and under which constraints, archaeology becomes traceable instead of speculative.\n\r\n\r\n\r\n\r\nContributor Context as the Differentiator\n\r\n\r\n\r\n\r\nThis is where I need to be precise, because vague praise does not help anyone.\n\r\n\r\n\r\n\r\nThe documentation of PostgreSQL stands out not because it is shorter, friendlier, or more interactive than everything else, but because it consistently preserves design context close to the moment of change. Contributors do not just implement features; they describe what they changed, what guarantees hold, and where those guarantees stop holding.\n\r\n\r\n\r\n\r\nDocumentation and release notes move with the code, not after it. Now, that closeness matters. It means the observer and the describer overlap. \n\r\n\r\n\r\n\r\nThe person who stood on the roof when the sunrise looked a certain way is usually the person who wrote down what they saw. Over decades, that habit compounds into trust.\n\r\n\r\n\r\n\r\nFeature Origins, Design Context, and MVCC\n\r\n\r\n\r\n\r\nMost features in PostgreSQL did not appear because someone invented an abstract capability. They appeared because someone ran into a real limitation, an inefficiency, or a correctness issue in an earlier version and worked through the implications until a solution emerged. That origin story, even when it is not written as a narrative, leaves traces in how the feature is documented.\n\r\n\r\n\r\n\r\nMVCC is a good example. Multi-Version Concurrency Control is not presented as a clever trick; it is documented as a set of guarantees and constraints around visibility and isolation. Different transactions can legitimately see different versions of the same data at the same time, and all of those views are correct within their isolation guarantees. There is no single global “now” inside the system.\n\r\n\r\n\r\n\r\nThis is phenomenology expressed as mechanics. Observation depends on context, and the documentation reflects that by stating what is visible from which position. The important part is not the acronym itself, but the fact that the documentation does not pretend there is a single, observer-free truth.\n\r\n\r\n\r\n\r\nDocs as Code and its Practical Limits\n\r\n\r\n\r\n\r\nI believe strongly in docs as code. Keeping documentation versioned with source, reviewed through the same workflows, and shipped alongside releases is necessary if documentation is to remain accurate over time. But docs as code by itself mostly protects behavioural correctness. It keeps descriptions aligned with what the system does now.\n\r\n\r\n\r\n\r\nWhat it does not automatically provide is etymology. It does not force anyone to explain why a feature exists, why certain trade-offs were accepted, or when a behaviour should not be relied upon. Many projects adopt docs as code and still end up with documentation that explains what and how, but leaves readers guessing about why.\n\r\n\r\n\r\n\r\nPostgreSQL goes further because of culture rather than tooling. Contributors document their own changes, release notes anchor those changes in time,and public discussions preserve the reasoning around them.\n\r\n\r\n\r\n\r\nThe result is not explicit philosophy, but enough context to reconstruct intent when it matters.\n\r\n\r\n\r\n\r\nThe John Doe problem and the New Developer Perspective\n\r\n\r\n\r\n\r\nI often think about a simple scenario. John Doe buys a product and reads a manual that explains every feature perfectly from a usage point of view. He follows it carefully and still ends up confused, because the manual never explains the base assumptions the product relies on. Calibration shifts, internal references change, and behaviour that is technically correct feels wrong because the base was invisible.\n\r\n\r\n\r\n\r\nThe same thing happens in software. When the base is hidden, people are forced into blind experimentation. When the base is visible, learning becomes intentional.\n\r\n\r\n\r\n\r\nFor a developer building, for example, an analytics tool on top of pg_stat views, this difference is decisive.\n\r\n\r\n\r\n\r\nThey can read the documentation to understand what those statistics are meant to represent, consult release notes to see when and why behaviour changed, and trace decisions back through commits and public discussions when their logic depends on those details.\n\r\n\r\n\r\n\r\nIf something still remains unclear, the address book is effectively there: the contributor discussions are public, the context is discoverable, and questions can be asked in a focused way rather than through weeks of guesswork.\n\r\n\r\n\r\n\r\nTesting then becomes validation, not archaeology.\n\r\n\r\n\r\n\r\nBehavioural APIs versus Foundational Building Blocks\n\r\n\r\n\r\n\r\nIt is useful to contrast this with excellent documentation that serves a different purpose. Stripe documentation is world-class at describing behaviour through stable interfaces. It tells you exactly what will happen when you call an endpoint with given parameters, and it deliberately hides internal complexity so you can integrate quickly.\n\r\n\r\n\r\n\r\nPostgreSQL operates at a different layer. It is a building block. Other systems compose on top of it. The documentation therefore has a different responsibility: to expose assumptions, constraints, and limits so that higher-level behaviour can be built safely. \n\r\n\r\n\r\n\r\nComparing the two without acknowledging this difference misses the point.\n\r\n\r\n\r\n\r\nMy perspective as a Technical Writer\n\r\n\r\n\r\n\r\nI started as a developer who used documentation to learn tools. For a long time, I rarely found answers to why something was developed a certain way. Later, when I moved into technical writing, I found myself writing that missing context, trying to preserve intent rather than just describing behaviour.\n\r\n\r\n\r\n\r\nThat second perspective made the gap obvious. In PostgreSQL, that gap is unusually small to zero. The people who experience the problem, design the solution, implement it, and document it often overlap. \n\r\n\r\n\r\n\r\nThe documentation feels grounded because it is rooted in lived engineering decisions rather than retrospective explanations.\n\r\n\r\n\r\n\r\nFinally my lessons and observations \n\r\n\r\n\r\n\r\nThe sunrise does not look the same for everyone, but it becomes understandable once you know where the observer is standing and what blocks the view. \n\r\n\r\n\r\n\r\nPostgreSQL documentation works for the same reason. It does not claim a view from nowhere. It preserves perspective.\n\r\n\r\n\r\n\r\nAs a technical writer, this shapes how I work. When I document APIs, docs as code is often enough because contracts are the product. When I document features and building blocks, I prefer a phenomenological approach, one that records who saw what, when, and under which constraints, because that is what future builders will need.\n\r\n\r\n\r\n\r\nThat is why, in these terms, PostgreSQL documentation stands out.\n\r\n\r\n\r\n\r\nLet me know your thoughts!!!\n\r\nThe post Phenomenology through PostgreSQL Documentation appeared first on CYBERTEC PostgreSQL | Services & Support.	The author explores how PostgreSQL documentation excels by applying phenomenological principles - the idea that understanding depends on perspective and context. Unlike documentation that only describes current behavior, PostgreSQL's docs preserve the design context and reasoning behind features. Contributors document not just what they implemented, but why changes were made and under what constraints. This approach creates a historical record that helps developers understand intent rather than just functionality. The author contrasts this with API documentation like Stripe's, noting PostgreSQL serves as a foundational building block requiring deeper contextual understanding. The documentation succeeds because the people experiencing problems, designing solutions, and documenting them often overlap, creating grounded explanations rooted in actual engineering decisions rather than retrospective descriptions.	作者探讨了PostgreSQL文档如何通过应用现象学原理而表现出色——即理解取决于视角和背景的观点。与仅描述当前行为的文档不同，PostgreSQL的文档保留了功能背后的设计背景和推理过程。贡献者不仅记录他们实现的内容，还记录为什么进行更改以及在什么约束条件下进行。这种方法创建了历史记录，帮助开发者理解意图而不仅仅是功能。作者将此与Stripe等API文档进行对比，指出PostgreSQL作为基础构建块需要更深层的背景理解。该文档之所以成功，是因为遇到问题、设计解决方案和记录文档的人员经常重叠，创造了植根于实际工程决策而非回顾性描述的扎实解释。
32	TimescaleDB for Manufacturing IoT: Optimizing for High-Volume Production Data	https://www.tigerdata.com/blog/timescaledb-for-manufacturing-iot-optimizing-for-high-volume-production-data	NanoHertz Solutions - Jake Hertz	2026-01-28 13:07:24+00	<p>In industrial environments with hundreds of machines streaming sensor signals every second, optimizing your database for analytics is critical. In a follow-up to our initial tutorial on building a data pipeline, we’ll take you step-by-step from slow, unoptimized queries to highly performant analytical queries using TimescaleDB’s advanced features.</p><p>We’ll use the example of high-frequency machine vibration telemetry to show you how to tune TimescaleDB to improve query performance, measured using EXPLAIN ANALYZE. We will be using the same service we created in the <a href="https://www.tigerdata.com/blog/timescaledb-manufacturing-iot-building-data-pipeline"><u>previous tutorial</u></a>, which has a compute size of 8 CPU / 32 GiB Memory and is hosted in AWS US East (Ohio).&nbsp; All the performance metrics you will see in this tutorial are specific to this service instance and data set, so your results may differ.</p><h2 id="example-machine-vibration-telemetry">Example: Machine Vibration Telemetry</h2><p>Imagine you’re collecting <strong>vibration data</strong> from <strong>50 rotating machines</strong> at <strong>10 samples per second</strong>, 24/7 for <strong>6 months</strong>.&nbsp; With this volume, the raw table quickly grows into billions of rows—a perfect example of workloads that reward <a href="https://www.tigerdata.com/timescaledb"><u>TimescaleDB</u></a> optimizations.</p><p>Our initial table schema looks like this:</p><pre><code class="language-SQL">CREATE TABLE vibration_readings (\n  time TIMESTAMPTZ NOT NULL,\n  machine_id TEXT NOT NULL,\n  vibration_rms DOUBLE PRECISION NOT NULL\n);\n</code></pre><p>For this tutorial, we will generate randomized data:</p><pre><code class="language-SQL">INSERT INTO vibration_readings (time, machine_id, vibration_rms)\nSELECT\n  t.ts,\n  m.machine_id,\n  2.5\n  + 0.5 * sin(extract(epoch from t.ts) / 3600)\n  + 0.3 * random()                    \n  + (m.machine_id * 0.005)\nFROM generate_series(\n       now() - INTERVAL '180 days',\n       now(),\n       INTERVAL '100 milliseconds'\n     ) AS t(ts)\nCROSS JOIN generate_series(1,50) AS m(machine_id);\n</code></pre><p>At this stage, queries against this table are correct, but slow and non-scalable.</p><h2 id="real-operational-questions">Real Operational Questions</h2><p>Before we optimize, it’s important to define a few operational questions that your maintenance team may need to answer. These questions will drive how we tune TimescaleDB features.</p><p>Here are a few key questions for our machine vibration telemetry example:</p><h3 id="question-1trending-is-vibration-increasing-over-time-for-any-machine">Question 1 - Trending: Is vibration increasing over time for any machine?</h3><p>We want to monitor trend changes that could indicate bearing wear or other mechanical degradation.</p><p>Baseline query:</p><pre><code class="language-SQL">SELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration\nFROM vibration_readings\nWHERE time &gt; now() - INTERVAL '7 days'\nGROUP BY machine_id, hour;\n</code></pre><p><em>Observation:</em> On the unoptimized table, this query will do a sequential scan of billions of rows, which is slow and inefficient.</p><h3 id="question-2monitoring-how-long-did-each-machine-operate-above-the-alarm-threshold-this-week">Question 2 - Monitoring: How long did each machine operate above the alarm threshold this week?</h3><p>Maintenance teams often need to know how much time each machine spent above a critical vibration threshold, which drives alerts and prioritization.</p><p>Baseline query:</p><pre><code class="language-SQL">SELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE time &gt; now() - INTERVAL '7 days'\n  AND vibration_rms &gt; 5.0\nGROUP BY machine_id;\n</code></pre><p><em>Observation:</em> This query also scans large amounts of historical data, which will be incredibly slow without indexing or chunking.</p><h3 id="question-3comparing-which-machine-has-the-most-unstable-vibration-signal">Question 3 - Comparing: Which machine has the most unstable vibration signal?</h3><p>Detecting high variance in a machine’s signal helps identify mechanical imbalance or failing sensors.</p><p>Baseline query:</p><pre><code class="language-SQL">SELECT\n  machine_id,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nWHERE time &gt; now() - INTERVAL '7 days'\nGROUP BY machine_id;\n</code></pre><p><em>Observation:</em> Without optimization, aggregation over billions of rows will be slow, making real-time anomaly detection impractical.</p><p>By defining these three queries first, we now have specific performance goals. Every optimization we introduce—hypertables, indexes, chunk interval tuning, continuous aggregates, and compression—can be measured against these queries using EXPLAIN ANALYZE.</p><h2 id="step-1-convert-the-table-to-a-hypertable">Step 1: Convert the Table to a Hypertable</h2><p>TimescaleDB’s hypertables partition your data by time and (optionally) by another key like machine_id. This allows the database to prune irrelevant chunks and execute queries in parallel across partitions.</p><p>Convert the table to a hypertable:</p><pre><code class="language-SQL">SELECT create_hypertable(\n  'vibration_readings',\n  'time',\n  'machine_id',\n  8\n);\n</code></pre><p>Running the trend query from Question 1 now completes in about half the time as the query on the original table.</p><p>Instead of scanning one huge table, TimescaleDB is scanning only the relevant chunks—reducing overall execution time.</p><h2 id="step-2-add-a-composite-index-for-faster-filters">Step 2: Add a Composite Index for Faster Filters</h2><p>After converting the table to a hypertable, TimescaleDB can prune irrelevant chunks—but inside each chunk, PostgreSQL is still forced to scan rows sequentially.&nbsp; With high-frequency telemetry, each chunk can contain millions of rows, so we need to improve how each chunk is accessed.</p><p>Our queries consistently filter and group by time and machine_id, which makes a composite index a natural fit:</p><pre><code class="language-SQL">CREATE INDEX ON vibration_readings (machine_id, time DESC);</code></pre><p>Consider the baseline query from Question 2. If we run the query after an EXPLAIN ANALYZE statement, then we’ll be able to see exactly how PostgreSQL is finding the data.</p><pre><code class="language-SQL">EXPLAIN ANALYZE\nSELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE\n  time &gt; now() - INTERVAL '7 days'\n  AND vibration_rms &gt; 5.0\nGROUP BY machine_id;\n</code></pre><p>The query plan now shows an <strong>index scan</strong> with an execution time of 265 milliseconds.</p><p>This index allows the database to quickly locate relevant rows for both time and machine_id filters without scanning the whole dataset—delivering faster queries and enabling predictable performance as data volume grows.</p><h2 id="step-3-tune-chunk-intervals-for-high-frequency-data">Step 3: Tune Chunk Intervals for High-Frequency Data</h2><p>With 10 samples per second, default chunk intervals (e.g. weekly) can lead to overly large chunks. A smaller, daily chunk interval often works better by reducing scan times:</p><pre><code class="language-SQL">SELECT set_chunk_time_interval(\n  'vibration_readings',\n  INTERVAL '1 day'\n);\n</code></pre><p>Running the rolling average query from Question 1 yields an execution time of 17,185 milliseconds, which is significantly shorter than even the query time on the hypertable (after Step 1).</p><p>By pruning more chunks during planning, TimescaleDB reduces both planning time and scan effort—an easy win for high-frequency data.</p><h2 id="step-4-continuous-aggregates-for-feature-extraction">Step 4: Continuous Aggregates for Feature Extraction</h2><p>Calculating hourly or daily summaries from raw data can still be expensive. Continuous aggregates let TimescaleDB incrementally materialize that summary ahead of time:</p><pre><code class="language-SQL">CREATE MATERIALIZED VIEW vibration_hourly\nWITH (timescaledb.continuous) AS\nSELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nGROUP BY machine_id, hour;\n</code></pre><p>Run the query from Question 3 on this view:</p><pre><code class="language-SQL">EXPLAIN ANALYZE\nSELECT\n  machine_id,\n  STDDEV(avg_vibration) AS vibration_instability\nFROM vibration_hourly\nWHERE hour &gt; now() - INTERVAL '7 days'\nGROUP BY machine_id;\n</code></pre><p>Compared to the baseline query, our new query using continuous aggregates runs in just 1.4 milliseconds.</p><p>This gives you pre-aggregated features at lightning speed—essential for dashboards and ML workflows.</p><h2 id="step-5-compress-historical-vibration-data">Step 5: Compress Historical Vibration Data</h2><p>While raw recent data is useful for anomaly detection, older data can often be stored in compressed form without analytical access.</p><p>Compressing vibration data by machine_id, and leaving the last 3 days uncompressed maximizes query performance for both recent and historical data:</p><pre><code class="language-SQL">ALTER TABLE vibration_readings\nSET (\n  timescaledb.compress,\n  timescaledb.compress_segmentby = 'machine_id'\n);\n\nSELECT add_compression_policy(\n  'vibration_readings',\n  INTERVAL '3 days'\n);\n</code></pre><p>Running a query on historical vibration data still works:</p><pre><code class="language-SQL">EXPLAIN ANALYZE\nSELECT\n  machine_id,\n  AVG(vibration_rms)\nFROM vibration_readings\nWHERE time BETWEEN now() - INTERVAL '90 days'\n             AND now() - INTERVAL '30 days'\nGROUP BY machine_id;\n</code></pre><p>Because we used compression, our query runs in just 13 milliseconds.</p><p>Compression is transparent to queries, meaning nothing changes from the query’s perspective. However, under-the-hood far less data is read from disk while keeping analytical access.</p><h2 id="overall-optimization-results">Overall Optimization Results</h2><p>Here’s how database query performance improved as we applied each optimization:</p><figure class="kg-card kg-image-card"><img src="https://timescale.ghost.io/blog/content/images/2026/01/diagram-3.png" class="kg-image" alt="" loading="lazy" width="2000" height="1762" srcset="https://timescale.ghost.io/blog/content/images/size/w600/2026/01/diagram-3.png 600w, https://timescale.ghost.io/blog/content/images/size/w1000/2026/01/diagram-3.png 1000w, https://timescale.ghost.io/blog/content/images/size/w1600/2026/01/diagram-3.png 1600w, https://timescale.ghost.io/blog/content/images/2026/01/diagram-3.png 2150w" sizes="(min-width: 720px) 720px"></figure><p>Every optimization step, from indexing and chunking, to continuous aggregation and compression, delivers a significant performance win.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we started by defining three real operational questions that a maintenance team may need to answer:</p><ol><li>Is vibration increasing over time for any machine?</li><li>How long did each machine operate above the alarm threshold this week?</li><li>Which machine has the most unstable vibration signal?</li></ol><p>These questions set the stage for every optimization we applied. By converting the raw table into a <strong>hypertable</strong>, we enabled TimescaleDB to prune irrelevant chunks and scan only the data that mattered. Adding a <strong>composite index </strong>allowed queries to target individual machines and recent time ranges without scanning all rows. Tuning <strong>chunk intervals</strong> reduced planning and execution overhead for high-frequency data.&nbsp; <strong>Continuous aggregates</strong> pre-computed summaries for rapid access to hourly and daily metrics, and <strong>compression</strong> reduced storage for historical data while keeping it accessible for analytics.</p><p>The result of these optimizations combined was a dramatic performance improvement across all queries. What initially took many seconds now runs in just a few milliseconds.&nbsp; Hourly averages over a week for Question 1 dropped from over 67 seconds to 1.8 milliseconds. Alarm threshold duration queries for Question 2 dropped from over 5 seconds to 13 milliseconds. Historical aggregates over months for Question 3 dropped from over 15 seconds to just 1.4 milliseconds. While your query execution times may differ, you will see an undeniable benefit from these optimizations on your analytical query performance.</p><p>TimescaleDB is built to handle high-volume, high-frequency machine telemetry efficiently, providing both immediate insights for operational alerts, and long-term, accessible history for predictive maintenance modeling.&nbsp;</p>	In industrial environments with hundreds of machines streaming sensor signals every second, optimizing your database for analytics is critical. In a follow-up to our initial tutorial on building a data pipeline, we’ll take you step-by-step from slow, unoptimized queries to highly performant analytical queries using TimescaleDB’s advanced features.\nWe’ll use the example of high-frequency machine vibration telemetry to show you how to tune TimescaleDB to improve query performance, measured using EXPLAIN ANALYZE. We will be using the same service we created in the previous tutorial, which has a compute size of 8 CPU / 32 GiB Memory and is hosted in AWS US East (Ohio).  All the performance metrics you will see in this tutorial are specific to this service instance and data set, so your results may differ.\nExample: Machine Vibration Telemetry\nImagine you’re collecting vibration data from 50 rotating machines at 10 samples per second, 24/7 for 6 months.  With this volume, the raw table quickly grows into billions of rows—a perfect example of workloads that reward TimescaleDB optimizations.\nOur initial table schema looks like this:\nCREATE TABLE vibration_readings (\n  time TIMESTAMPTZ NOT NULL,\n  machine_id TEXT NOT NULL,\n  vibration_rms DOUBLE PRECISION NOT NULL\n);\n\nFor this tutorial, we will generate randomized data:\nINSERT INTO vibration_readings (time, machine_id, vibration_rms)\nSELECT\n  t.ts,\n  m.machine_id,\n  2.5\n  + 0.5 * sin(extract(epoch from t.ts) / 3600)\n  + 0.3 * random()                    \n  + (m.machine_id * 0.005)\nFROM generate_series(\n       now() - INTERVAL '180 days',\n       now(),\n       INTERVAL '100 milliseconds'\n     ) AS t(ts)\nCROSS JOIN generate_series(1,50) AS m(machine_id);\n\nAt this stage, queries against this table are correct, but slow and non-scalable.\nReal Operational Questions\nBefore we optimize, it’s important to define a few operational questions that your maintenance team may need to answer. These questions will drive how we tune TimescaleDB features.\nHere are a few key questions for our machine vibration telemetry example:\nQuestion 1 - Trending: Is vibration increasing over time for any machine?\nWe want to monitor trend changes that could indicate bearing wear or other mechanical degradation.\nBaseline query:\nSELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration\nFROM vibration_readings\nWHERE time > now() - INTERVAL '7 days'\nGROUP BY machine_id, hour;\n\nObservation: On the unoptimized table, this query will do a sequential scan of billions of rows, which is slow and inefficient.\nQuestion 2 - Monitoring: How long did each machine operate above the alarm threshold this week?\nMaintenance teams often need to know how much time each machine spent above a critical vibration threshold, which drives alerts and prioritization.\nBaseline query:\nSELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE time > now() - INTERVAL '7 days'\n  AND vibration_rms > 5.0\nGROUP BY machine_id;\n\nObservation: This query also scans large amounts of historical data, which will be incredibly slow without indexing or chunking.\nQuestion 3 - Comparing: Which machine has the most unstable vibration signal?\nDetecting high variance in a machine’s signal helps identify mechanical imbalance or failing sensors.\nBaseline query:\nSELECT\n  machine_id,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nWHERE time > now() - INTERVAL '7 days'\nGROUP BY machine_id;\n\nObservation: Without optimization, aggregation over billions of rows will be slow, making real-time anomaly detection impractical.\nBy defining these three queries first, we now have specific performance goals. Every optimization we introduce—hypertables, indexes, chunk interval tuning, continuous aggregates, and compression—can be measured against these queries using EXPLAIN ANALYZE.\nStep 1: Convert the Table to a Hypertable\nTimescaleDB’s hypertables partition your data by time and (optionally) by another key like machine_id. This allows the database to prune irrelevant chunks and execute queries in parallel across partitions.\nConvert the table to a hypertable:\nSELECT create_hypertable(\n  'vibration_readings',\n  'time',\n  'machine_id',\n  8\n);\n\nRunning the trend query from Question 1 now completes in about half the time as the query on the original table.\nInstead of scanning one huge table, TimescaleDB is scanning only the relevant chunks—reducing overall execution time.\nStep 2: Add a Composite Index for Faster Filters\nAfter converting the table to a hypertable, TimescaleDB can prune irrelevant chunks—but inside each chunk, PostgreSQL is still forced to scan rows sequentially.  With high-frequency telemetry, each chunk can contain millions of rows, so we need to improve how each chunk is accessed.\nOur queries consistently filter and group by time and machine_id, which makes a composite index a natural fit:\nCREATE INDEX ON vibration_readings (machine_id, time DESC);\nConsider the baseline query from Question 2. If we run the query after an EXPLAIN ANALYZE statement, then we’ll be able to see exactly how PostgreSQL is finding the data.\nEXPLAIN ANALYZE\nSELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE\n  time > now() - INTERVAL '7 days'\n  AND vibration_rms > 5.0\nGROUP BY machine_id;\n\nThe query plan now shows an index scan with an execution time of 265 milliseconds.\nThis index allows the database to quickly locate relevant rows for both time and machine_id filters without scanning the whole dataset—delivering faster queries and enabling predictable performance as data volume grows.\nStep 3: Tune Chunk Intervals for High-Frequency Data\nWith 10 samples per second, default chunk intervals (e.g. weekly) can lead to overly large chunks. A smaller, daily chunk interval often works better by reducing scan times:\nSELECT set_chunk_time_interval(\n  'vibration_readings',\n  INTERVAL '1 day'\n);\n\nRunning the rolling average query from Question 1 yields an execution time of 17,185 milliseconds, which is significantly shorter than even the query time on the hypertable (after Step 1).\nBy pruning more chunks during planning, TimescaleDB reduces both planning time and scan effort—an easy win for high-frequency data.\nStep 4: Continuous Aggregates for Feature Extraction\nCalculating hourly or daily summaries from raw data can still be expensive. Continuous aggregates let TimescaleDB incrementally materialize that summary ahead of time:\nCREATE MATERIALIZED VIEW vibration_hourly\nWITH (timescaledb.continuous) AS\nSELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nGROUP BY machine_id, hour;\n\nRun the query from Question 3 on this view:\nEXPLAIN ANALYZE\nSELECT\n  machine_id,\n  STDDEV(avg_vibration) AS vibration_instability\nFROM vibration_hourly\nWHERE hour > now() - INTERVAL '7 days'\nGROUP BY machine_id;\n\nCompared to the baseline query, our new query using continuous aggregates runs in just 1.4 milliseconds.\nThis gives you pre-aggregated features at lightning speed—essential for dashboards and ML workflows.\nStep 5: Compress Historical Vibration Data\nWhile raw recent data is useful for anomaly detection, older data can often be stored in compressed form without analytical access.\nCompressing vibration data by machine_id, and leaving the last 3 days uncompressed maximizes query performance for both recent and historical data:\nALTER TABLE vibration_readings\nSET (\n  timescaledb.compress,\n  timescaledb.compress_segmentby = 'machine_id'\n);\n\nSELECT add_compression_policy(\n  'vibration_readings',\n  INTERVAL '3 days'\n);\n\nRunning a query on historical vibration data still works:\nEXPLAIN ANALYZE\nSELECT\n  machine_id,\n  AVG(vibration_rms)\nFROM vibration_readings\nWHERE time BETWEEN now() - INTERVAL '90 days'\n             AND now() - INTERVAL '30 days'\nGROUP BY machine_id;\n\nBecause we used compression, our query runs in just 13 milliseconds.\nCompression is transparent to queries, meaning nothing changes from the query’s perspective. However, under-the-hood far less data is read from disk while keeping analytical access.\nOverall Optimization Results\nHere’s how database query performance improved as we applied each optimization:\n\nEvery optimization step, from indexing and chunking, to continuous aggregation and compression, delivers a significant performance win.\nConclusion\nIn this tutorial, we started by defining three real operational questions that a maintenance team may need to answer:\n\nIs vibration increasing over time for any machine?\nHow long did each machine operate above the alarm threshold this week?\nWhich machine has the most unstable vibration signal?\n\nThese questions set the stage for every optimization we applied. By converting the raw table into a hypertable, we enabled TimescaleDB to prune irrelevant chunks and scan only the data that mattered. Adding a composite index allowed queries to target individual machines and recent time ranges without scanning all rows. Tuning chunk intervals reduced planning and execution overhead for high-frequency data.  Continuous aggregates pre-computed summaries for rapid access to hourly and daily metrics, and compression reduced storage for historical data while keeping it accessible for analytics.\nThe result of these optimizations combined was a dramatic performance improvement across all queries. What initially took many seconds now runs in just a few milliseconds.  Hourly averages over a week for Question 1 dropped from over 67 seconds to 1.8 milliseconds. Alarm threshold duration queries for Question 2 dropped from over 5 seconds to 13 milliseconds. Historical aggregates over months for Question 3 dropped from over 15 seconds to just 1.4 milliseconds. While your query execution times may differ, you will see an undeniable benefit from these optimizations on your analytical query performance.\nTimescaleDB is built to handle high-volume, high-frequency machine telemetry efficiently, providing both immediate insights for operational alerts, and long-term, accessible history for predictive maintenance modeling.	This tutorial demonstrates optimizing TimescaleDB for manufacturing IoT workloads handling high-frequency sensor data. Using machine vibration telemetry as an example (50 machines, 10 samples/second, 6 months), it shows step-by-step performance improvements through five optimizations. Converting to hypertables enabled chunk pruning, reducing query time by half. Adding composite indexes on machine_id and time further accelerated filtering. Tuning chunk intervals to daily reduced scan overhead for high-frequency data. Continuous aggregates pre-computed hourly summaries, delivering millisecond query times. Compression reduced storage while maintaining analytical access. Combined optimizations transformed queries from taking 15+ seconds to under 2 milliseconds, demonstrating TimescaleDB's effectiveness for industrial IoT analytics.	本教程展示了如何为制造业IoT工作负载优化TimescaleDB以处理高频传感器数据。以机器振动遥测数据为例（50台机器，每秒10个样本，6个月），逐步展示了通过五项优化实现的性能改进。转换为hypertable实现了chunk修剪，查询时间减少一半。在machine_id和时间上添加复合索引进一步加速了过滤。将chunk间隔调整为每日减少了高频数据的扫描开销。连续聚合预计算小时摘要，实现毫秒级查询时间。压缩减少了存储空间同时保持分析访问能力。综合优化将查询时间从15秒以上缩短到2毫秒以下，展示了TimescaleDB在工业IoT分析方面的有效性。
33	TimescaleDB for Manufacturing IoT: Optimizing for High-Volume Production Data	https://www.tigerdata.com/blog/timescaledb-for-manufacturing-iot-optimizing-for-high-volume-production-data	NanoHertz Solutions - Jake Hertz	2026-01-28 13:07:24+00	<p>In industrial environments with hundreds of machines streaming sensor signals every second, optimizing your database for analytics is critical. In a follow-up to our initial tutorial on building a data pipeline, we’ll take you step-by-step from slow, unoptimized queries to highly performant analytical queries using TimescaleDB’s advanced features.</p><p>We’ll use the example of high-frequency machine vibration telemetry to show you how to tune TimescaleDB to improve query performance, measured using EXPLAIN ANALYZE. We will be using the same service we created in the <a href="https://www.tigerdata.com/blog/timescaledb-manufacturing-iot-building-data-pipeline"><u>previous tutorial</u></a>, which has a compute size of 8 CPU / 32 GiB Memory and is hosted in AWS US East (Ohio).&nbsp; All the performance metrics you will see in this tutorial are specific to this service instance and data set, so your results may differ.</p><h2 id="example-machine-vibration-telemetry">Example: Machine Vibration Telemetry</h2><p>Imagine you’re collecting <strong>vibration data</strong> from <strong>50 rotating machines</strong> at <strong>10 samples per second</strong>, 24/7 for <strong>6 months</strong>.&nbsp; With this volume, the raw table quickly grows into billions of rows—a perfect example of workloads that reward <a href="https://www.tigerdata.com/timescaledb"><u>TimescaleDB</u></a> optimizations.</p><p>Our initial table schema looks like this:</p><pre><code class="language-SQL">CREATE TABLE vibration_readings (\n  time TIMESTAMPTZ NOT NULL,\n  machine_id TEXT NOT NULL,\n  vibration_rms DOUBLE PRECISION NOT NULL\n);\n</code></pre><p>For this tutorial, we will generate randomized data:</p><pre><code class="language-SQL">INSERT INTO vibration_readings (time, machine_id, vibration_rms)\nSELECT\n  t.ts,\n  m.machine_id,\n  2.5\n  + 0.5 * sin(extract(epoch from t.ts) / 3600)\n  + 0.3 * random()                    \n  + (m.machine_id * 0.005)\nFROM generate_series(\n       now() - INTERVAL '180 days',\n       now(),\n       INTERVAL '100 milliseconds'\n     ) AS t(ts)\nCROSS JOIN generate_series(1,50) AS m(machine_id);\n</code></pre><p>At this stage, queries against this table are correct, but slow and non-scalable.</p><h2 id="real-operational-questions">Real Operational Questions</h2><p>Before we optimize, it’s important to define a few operational questions that your maintenance team may need to answer. These questions will drive how we tune TimescaleDB features.</p><p>Here are a few key questions for our machine vibration telemetry example:</p><h3 id="question-1trending-is-vibration-increasing-over-time-for-any-machine">Question 1 - Trending: Is vibration increasing over time for any machine?</h3><p>We want to monitor trend changes that could indicate bearing wear or other mechanical degradation.</p><p>Baseline query:</p><pre><code class="language-SQL">SELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration\nFROM vibration_readings\nWHERE time &gt; now() - INTERVAL '7 days'\nGROUP BY machine_id, hour;\n</code></pre><p><em>Observation:</em> On the unoptimized table, this query will do a sequential scan of billions of rows, which is slow and inefficient.</p><h3 id="question-2monitoring-how-long-did-each-machine-operate-above-the-alarm-threshold-this-week">Question 2 - Monitoring: How long did each machine operate above the alarm threshold this week?</h3><p>Maintenance teams often need to know how much time each machine spent above a critical vibration threshold, which drives alerts and prioritization.</p><p>Baseline query:</p><pre><code class="language-SQL">SELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE time &gt; now() - INTERVAL '7 days'\n  AND vibration_rms &gt; 5.0\nGROUP BY machine_id;\n</code></pre><p><em>Observation:</em> This query also scans large amounts of historical data, which will be incredibly slow without indexing or chunking.</p><h3 id="question-3comparing-which-machine-has-the-most-unstable-vibration-signal">Question 3 - Comparing: Which machine has the most unstable vibration signal?</h3><p>Detecting high variance in a machine’s signal helps identify mechanical imbalance or failing sensors.</p><p>Baseline query:</p><pre><code class="language-SQL">SELECT\n  machine_id,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nWHERE time &gt; now() - INTERVAL '7 days'\nGROUP BY machine_id;\n</code></pre><p><em>Observation:</em> Without optimization, aggregation over billions of rows will be slow, making real-time anomaly detection impractical.</p><p>By defining these three queries first, we now have specific performance goals. Every optimization we introduce—hypertables, indexes, chunk interval tuning, continuous aggregates, and compression—can be measured against these queries using EXPLAIN ANALYZE.</p><h2 id="step-1-convert-the-table-to-a-hypertable">Step 1: Convert the Table to a Hypertable</h2><p>TimescaleDB’s hypertables partition your data by time and (optionally) by another key like machine_id. This allows the database to prune irrelevant chunks and execute queries in parallel across partitions.</p><p>Convert the table to a hypertable:</p><pre><code class="language-SQL">SELECT create_hypertable(\n  'vibration_readings',\n  'time',\n  'machine_id',\n  8\n);\n</code></pre><p>Running the trend query from Question 1 now completes in about half the time as the query on the original table.</p><p>Instead of scanning one huge table, TimescaleDB is scanning only the relevant chunks—reducing overall execution time.</p><h2 id="step-2-add-a-composite-index-for-faster-filters">Step 2: Add a Composite Index for Faster Filters</h2><p>After converting the table to a hypertable, TimescaleDB can prune irrelevant chunks—but inside each chunk, PostgreSQL is still forced to scan rows sequentially.&nbsp; With high-frequency telemetry, each chunk can contain millions of rows, so we need to improve how each chunk is accessed.</p><p>Our queries consistently filter and group by time and machine_id, which makes a composite index a natural fit:</p><pre><code class="language-SQL">CREATE INDEX ON vibration_readings (machine_id, time DESC);</code></pre><p>Consider the baseline query from Question 2. If we run the query after an EXPLAIN ANALYZE statement, then we’ll be able to see exactly how PostgreSQL is finding the data.</p><pre><code class="language-SQL">EXPLAIN ANALYZE\nSELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE\n  time &gt; now() - INTERVAL '7 days'\n  AND vibration_rms &gt; 5.0\nGROUP BY machine_id;\n</code></pre><p>The query plan now shows an <strong>index scan</strong> with an execution time of 265 milliseconds.</p><p>This index allows the database to quickly locate relevant rows for both time and machine_id filters without scanning the whole dataset—delivering faster queries and enabling predictable performance as data volume grows.</p><h2 id="step-3-tune-chunk-intervals-for-high-frequency-data">Step 3: Tune Chunk Intervals for High-Frequency Data</h2><p>With 10 samples per second, default chunk intervals (e.g. weekly) can lead to overly large chunks. A smaller, daily chunk interval often works better by reducing scan times:</p><pre><code class="language-SQL">SELECT set_chunk_time_interval(\n  'vibration_readings',\n  INTERVAL '1 day'\n);\n</code></pre><p>Running the rolling average query from Question 1 yields an execution time of 17,185 milliseconds, which is significantly shorter than even the query time on the hypertable (after Step 1).</p><p>By pruning more chunks during planning, TimescaleDB reduces both planning time and scan effort—an easy win for high-frequency data.</p><h2 id="step-4-continuous-aggregates-for-feature-extraction">Step 4: Continuous Aggregates for Feature Extraction</h2><p>Calculating hourly or daily summaries from raw data can still be expensive. Continuous aggregates let TimescaleDB incrementally materialize that summary ahead of time:</p><pre><code class="language-SQL">CREATE MATERIALIZED VIEW vibration_hourly\nWITH (timescaledb.continuous) AS\nSELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nGROUP BY machine_id, hour;\n</code></pre><p>Run the query from Question 3 on this view:</p><pre><code class="language-SQL">EXPLAIN ANALYZE\nSELECT\n  machine_id,\n  STDDEV(avg_vibration) AS vibration_instability\nFROM vibration_hourly\nWHERE hour &gt; now() - INTERVAL '7 days'\nGROUP BY machine_id;\n</code></pre><p>Compared to the baseline query, our new query using continuous aggregates runs in just 1.4 milliseconds.</p><p>This gives you pre-aggregated features at lightning speed—essential for dashboards and ML workflows.</p><h2 id="step-5-compress-historical-vibration-data">Step 5: Compress Historical Vibration Data</h2><p>While raw recent data is useful for anomaly detection, older data can often be stored in compressed form without analytical access.</p><p>Compressing vibration data by machine_id, and leaving the last 3 days uncompressed maximizes query performance for both recent and historical data:</p><pre><code class="language-SQL">ALTER TABLE vibration_readings\nSET (\n  timescaledb.compress,\n  timescaledb.compress_segmentby = 'machine_id'\n);\n\nSELECT add_compression_policy(\n  'vibration_readings',\n  INTERVAL '3 days'\n);\n</code></pre><p>Running a query on historical vibration data still works:</p><pre><code class="language-SQL">EXPLAIN ANALYZE\nSELECT\n  machine_id,\n  AVG(vibration_rms)\nFROM vibration_readings\nWHERE time BETWEEN now() - INTERVAL '90 days'\n             AND now() - INTERVAL '30 days'\nGROUP BY machine_id;\n</code></pre><p>Because we used compression, our query runs in just 13 milliseconds.</p><p>Compression is transparent to queries, meaning nothing changes from the query’s perspective. However, under-the-hood far less data is read from disk while keeping analytical access.</p><h2 id="overall-optimization-results">Overall Optimization Results</h2><p>Here’s how database query performance improved as we applied each optimization:</p><figure class="kg-card kg-image-card"><img src="https://timescale.ghost.io/blog/content/images/2026/01/diagram-3.png" class="kg-image" alt="" loading="lazy" width="2000" height="1762" srcset="https://timescale.ghost.io/blog/content/images/size/w600/2026/01/diagram-3.png 600w, https://timescale.ghost.io/blog/content/images/size/w1000/2026/01/diagram-3.png 1000w, https://timescale.ghost.io/blog/content/images/size/w1600/2026/01/diagram-3.png 1600w, https://timescale.ghost.io/blog/content/images/2026/01/diagram-3.png 2150w" sizes="(min-width: 720px) 720px"></figure><p>Every optimization step, from indexing and chunking, to continuous aggregation and compression, delivers a significant performance win.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we started by defining three real operational questions that a maintenance team may need to answer:</p><ol><li>Is vibration increasing over time for any machine?</li><li>How long did each machine operate above the alarm threshold this week?</li><li>Which machine has the most unstable vibration signal?</li></ol><p>These questions set the stage for every optimization we applied. By converting the raw table into a <strong>hypertable</strong>, we enabled TimescaleDB to prune irrelevant chunks and scan only the data that mattered. Adding a <strong>composite index </strong>allowed queries to target individual machines and recent time ranges without scanning all rows. Tuning <strong>chunk intervals</strong> reduced planning and execution overhead for high-frequency data.&nbsp; <strong>Continuous aggregates</strong> pre-computed summaries for rapid access to hourly and daily metrics, and <strong>compression</strong> reduced storage for historical data while keeping it accessible for analytics.</p><p>The result of these optimizations combined was a dramatic performance improvement across all queries. What initially took many seconds now runs in just a few milliseconds.&nbsp; Hourly averages over a week for Question 1 dropped from over 67 seconds to 1.8 milliseconds. Alarm threshold duration queries for Question 2 dropped from over 5 seconds to 13 milliseconds. Historical aggregates over months for Question 3 dropped from over 15 seconds to just 1.4 milliseconds. While your query execution times may differ, you will see an undeniable benefit from these optimizations on your analytical query performance.</p><p>TimescaleDB is built to handle high-volume, high-frequency machine telemetry efficiently, providing both immediate insights for operational alerts, and long-term, accessible history for predictive maintenance modeling.&nbsp;</p>	In industrial environments with hundreds of machines streaming sensor signals every second, optimizing your database for analytics is critical. In a follow-up to our initial tutorial on building a data pipeline, we’ll take you step-by-step from slow, unoptimized queries to highly performant analytical queries using TimescaleDB’s advanced features.\nWe’ll use the example of high-frequency machine vibration telemetry to show you how to tune TimescaleDB to improve query performance, measured using EXPLAIN ANALYZE. We will be using the same service we created in the previous tutorial, which has a compute size of 8 CPU / 32 GiB Memory and is hosted in AWS US East (Ohio).  All the performance metrics you will see in this tutorial are specific to this service instance and data set, so your results may differ.\nExample: Machine Vibration Telemetry\nImagine you’re collecting vibration data from 50 rotating machines at 10 samples per second, 24/7 for 6 months.  With this volume, the raw table quickly grows into billions of rows—a perfect example of workloads that reward TimescaleDB optimizations.\nOur initial table schema looks like this:\nCREATE TABLE vibration_readings (\n  time TIMESTAMPTZ NOT NULL,\n  machine_id TEXT NOT NULL,\n  vibration_rms DOUBLE PRECISION NOT NULL\n);\n\nFor this tutorial, we will generate randomized data:\nINSERT INTO vibration_readings (time, machine_id, vibration_rms)\nSELECT\n  t.ts,\n  m.machine_id,\n  2.5\n  + 0.5 * sin(extract(epoch from t.ts) / 3600)\n  + 0.3 * random()                    \n  + (m.machine_id * 0.005)\nFROM generate_series(\n       now() - INTERVAL '180 days',\n       now(),\n       INTERVAL '100 milliseconds'\n     ) AS t(ts)\nCROSS JOIN generate_series(1,50) AS m(machine_id);\n\nAt this stage, queries against this table are correct, but slow and non-scalable.\nReal Operational Questions\nBefore we optimize, it’s important to define a few operational questions that your maintenance team may need to answer. These questions will drive how we tune TimescaleDB features.\nHere are a few key questions for our machine vibration telemetry example:\nQuestion 1 - Trending: Is vibration increasing over time for any machine?\nWe want to monitor trend changes that could indicate bearing wear or other mechanical degradation.\nBaseline query:\nSELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration\nFROM vibration_readings\nWHERE time > now() - INTERVAL '7 days'\nGROUP BY machine_id, hour;\n\nObservation: On the unoptimized table, this query will do a sequential scan of billions of rows, which is slow and inefficient.\nQuestion 2 - Monitoring: How long did each machine operate above the alarm threshold this week?\nMaintenance teams often need to know how much time each machine spent above a critical vibration threshold, which drives alerts and prioritization.\nBaseline query:\nSELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE time > now() - INTERVAL '7 days'\n  AND vibration_rms > 5.0\nGROUP BY machine_id;\n\nObservation: This query also scans large amounts of historical data, which will be incredibly slow without indexing or chunking.\nQuestion 3 - Comparing: Which machine has the most unstable vibration signal?\nDetecting high variance in a machine’s signal helps identify mechanical imbalance or failing sensors.\nBaseline query:\nSELECT\n  machine_id,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nWHERE time > now() - INTERVAL '7 days'\nGROUP BY machine_id;\n\nObservation: Without optimization, aggregation over billions of rows will be slow, making real-time anomaly detection impractical.\nBy defining these three queries first, we now have specific performance goals. Every optimization we introduce—hypertables, indexes, chunk interval tuning, continuous aggregates, and compression—can be measured against these queries using EXPLAIN ANALYZE.\nStep 1: Convert the Table to a Hypertable\nTimescaleDB’s hypertables partition your data by time and (optionally) by another key like machine_id. This allows the database to prune irrelevant chunks and execute queries in parallel across partitions.\nConvert the table to a hypertable:\nSELECT create_hypertable(\n  'vibration_readings',\n  'time',\n  'machine_id',\n  8\n);\n\nRunning the trend query from Question 1 now completes in about half the time as the query on the original table.\nInstead of scanning one huge table, TimescaleDB is scanning only the relevant chunks—reducing overall execution time.\nStep 2: Add a Composite Index for Faster Filters\nAfter converting the table to a hypertable, TimescaleDB can prune irrelevant chunks—but inside each chunk, PostgreSQL is still forced to scan rows sequentially.  With high-frequency telemetry, each chunk can contain millions of rows, so we need to improve how each chunk is accessed.\nOur queries consistently filter and group by time and machine_id, which makes a composite index a natural fit:\nCREATE INDEX ON vibration_readings (machine_id, time DESC);\nConsider the baseline query from Question 2. If we run the query after an EXPLAIN ANALYZE statement, then we’ll be able to see exactly how PostgreSQL is finding the data.\nEXPLAIN ANALYZE\nSELECT\n  machine_id,\n  COUNT(*) * 0.1 AS seconds_above_threshold\nFROM vibration_readings\nWHERE\n  time > now() - INTERVAL '7 days'\n  AND vibration_rms > 5.0\nGROUP BY machine_id;\n\nThe query plan now shows an index scan with an execution time of 265 milliseconds.\nThis index allows the database to quickly locate relevant rows for both time and machine_id filters without scanning the whole dataset—delivering faster queries and enabling predictable performance as data volume grows.\nStep 3: Tune Chunk Intervals for High-Frequency Data\nWith 10 samples per second, default chunk intervals (e.g. weekly) can lead to overly large chunks. A smaller, daily chunk interval often works better by reducing scan times:\nSELECT set_chunk_time_interval(\n  'vibration_readings',\n  INTERVAL '1 day'\n);\n\nRunning the rolling average query from Question 1 yields an execution time of 17,185 milliseconds, which is significantly shorter than even the query time on the hypertable (after Step 1).\nBy pruning more chunks during planning, TimescaleDB reduces both planning time and scan effort—an easy win for high-frequency data.\nStep 4: Continuous Aggregates for Feature Extraction\nCalculating hourly or daily summaries from raw data can still be expensive. Continuous aggregates let TimescaleDB incrementally materialize that summary ahead of time:\nCREATE MATERIALIZED VIEW vibration_hourly\nWITH (timescaledb.continuous) AS\nSELECT\n  machine_id,\n  time_bucket('1 hour', time) AS hour,\n  AVG(vibration_rms) AS avg_vibration,\n  STDDEV(vibration_rms) AS vibration_stddev\nFROM vibration_readings\nGROUP BY machine_id, hour;\n\nRun the query from Question 3 on this view:\nEXPLAIN ANALYZE\nSELECT\n  machine_id,\n  STDDEV(avg_vibration) AS vibration_instability\nFROM vibration_hourly\nWHERE hour > now() - INTERVAL '7 days'\nGROUP BY machine_id;\n\nCompared to the baseline query, our new query using continuous aggregates runs in just 1.4 milliseconds.\nThis gives you pre-aggregated features at lightning speed—essential for dashboards and ML workflows.\nStep 5: Compress Historical Vibration Data\nWhile raw recent data is useful for anomaly detection, older data can often be stored in compressed form without analytical access.\nCompressing vibration data by machine_id, and leaving the last 3 days uncompressed maximizes query performance for both recent and historical data:\nALTER TABLE vibration_readings\nSET (\n  timescaledb.compress,\n  timescaledb.compress_segmentby = 'machine_id'\n);\n\nSELECT add_compression_policy(\n  'vibration_readings',\n  INTERVAL '3 days'\n);\n\nRunning a query on historical vibration data still works:\nEXPLAIN ANALYZE\nSELECT\n  machine_id,\n  AVG(vibration_rms)\nFROM vibration_readings\nWHERE time BETWEEN now() - INTERVAL '90 days'\n             AND now() - INTERVAL '30 days'\nGROUP BY machine_id;\n\nBecause we used compression, our query runs in just 13 milliseconds.\nCompression is transparent to queries, meaning nothing changes from the query’s perspective. However, under-the-hood far less data is read from disk while keeping analytical access.\nOverall Optimization Results\nHere’s how database query performance improved as we applied each optimization:\n\nEvery optimization step, from indexing and chunking, to continuous aggregation and compression, delivers a significant performance win.\nConclusion\nIn this tutorial, we started by defining three real operational questions that a maintenance team may need to answer:\n\nIs vibration increasing over time for any machine?\nHow long did each machine operate above the alarm threshold this week?\nWhich machine has the most unstable vibration signal?\n\nThese questions set the stage for every optimization we applied. By converting the raw table into a hypertable, we enabled TimescaleDB to prune irrelevant chunks and scan only the data that mattered. Adding a composite index allowed queries to target individual machines and recent time ranges without scanning all rows. Tuning chunk intervals reduced planning and execution overhead for high-frequency data.  Continuous aggregates pre-computed summaries for rapid access to hourly and daily metrics, and compression reduced storage for historical data while keeping it accessible for analytics.\nThe result of these optimizations combined was a dramatic performance improvement across all queries. What initially took many seconds now runs in just a few milliseconds.  Hourly averages over a week for Question 1 dropped from over 67 seconds to 1.8 milliseconds. Alarm threshold duration queries for Question 2 dropped from over 5 seconds to 13 milliseconds. Historical aggregates over months for Question 3 dropped from over 15 seconds to just 1.4 milliseconds. While your query execution times may differ, you will see an undeniable benefit from these optimizations on your analytical query performance.\nTimescaleDB is built to handle high-volume, high-frequency machine telemetry efficiently, providing both immediate insights for operational alerts, and long-term, accessible history for predictive maintenance modeling.	This tutorial demonstrates optimizing TimescaleDB for manufacturing IoT data handling high-volume machine telemetry. Using vibration sensor data from 50 machines sampled 10 times per second over 6 months, the author shows step-by-step performance improvements. Starting with an unoptimized table causing slow sequential scans, optimizations include converting to hypertables for time-based partitioning, adding composite indexes for faster filtering, tuning chunk intervals for high-frequency data, implementing continuous aggregates for pre-computed summaries, and applying compression for historical data. Results show dramatic performance gains: queries dropping from 67+ seconds to milliseconds. The approach targets three operational questions about vibration trending, alarm threshold monitoring, and signal stability analysis, demonstrating how TimescaleDB's features enable both real-time operational alerts and long-term predictive maintenance analytics.	本教程演示了如何为制造业IoT优化TimescaleDB，处理大容量机器遥测数据。使用来自50台机器的振动传感器数据，每秒采样10次，持续6个月，作者展示了逐步的性能改进过程。从导致慢速顺序扫描的未优化表开始，优化措施包括转换为hypertable以实现基于时间的分区、添加复合索引以加快过滤速度、调整chunk间隔以适应高频数据、实现连续聚合以预计算摘要，以及对历史数据应用压缩。结果显示了显著的性能提升：查询时间从67秒以上降至毫秒级。该方法针对振动趋势、报警阈值监控和信号稳定性分析三个操作问题，展示了TimescaleDB的功能如何同时实现实时操作警报和长期预测性维护分析。
33	Databases, Data Lakes, And Encryption	https://www.percona.com/blog/databases-data-lakes-and-encryption/	Robert Bernier	2026-01-28 16:15:52+00	\N	\N	Object storage has evolved from handling infrequently accessed data to becoming the dominant archival medium for unstructured content. This blog post by Robert Bernier explores the relationship between databases, data lakes, and encryption in the context of modern data storage architectures. The discussion covers how object storage systems have transformed data management practices and the encryption considerations that come with storing database content and data lake information in object storage environments.	对象存储已从处理不经常访问的数据发展为非结构化内容的主要存档介质。Robert Bernier在这篇博客文章中探讨了数据库、数据湖和加密在现代数据存储架构中的关系。讨论涵盖了对象存储系统如何改变数据管理实践，以及在对象存储环境中存储数据库内容和数据湖信息时的加密考虑因素。
\.


--
-- PostgreSQL database dump complete
--

\unrestrict 7SkCvt6571C87csrsH9l4YiqotyEp3q2fzP3Cgb159WbnSc3LQNJbb4oVHRAt2O

